{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "pd.set_option(\n",
    "    'display.precision', 2,\n",
    "    'display.max_colwidth', 200\n",
    ")\n",
    "from collections import namedtuple\n",
    "from tqdm.notebook import tqdm\n",
    "from deepeval.metrics import (\n",
    "    ContextualPrecisionMetric,\n",
    "    FaithfulnessMetric,\n",
    "    ContextualRecallMetric,\n",
    "    AnswerRelevancyMetric,\n",
    ")\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.evaluate import evaluate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T02:09:27.952066Z",
     "start_time": "2024-04-09T02:09:25.999115Z"
    }
   },
   "id": "77b59ab9e55e055",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T02:09:27.964942Z",
     "start_time": "2024-04-09T02:09:27.956008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_evaluations(qa_set_df, metrics, nrows=5):\n",
    "    \"\"\"\n",
    "    Run the measurement of contextual_precision, contextual_recall,\n",
    "    answer_relevancy, and faithfulness metrics implemented by\n",
    "    DeepEval. \n",
    "    :param qa_set_df: A dataframe containing the Q/A pairs,\n",
    "    ground truth and context required by DeepEval to run a\n",
    "    test case. \n",
    "    :param metrics: A list of metrics to execute on each test case.\n",
    "    :param nrows: Number of the first n rows to be extracted from\n",
    "    the qa_set_df to run the test cases.\n",
    "    :return: The results from deepeval.evaluate.\n",
    "    \"\"\"\n",
    "    \n",
    "    test_cases =[]\n",
    "    for _, row in qa_set_df.head(nrows).iterrows():  \n",
    "        test_case = LLMTestCase(\n",
    "            input=row['query'],\n",
    "            actual_output=row['answer'],\n",
    "            expected_output=row['ground_truth'],\n",
    "            retrieval_context=[row['contexts']],\n",
    "        )\n",
    "        test_cases.append(test_case)\n",
    "    \n",
    "    return evaluate(\n",
    "        test_cases=test_cases,\n",
    "        metrics=metrics,\n",
    "        show_indicator=False,\n",
    "        print_results=False,\n",
    "    )"
   ],
   "id": "e4156965b3878c15",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T02:09:27.977865Z",
     "start_time": "2024-04-09T02:09:27.967798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def deepeval_on_test_sets(test_sets, metrics, nrows=5):\n",
    "    \"\"\"\n",
    "    Runs DeepEval on each element of test_sets and returns a named tuple containing\n",
    "    the name of the RAG pipeline and a Pandas dataframe containing the scores \n",
    "    from each DeepEval metric.\n",
    "    :param test_sets: The list of test sets containing the Q/A pairs, ground truth and\n",
    "    context of a RAG pipeline.\n",
    "    :param metrics: A list of metrics to execute on each test case.\n",
    "    :param nrows: Number of rows of the test set to be used by DeepEval to evaluate a\n",
    "    RAG pipeline.\n",
    "    :return: A list named tuples containing the DeepEval scores for each test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Try opening all test sets, if one does not exist, rise an exception\n",
    "    for file in test_sets:\n",
    "        f = open(file)\n",
    "        f.close()\n",
    "\n",
    "    ModelEval = namedtuple(\"ModelEval\",\n",
    "                           \"modelmix results\")\n",
    "    model_evals = []\n",
    "    \n",
    "    for tset in tqdm(test_sets):\n",
    "        model_mix = tset.split('/')[-1].split('.')[0]\n",
    "        print(f\"Evaluating {model_mix}\")\n",
    "        qa_set_df = pd.read_csv(\n",
    "            filepath_or_buffer=tset,\n",
    "        )\n",
    "        results = run_evaluations(\n",
    "            qa_set_df,\n",
    "            metrics,\n",
    "            nrows=nrows)\n",
    "        \n",
    "        model_evals.append(\n",
    "            ModelEval(\n",
    "                model_mix,\n",
    "                results\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return model_evals"
   ],
   "id": "72a301009d992a5b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T02:09:27.990441Z",
     "start_time": "2024-04-09T02:09:27.981526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def deepeval_to_dict(evals):\n",
    "    \"\"\"\n",
    "    Converts a list of DeepEval results into a dictionary that can be used to\n",
    "    create Pandas dataframes.\n",
    "    :param evals: A list with DeepEval results from 'eval'\n",
    "    :return: A dictionary with the dataset name as key and the DeepEval results as value\n",
    "    \"\"\"\n",
    "    res_summary = {}\n",
    "    for dset in evals:\n",
    "        res_summary[dset.modelmix] = {}\n",
    "        metrics = dset.results[0].metrics\n",
    "        for metric in metrics:\n",
    "            res_summary[dset.modelmix][f\"{metric.__name__} Score\"] = []\n",
    "            res_summary[dset.modelmix][f\"{metric.__name__} Reason\"] = []\n",
    "        for result in dset.results:\n",
    "            for metric in result.metrics:\n",
    "                res_summary[dset.modelmix] \\\n",
    "                    [f\"{metric.__name__} Score\"].append(metric.score)\n",
    "                res_summary[dset.modelmix]\\\n",
    "                    [f\"{metric.__name__} Reason\"].append(metric.reason)\n",
    "    return res_summary        \n",
    "    "
   ],
   "id": "d91e48b47d0fbbe3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T02:09:28.377287Z",
     "start_time": "2024-04-09T02:09:27.992065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# File paths for the inference results from each RAG variant\n",
    "# on the same Q/A pairs evaluation dataset.\n",
    "PATH_BASE = \"../../04-RAG_Variants\"\n",
    "SIMPLE_RAG_PATH = (f\"{PATH_BASE}/01-Simple_Retrieval/\"\n",
    "                   f\"Standard_RAG_zephyr-7b-alpha_bge-base-en-v1.5.csv\")\n",
    "SENTENCE_WINDOW_RAG_PATH = (f\"{PATH_BASE}/02-Sentence_Window_Retrieval/\"\n",
    "                            \"Sentence_Window_RAG_zephyr-7b-alpha_bge-base-en-v1.5.csv\")\n",
    "AUTO_MERGE_RAG_PATH = (f\"{PATH_BASE}/03-Auto_Merging_Retrieval/\"\n",
    "                       \"Auto_Merging_RAG_zephyr-7b-alpha_bge-base-en-v1.5.csv\")\n",
    "test_sets = [\n",
    "    SIMPLE_RAG_PATH,\n",
    "    SENTENCE_WINDOW_RAG_PATH,\n",
    "    AUTO_MERGE_RAG_PATH\n",
    "]\n",
    "\n",
    "# OpenAI LLM to get used as evaluator\n",
    "JUDGE_LLM = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "# DeepEval evaluation parameters\n",
    "DECISION_THRESHOLD = 0.5\n",
    "NUM_EVAL_SAMPLES = 30\n",
    "eval_parameters = {\n",
    "    \"threshold\": DECISION_THRESHOLD,\n",
    "    \"model\": JUDGE_LLM,\n",
    "}\n",
    "\n",
    "# DeepEval list of metrics to get applied on each\n",
    "# test case.\n",
    "metrics = [\n",
    "    ContextualPrecisionMetric(**eval_parameters),\n",
    "    ContextualRecallMetric(**eval_parameters),\n",
    "    AnswerRelevancyMetric(**eval_parameters),\n",
    "    FaithfulnessMetric(**eval_parameters), \n",
    "]"
   ],
   "id": "c7c10fa453614b7b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T02:23:12.410560Z",
     "start_time": "2024-04-09T02:09:28.379740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Execute DeepEval evaluations on test cases\n",
    "evals = deepeval_on_test_sets(\n",
    "    test_sets,\n",
    "    metrics,\n",
    "    NUM_EVAL_SAMPLES)"
   ],
   "id": "f25e79b8a27d2536",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73e84dafefc143ea821ee21563917ca2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Standard_RAG_zephyr-7b-alpha_bge-base-en-v1\n",
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "✅ Tests finished! Run \u001B[32m\"deepeval login\"\u001B[0m to view evaluation results on the web.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Sentence_Window_RAG_zephyr-7b-alpha_bge-base-en-v1\n",
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "✅ Tests finished! Run \u001B[32m\"deepeval login\"\u001B[0m to view evaluation results on the web.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Auto_Merging_RAG_zephyr-7b-alpha_bge-base-en-v1\n",
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "✅ Tests finished! Run \u001B[32m\"deepeval login\"\u001B[0m to view evaluation results on the web.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Display DeepEval summarized results\n",
    "\n",
    "- Notice __there is no absolute winner RAG approach__. Further tweaking is required to get a configuration\n",
    "that maximizes the metric(s) of interest.\n",
    "- It might be (too) hard to make a single RAG approach get\n",
    "the highest scores all across the board.  "
   ],
   "id": "795018c72d3b6806"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T02:23:12.455369Z",
     "start_time": "2024-04-09T02:23:12.412601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the evaluation results. \n",
    "# Use a summarized view of the results to facilitate the comparison\n",
    "print(\"DeepEval Results\")\n",
    "summary = deepeval_to_dict(evals)\n",
    "labels = [modelmix for modelmix in summary.keys()]\n",
    "dframes = [pd.DataFrame.from_dict(summary[label]).describe(percentiles=[]) for label in labels]\n",
    "results_df = pd.concat(dframes, keys=labels)\n",
    "display(results_df)"
   ],
   "id": "f04172b28382425e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepEval Results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                          Contextual Precision Score  \\\n",
       "Standard_RAG_zephyr-7b-alpha_bge-base-en-v1        count                       30.00   \n",
       "                                                   mean                         0.76   \n",
       "                                                   std                          0.42   \n",
       "                                                   min                          0.00   \n",
       "                                                   50%                          1.00   \n",
       "                                                   max                          1.00   \n",
       "Sentence_Window_RAG_zephyr-7b-alpha_bge-base-en-v1 count                       30.00   \n",
       "                                                   mean                         0.88   \n",
       "                                                   std                          0.30   \n",
       "                                                   min                          0.00   \n",
       "                                                   50%                          1.00   \n",
       "                                                   max                          1.00   \n",
       "Auto_Merging_RAG_zephyr-7b-alpha_bge-base-en-v1    count                       30.00   \n",
       "                                                   mean                         0.67   \n",
       "                                                   std                          0.46   \n",
       "                                                   min                          0.00   \n",
       "                                                   50%                          1.00   \n",
       "                                                   max                          1.00   \n",
       "\n",
       "                                                          Contextual Recall Score  \\\n",
       "Standard_RAG_zephyr-7b-alpha_bge-base-en-v1        count                    30.00   \n",
       "                                                   mean                      0.80   \n",
       "                                                   std                       0.33   \n",
       "                                                   min                       0.00   \n",
       "                                                   50%                       1.00   \n",
       "                                                   max                       1.00   \n",
       "Sentence_Window_RAG_zephyr-7b-alpha_bge-base-en-v1 count                    30.00   \n",
       "                                                   mean                      0.68   \n",
       "                                                   std                       0.38   \n",
       "                                                   min                       0.00   \n",
       "                                                   50%                       0.80   \n",
       "                                                   max                       1.00   \n",
       "Auto_Merging_RAG_zephyr-7b-alpha_bge-base-en-v1    count                    30.00   \n",
       "                                                   mean                      0.74   \n",
       "                                                   std                       0.32   \n",
       "                                                   min                       0.00   \n",
       "                                                   50%                       0.92   \n",
       "                                                   max                       1.00   \n",
       "\n",
       "                                                          Answer Relevancy Score  \\\n",
       "Standard_RAG_zephyr-7b-alpha_bge-base-en-v1        count                   30.00   \n",
       "                                                   mean                     0.76   \n",
       "                                                   std                      0.26   \n",
       "                                                   min                      0.11   \n",
       "                                                   50%                      0.83   \n",
       "                                                   max                      1.00   \n",
       "Sentence_Window_RAG_zephyr-7b-alpha_bge-base-en-v1 count                   30.00   \n",
       "                                                   mean                     0.90   \n",
       "                                                   std                      0.19   \n",
       "                                                   min                      0.33   \n",
       "                                                   50%                      1.00   \n",
       "                                                   max                      1.00   \n",
       "Auto_Merging_RAG_zephyr-7b-alpha_bge-base-en-v1    count                   30.00   \n",
       "                                                   mean                     0.93   \n",
       "                                                   std                      0.15   \n",
       "                                                   min                      0.33   \n",
       "                                                   50%                      1.00   \n",
       "                                                   max                      1.00   \n",
       "\n",
       "                                                          Faithfulness Score  \n",
       "Standard_RAG_zephyr-7b-alpha_bge-base-en-v1        count               30.00  \n",
       "                                                   mean                 0.67  \n",
       "                                                   std                  0.26  \n",
       "                                                   min                  0.00  \n",
       "                                                   50%                  0.72  \n",
       "                                                   max                  1.00  \n",
       "Sentence_Window_RAG_zephyr-7b-alpha_bge-base-en-v1 count               30.00  \n",
       "                                                   mean                 0.68  \n",
       "                                                   std                  0.31  \n",
       "                                                   min                  0.00  \n",
       "                                                   50%                  0.73  \n",
       "                                                   max                  1.00  \n",
       "Auto_Merging_RAG_zephyr-7b-alpha_bge-base-en-v1    count               30.00  \n",
       "                                                   mean                 0.77  \n",
       "                                                   std                  0.21  \n",
       "                                                   min                  0.33  \n",
       "                                                   50%                  0.79  \n",
       "                                                   max                  1.00  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Contextual Precision Score</th>\n",
       "      <th>Contextual Recall Score</th>\n",
       "      <th>Answer Relevancy Score</th>\n",
       "      <th>Faithfulness Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Standard_RAG_zephyr-7b-alpha_bge-base-en-v1</th>\n",
       "      <th>count</th>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Sentence_Window_RAG_zephyr-7b-alpha_bge-base-en-v1</th>\n",
       "      <th>count</th>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Auto_Merging_RAG_zephyr-7b-alpha_bge-base-en-v1</th>\n",
       "      <th>count</th>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
