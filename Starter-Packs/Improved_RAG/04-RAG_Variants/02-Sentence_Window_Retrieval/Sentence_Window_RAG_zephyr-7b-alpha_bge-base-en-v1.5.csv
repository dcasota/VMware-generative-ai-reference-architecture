query,answer,contexts,ground_truth
"Based on the provided context information, what are the key findings from pages 12-15, 18, 18-19, 29, and 40 of the document ""Promise Denied""? Additionally, summarize the information presented in AIAA-2001-1791, AIAA 2001-1874, and AIAA 99-4865 related to reusable space vehicles and their design. Lastly, discuss the cost-optimized launch vehicle design approach mentioned in AIAA 92-1281 and the Skylon spaceplane technology from Reaction Engines Limited.","Based on the provided context information, the key findings from pages 12-15, 18, 18-19, 29, and 40 of the document ""Promise Denied"" are:

- On page 12, the author discusses the history of reusable launch vehicles (RLVs) and their potential benefits, including reduced costs and increased reliability.
- On page 15, the author highlights the challenges of developing RLVs, including technical difficulties and political opposition.
- On page 18, the author discusses the NASA X-30 National Hypersonic Flight Research Vehicle (NHFRV) program, which aimed to develop a reusable hypersonic vehicle for military and commercial applications.
- On page 18-19, the author discusses the NASA X-33 VentureStar program, which aimed to develop a reusable launch vehicle for commercial space transportation.
- On page 29, the author discusses the NASA X-34 program, which aimed to develop a reusable hypersonic vehicle for military applications.
- On page 40, the author discusses the NASA X-37 program, which aims to develop a reusable spaceplane for military applications.

Regarding the information presented in AIAA-2001-1791, AIAA 2001-1874, and AIAA 99-4865 related to reusable space vehicles and their design:

- In AIAA-2001-1791, the author discusses the development of the Hypersonic Technology Vehicle (HTV) program, which aimed to develop a reusable hypersonic vehicle for military applications. The author highlights the technical challenges of developing such a vehicle and the potential benefits of doing so.
- In AIAA 2001-1874, the author discusses the development of the Skylon spaceplane, which is being developed by Reaction Engines Limited. The author highlights the technical challenges of developing such a vehicle and the potential benefits of doing so.
- In AIAA 99-4865, the author discusses the development of reusable hypersonic vehicles and the challenges of doing so. The author highlights the potential benefits of developing such","['V. Lazarev, “Structure of Reusable Hypersonic Vehicles: Problems of \nWeight, Cost and Operating Effectiveness,” paper presented at the 9th \nInternational Space Planes and Hypersonic Systems and Technologies \nConference, Norfolk, VA, November 1–4, 1999, AIAA 99-4865, pp.\xa02–8.\n 67.\t D.E.  Koelle, “Cost-Optimized Launch Vehicle Design,” paper presented \nat the AIAA Space Programs and Technologies Conference, Huntsville, \nAL, March 24–27, 1992, AIAA 92-1281, p.  2. \n 68.\t Reaction Engines Limited, https://web.archive.org/web/20140702220051/\nhttp://www.reactionengines.co.uk/space_skylon_tech.html, accessed June 18, \n2014.\n', 'Ibid., p.  629.\n 37.\t NASA-Industry Team, “Reusable Launch Vehicle Concept Studies: \nWinged Body Concept, Executive Overview: Questions to be Addressed,” \nFebruary 3, 1995, p.  5, Box 19, file folder 501., NARA accession no.  255-\n04-0645 , NASA Marshall History Office, Huntsville, AL.\n 38.\t', 'Hirofumi Taniguchi, “Development Plan and Status of the RLVs,” paper \npresented at the AIAA/NAL-NASDA-ISAS 10th International Space \nPlanes and Hypersonic Systems and Technologies Conference, Kyoto, \nJapan, April 24–27, 2001, AIAA 2001-1874, pp.  1–6.\n 66.\t V. Lazarev, “Structure of Reusable Hypersonic Vehicles: Problems of \nWeight, Cost and Operating Effectiveness,” paper presented at the 9th \nInternational Space Planes and Hypersonic Systems and Technologies \nConference, Norfolk, VA, November 1–4, 1999, AIAA 99-4865, pp.\xa02–8.\n 67.\t D.E.  Koelle, “Cost-Optimized Launch Vehicle Design,” paper presented \nat the AIAA Space Programs and Technologies Conference, Huntsville, \nAL, March 24–27, 1992, AIAA 92-1281, p. ', 'Huntsville: NASA \nMSFC, 28 July 2015, at https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.\n gov/20150016565.pdf (accessed March 20, 2017).\n Koelle, D. E.  “Cost-Optimized Launch Vehicle Design.” Paper presented \nat the 34th AIAA Space Programs and Technologies Conference, \nHuntsville, AL, March 24–27, 1992.  AIAA 2-1281. \n Ladner, Lt.  Colonel Pat, and Major Jess Sponable. ', 'Promise Denied\n120\n24.\t Delma C. Freeman, Jr., Theodore A. Talay, and R. Eugene Austin, \n“Reusable Launch Vehicle Technology Program,” paper presented at \nthe 47th International Astronautical Congress, Beijing, China, October \n7–11, 1996, IAF 96-V.4.-1, p.  7.\n 25.\t These all were, incidentally, major challenges in the early days of stealth \naircraft, such as the Lockheed F-117A strike aircraft and the Northrop \n(later Northrop Grumman) B-2A Spirit bomber.\n']","

Key findings from ""Promise Denied"":

* Pages 12-15 discuss the history of the X-33/X-34 program and its cancellation.
* Page 18 mentions the first X-34 study effort being canceled in early 1996.
* Pages 18-19 provide information on the X-34 Technology Testbed Demonstrator.
* Page 29 discusses the National Aerospace Plane (NASP) program.
* Page 40 mentions the X-33/X-34 program's impact on the aerospace industry.

AIAA-2001-1791, AIAA 2001-1874, and AIAA 99-4865 related to reusable space vehicles and their design:

* AIAA-2001-1791 presents a parametric sizing study for future Single-Stage-To-Orbit (SSTO) spaceplanes.
* AIAA 2001-1874 discusses the development plan and status of the Reusable Launch Vehicles (RLVs).
* AIAA 99-4865 addresses the structure of reusable hypersonic vehicles, focusing on weight, cost, and operating effectiveness.

Cost-optimized launch vehicle design approach and Skylon spaceplane technology:

* AIAA 92-1281 mentions a cost-optimized launch vehicle design approach that considers various factors, including vehicle size, propulsion system, and mission requirements.
* Reaction Engines Limited's Skylon spaceplane technology, as presented in AIAA 92-1281, utilizes an air-breathing engine for efficient and cost-effective space travel. The Skylon spaceplane is designed to take off and land like a conventional aircraft, reducing the need for expensive ground support equipment and launch infrastructure."
"Question: What was the role of the flying boat in aviation development before 1940, and how did it contribute to military and commercial power projection?","The flying boat was an important form of aircraft that contributed to aviation's projection of military and commercial power in the pre-World War II era. It was a vehicle that could have radically affected the course of World War II combat if it had been available. The design of a flying boat posed many special problems inherent to its amphibious nature. First of all, the vehicle had to be buoyant and have an effective displacement so that it performed effectively in the water as a true boat. It had to be maneuverable and stable as well as structurally strong and seaworthy. The flying boat was its own distinct and extraordinary form of aircraft, one with a genuine boatlike main central body or hull that allowed the plane structure itself to float, take off, and alight on water. The fly­ing boat was an airplane; it certainly flew aerodynamically rather than aerostati­cally as airships did. It was also a “seaplane,” but not just one mounted on floats or pontoons in place of conventional landing gear, as the simpler form of seaplane would be outfitted. No, the flying boat was its own distinct and extraordinary form of aircraft. The flying boat played a significant role in building up civil air routes and in helping to beat down the submarine menace in two World Wars. However, the immediate future for the British flying boat industry is black, with only two types—the Short Sealand and Saunders-Roe Princess—in production, and no new prototypes being built. The decision of B.O.A.C. to withdraw all its flying boats has serious repercussions, and the Minister of Civil Aviation's statement that he is not aware of any national consideration that would lead him to request the Corporation to reconsider its decision does not improve matters.","['Some enthusiasts \neven felt that they would become a predominant form of aircraft and monopolize \ncertain aviation missions and arenas.  Commercial, military, and government estab\xad\nlishments dedicated substantial resources to their development; as we have already \nseen, the National Advisory Committee for Aeronautics, for one, focused consider\xad\nable attention on both through regular subcommittees devoted to their advance\xad\nment.  As aircraft technologies progressed generally, the form of the airship and the \nflying boat improved as well.  Both types contributed to aviation’s projection of \nmilitary and commercial power in the pre–World War II era, and both launched a \nnumber of airline routes, including the first transoceanic ones.  So important were \nthese two types of aircraft that it is impossible to understand aviation development \nbefore 1940 without paying attention to the roles fulfilled by these machines.\n As the airship and flying boat passed into twilight, another form of aircraft \ncame out of the shadows.  This was the rotary-wing machine, notably the helicop\xad\nter: a vehicle that could have radically affected the course of World War II combat \nif it had been available. ', 'The Wind and Beyond, Volume III\n18\nand to places where there were no runways for planes to land.  Technically, the fly\xad\ning boat was an airplane; it certainly flew aerodynamically rather than aerostati\xad\ncally as airships did.  It was also a “seaplane,” but not just one mounted on floats \nor pontoons in place of conventional landing gear, as the simpler form of seaplane \nwould be outfitted.  No, the flying boat was its own distinct and extraordinary form \nof aircraft, one with a genuine boatlike main central body or hull that allowed the \nplane structure itself to float, take off, and alight on water.\n The design of a flying boat posed many special problems inherent to its \namphibious nature.  First of all, the vehicle had to be buoyant and have an effective \ndisplacement so that it performed effectively in the water as a true boat.  It had to \nbe maneuverable and stable as well as structurally strong and seaworthy. ', 'Whilst believing and hoping for the former, it is useless to deny that the imme\xad\ndiate future for the British flying boat industry is black.  Only two types—the Short \nSealand and Saunders-Roe Princess—are in production.  Not a single prototype, \neither civil or military, is being built, and only one new civil ’boat—the Saunders-\nRoe Duchess—is projected.  Flying boat development is, in fact, almost at a stand\xad\nstill despite the great part these craft have played in building up our civil air routes \nand in helping to beat down the submarine menace in two World Wars.\n Much of the blame for this sorry state of affairs must be laid at the door of \nB.O.A.C.  and the Ministry of Civil Aviation, for a decision such as that of B.O.A.C.’s \nto withdraw all its flying boats can only have the most serious repercussions.\n Nor does the Minister of Civil Aviation improve matters with such statements \nas the one in which he expressed his “complete confidence in the commercial judg\xad\nment of B.O.A.C.,” adding that he was not aware of any national consideration \nwhich would lead him to request the Corporation to reconsider its decision.\n', '3–4.\n (b) “Wings for Tomorrow,” pp.  97–104.\n Flying boat development was not just an American phenomenon; it was inter\xad\nnational from the start.  It is erroneous even to suggest that the United States led \nthe way in this field.  The biggest users of commercial seaplanes and flying boats \nwere France and Italy, which both had a number of Mediterranean and Adriatic \nroutes to service.  Germany utilized a number of marine aircraft in the Baltic and on \ncoastal resort services to places like Naples, Venice, Tripoli, and Haifa. ', 'Chapter 5: Other Paths, Other Flyways\n17\nRobinson continued: “All kinds of technological advances made in the last \ntwenty years for the benefit of the aeroplane would benefit the airship also.” (In \nthis context, Robinson specifically mentioned the turboprop, modern instruments, \nradios, and electronic navigation aids; if written a bit later, his list would also have \nincluded the computer.  Obviously, the most revolutionary new technologies chang\xad\ning the nature of flight after 1945, the jet engine and the rocket, were not applicable \nto the airship.)  Some of the major problems that had plagued airship operation in \nthe early days, such as ground handling, had been “largely solved years ago by the \nUnited States Navy.” In sum, “The obstacles are not technical, they are psychologi\xad\ncal and financial; and if attitudes change and the money is forthcoming, we may \nstill some day see again the giants in the sky which thrilled and enthralled our \nparents with their awesome size and majesty.”4\nPart 2: The Flying Boat\nAnother kind of giant in the sky that enthralled the public prior to 1945—and \nthat also mostly went the way of the dodo bird afterward—was the flying boat. \n Unlike the airship, the flying boat did not compete so directly with the airplane \nbut rather complimented it by carrying goods and passengers over watery distances \n4\t Ibid.Photo of a Good Year Lifeguard blimp flying over farmland.\n FIGURE 5.11.  The Goodyear Enterprise and other blimps persist today primarily as vehicles for advertising. \n']","
The flying boat played a significant role in aviation development before 1940. It was one of the two types of aircraft that enjoyed a golden age during the 1920s and 1930s, with most experts believing that they would make fundamental and long-lasting contributions to aviation. The flying boat was considered a predominant form of aircraft and was expected to monopolize certain aviation missions and arenas. Commercial, military, and government establishments dedicated substantial resources to their development.

The flying boat contributed to aviation's projection of military and commercial power in the pre-World War II era. It launched a number of airline routes, including the first transoceanic ones. The National Advisory Committee for Aeronautics focused considerable attention on the flying boat through regular subcommittees devoted to its advancement. It is impossible to understand aviation development before 1940 without paying attention to the roles fulfilled by the flying boat."
Question: What is an Autogiro and what are some of its unique features compared to airplanes?,"An Autogiro, also known as a rotorcraft, is a type of rotorcraft that is capable of short takeoff and landing (STOL) but not hovering. It differs from a helicopter in that its rotor is not powered but turns automatically (i.e., autorotation) from the very motion of the craft through the air. The Autogiro was introduced by the Spanish engineer Juan de la Cierva in 1923, and it has unique features compared to airplanes. One of its main advantages is that it is not affected by loss of speed, which diminishes the lifting force and leaves the airplane subject to the force of gravity. An engine failure, a sudden ""nose up"" or a very sharp turn may interrupt its horizontal flight and make it descend toward the ground, but it can still maintain its vertical descent and dead stop landing qualities. Additionally, the Autogiro has about half the minimum velocity compared to airplanes, and it can practically do everything a helicopter is supposed to do, with performances that, while not strictly those of the theoretical helicopter, can still be obtained immediately.","['Incidentally, \nthat flexibility also considerably relieves any sudden overload making the autogiro \nthe stronger the flimsier it looks.\n All this makes comparison between aeroplane and autogiro unfair assuming \nthe same span for both, since span, that precious parameter, costs much less in the \nsecond, and this consideration corrects for the autogiro in practice the greater sen\xad\nsitiveness to the weight and altitude.  Autogiros with correct proportions can carry \nthe same normal load as equivalent aeroplanes and have about the same ceiling.\n A definite advantage of the autogiro with regard to the aeroplane is its extraor\xad\ndinary aerodynamical flexibility and adaptability.  In an aeroplane the load per \nsquare foot of wing area defines its landing qualities, and if the power is increased, \nin order to obtain the full benefit, an increase in wing loading must follow with a \ncorresponding increase in the landing speed.  Roughly speaking, the landing speed \nof an aeroplane is proportional to its top speed.  In an autogiro the landing qualities \ndepend almost exclusively on the load per square foot of disc area, while in order to \nobtain the best possible efficiency at top speed it is only necessary to keep the ratio \ntip speed to top speed equal to about one point five, which ratio depends only on \nactual blade area, assuming the pitch constant. ', 'The first free flight of my machine \nlasted 28 seconds, the fourth 16 minutes.  Even if a large part of the credit may be \nascribed to the skill of Pilot Rohlfs, the results achieved would have been unthink\xad\nable without a thorough sifting of the technical material.\n Considering now the performance, I should like to differentiate between what \nis already directly attainable today, or shown to be possible, and what we are to \nexpect in a more distant future from the rotating-wing aircraft.\n A) AUTOGIROS\nSchrenk has made an interesting comparison between the characteristics of \nairplanes and autogiros (fig.  4).  The actual difference occurring is partly due, how\xad\never, to the impaired relations with respect to the harmful drag which by better \nstreamlining of the propeller hub, etc., may be reduced in the future.  It may there\xad\nfore be estimated that an autogiro will remain inferior to the conventional airplane \nas regards speed by about 10 percent, but on the other hand, has about half the \nminimum velocity.\n', 'The Wind and Beyond, Volume III\n532\nDocument 5-36 (a–b)\n(a) Juan de la Cierva, “The Development of the Autogyro,” \nJournal of the Royal Aeronautical Society (January 1926): 8–29.\n (b) Juan de la Cierva, “The Development of the Autogiro,” \nJournal of the Royal Aeronautical Society \n(November 1930): 902–921.\n In the early 1920s, the Spanish engineer Juan de la Cierva (1895–1936) intro\xad\nduced the world to the “autogiro,” a word that Cierva himself coined and that was \noriginally a proprietary term for just the Cierva machine.  The autogiro (British \nspelling, “autogyro”) was not a helicopter, but a different type of rotorcraft that was \ncapable of short takeoff and landing (STOL) but not hovering.  It differed from the \nhelicopter in that its rotor was not powered but turned automatically (i.e., autorota\xad\ntion) from the very motion of the craft through the air.  The Cierva autogiro began \nmaking successful flights in 1923.  Soon other inventors came to design their own \nautogiros. ', '4 was the last of the experimental \nseries, and No.  5 will be the first of the commercial series.  Those who have followed \nits progress will not go to the airport simply to see it fly and descend vertically \nwithout an appreciable forward speed, but to see it compete with its elder brother, \nthe airplane.\n The “Autogiro” is not a helicopter nor an aeronautic freak pretending to solve a \ndifficult problem of mechanics, but is a perfected airplane, although not designed \nwith the sporting purpose of increasing speed nor with the commercial object of \nenlarging the radius of action, but with the humanitarian purpose of reducing to a \nminimum the number of accidents and the number of human lives sacrificed in the \nfight for the conquest of the air.\n Nearly all aviation accidents are due to loss of speed, which diminishes the lift\xad\ning force and leaves the airplane subject to the force of gravity.  The “Autogiro” is \nnot affected by loss of speed.  An engine failure, a sudden “nose up” or a very sharp \nturn may interrupt its horizontal flight and make it descend toward the ground, Phot of autogiro Number 4 flying at Cuatro Vientos, January 31, 1923.\n', 'The Wind and Beyond, Volume III\n562\nit would be justified) an over-powered autogiro, in which only load would be sac\xad\nrificed, could practically do everything the helicopter is supposed to do.  Take off \nin ten to twenty yards, forty to fifty degrees steepness of climb, eighteen miles an \nhour minimum horizontal speed or ten miles an hour when losing altitude at seven \nor eight feet per second, in addition to the vertical descent and dead stop landing \nqualities, would constitute performances which, while not strictly those of the theo\xad\nretical helicopter, could yet be obtained immediately and would, in practice, open \nfor such a machine all the possibilities of a helicopter.  To my mind, the autogiro \ncould be classified in two categories: The autogiro-aeroplanes, with performances \ncomparable with those of the ordinary aeroplanes in speed and climb and relatively \nlow powered, and the autogiro-helicopters.  There is, of course, no definite point of \ndivision between both.\n Before ending this paper, I must say once more that the autogiro is still suscep\xad\ntible to considerable development and improvement.  At the same time it is already \na thoroughly practical machine, and in the very near future it will be, I hope, a still \nbetter one.\n']","
An Autogiro is a type of aircraft that has unique features compared to airplanes. It is a rotorcraft that uses an unpowered rotor in autorotation to develop lift. Unlike airplanes, an Autogiro does not have a fixed wing and does not require an engine to generate lift.

One of the most characteristic features of Autogiro performance is that it will not stall in the airplane sense of the word and cannot spin. This is because the rotor blades continue to turn even when the Autogiro is not moving forward, providing lift and stability.

Another unique feature of Autogiros is that they can take off and land vertically, making them useful for operations in confined spaces. They can also hover in place, which is not possible with airplanes.

The American organization engaged in Autogiro development was awarded the Collier Trophy in 1931 for the greatest achievement in aviation, demonstrating the value of Autogiros in actual use during the preceding year."
"What research was conducted on rotating-wing aircraft in the National Advisory Committee for Aeronautics (NACA) annual reports from 1938 to 1939, specifically focusing on the study of rotor control systems, the investigation of lift-drag ratio improvement, and the analysis of control vibration in direct-control autogiros?","The NACA's annual reports from 1938 to 1939 focused on research related to rotating-wing aircraft, specifically on the study of rotor control systems, the investigation of lift-drag ratio improvement, and the analysis of control vibration in direct-control autogiros. In the hope of developing an improved method of direct control for rotating-wing aircraft, research during the past year has been restricted to a theoretical study of rotor control systems. The effect of periodically feathering the blades of an articulated rotor has been analyzed in detail and the aerodynamic identity of the Hafner and Cierva control systems has been mathematically demonstrated. As yet, the study has not been extended to cover feathering control of rigid rotors, but it is hoped that this can be done in the near future. The NACA also conducted an investigation of lift-drag ratio improvement, which involved the use of a new type of rotor blade with a curved leading edge and a straight trailing edge. The results of this investigation showed that the new blade design resulted in a significant improvement in lift-drag ratio. Finally, the NACA analyzed control vibration in direct-control autogiros, which involved the use of a new type of control system that allowed for direct control of the rotor blades. The results of this analysis showed that control vibration could be significantly reduced using this new control system.","['Besides works by Gessow and Myers themselves, other NACA authors whose \nhelicopter work was cited in the text included F.\xa0J. Bailey, Jr., T.\xa0J. Voglewede, \nW.\xa0 B. Boothby, Richard C. Dingeldein, Raymond F. Schaefer, Montgomery \nKnight, Ralph A. Hefner, Stanley Lipson, John B. Wheatley, Carlton Bioletti, \nWilliam C. Clay, Ray Windler, F.\xa0J. Bailey, Paul J. Carpenter, Herbert Talkin, \nEugene Mitgotsky, Robert P. Coleman, Arnold M. Feingold, Carl W. Stempin, P.\xa0J. \nCarpenter, R.\xa0S. Paulnock, W.\xa0Castles, Jr., R.\xa0B. Gray, P.\xa0de Gullenschmidt, John \nE. Duberg, A.\xa0R. Lueker, Frederic B. Gustafson, and John P. Reeder.  Even Robert \nR. Gilruth, the future head of NASA’s Mercury program, published a set of research \nreports related to rotary-wing flight.  And much of this work in fact predated the \nSecond World War.  Wheatley published at least one report on rotary-wing design \n(primarily about autogiro aerodynamics and control) in every year from 1933 to \n1938.  The collaborative work of Montgomery Knight and Ralph A. Hefner dated \nfrom 1937 and concerned thrust analysis of “lifting airscrews.” (After moving to a \nteaching post at the Guggenheim School of Aeronautics at the Georgia Institute of \nTechnology (Georgia Tech) in 1930, Knight built a single-blade jet-driven rotor test \nrig whose data led to his design of an innovative helicopter concept.)\n Along with Gustafson, Gessow ranks as one of the greatest helicopter experts \never to have worked for the NACA/NASA.  In 1980, Gessow moved from NASA \n', 'Although isolated references to rotary-wing developments can be found in the \nNACA’s annual reports prior to 1933, it was not until that year that a regular entry \non “Rotary-Wing Aircraft” began to appear in the publication.  In that first year of \nreporting on it, the NACA explained that it was paying attention to “three prom\xad\nising types” of rotating-wing aircraft: first, the “familiar” autogiro; second, the \n“gyroplane,” a special form of autogiro with a different kind of rotor arrangement \nand operation, one seeking a greater symmetry of lift; and third, the “cyclogiro,” \nessentially a helicopter, though the NACA did not call it that in this first report. \n Most of this work on rotorcraft was being done in the form of wind tunnel tests. \n The Committee reported in the Annual Report of the National Advisory Committee \nfor Aeronautics for 1933 that its researchers were conducting the tests “principally \nfor the purpose of improving the rotor characteristics of the autogiro and gyroplane \nand confirming the soundness of the principles involved in the cyclogiro” (p.  15). \n Most interestingly, it wrote that “the aerodynamic principles of vertical flight” were \n“sound” and “that hovering flight, vertical climb, and a reasonable forward speed \nmay be expected with a reasonable expenditure of power” (p.  15). ', '589\nDocument 5-39 (a–h)\nDocument 5-39 (f), Excerpts from Annual Report of the National \nAdvisory Committee for Aeronautics (Washington, DC), 1933–40, \n“Rotating-Wing Aircraft,” Annual Report (1938), p.  17.\n In the hope of developing an improved method of direct control for rotating-\nwing aircraft, research during the past year has been restricted to a theoretical \nstudy of rotor control systems.  The effect of periodically feathering the blades of an \narticulated rotor has been analyzed in detail and the aerodynamic identity of the \nHafner and Cierva control systems has been mathematically demonstrated.  As yet \nthe study has not been extended to cover feathering control of rigid rotors but it is \nhoped that this can be done in the near future.\n A study of the torque equilibrium in the autogiro rotor has been completed \nand the results published in Technical Report No. ', 'Beginning in June 1933, at the request of the Aeronautics Branch of the \nDepartment of Commerce, researchers at Langley formally began an effort called \n“Investigation of Landing Characteristics of an Autogiro” under the auspices of \nNACA research authorization number 418.  Between July 1931 and January 1940, \nLangley test pilots evaluated the performance of no fewer than six different auto\xad\ngiros, including a Pitcairn PCA‑2 (July 1931 to September 1933), Pitcairn PAA-1 \n(which arrived at Langley Field sometime in 1933), Kellett YG-1 (January 1936 \nto May 1936), Kellett YG-2 (December 1935 to March 1936), Wilford XOZ-1 \n(August 1937 to sometime in 1941), and Kellett YG-1B (September 1939 to January \n1940).  All told, autogiros flew experimentally at Langley between 1931 and 1940 \nfor no less than an estimated cumulative total of 86 months, or over 7 flying years. \n Specific entries on “Rotating Wing Aircraft” began to appear in the NACA’s annual \nreports in 1933.  Document 5-39 reproduces all of the NACA annual report entries \non rotating-wing aircraft from 1933 through 1940.\n In summarizing for his textbook on helicopter aerodynamics, Professor \nLeishman recognized that the NACA extensively tested the autogiro in the United \nStates.  More than that, he pronounced, based on his review of all the extant tech\xad\nnical literature, that the NACA’s critical evaluation of rotary-wing performance \nhelped lead to the demise of the autogiro and to a renaissance of interest in heli\xad\ncopters. ', '583\nDocument 5-39 (a–h)\nNACA researchers by the late 1930s appear to have become more interested in true \nhelicopters, the NACA’s entries on rotary-wing aircraft in its annual reports con\xad\ntinued to focus on autogiros.  Perhaps NACA leadership still considered helicopters \ntoo early in their experimental development.\n Document 5-39 (a), Excerpts from Annual Report of the National \nAdvisory Committee for Aeronautics (Washington, DC), 1933–40, \n“Rotating-Wing Aircraft,” Annual Report (1933), pp.  14–15.\n']","
1. Research on rotor control systems: In 1938, a theoretical study of rotating-wing aircraft control systems was conducted, focusing on the effect of periodically feathering the blades of an articulated rotor. The aerodynamic identity of the Hafner and Cierva control systems was mathematically demonstrated. A study of the torque equilibrium in the autogiro rotor was completed and published in Technical Report No. 623, simplifying and improving the previous method of calculating the inflow velocity required to maintain autorotation. The study did not yet extend to rigid rotors, but it was hoped that it could be done in the near future.

2. Investigation of lift-drag ratio improvement: In 1939, the possibility of improving the lift-drag ratio of rotors in forward flight, specifically retarding or preventing the stalling of the inboard elements of the retreating blades, was being investigated. The preliminary step involved supplementing theoretical calculations with photographic observations of silk tufts mounted on the blades of a YG-1B autogiro. The tuft observations indicated that the stalled portion of the rotor disk was larger than expected. A technical note presenting the results of the initial observations was being prepared, and additional observations on blades of various airfoil sections and plan forms were in progress.

3. Analysis of control vibration in direct-control autogiros: An attempt was made to isolate the factors responsible for the severe vibration present in the control systems of present-day direct-control autogiros. The varying loads in the control system of a YG-1B autogiro were recorded in flight at various air speeds. Analysis of the records indicated that mass unbalance or improper matching of the blades was not responsible for the control vibration in this machine. Some modification of hub and blades was deemed desirable. Similar tests on the same machine equipped with blades of improved design were in progress. Data on the blade motion and the control characteristics of nonarticulated feathering rotors were obtained from flight tests of the Wilford XOZ-1 sea gyroplane and were being evaluated."
"Question: Why did Kennedy propose making Apollo a joint mission with the Soviet Union, and what were the Soviet's responses to this proposal?","Kennedy proposed making Apollo a joint mission with the Soviet Union to defuse the situation regarding Republican charges concerning the Moon program. Within two weeks of giving his 25 May speech, Kennedy met Khrushchev at the Vienna summit and proposed making Apollo a joint mission with the Soviets. The Soviet leader reportedly first said no, then replied ""why not?"" and then changed his mind again, saying that disarmament was a prerequisite for U.S.-U.S.S.R. cooperation in space. Kennedy confided to James Webb that he felt vulnerable to the Republican charges concerning the Moon program and thought refashioning it into a cooperative effort could defuse the situation. On 20 September 1963, Kennedy made a well-known speech before the United Nations, in which he again proposed a joint human mission to the Moon. However, the Soviet Union was noncommittal in response to this proposal, with the Soviet official newspaper, Pravda, dismissing the 1963 proposal as premature. Some have suggested that Khrushchev viewed the American offer as a ploy to open up Soviet society and compromise Soviet technology.","['NACA to NASA to Now\n86\nFrom here on, I think we should proceed in an orderly, scientific way, building \none accomplishment on another.”7 Likewise, in the 1964 presidential election, \nRepublican candidate Senator Barry Goldwater urged a reduction of the Apollo \ncommitment to pay for national security initiatives. \n Anticipating these attacks, Kennedy always hedged his bets in supporting \nApollo.  He harbored the possibility of making the program a joint effort with \nthe Soviet Union.  In his inaugural address in January 1961, Kennedy spoke \ndirectly to Soviet Premier Nikita Khrushchev and asked him to cooperate in \nexploring “the stars.” In his State of the Union address 10 days later, he asked \nthe Soviet Union “to join us in developing a weather prediction program, in a \nnew communications satellite program, and in preparation for probing the dis\xad\ntant planets of Mars and Venus, probes which may someday unlock the deepest \nsecrets of the Universe.”8\nWithin two weeks of giving his 25 May speech, Kennedy met Khrushchev \nat the Vienna summit and proposed making Apollo a joint mission with the \nSoviets.  The Soviet leader reportedly first said no, then replied “why not?” and \nthen changed his mind again, saying that disarmament was a prerequisite for \nU.S.-U.S.S.R.  cooperation in space.  Kennedy confided to James Webb that he\nfelt vulnerable to the Republican charges concerning the Moon program and\nthought refashioning it into a cooperative effort could defuse the situation.\n', 'Anticipating these attacks, Kennedy always hedged his bets in supporting \nApollo.  He harbored the possibility of making the program a joint effort with \nthe Soviet Union.  In his inaugural address in January 1961, Kennedy spoke \ndirectly to Soviet Premier Nikita Khrushchev and asked him to cooperate in \nexploring “the stars.” In his State of the Union address 10 days later, he asked \nthe Soviet Union “to join us in developing a weather prediction program, in a \nnew communications satellite program, and in preparation for probing the dis\xad\ntant planets of Mars and Venus, probes which may someday unlock the deepest \nsecrets of the Universe.”8\nWithin two weeks of giving his 25 May speech, Kennedy met Khrushchev \nat the Vienna summit and proposed making Apollo a joint mission with the \nSoviets.  The Soviet leader reportedly first said no, then replied “why not?” and \nthen changed his mind again, saying that disarmament was a prerequisite for \nU.S.-U.S.S.R.  cooperation in space.  Kennedy confided to James Webb that he\nfelt vulnerable to the Republican charges concerning the Moon program and\nthought refashioning it into a cooperative effort could defuse the situation.\n On 20 September 1963, Kennedy made a well-known speech before the \nUnited Nations, in which he again proposed a joint human mission to the \nMoon. ', 'The Soviet leader reportedly first said no, then replied “why not?” and \nthen changed his mind again, saying that disarmament was a prerequisite for \nU.S.-U.S.S.R.  cooperation in space.  Kennedy confided to James Webb that he\nfelt vulnerable to the Republican charges concerning the Moon program and\nthought refashioning it into a cooperative effort could defuse the situation.\n On 20 September 1963, Kennedy made a well-known speech before the \nUnited Nations, in which he again proposed a joint human mission to the \nMoon.  He closed by urging, “Let us do the big things together.”9 In public, \nthe Soviet Union was noncommittal.  The Soviet official newspaper, Pravda, \nfor example, dismissed the 1963 proposal as premature.  Some have suggested \nthat Khrushchev viewed the American offer as a ploy to open up Soviet society \nand compromise Soviet technology. ', 'John F. Kennedy and the Race to the Moon.  New York: Palgrave \nMacmillan, 2010.  This study, based on extensive research in primary \ndocuments and archival interviews with key members of the Kennedy \nadministration, is the definitive examination of John Kennedy’s role in \nsending Americans to the Moon.  Among other revelations, the author \nfinds that from the conclusion of the Cuban Missile Crisis in 1962, JFK \npursued an effort to turn Apollo into a cooperative program with the \nSoviet Union.\n 58.\t  ____.  Ronald Reagan and the Space Frontier. ', '____.  John F. Kennedy and the Race to the Moon.  New York: Palgrave \nMacmillan, 2010.  This study, based on extensive research in primary \ndocuments and archival interviews with key members of the Kennedy \nadministration, is the definitive examination of John Kennedy’s role in \nsending Americans to the Moon.  Among other revelations, the author \nfinds that from the conclusion of the Cuban Missile Crisis in 1962, JFK \npursued an effort to turn Apollo into a cooperative program with the \nSoviet Union.\n 58.\t  ____. ']","
Kennedy proposed making Apollo a joint mission with the Soviet Union to defuse the situation regarding Republican charges concerning the Moon program and to make the program a joint effort with the Soviet Union in an orderly, scientific way. He first proposed this to Soviet Premier Nikita Khrushchev at the Vienna summit in June 1961, but Khrushchev initially said no. He then changed his mind and said that disarmament was a prerequisite for U.S.-U.S.S.R. cooperation in space. Kennedy confided to James Webb that he felt vulnerable to the Republican charges concerning the Moon program and thought refashioning it into a cooperative effort could defuse the situation.

In September 1963, Kennedy made a well-known speech before the United Nations, in which he again proposed a joint human mission to the Moon. He closed by urging, “Let us do the big things together.” However, the Soviet Union was noncommittal in public, with the Soviet official newspaper, Pravda, dismissing the 1963 proposal as premature. Some have suggested that Khrushchev viewed the American offer as a ploy to open up Soviet society and compromise Soviet technology. Although these efforts did not produce any space agreements, the fact that Kennedy pursued various forms of space cooperation until his assassination in 1963 portended what might have resulted had he remained in office for a full two terms."
What is the difference between PNdB and EPNdB in the context of aircraft noise measurement?,"PNdB and EPNdB are both measures used to quantify aircraft noise, but they differ in their approach. PNdB, or ""perceived noise in decibels,"" is a subjective measure that reflects the overall intensity of a sound, its frequency content, and how people respond to it. It was commonly used in early aircraft noise research. However, the special circumstances of the aircraft noise problem, characterized by whining jet aircraft passing overhead, necessitated a better and more relevant measure. This led to the defining of a more appropriate and relevant noise measurement unit, the effective perceived noise in decibels, or EPNdB. EPNdB accounts for two additional factors beyond PNdB: first, it gives more importance to tones in the noise spectrum, and second, it accounts for the duration, or rise and fall, of a sound. In essence, EPNdB provides the single number that expresses the measure of the total annoyance a person experiences as an airplane flies over.","['The Power for Flight\n74\nthat noise was “the curse of modern times and a major environmental prob\xad\nlem.”3 The scientific measure of sound intensity, most commonly heard as \nnoise, is the decibel.  The threshold of pain starts at 120 dB, while 140 produces \npermanent damage.  While the decibel is a specific term for the level of sound \noutput, acoustics researchers use “PNdB,” or “perceived noise in decibels,” \nto measure the sound affecting people in the vicinity of an aircraft.  In early \naircraft noise research, PNdB was the subjective “measure of annoyance” that \nreflected the overall intensity of a sound, its frequency content, and how people \nresponded to it.  But the special circumstances of the aircraft noise problem \ncharacterized by whining jet aircraft passing overhead necessitated a better \nand more relevant measure and resulted in the defining of a more appropriate \nand relevant noise measurement unit, the effective perceived noise in decibels, \nor EPNdB.  The EPNdB accounted for two additional factors beyond PNdB: \nfirst, it gave more importance to tones in the noise spectrum, and second, it \naccounted for the duration, or rise and fall, of a sound.  In essence, EPNdB \nprovided the single number that expressed the measure of the total annoyance \na person experienced as an airplane flew over.\n', 'The Power for Flight\n74\nthat noise was “the curse of modern times and a major environmental prob\xad\nlem.”3 The scientific measure of sound intensity, most commonly heard as \nnoise, is the decibel.  The threshold of pain starts at 120 dB, while 140 produces \npermanent damage.  While the decibel is a specific term for the level of sound \noutput, acoustics researchers use “PNdB,” or “perceived noise in decibels,” \nto measure the sound affecting people in the vicinity of an aircraft.  In early \naircraft noise research, PNdB was the subjective “measure of annoyance” that \nreflected the overall intensity of a sound, its frequency content, and how people \nresponded to it.  But the special circumstances of the aircraft noise problem \ncharacterized by whining jet aircraft passing overhead necessitated a better \nand more relevant measure and resulted in the defining of a more appropriate \nand relevant noise measurement unit, the effective perceived noise in decibels, \nor EPNdB.  The EPNdB accounted for two additional factors beyond PNdB: \nfirst, it gave more importance to tones in the noise spectrum, and second, it \naccounted for the duration, or rise and fall, of a sound. ', 'The threshold of pain starts at 120 dB, while 140 produces \npermanent damage.  While the decibel is a specific term for the level of sound \noutput, acoustics researchers use “PNdB,” or “perceived noise in decibels,” \nto measure the sound affecting people in the vicinity of an aircraft.  In early \naircraft noise research, PNdB was the subjective “measure of annoyance” that \nreflected the overall intensity of a sound, its frequency content, and how people \nresponded to it.  But the special circumstances of the aircraft noise problem \ncharacterized by whining jet aircraft passing overhead necessitated a better \nand more relevant measure and resulted in the defining of a more appropriate \nand relevant noise measurement unit, the effective perceived noise in decibels, \nor EPNdB.  The EPNdB accounted for two additional factors beyond PNdB: \nfirst, it gave more importance to tones in the noise spectrum, and second, it \naccounted for the duration, or rise and fall, of a sound.  In essence, EPNdB \nprovided the single number that expressed the measure of the total annoyance \na person experienced as an airplane flew over.\n A four-engine commercial airliner of the 1960s or early 1970s generated \n95 to 120 EPNdB at takeoff, which was a potential cause of hearing damage \nto the general populace and detrimental overall to the quality of life around \nairports. ', 'While the decibel is a specific term for the level of sound \noutput, acoustics researchers use “PNdB,” or “perceived noise in decibels,” \nto measure the sound affecting people in the vicinity of an aircraft.  In early \naircraft noise research, PNdB was the subjective “measure of annoyance” that \nreflected the overall intensity of a sound, its frequency content, and how people \nresponded to it.  But the special circumstances of the aircraft noise problem \ncharacterized by whining jet aircraft passing overhead necessitated a better \nand more relevant measure and resulted in the defining of a more appropriate \nand relevant noise measurement unit, the effective perceived noise in decibels, \nor EPNdB.  The EPNdB accounted for two additional factors beyond PNdB: \nfirst, it gave more importance to tones in the noise spectrum, and second, it \naccounted for the duration, or rise and fall, of a sound.  In essence, EPNdB \nprovided the single number that expressed the measure of the total annoyance \na person experienced as an airplane flew over.\n A four-engine commercial airliner of the 1960s or early 1970s generated \n95 to 120 EPNdB at takeoff, which was a potential cause of hearing damage \nto the general populace and detrimental overall to the quality of life around \nairports.  In a world full of “chattering jackhammers, whining motorcycles, and \nroaring jetliners,” Representative William F. Ryan (D-NY) asserted, “the right \nto a quiet, peaceful environment is as basic as the right to clean air and water \nand pure food.” The EPA led the effort to limit noise emissions as it had done \nfor air and water, but Congress planned comprehensive legislation addressing \nnoise in the 1970s. ', 'In early \naircraft noise research, PNdB was the subjective “measure of annoyance” that \nreflected the overall intensity of a sound, its frequency content, and how people \nresponded to it.  But the special circumstances of the aircraft noise problem \ncharacterized by whining jet aircraft passing overhead necessitated a better \nand more relevant measure and resulted in the defining of a more appropriate \nand relevant noise measurement unit, the effective perceived noise in decibels, \nor EPNdB.  The EPNdB accounted for two additional factors beyond PNdB: \nfirst, it gave more importance to tones in the noise spectrum, and second, it \naccounted for the duration, or rise and fall, of a sound.  In essence, EPNdB \nprovided the single number that expressed the measure of the total annoyance \na person experienced as an airplane flew over.\n A four-engine commercial airliner of the 1960s or early 1970s generated \n95 to 120 EPNdB at takeoff, which was a potential cause of hearing damage \nto the general populace and detrimental overall to the quality of life around \nairports.  In a world full of “chattering jackhammers, whining motorcycles, and \nroaring jetliners,” Representative William F. Ryan (D-NY) asserted, “the right \nto a quiet, peaceful environment is as basic as the right to clean air and water \nand pure food.” The EPA led the effort to limit noise emissions as it had done \nfor air and water, but Congress planned comprehensive legislation addressing \nnoise in the 1970s.  Congress specifically authorized the FAA to muffle “the \nloudest source of urban noise”: low-flying jet aircraft.4\nEarly in the Jet Age, communities and environmental activists recognized \nthat noise and emissions were significant byproducts of jet travel. ']","
PNdB is a subjective measure of annoyance that reflects the overall intensity of a sound, its frequency content, and how people respond to it. It was used in early aircraft noise research.
EPNdB, on the other hand, is a more appropriate and relevant noise measurement unit for aircraft noise. It accounts for two additional factors beyond PNdB: first, it gives more importance to tones in the noise spectrum, and second, it accounts for the duration, or rise and fall, of a sound. EPNdB provides the single number that expresses the measure of the total annoyance a person experiences as an airplane flies over."
What were the concerns with the sidestick controller and how were they addressed?,"The concerns with the sidestick controller were whether it would provide the same level of control as the conventional center stick and whether it could perform adequately during ""degraded"" flight control system conditions. To address these concerns, a piloted simulation evaluation and a full flight investigation of a 3-axis sidestick controller were performed on an XV-15 TRRA for both normal and ""degraded"" flight control system conditions. Gary Churchill, senior controls engineer with the TRRA Project Office, developed the control laws and was the primary investigator. Each pilot received a familiarization flight in the left seat using a conventional center stick control and flew an evaluation flight in the right seat which was equipped with a sidestick controller. Without exception, all of the evaluation pilots found the sidestick to be a viable controller and that the aircraft was safe to fly with a degraded control system. The pilots even reported that some tasks could be performed with more precision with the sidestick controller than with the conventional center stick.","['SIDESTICK CONTROLLER\nAmong the many decisions made early in the development of the TRRA was \nthe cockpit control configuration.  Simulation and flight evaluations by Bell and \nGovernment pilots resulted in the selection of a helicopter-type power lever for rotor \ncontrol and a conventional center stick and rudder pedals for longitudinal, direc\xad\ntional, and pitch control inputs.  The tall center stick, however, with its mass-center \nseveral inches above its pivot point, introduced undesirable dynamic effects (called \n“bobweight” motions) during maneuvers.  This issue, coupled with the possible inter\xad\nference of the center stick with crew station structure (instrument panel), problems \nwith cockpit ingress or egress, and the general interest in conserving limited cockpit \n“real estate,” led researchers to investigate the use of a sidestick controller as the prin\xad\ncipal flight control for the developing military JVX tilt rotor aircraft (later called the \nV-22 Osprey).  The principal concerns with this type [of] controller were whether it \nwould be able to provide the same level of control as the conventional center stick, \nand whether it could perform adequately during “degraded” flight control system \nconditions (such as a malfunctioning or battle-damaged control system).\n To answer these questions, it was decided to perform a piloted simulation eval\xad\nuation and a full flight investigation of a 3-axis sidestick controller on an XV-15 \nTRRA for both normal and “degraded” flight control system conditions.  Gary \nChurchill, senior controls engineer with the TRRA Project Office, developed the \ncontrol laws and was the primary investigator.\n', 'The tall center stick, however, with its mass-center \nseveral inches above its pivot point, introduced undesirable dynamic effects (called \n“bobweight” motions) during maneuvers.  This issue, coupled with the possible inter\xad\nference of the center stick with crew station structure (instrument panel), problems \nwith cockpit ingress or egress, and the general interest in conserving limited cockpit \n“real estate,” led researchers to investigate the use of a sidestick controller as the prin\xad\ncipal flight control for the developing military JVX tilt rotor aircraft (later called the \nV-22 Osprey).  The principal concerns with this type [of] controller were whether it \nwould be able to provide the same level of control as the conventional center stick, \nand whether it could perform adequately during “degraded” flight control system \nconditions (such as a malfunctioning or battle-damaged control system).\n To answer these questions, it was decided to perform a piloted simulation eval\xad\nuation and a full flight investigation of a 3-axis sidestick controller on an XV-15 \nTRRA for both normal and “degraded” flight control system conditions.  Gary \nChurchill, senior controls engineer with the TRRA Project Office, developed the \ncontrol laws and was the primary investigator.\n The XV-15 TRRA was ideal for the installation of the sidestick controller \nbecause it had bulging side windows (designed into the aircraft for better visibility) \nand an uncluttered side console which provided room for a functional installation, \nincluding an adjustable arm rest.  A control and status panel for the sidestick con\xad\ntroller was added to the instrument panel.\n', 'The principal concerns with this type [of] controller were whether it \nwould be able to provide the same level of control as the conventional center stick, \nand whether it could perform adequately during “degraded” flight control system \nconditions (such as a malfunctioning or battle-damaged control system).\n To answer these questions, it was decided to perform a piloted simulation eval\xad\nuation and a full flight investigation of a 3-axis sidestick controller on an XV-15 \nTRRA for both normal and “degraded” flight control system conditions.  Gary \nChurchill, senior controls engineer with the TRRA Project Office, developed the \ncontrol laws and was the primary investigator.\n The XV-15 TRRA was ideal for the installation of the sidestick controller \nbecause it had bulging side windows (designed into the aircraft for better visibility) \nand an uncluttered side console which provided room for a functional installation, \nincluding an adjustable arm rest.  A control and status panel for the sidestick con\xad\ntroller was added to the instrument panel.\n Initial sidestick control system gains and sensitivities were established using \nthe Ames Vertical Motion Simulator (VMS) and a refined simulation math model \nbased on the one originally developed in the early stages of the XV-15 project.  These \ncontrol law parameters were adjusted during XV-15 installation/hangar checks, and \nthe resulting configuration was taken into the flight program.\n', 'Each pilot received \na familiarization flight in the left seat using a conventional center stick control \nand flew an evaluation flight in the right seat which was equipped with a sidestick \ncontroller.  Without exception, all of the evaluation pilots found the sidestick to \nbe a viable controller and that the aircraft was safe to fly with a degraded control \nsystem (i.e.  with the SCAS turned off).  The pilots even reported that some tasks \ncould be performed with more precision with the sidestick controller than with the \nconventional center stick.\n While the sidestick investigation successfully achieved its objectives, the V-22 \nOsprey was nonetheless configured with a center stick control.  However, the side\xad\nstick controller continues to be considered by the V-22 Project Office for future \napplication to the tilt rotor aircraft.\n ACOUSTICS\nBy the late 1970s, communities adjacent to airports and heliports had become \nquite sensitive to the noise generated by aircraft operations, in particular, to the \ndisturbing character of the sound of rotorcraft noise. ', 'During a nine day period, a total of 13 flights \nwere flown with eight pilots from six agencies (the NASA, Army, Navy, Marine \nCorps, Bell Helicopter Textron, and Boeing Helicopters).  Control characteristics \nof the center stick and the sidestick controller were compared.  Each pilot received \na familiarization flight in the left seat using a conventional center stick control \nand flew an evaluation flight in the right seat which was equipped with a sidestick \ncontroller.  Without exception, all of the evaluation pilots found the sidestick to \nbe a viable controller and that the aircraft was safe to fly with a degraded control \nsystem (i.e.  with the SCAS turned off).  The pilots even reported that some tasks \ncould be performed with more precision with the sidestick controller than with the \nconventional center stick.\n While the sidestick investigation successfully achieved its objectives, the V-22 \nOsprey was nonetheless configured with a center stick control. ']","
The concerns with the sidestick controller were whether it would be able to provide the same level of control as the conventional center stick, and whether it could perform adequately during ""degraded"" flight control system conditions (such as a malfunctioning or battle-damaged control system). To address these concerns, a piloted simulation evaluation and a full flight investigation of a 3-axis sidestick controller on an XV-15 TRRA were performed for both normal and ""degraded"" flight control system conditions. The sidestick controller was installed on the XV-15 TRRA because it had bulging side windows and an uncluttered side console which provided room for a functional installation, including an adjustable arm rest. Initial sidestick control system gains and sensitivities were established using the Ames Vertical Motion Simulator (VMS) and a refined simulation math model based on the one originally developed in the early stages of the XV-15 project. These control law parameters were adjusted during XV-15 installation/hangar checks, and the resulting configuration was taken into the flight program."
Question: What is the mission objective of the ACE spacecraft and which scientific instruments are used to achieve these objectives?,"The mission objective of the ACE spacecraft is to study spaceborne energetic particles from the Sun-Earth L1 libration point, about 1.4 million kilometers from Earth, to investigate the matter ejected from the Sun and establish the commonality and interaction between the Sun, Earth, and the Milky Way galaxy. The spacecraft was launched on August 25, 1997, and its nine scientific instruments include a solar wind ion mass spectrometer (SWIMS) and solar wind ion composition spectrometer (SWICS), ultra-low energy isotope spectrometer (ULEIS), solar energetic particle ionic charge analyzer (SEPICA), solar isotope spectrometer (SIS), cosmic ray isotope spectrometer (CRIS), solar wind electron, proton, and alpha monitor (SWEPAM), electron, proton, and alpha-particle monitor (EPAM), and magnetometer (MAG). The spacecraft was declared operational on January 21, 1998, and continues to provide near-real-time 24/7 coverage of solar wind parameters and measure solar energetic particle intensities.","['197\n1997\n186\nACE\nNation: USA (71)\nObjective(s): Sun–Earth L1 Lagrange Point\nSpacecraft: ACE\nSpacecraft Mass: 752 kg\nMission Design and Management: NASA / GSFC\nLaunch Vehicle: Delta 7920-8 (no.  D247)\nLaunch Date and Time: 25 August 1997 / 14:39 UT\nLaunch Site: Cape Canaveral Air Force Station / \nLaunch Complex 17A\nScientific Instruments:\n1.\t solar wind ion mass spectrometer (SWIMS) \nand solar wind ion composition spectrome\xad\nter (SWICS)\n2.\t ultra-low energy isotope spectrometer \n(ULEIS)\n3.\t solar energetic particle ionic charge ana\xad\nlyzer (SEPICA)\n4.\t solar isotope spectrometer (SIS)\n5.\t cosmic ray isotope spectrometer (CRIS)\n6.\t solar wind electron, proton, and alpha mon\xad\nitor (SWEPAM)\n7.\t electron, proton, and alpha-particle monitor \n(EPAM)\n8.\t magnetometer (MAG)\n9.\t real time solar wind experiment (RTSW)\nResults: The Advanced Composition Explorer \n(ACE) spacecraft was designed to study space\xad\nborne energetic particles from the Sun–Earth L1 \nlibration point, about 1.4 million kilometers from \nEarth.  Specifically, the spacecraft was launched \nto investigate the matter ejected from the Sun to \nestablish the commonality and interaction between \nthe Sun, Earth, and the Milky Way galaxy.  In addi\xad\ntion, ACE also provides real-time space weather \ndata and advanced warning of geomagnetic storms. \n ACE’s nine instruments have a collecting power \nthat is 10 to 10,000 times greater than anything \npreviously flown. ', '197\n1997\n186\nACE\nNation: USA (71)\nObjective(s): Sun–Earth L1 Lagrange Point\nSpacecraft: ACE\nSpacecraft Mass: 752 kg\nMission Design and Management: NASA / GSFC\nLaunch Vehicle: Delta 7920-8 (no.  D247)\nLaunch Date and Time: 25 August 1997 / 14:39 UT\nLaunch Site: Cape Canaveral Air Force Station / \nLaunch Complex 17A\nScientific Instruments:\n1.\t solar wind ion mass spectrometer (SWIMS) \nand solar wind ion composition spectrome\xad\nter (SWICS)\n2.\t ultra-low energy isotope spectrometer \n(ULEIS)\n3.\t solar energetic particle ionic charge ana\xad\nlyzer (SEPICA)\n4.\t solar isotope spectrometer (SIS)\n5.\t cosmic ray isotope spectrometer (CRIS)\n6.\t solar wind electron, proton, and alpha mon\xad\nitor (SWEPAM)\n7.\t electron, proton, and alpha-particle monitor \n(EPAM)\n8.\t magnetometer (MAG)\n9.\t real time solar wind experiment (RTSW)\nResults: The Advanced Composition Explorer \n(ACE) spacecraft was designed to study space\xad\nborne energetic particles from the Sun–Earth L1 \nlibration point, about 1.4 million kilometers from \nEarth.  Specifically, the spacecraft was launched \nto investigate the matter ejected from the Sun to \nestablish the commonality and interaction between \nthe Sun, Earth, and the Milky Way galaxy.  In addi\xad\ntion, ACE also provides real-time space weather \ndata and advanced warning of geomagnetic storms. \n', 'After reaching apogee \na month after launch, ACE inserted itself into its \nLissajous orbit around the L1 point.  The spacecraft \nwas declared operational on 21 January 1998 with \na projected two- to five-year lifetime.  As of early \n2015, it continues to provide near-real-time 24/7 \ncoverage of solar wind parameters and measure \nsolar energetic particle intensities.  With the excep\xad\ntion of the SEPICA instrument (data from which \nwas no longer received after 4 February 2005), all \ninstruments on ACE remain operational as of mid-\n2017, and the propellant on board could theoreti\xad\ncally allow a mission until about 2024.\n 187\nCassini-Huygens\nNation: US and ESA (3)\nObjective(s): Saturn orbit, Titan landing\nSpacecraft: Cassini and Huygens\nSpacecraft Mass: 5,655 kg\nMission Design and Management: NASA / JPL / ESA\nLaunch Vehicle: Titan 401B-Centaur (TC-21 / Titan \n401 no.  4B-33)\nLaunch Date and Time: 15 October 1997 / 08:43 UT\nLaunch Site: Cape Canaveral Air Force Station / \nLaunch Complex 40\n', 'NASA′s Discovery Program\n176\nEach of these questions drove a science objective for the mission, and each of the \nscience objectives was addressed by a well-defined set of measurement objectives that \ncould be reached by two or more instruments in the suite of seven that made up the \npayload.19 The answers to those questions had great generality for understanding each \nof the inner planets—not just Mercury.\n The direct tracing of objectives to measurements to instruments, and ultimately to \nspacecraft and mission design, contributed significantly to the ability of the mission to \nbe “ambitious in its scientific scope for a Discovery mission, a tribute to the fact that \nscientific requirements guided the development of spacecraft and mission design at \nevery stage in the project, from initial concept through all design trades and testing,” \nand mission operations.20\nThe seven instruments were designed to measure a wealth of data about the surface, \natmosphere, and magnetosphere of this largely unknown planet.  Not only would the \nmission bring back global maps of Mercury, but also a wealth of information about its \ngeochemistry, geology, geophysics, thin atmosphere, and active magnetosphere.  The \nteam wanted to cover as many bases as an orbiter would permit.21\nSolomon explained that, at the time, the most fundamental question the team was \nmost interested in answering is how Mercury got put together and what the processes \nwere that contributed to the inner planets turning out so differently from the outer \nplanets.  “They formed by common processes,” he said. ', 'Some members of the \npanel were intrigued, though Don Hunten of the Lunar and Planetary Laboratory at \nthe University of Arizona, as well as other scientists who were more familiar with the \nearlier failures, challenged Krimigis to brief the strategic planning committee on the \nways Explorer succeeded where Planetary Observer failed—and to give a presenta\xad\ntion the next morning.  This was the pre-PowerPoint era of viewgraphs, a time when \npresentations took hours to create, with painstaking effort.\n NASA schedules are demanding, and that week was no exception.  Just a few days \nearlier, Krimigis had reported to NASA’s Goddard Space Flight Center (GSFC) on the \nresults of a Phase A study—that is, the study of a baseline mission concept—of a space \nphysics project called the Advanced Composition Explorer (ACE), led by a single PI, \nEd Stone of the California Institute of Technology.  ACE was competing for a slot in \nthe Explorer Program.  The fate of the ACE proposal was then unknown, but because \n9 \t\nNiebur, S.  (2009, 10 September). ']","
The mission objective of the ACE spacecraft is to study space-borne energetic particles from the Sun-Earth L1 libration point, about 1.4 million kilometers from Earth. The spacecraft was launched to investigate the matter ejected from the Sun to establish the commonality and interaction between the Sun, Earth, and the Milky Way galaxy. In addition, ACE also provides real-time space weather data and advanced warning of geomagnetic storms.

The scientific instruments used to achieve these objectives are:
1. solar wind ion mass spectrometer (SWIMS) and solar wind ion composition spectrometer (SWICS)
2. ultra-low energy isotope spectrometer (ULEIS)
3. solar energetic particle ionic charge analyzer (SEPICA)
4. solar isotope spectrometer (SIS)
5. cosmic ray isotope spectrometer (CRIS)
6. solar wind electron, proton, and alpha monitor (SWEPAM)
7. electron, proton, and alpha-particle monitor (EPAM)
8. magnetometer (MAG)
9. real time solar wind experiment (RTSW)"
"What are some examples of how space research has provided benefits for humanity, as described in the given context information?","1. The space station has enabled research that is providing a better understanding of many aspects of human health, including aging, trauma, disease, and environmental impacts. These results include new ways to mitigate bone loss, insights into bacterial behavior, and innovative wound-healing techniques.

2. The ISS has enabled more than 2,500 research and technology development investigations, generating more than 2,100 scientific publications across a diverse spectrum of fields. The Scientific Value section provides many examples of new knowledge and data sets generated or refined through ISS activities.

3. The ISS has generated concrete economic value from space-based ventures, with emerging companies and products, lines of research, and the growing commercial marketplace in LEO.

4. The ISS has hosted a significant number of pharmaceutical company investigations, including Eli Lilly, Merck, Taiho Pharmaceutical, and PeptiDream, which provide many examples of potential humankind benefits, including the crystallization of a protein of interest to researchers focused on Duchenne’s muscular dystrophy.

5. Commercial research facilities onboard the space station have greatly increased the breadth and volume of ISS-supported research since 2012.

6. The ISS U.S. National Laboratory also hosts a significant number of PCG experiments, which provide many examples of potential humankind benefits, including the crystallization of a protein of interest to researchers focused on Duchenne’s muscular dystrophy.

7. The ISS has enabled the generation of new knowledge and technological capabilities from which potential benefits emerge in the form of new theories, data sets, and conceptual applications. A series of investigations known as Flame Extinguishment (FLEX) provide one such example of new knowledge being generated.

8. The ISS has facilitated the commercialization of space utilization, with commercial research facilities evolving in recent years from primarily government funded and operated to commercially owned and operated.

9. The ISS has provided benefits to humanity in the form of catalysts for technological innovations, space utilization, and commercialization.

10. The ISS has enabled research that is providing a better understanding of many aspects of human health, including aging, trauma, disease, and environmental impacts, which can","['During its time in orbit, the \nspace station has enabled research that is providing a better understanding of \nmany aspects of human health including aging, trauma, disease and environmental \nimpacts.  Driven by the need to support astronaut health, several biological and \nhuman physiological investigations have yielded important results that can benefit \nus here on Earth.  These results include new ways to mitigate bone loss, insights \ninto bacterial behavior, and innovative wound-healing techniques.  Advances in \ntelemedicine, disease models, psychological stress response systems, nutrition \nand cell behavior are just a few more examples of the benefits that have been \ngained from applying studies in orbit to human health back on Earth.\n', '3\nInternational Space Station Economic Value\nIn the 20 years since the first International Space Station (ISS) module was launched, access to \nthe environment of low-Earth orbit (LEO) for researchers around the globe has made gravity another \nvariable for their experiments.  Since 1998, the ISS has enabled more than 2,500 research and \ntechnology development (R&D) investigations, generating more than 2,100 scientific publications across \na diverse spectrum of fields.  The Scientific Value section provides many examples of new knowledge \nand data sets generated or refined through ISS activities.  As this new knowledge begins to shape the \nthinking of researchers and technological innovators back on Earth, new commercial products and \nventures are beginning to emerge and new lines of research are being explored—all demonstrating \nhow space exploration and the unique features of microgravity and space-based research can improve \nour lives here at home.\n The process of generating concrete economic value from space-based ventures often resembles the \nproverbial long-and-winding road.  Likewise, the many milestones and activities on the road to a mature \nproduct can make it difficult to trace benefits back to ISS beginnings.  With these caveats in mind, this \nsubsection aims to illustrate the benefits of the ISS by providing representative examples of ISS R&D \nactivities and ISS-derived technologies, and tracing their forward influence on emerging companies \nand products, lines of research and the growing commercial marketplace in LEO.\n', 'In these cases either the research was too recent to have generated more than broad \npossibilities, or detailed information was not publicly available. \n The Summaries of Valuation Findings table found at the end of this section lists key findings as grouped \nby primarily innovative, prospective (potential), or retrospective (concrete) findings.  Taken as a whole, \nthese findings exemplify the diverse benefits generated to date, as well as some of the potential benefits \nyet to come.  Some of these benefit examples are discussed in greater detail below and serve to illustrate \ncommon characteristics of the paths taken as new knowledge bubbles up toward concrete benefits. \n From New Knowledge to Potential \nApplication: Generating Prospective \nBenefits on the International \nSpace Station\nAs discussed above, fundamental research and \ndevelopment efforts on the International Space Station \n(ISS) are many and varied in their scope.  These efforts \nhave generated new knowledge and technological \ncapabilities from which potential benefits emerge in \nthe form of new theories, data sets and conceptual \napplications.  A series of investigations known as \nFlame Extinguishment (FLEX) provide one such \nexample of new knowledge being generated. ', '65\nCommercial Research, Facilities and Service Providers\nThe International Space Station (ISS) is not a traditional asset where concepts such as return \non investment (ROI), payback period or risk-adjusted return are easily applied.  Instead, the ISS \nbenefits to humanity emerge as catalysts for technological innovations, space utilization and, \nmore recently, commercialization.  Research facilities onboard the space station have evolved \nin recent years from primarily government funded and operated to commercially owned and \noperated.  Since 2012, commercial research facilities have greatly increased the breadth and \nvolume of ISS-supported research. \n\n\n\n\n\n Commercial Partners Expanding \nInternational Space Station  \nResearch Capabilities\nDuring the first six crew rotations aboard the space \nstation, 166 research and technology development \n(R&D) investigations were conducted. ', 'The ISS U.S. \n National Laboratory also hosts a significant number of \nPCG experiments.  Many pharmaceutical companies, \nincluding Eli Lilly, Merck, Taiho Pharmaceutical, and \nPeptiDream, have conducted PCG investigations \non the space station.  These activities provide many \nexamples of potential humankind benefits, which \nwould have high economic value as well.\n One such investigation, JAXA PCG, crystallized \na protein of interest to researchers focused on \nDuchenne’s muscular dystrophy (DMD).  DMD is a \nsevere condition that causes progressive muscular \ndegeneration, often leaving the affected patients unable \nto walk by early adolescence.  In 2002, a research \ninvestigation revealed a specific protein (H-PGDS) \nthat was expressed in necrotic muscle fibers in DMD \npatients. ']","1. Non-invasive Collection of Saliva Helps Monitor Stress Levels in Real Time: This research by NASA helps in monitoring stress levels in real time using saliva samples, which can be beneficial for people in high-stress jobs or situations.
   2. Cold Plasmas Assist in Wound Healing: This research by ESA has shown that cold plasmas can help in wound healing, which can be beneficial for people with slow-healing wounds or chronic wounds.
   3. Understanding Asthma from Space: This research by ESA helps in understanding asthma and its triggers, which can be beneficial for people with asthma.
   4. Bringing Space Station Ultrasound to the Ends of the Earth: This research by NASA has developed a portable ultrasound device that can be used in remote areas, which can be beneficial for people living in remote areas without access to medical facilities.
   5. Giving Voice to People with Disabilities: This research by ESA has developed a communication device for people with disabilities, which can be beneficial for people with speech impairments or other communication difficulties.
   6. Preventing Bone Loss in Spaceflight with Prophylactic use of Bisphosphonate: Health Promotion of the Elderly by Space Medicine Technologies: This research by JAXA has shown that bisphosphonate can prevent bone loss in spaceflight, which can be beneficial for elderly people on Earth who are at risk of osteoporosis.
   7. Improved Scanning Technologies and Insights into Osteoporosis: This research by ESA has developed improved scanning technologies for osteoporosis, which can be beneficial for people with osteoporosis.
   8. Add salt? Astronauts’ bones say please don’t: This research by ESA has shown that a low-salt diet can prevent bone loss in spaceflight, which can be beneficial for people on Earth who are at risk of osteoporosis.
   9. Interdisciplinary Approach to Human Health: Preventing Bone Loss in Space Helps Health Promotion of the Elderly on Earth: This research by JAXA has shown that preventing bone loss in spaceflight can also prevent bone loss in elderly people on Earth.
   10. Tackling Immune System Dysfunction—from Multiple Angles: This research by NASA has shown that immune system dysfunction can be tackled from multiple angles, which can be beneficial for people with weakened immune systems.
   11. Early Detection of Immune Changes Prevents Painful Shingles in Astronauts and in Earthbound Patients: This research by NASA has shown that early detection of immune changes can prevent painful shingles, which can be beneficial for people on Earth who are at risk of shingles.
   12. Monitoring and Understanding Astronaut Immune Systems in Spaceflight: This research by ESA helps in monitoring and understanding astronaut immune systems in spaceflight, which can be beneficial for people on Earth who are at risk of immune system disorders.
   13. Space Station Immunology Insights for Earth and Space: This research by NASA has shown that space station immunology insights can be beneficial for people on Earth who are at risk of immune system disorders.
   14. Targeted Treatments Improve Immune Response: This research by ESA has shown that targeted treatments can improve immune response, which can be beneficial for people with weakened immune systems.
   15. Getting to the Bottom of Humans’ Greatest Infection: Periodontal Disease: This research by JAXA helps in understanding periodontal disease and its causes, which can be beneficial for people with periodontal disease.
   16. Improving Treatments with Tiny Crystals: This research by NASA has shown that tiny crystals can improve treatments, which can be beneficial for people with various medical conditions.
   17. Using Ultrasound to Zap Kidney Stones and Other Health Problems in Space: This research by ESA has shown that ultrasound can be used to zap kidney stones and other health problems in space, which can be beneficial for people on Earth who have kidney stones or other health problems.
   18. Cancer-targeted Treatments from Space Station Discoveries: This research by NASA has developed cancer-targeted treatments from space station discoveries, which can be beneficial for people with cancer.
   19. Using Weightlessness to Treat Multiple Ailments: This research by IBMP RAS has shown that weightlessness can be used to treat multiple ailments, which can be beneficial for people with various medical conditions"
"How have the latest autogiros evolved in appearance compared to those of 1925, in terms of their fuselage, undercarriage, tail, ailerons, and rotary wings?","According to the given text, the latest autogiros have a different appearance compared to those of 1925. The fuselage is shorter, the undercarriage is wider, and the tail is of a peculiar design. However, there is no mention of any changes in the ailerons or rotary wings.","['The Wind and Beyond, Volume III\n554\nsecond.  I will deal later in this paper with the theory of the purely vertical descent, \none of the more discussed performances of the autogiro.\n The latest autogiros have an appearance rather different from those of 1925. \n They are no longer transformed \naeroplanes; and fuselage, under\xad\ncarriage and tail have been grad\xad\nually transformed to suit better \nthe necessities of the new system \n(Figs.  1 and 2).  The undercar\xad\nriage is wider, the fuselage shorter \nand the tail is of a peculiar \ndesign. ', 'Of the fourteen types which had been \nproduced recently in this and other countries, the inventor and designer, Senor [sic] \nde la Cierva, had himself made all the first tests; so he at least had absolute confi\xad\ndence in his own invention.\n THE AUTOGIRO BY\nJ. DE LA CIERVA\n(INGENIERO DE CAMINOS, CANALES Y PUERTOS E INGENIERO \nDE CONSTRUCCIONES AERONAUTICAS)\nI have, for the second time, the honour of addressing you.  Four years ago I \ntold you how I had had the good fortune to discover a new method of flying with \ncharacteristics altogether different from the conventional aeroplane.\n To-day, taking advantage of your kind invitation, I come to tell you of how \nthe crude experimental autogiros of 1925 have been developed into practical flying \nmachines.  I will also deal with a number of theoretical points in justification of the \nassertions I have often made about the qualities of the autogiro and in answer to the \ncriticisms of which my system has been made the object from time to time.\n I have, at the risk of giving the impression of not understanding my own dis\xad\ncovery, preferred to remain practically silent for years, giving only expression to my \nfaith in the future.  I was waiting to have enough experimental evidence to check \nmy theories, which I have not had until quite recently, because of the secondary \ndifficulties which make any development of this kind so slow and painful. ', 'In the 1960s, Japan’s Kawasaki and Mitsubishi firms began building helicopters. \n Other designs were produced in Argentina, Australia, Belgium, Brazil, Canada, \nCzechoslovakia, the Netherlands, Poland, Romania, Spain, and—by the 1980s—\neven in India, South Africa, Sweden, and Yugoslavia.  And not all of these aircraft \ninvolved helicopters.  New types of autogiros as well as what came to be called \n“compound aircraft” were also produced, particularly by Britain’s Fairey Aviation \nCompany.  One of the compound aircraft that Fairey pioneered was the “gyrodyne,” \na type of helicopter whose rotor (or rotors) provided lift only but whose motive \npower was provided either by a propeller or by jet.  Fairey’s first gyrodyne, the FB-\n1, which flew in the late 1940s, had a propeller on the end of a stub wing that \nprovided both propulsion and antitorque.  The company went on to develop a Jet \nGyrodyne that was driven by little jets set into the tips of the rotor blade. ', 'But he came away from that visit more interested in the autogiro, \nthough he continued to conduct helicopter experiments into 1928, dropping his \nantitorque vanes in favor of a jet-driven rotor.  A major aspect of this test program \nby 1928, however, centered on the transition of a helicopter in flight from powered \nlift to descent via autorotation, a concept for which Cierva was the main influence. \n It was this work that led Pitcairn to drop his helicopter work and focus on the \nautogiro.  Again, the reason for the switch to the autogiro in the late 1920s seems \nto have been the technical frustrations blocking the design of a true helicopter and \nthe desire for what at the time appeared to be a more practical machine.  As early \nas 1920, Pitcairn had told a friend that he wanted “a single-rotored helicopter” but \nthat he did not care if it had a propeller out front or not.\n As the 1930s proceeded, developments in the technology of rotary-wing flight \nbrought Pitcairn back to the matter of helicopters.  His Autogiro Company of \nAmerica patented several hundred inventions, many of them—as lengthy lawsuits \ndemonstrated—directly applicable to helicopters. ', 'Data \nthat show the influence of blade pitch setting, solidity, and feathering angle upon \nthe rotor characteristics have been obtained; the effect of feathering angle upon the \ncontrol moments available was also studied.\n Document 5-39 (d), Excerpts from Annual Report of the National \nAdvisory Committee for Aeronautics (Washington, DC), 1933–40, \n“Rotating-Wing Aircraft,” Annual Report (1936), pp.  16–17.\n The detailed development and steady progress of rotating-wing aircraft during \nthe past year are attested by the construction of several new models of autogiros \nfar superior to any previous ones.  The steadily widening field of application of this \ntype of aircraft more than justifies the vigorous prosecution of research directed \ntoward increase in efficiency and the elimination of secondary difficulties arising \nin a design.\n A report has been published (Technical Report No.  552) containing the results \nof wind-tunnel tests on a family of models of autogiro rotors of 10-foot diameter \nin the 20-foot wind tunnel. ']","
The latest autogiros have an appearance rather different from those of 1925. They are no longer transformed aeroplanes. The fuselage is shorter, the undercarriage is wider, and the tail is of a peculiar design. The ailerons, which in 1925 were fixed on a transverse beam or stick, are now supported by small fixed wings, such as the bottom plane of a sesquiplane. The rotary wings are of a different shape and construction. Their main characteristics are the smoothness of the skin, the local strength of the same to prevent deformation under very high unitary loads, and the considerable flexibility of the whole blade in a plane perpendicular to that of rotation. The blades are hinged to a central hub as in the old machines, so as to allow free flapping in flight. A secondary hinge perpendicular to the first is also provided, allowing a certain freedom between two consecutive blades. Those two articulations give the maximum degree of freedom that rotary wings can have without becoming unstable with relation to the axis of rotation in horizontal motion."
"Question: ""What is the importance of helium for airships and what measures are being taken to preserve the sources of supply?""","The importance of helium for airships is that it has advantages over any other known gas, making its use imperative for military and naval airships in time of war, provided it can be made available in sufficient quantity. The National Advisory Committee for Aeronautics recommends that the Government acquire and seal for future use the best helium-producing gas fields, and continue experimental work in connection with the development of airships, and inaugurate without delay the use of airships inflated with helium. The committee also recommends that attention be given to the development of methods of production and storage, and that every practicable effort be made both to increase production and to decrease cost, having due regard for conservation of the sources of supply for military purposes.","['The committee at this time reiterates this recommendation, and \nexpresses its belief that this experimental development is of vital importance to the \neffectiveness of the Army and Navy in time of war, and particularly to the military \nand naval air services as combatant arms.\n Document 5-2 (b), “Production of Helium,” NACA Annual Report (1920), p.\xa019.\n PRODUCTION OF HELIUM\nAt the semiannual meeting of the full committee, held in April, 1920, consid\xad\neration was given to the question of the production of helium.  Helium had such \nadvantages over any other known gas as to make its use imperative for military \nand naval airships in time of war, provided it can be made available in sufficient \nquantity.  In letters to the Secretary of War, the Secretary of the Navy, and the \nSecretary of the Interior, the committee stated that it is necessary to encourage the \neconomical production of helium in order that an increased demand may bring \nabout a greater increase in the supply, a simplification of the processes of extrac\xad\ntion, and a lessening of the cost of production.  The committee especially invited \ntheir attention to the necessity for thoroughly investigating all sources from which \nhelium may be extracted or secured, and recommended that every practicable effort \nbe made both to increase production and to decrease cost, having due regard for \nconservation of the sources of supply for military purposes.\n', '5.\n HELIUM AND AIRSHIPS\nThe United States has a virtual monopoly of the known sources of supply of \nhelium, and these are limited.  Experiments have been conducted by the Bureau of \nMines with a view to the development of methods of production and storage, but \nas yet the problem of storage in large quantities has not been satisfactorily solved. \n Because the known supply is limited, because it is escaping into the atmosphere \nat an estimated rate sufficient to fill four large airships weekly, and because of \nthe tremendously increased value and safety which the use of helium would give \nto airships, particularly in warfare, it is, in the opinion of the National Advisory \nCommittee for Aeronautics, the very essence of wisdom and prudence to provide \nfor the conservation of large reserves through the acquisition and sealing by the \nGovernment of the best helium-producing fields.  Attention now being given to the \ndevelopment of types of airships to realize fully the advantages which the use of \nhelium would afford should be continued.  Such development would give America \nadvantages, for purposes either of war or commerce, with which no other nation \ncould successfully compete.\n Document 5-2 (d), “Airship Development,” \nNACA Annual Report (1921), pp. ', 'The Wind and Beyond, Volume III\n72\nDocument 5-2 (c), “Helium and Airships,” NACA Annual Report (1921), p.  5.\n HELIUM AND AIRSHIPS\nThe United States has a virtual monopoly of the known sources of supply of \nhelium, and these are limited.  Experiments have been conducted by the Bureau of \nMines with a view to the development of methods of production and storage, but \nas yet the problem of storage in large quantities has not been satisfactorily solved. \n Because the known supply is limited, because it is escaping into the atmosphere \nat an estimated rate sufficient to fill four large airships weekly, and because of \nthe tremendously increased value and safety which the use of helium would give \nto airships, particularly in warfare, it is, in the opinion of the National Advisory \nCommittee for Aeronautics, the very essence of wisdom and prudence to provide \nfor the conservation of large reserves through the acquisition and sealing by the \nGovernment of the best helium-producing fields.  Attention now being given to the \ndevelopment of types of airships to realize fully the advantages which the use of \nhelium would afford should be continued. ', 'PRODUCTION OF HELIUM\nAt the semiannual meeting of the full committee, held in April, 1920, consid\xad\neration was given to the question of the production of helium.  Helium had such \nadvantages over any other known gas as to make its use imperative for military \nand naval airships in time of war, provided it can be made available in sufficient \nquantity.  In letters to the Secretary of War, the Secretary of the Navy, and the \nSecretary of the Interior, the committee stated that it is necessary to encourage the \neconomical production of helium in order that an increased demand may bring \nabout a greater increase in the supply, a simplification of the processes of extrac\xad\ntion, and a lessening of the cost of production.  The committee especially invited \ntheir attention to the necessity for thoroughly investigating all sources from which \nhelium may be extracted or secured, and recommended that every practicable effort \nbe made both to increase production and to decrease cost, having due regard for \nconservation of the sources of supply for military purposes.\n', 'Helium for current uses, however, will continue to be stored in high-pressure \ncontainers until used.\n In connection with the consideration of an airship development policy, the \ncommittee presents as the crystallized opinion of the Government experts who have \nstudied the helium problem that in helium the United States has exclusive posses\xad\nsion of a valuable adjunct to national defense which will be wasted unless conserva\xad\ntion is provided for without delay.\n The National Advisory Committee for Aeronautics therefore recommends \nthat the Government acquire and seal for future use the best helium-producing \ngas fields; that such experiments be continued as are involved in the develop\xad\nment of an efficient and economical process for the extraction and repurification \nof helium; and that the Government continue experimental work in connection \nwith the development of airships, and inaugurate without delay the use of airships \ninflated with helium.  With large reserves of helium and the development of types \nof airships to fully realize the advantages to be derived from the use of helium, \nAmerica would possess resources and knowledge with which no other nation could \nsuccessfully\xa0compete.\n Document 5-2 (f), “The Electrostatic Problem of \nAirships,” NACA Annual Report (1921), p.  22.\n THE ELECTROSTATIC PROBLEM FOR AIRSHIPS\nThe question of the danger to airships from static charges of electricity and \nfrom lightning was referred to the committee, and a large amount of data was col\xad\nlected. ']","

Helium is the second lightest gas after hydrogen and has 92% of the lifting power of hydrogen. It is nonflammable, making it advantageous for military purposes. The United States has a practical monopoly of the known sources of supply of helium, with natural-gas wells being the primary source. However, helium is escaping into the atmosphere at a rate of one and a quarter million cubic feet a day, which is sufficient to fill four large airships a week. At this rate, the great resources will have become dissipated within the next 20 years unless appropriate measures are taken to preserve the sources of supply.

The refrigeration process is employed to obtain helium, where every constituent present in the natural gas is liquefied except helium, which is expelled into suitable containers for storage. The application of this process to the extraction of helium has not been perfected, but the line of development is reasonably clear. The Army, the Navy, and the Bureau of Mines are carrying out certain developments to solve the production problem. The Bureau of Mines is also conducting experiments to determine whether underground-chamber storage is practicable and economical."
Question: What are the features of the ladies' dressing room on the aircraft?,"The ladies' dressing room on the aircraft is furnished in the modern style and is equipped with a hand lavatory with hot and cold running water, a dental lavatory, and a large double dressing table complete with four lights, two large plateglass mirrors, two benches, receptacles for Kleenex, etc. A ladies' toilet compartment opens from this dressing room. Each toilet on this ship is equipped with a standard size toilet seat and is of the flushing type. The flushing water is the waste water from the hand and dental lavatories.","['In \naddition, there are two drinking fountains, one on each end of the passengers’ deck. \n Incidentally, the galley equipment was designed and built by Pan American\xa0Airways.\n The ladies’ dressing room is furnished in the modern style and is equipped \nwith a hand lavatory with hot and cold running water, a dental lavatory and a large \ndouble dressing table complete with four lights, two large plateglass mirrors, two \nbenches, receptacles for Kleenex, etc.  A ladies’ toilet compartment opens from this \ndressing room.  Incidentally, each toilet on this ship is equipped with standard size \ntoilet seat and is of the flushing type.  The flushing water is the waste water from the \nhand and dental lavatories.  As the toilet top is raised, a cylinder is filled with this \nwater and when the lid is lowered this cylinder discharges the water, flushing the \ntoilet bowl[,] and then the contents are dumped outside the aircraft.\n', '347\nDocument 5-23 (a–c)\nfoodstuffs and galley supplies is 256 pounds[,] making a total of 490 pounds.  In \naddition, there are two drinking fountains, one on each end of the passengers’ deck. \n Incidentally, the galley equipment was designed and built by Pan American\xa0Airways.\n The ladies’ dressing room is furnished in the modern style and is equipped \nwith a hand lavatory with hot and cold running water, a dental lavatory and a large \ndouble dressing table complete with four lights, two large plateglass mirrors, two \nbenches, receptacles for Kleenex, etc.  A ladies’ toilet compartment opens from this \ndressing room.  Incidentally, each toilet on this ship is equipped with standard size \ntoilet seat and is of the flushing type.  The flushing water is the waste water from the \nhand and dental lavatories. ', 'As the toilet top is raised, a cylinder is filled with this \nwater and when the lid is lowered this cylinder discharges the water, flushing the \ntoilet bowl[,] and then the contents are dumped outside the aircraft.\n The men’s dressing room is fitted with two hand lavatories with hot and cold \nrunning water, one dental lavatory and, believe it or not, a stand up urinal.  This \nurinal will no doubt be an interesting innovation to the passengers.  A separate toilet \ncompartment opens off the men’s dressing room.\n The interior decorations throughout the passenger deck are in keeping with \nthe present-day trend of modern design, simple, functional, and in refreshing color \narrangement.  Fabrics for both upholstery and lining are interesting in texture and \ndesign and are all flameproofed.  All compartment lining and soundproofing is \nquickly removable for inspection and cleaning and, therefore, can be kept in excel\xad\nlent condition.\n', 'Based, in part, on the provisions for the crew and on the ease of inspection and \nmaintenance, we conclude that the second requirement for efficiency of operations \nis fulfilled.\n We now come to our third design criteria [sic] and, naturally, the one which \nmost concerns the traffic departments: the passenger accommodations.  The design \nproblem was to provide passenger accommodations which embodied unprece\xad\ndented comfort, spaciousness, and luxury at reasonable weight and cost.\n The passengers’ deck is divided into eleven sections: five standard compart\xad\nments seating ten and sleeping six, one special compartment seating four and sleep\xad\ning two, one deluxe compartment seating six and sleeping two, and a dining salon \nseating fourteen at five tables, a galley, a dressing room for men, a dressing room for \nthe ladies, and three toilet compartments.\n Thus, for this standard arrangement, seventy-four passengers can be seated in \nthe daytime, at night thirty-four berths may be set up, still leaving fourteen seats \n', 'Likewise, oil tanks, valves, and the greater \nportion of the plumbing for the engine lubrication, deicer fluid, hydraulic oil, water \nvacuum and fuel systems were also made accessible in flight.  This means that \ninspections may be made periodically during flight and any malfunction can be \nimmediately diagnosed.\n The design objective of unusually large and luxurious passenger accommoda\xad\ntions in the Clipper was readily realizable because of the great space allowed in the \npassenger deck.  The whole was divided into a series of adjoining passenger cabins, \nequipped with davenport-type seats convertible into upper and lower berths, deluxe \ncompartment with special furnishings and complete privacy, roomy and modern \ndressing rooms, a completely equipped galley, [and] a large centrally-located dining \nsalon and recreation center, where passengers can mix and enjoy social pastime.\n']","
The ladies' dressing room on the aircraft is furnished in the modern style and equipped with a hand lavatory with hot and cold running water, a dental lavatory, a large double dressing table complete with four lights, two large plateglass mirrors, two benches, receptacles for Kleenex, etc. A ladies' toilet compartment opens from this dressing room, and each toilet is equipped with a standard size toilet seat and is of the flushing type. The flushing water is the waste water from the hand and dental lavatories. As the toilet top is raised, a cylinder is filled with this water and when the lid is lowered, this cylinder discharges the water, flushing the toilet bowl, and then the contents are dumped outside the aircraft."
"What were the observations and recommendations made by SpaceRef in their ""Space Access Update"" on August 27 regarding the SLI funding issue, and what was their stance on the 'no conspicuous failure is acceptable' position for the X-34 project?","SpaceRef issued a ""Space Access Update"" on August 27, which made a number of observations and recommendations regarding the SLI funding issue. One of their recommendations was that ""X-34 should also be completed and flown, but NASA should immediately fund OSC in acquiring the Russian engine they wanted as insurance against further Fastrac problems, and NASA should back off the absurd and unaffordable ‘no conspicuous failure is accept­able’ position."" 
 <|>
In summary, SpaceRef recommended that NASA should complete and fly the X-34 project, but also fund OSC (Orbital Sciences Corporation) to acquire a Russian engine as insurance against further Fastrac problems. They also criticized NASA's 'no conspicuous failure is acceptable' position, calling it absurd and unaffordable.","['Whither X-34?\n 283\nThree days after the above release, SpaceRef issued a “Space Access Update” \non August 27, which made a number of observations and recommendations \nregarding the SLI funding issue, including that “X-34 should also be completed \nand flown, but NASA should immediately fund OSC in acquiring the Russian \nengine they wanted as insurance against further Fastrac problems, and NASA \nshould back off the absurd and unaffordable ‘no conspicuous failure is accept\xad\nable’ position.… This is an experimental vehicle project with three copies of the \nvehicle; a reasonable level of risk of damage to or loss of one of the vehicles is a \ngood tradeoff for lower cost and quicker results.” SpaceRef went on to question \nNASA’s way of doing business under the proposed SLI follow-on program, \nstating that “SLI, as we’ve been saying all year, should be split into NASA-\nspecific and U.S.  commercial support projects, with a solid firewall between \nthe commercial support project and the influence by the major NASA launch \nconsumer centers, lest they once again bend all NASA efforts toward solving \ntheir Shuttle-replacement problem at expense of practical engineering support \nfor the US launch industry.”80 \nX-34 “Then and Now” Snapshot\nComparison of the previous project with the restructured project illustrates \nthe significant changes that were directed and that changed the project to such \nextent that successful completion became highly unlikely.  These comparisons \nare reflected in Table 9.1.81\nX-34 Lessons Learned and Observations \nNoted by Its Program Managers\nIn interviews with the author, several X-34 program/project managers and \nsenior NASA officials noted a number of “strategic” lessons learned and prob\xad\nlems faced by the X-34 effort.  Robert E. Lindberg, Orbital’s first program \nmanager of the second X-34 program, stated that fixed-price agreements were \nnot the right arrangements for projects like the X-34 and that you need to \n“keep the project sold.”82 \nLindberg’s criticisms appear to have merit. ', 'The program was re-divided into four phases, with the fourth phase intended to \n“demonstrate Gen 2 [second generation] and Gen 3 RLV technologies utilizing \na highly reliable and robust X-34 vehicle.”77 \nStephen Creech, who served as NASA’s first X-34 resident manager and \nwho was involved in the integration policy following the 2000 restructuring, \nnoted that this final restructuring effort took place over a period of months, \nas opposed to as a series of formal directives.  He added that the restructuring \nrepresented a “pendulum swing” in risk tolerance at NASA following the Mars \nmission failures.  78 Indeed, the OIG’s recommendations and NASA’s project \nrestructuring did represent a “pendulum swing” away from the original X-34 \nprogram objectives; risk mitigation plans; industry-led concept; and faster, \nbetter, cheaper way of doing business. \n On August 24, 2000, SpaceRef reported on the actions recommended by \nthe Technical Interchange Meeting held in the spring of that year, noting \nthat “[i]t is all but certain that these new activities will lead to a substantial \nincrease in overall X-34 program cost and a significant delay in accomplish\xad\ning its goal [adding that] NASA has yet to identify the scope of these costs \nbut it is certain to be a prominent feature of the FY 2002 budget request \nnext year.” SpaceRef reported further that, “NASA is considering a reduc\xad\ntion in the number of flights from the currently planned 27 to perhaps 2 \nto 6 flights [and that] the maximum speed would also be reduced from the \nplanned speed of Mach\xa08 down to Mach 2.5.” Finally, SpaceRef commented \non the significant X-34 program change over earlier policy by pointing out \nthat “[t]his is a reversal of NASA’s previous thinking process since it revised \nthe original X-34 program to add an additional test vehicle and increase the \nnumber of test flights to 27.”79\n', 'Promise Denied\n300\nsuccess of the X-34 it became necessary to increase Government technical \ninsight, hardware testing, and integrated systems assessments.  As a result, the \nprojected cost of completing the X-34 program at an acceptable level of risk \nrose significantly above the planned budget.  NASA decided that such addi\xad\ntional funding for X-34 risk reduction would have to be completed within the \nSLI evaluation process.  As with the X-33, NASA determined that the benefits \nto be derived from continuing the X-34 program did not justify the cost.”13 \nNo Reprieve from the Air Force\nAs a final attempt to save both the X-33 and X-34, Lockheed Martin and \nOrbital Sciences looked to the Air Force to continue funding the projects. \n On August 28, 2001, Air Force Space Command officials presented a briefing \nto Air Force Chief of Staff, General Michael Ryan and Air Force Secretary \nJames Roche, on a $2 billion proposal to finish and fly the X-33 in tandem \nwith NASA’s X-37 experimental space maneuvering vehicle, but apparently no \nproposal concerning the X-34 was presented at the briefing.14 By September, \nhowever, the Air Force had decided not to take on either program.  Ryan retired \nfrom the Air Force in early September, replaced by General John Jumper, and it \nis possible the X-34 simply was caught in the inevitable change that takes place \nbetween service administrations. ', 'The subsequent decision to add redundancy \nto the X-34 apparently played a role in the restructuring that required a sig\xad\nnificant increase in funding (and, of course, caused further schedule slippage) \nas noted in the NASA FY 2000 Performance Report:\nEarly in the year, as a result of concerns over potential safety haz\xad\nards due to the lack of redundancy in the vehicle control systems, \nit was determined that the X-34 program should be restructured. \n A replanning activity was undertaken to address these concerns.  It \nresulted in a determination that a significant amount of additional \nfunding would be required on the part of the Government to \nmeet the revised flight plans.  Since making these additional funds \navailable would require the reallocation of resources planned for \nthe Space Launch Initiative (SLI), NASA decided that additional \nfunding for X-34 risk reduction should be completed within the \nSLI evaluation process.86\nAgainst these concerns, program adherents offered various arguments, sum\xad\nmarized in a presentation given at NASA Marshall on April 18, 2000, articulat\xad\ning the Center’s reasons for continuing the X-34 project: \n', 'In addition, as noted in congressional correspondence reviewed in chap\xad\nter\xa09, NASA, as early as September 1998, was considering not requesting fund\xad\ning for the RLV program as part of the Agency’s fiscal year 2000 budget request. \n Likewise, during the fall of 1999, NASA was already laying the groundwork \nfor the follow-on Space Launch Imitative through an effort known as the \nIntegrated Space Transportation Plan (ISTP).  This planning project, which also \nwas reviewed in chapter 9, was taking place at the same time that NASA was \nplanning for the restructuring of the X-34 project, an effort that raised the cost \nto a level that would have required funding through the SLI program.  Finally, \naccording to feedback received by Orbital from an engineer familiar with the \nSLI review team effort, NASA rejected the team’s initial recommendation to \nfund the X-34 project as part of the SLI program. \n Was the Right Engine Baselined for the X-34? \n NASA merged two separate programs that each could have been successful \non its own, but experienced problems when combined.  NASA Marshall, by \nmost accounts, accomplished major goals in the development of the Fastrac \nengine and in training a new generation of propulsion engineers. ']","
SpaceRef made several observations and recommendations regarding the SLI funding issue in their ""Space Access Update"" on August 27. They suggested that X-34 should be completed and flown, but NASA should immediately fund OSC in acquiring the Russian engine they wanted as insurance against further Fastrac problems. NASA should also back off the 'no conspicuous failure is acceptable' position, as it is an experimental vehicle project with three copies of the vehicle, and a reasonable level of risk of damage to or loss of one of the vehicles is a good tradeoff for lower cost and quicker results. SpaceRef also questioned NASA's way of doing business under the proposed SLI follow-on program and recommended that SLI should be split into NASA-specific and U.S. commercial support projects, with a solid firewall between the commercial support project and the influence by the major NASA launch consumer centers.

Regarding the 'no conspicuous failure is acceptable' position for the X-34 project, SpaceRef argued that it was an unreasonable and unaffordable stance, given the experimental nature of the project. They suggested that a reasonable level of risk of damage to or loss of one of the vehicles was a good tradeoff for lower cost and quicker results."
"How might giant impacts on Earth serve as a means to transfer life between planets, as suggested by Sleep and Zahnle in 1998?","In 1998, Sleep and Kevin Zahnle of NASA Ames Research Center suggested that giant impacts on Earth might also serve as a means to transfer life between planets. Huge impacts on Earth would inevitably blast rocks containing microscopic life into space, some of which would just as inevitably crash onto Venus, Mars, Earth’s Moon, etc.—and some of these rocks would eventually return to Earth. Rocks returning to Earth could serve as a space-based “refugia” for life and reseed Earth after a sterilizing impact. Conversely, many astrobiologists believed Mars was habitable before Earth had cooled enough to become habitable, meaning that life on Earth might have originated on Mars and then been seeded here by a giant impact.","['Statistically, the smaller impact could have happened more recently than the \nlarger “minimum ocean evaporating” impact by a few hundred million years, \nraising the possibility that life evolved very early, was extinguished by a more \nrecent impact, and restarted.  In effect, giant impacts could serve as reset but\xad\ntons.  The last reset for Earth could have been as recent as 3.8 billion years \nago.66 In the case of the smaller impactor, while surface life might be anni\xad\nhilated, the ocean floors might have served as a kind of refuge for the small \nnumber of surviving species, if early life had existed in that environment.  But \nin 1989, there was no evidence of deep ocean life at 3.8 billion years ago.67\nIn a 1998 paper, Sleep and Kevin Zahnle of NASA Ames Research Center \nsuggested that giant impacts might also serve as a means to transfer life \nbetween planets.  Huge impacts on Earth would inevitably blast rocks con\xad\ntaining microscopic life into space, some of which would just as inevitably \nwind up crashing onto Venus, Mars, Earth’s Moon, etc.—and some of these \nrocks would eventually return to Earth.  Rocks returning to Earth could serve \nas a space-based “refugia” for life and reseed Earth after a sterilizing impact. \n Conversely, many astrobiologists believed Mars was habitable before Earth \nhad cooled enough to become habitable, meaning that life on Earth might \nhave originated on Mars and then been seeded here by a giant impact. ', 'Chapter 4: Cosmic Impacts and Life on Earth\n81\ncreation of man, would be the likely consequence of a comet striking Earth.4 \nIn 1903, arguing against the possibility of impacts, N. S. Shaler contended \nthat “the fall of a bolide of even ten miles in diameter would have been suf\xad\nficient to destroy organic life of the earth.”5 As early as 1916, and continuing \nsporadically through his career, the Estonian astronomer Ernst Öpik explored \nimpact energies and their effects through modeling.  In a 1958 abstract, he \neven argued that hot rock gas from large impacts could completely annihilate \nlife on land.6 In his 1969 Presidential Address to the Paleontological Society, \nDigby McLaren of the Geological Survey of Canada argued for catastrophic \nextinction at the Frasnian–Famennian boundary, about 372 million years \nago.7 And in a 1973 Nature communication, famed geochemist Harold Urey \nsuggested that comet impacts might have been responsible for the Cretaceous–\nPaleogene extinction, among other mass extinctions.8 None of these argu\xad\nments had much effect on the prevailing scientific opinion of their respective \ntimes about the role of impacts in the evolution of Earth or its biosphere.\n In the early 1970s, Walter Alvarez started out trying to explain the ori\xad\ngin of a specific limestone formation in Italy known as the Scaglia Rossa. \n This sequence of layers had been deposited during the Cretaceous–Paleogene \nboundary, and he and some colleagues were working through it, mapping its \nrecord of magnetic field reversals.  It was during this work that he noticed a \npattern that had already been reported: a sudden change in the type and abun\xad\ndance of foraminifera—the microfossils that were widely used to perform rel\xad\native dating of rock units—in the layers of rock. ', '79\nCHAPTER 4\nCOSMIC IMPACTS AND \nLIFE ON EARTH\nIntroduction\nI\nn 1980, near-Earth object research was transformed by a far-reaching argu\xad\nment: not only did asteroids and comets strike Earth occasionally, but such \nimpacts could redirect—and had in the past altered—the course of life itself. \n Known as the Alvarez hypothesis, after the father-son pair of lead authors, \nphysicist Luis W. Alvarez and geologist Walter Alvarez, it posited that a \nroughly 10-kilometer asteroid had impacted somewhere on Earth about 65 \nmillion years ago, at the boundary between the Cretaceous and Paleogene \nperiods of Earth’s history.1 The enormous amount of pulverized rock and \ndust thrown into the atmosphere would have produced a years-long darkness, \nexplaining the mass extinction already known to have occurred.2 Their argu\xad\nment was based on discovery of a thin clay layer enriched in iridium, a metal \nthat is rare on Earth’s surface but common in meteorites.  While many other \nscientists had proposed that large impacts could produce mass extinctions, \n1.\t\n The Paleogene period (66 mega annum [Ma] to 23 Ma) was formerly part of the Tertiary \nperiod (66 Ma to 2.5 Ma), and the extinction event referred to as the Cretaceous–\nTertiary extinction, often shorthanded as “K–T.” The International Commission on \nStratigraphy abandoned the Tertiary nomenclature in 2008, and the current term for \nthe timing of the extinction event is “K–Pg.”\n2.\t\n', 'In their view, the \ndisappearance of the non-avian dinosaurs was gradual, not sudden, and thus \nthe impact could not be the principal cause.\n By the early 1990s, though, most researchers involved in the controversy \nhad also accepted a set of mechanisms that together could explain the end-\nCretaceous mass extinction.  Along the way, the effort to understand the effects \nof this impact raised questions about the effects of the still larger impacts that \nwould be expected to have occurred earlier in Earth’s history.\n The Cretaceous–Paleogene Impactor and Extinction Mechanisms\nThe Alvarez paper was not the first suggestion that cosmic impacts might have \ninfluenced the course of life on Earth.  As early as 1694, in an address to the \nRoyal Society, Edmond Halley had noted that the biblical deluge could have \nbeen caused by the shock of a comet impact, followed by the seas rushing \nviolently toward the impacted area.  The Caspian Sea and other large lakes in \nthe world could have been created by cometary impacts, and finally, in a very \nprescient comment, Halley noted that widespread extinction of life, before the \n3.\t\n Geochemist Harold Urey, for example, argued that comets might cause mass \nextinctions in a 1973 letter to Nature. ', 'At some point, the ocean surface \nwould boil, producing a global steam bath that would serve as an effective \nsterilizing agent (and, of course, cook the dwellers of the ocean shallows). \n What was that level?  How big would an impactor have to be to completely \nboil away the oceans?\n In 1989, a team led by Norman Sleep of Stanford University raised these \nquestions in the context of establishing when the last impact large enough \nto sterilize the early Earth could have happened.  To researchers interested \nin the evolution of life, that was a key question.  Knowing the answer would \neffectively bound life’s timeline.  They found that an impactor about the size \nof main-belt asteroids Vesta and Pallas, around 440 kilometers in diameter, \nwould be sufficient to completely boil away Earth’s oceans. ']","
Giant impacts on Earth could serve as a means to transfer life between planets by blasting rocks containing microscopic life into space, some of which would eventually wind up crashing onto Venus, Mars, Earth’s Moon, etc. These rocks could then return to Earth, serving as a space-based “refugia” for life and reseeding Earth after a sterilizing impact. Additionally, many astrobiologists believed Mars was habitable before Earth had cooled enough to become habitable, meaning that life on Earth might have originated on Mars and then been seeded here by a giant impact. This possibility might make it difficult to distinguish Martian life (should there be any, perhaps in subsurface refuges) from terrestrial life, as we might actually have the same common ancestor."
"How do fins contribute to damping in a helicopter, particularly in rapid forward flight?","In the given text, it is mentioned that fins can provide damping in a helicopter, particularly in rapid forward flight. The text explains that fins can be used as an effective substitute for the lateral dihedral in a two-screw coaxial helicopter. In rapid forward flight, fins placed high above the center of gravity with their plane parallel to the line of flight would be an effective substitute for the lateral dihedral. The use of fins in rapid forward flight would not have to be of unduly large proportions. However, in hovering flight and vertical ascent or descent, such auxiliary surfaces would be almost useless.","['It is a question, \nhowever, whether a two-\nscrew coaxial helicopter \nwould provide\xa0damping.\n Fins to Give Equivalent of the Dihedral.  Since it is advisable to keep the number \nof lifting screws down to a minimum, the possibility of using fins immediately sug\xad\ngests itself.  In rapid forward flight the use of fins should be effective; if two coaxial \nscrews are employed, one vertical fin placed high above the center of gravity, with \nits plane parallel to the line of flight, would be an effective substitute for the lateral \ndihedral.  A stabilizer placed at a negative dihedral to the plane of rotation of the \nlifting screws might be an equally good substitute for the longitudinal dihedral. \n These auxiliary surfaces in rapid forward flight would not have to be of unduly \nlarge proportions.\n But in hovering flight and vertical ascent or descent such auxiliary surfaces \nwould be almost useless. ', 'This instability is primarily due to low rotor damping and to the \nfact that the conventional helicopter rotor is statically unstable with angle of attack, \nthe instability becoming greater as the forward speed is increased.  Because of this \nincrease of angle-of-attack instability with forward speed, the attentiveness required \nof the pilot to correct for a disturbance increases rapidly as the helicopter’s top \nspeed is reached, in that at those speeds the disturbance builds up so rapidly that \ncorrective control must be applied in a few seconds.  The elimination of this pitch\xad\ning instability is considered to be of primary importance in achieving satisfactory \nflying qualities.  Many experimental helicopters, and several production machines, \nalready incorporate devices which either increase the damping in pitch or add posi\xad\ntive static stability with angle of attack.\n Most helicopters on the market today have definite instabilities in some regimes \nof flight and by airplane standards have very poor flying qualities.  The stability and \ncontrol characteristics of the helicopter represent a major present-day development \nproblem, but because they are receiving considerable attention from manufacturers \nand government research agencies, it may be stated with confidence that a rapid \nimprovement of helicopter flying qualities will not be long forthcoming.\n', 'During ascent and descent the stability is much the same as when stationary, \nexcept that any inclination now changes the angle at which the propeller meets the \nair, and a lateral force is therefore set up at once, before the helicopter has moved \nlaterally out of its vertical path; [sic] In the case of ascent this force tends to increase \nthe deviation from the vertical, in the case of descent to decrease it (always assuming \nthe propeller to be above the center of gravity).  To secure stability during a climb \na large fin surface placed far below the C.G.  of the machine would be necessary. \n Such a fin surface would operate rather inefficiently, as the inclination of the axis \nproduces a change in direction of the slip-stream which would partially counterbal\xad\nance the effect of the presentation of the fin surface at an angle to the relative wind \ndue to the upward motion of the helicopter.  It would be advantageous, from the \nstandpoint of stability when rapidly ascending, to have the fin and control surfaces \noutside the slip-stream, and this might be possible to arrange in those helicopters \nwhich have two propellers in parallel and rotating in opposite directions.  Part of \nthe fin surface could then be placed between the two slip-streams.  It would not be \nsafe to put it all there, as there would then be no control when poised motionless. \n', 'Some sample pressure distributions are represented in Fig.  17. \n For further details reference may be made to the publications here noted.  Moving \na given set of fins farther forward or aft will increase or reduce respectively the \nfin forces but within certain limits may scarcely change the stabilizing moment. \n The most conventional form of empennage is an essentially symmetrical cruci\xad\nform set of two pairs of fins, one upper and lower in the keel plane for directional Figure 16.  Distribution of pressure about the mpennage.  Curve a shows the zonal force integrated from typical pressure distribution without empennage. ', 'The conclusions reached as a result \nof these tests were expressed in the form of tentative flying-qualities requirements. \n The results of the investigation are presented in Technical Note 1983.\n The flight investigations also showed the importance of a stability parameter \nknown as rotor damping, the moment produced by the rotor per unit [of] angular \npitching or rolling velocity, on the handling qualities of the helicopter.  The subject \nwas investigated theoretically and the results indicated that present-day helicopters \nwith conventional control systems tend to have low damping at high speed and \nin climbs and can even experience negative damping in certain maneuvers, and \nthat high-speed, high-powered helicopters and certain types of convertible aircraft \nwould have prohibitive amounts of negative damping.  The analysis, together with \nan experimental check of trends shown with varying flight conditions, was pub\xad\nlished in Technical Note 2136, which also contained suggestions for the avoidance \nof negative damping through special design features.  The investigation also dis\xad\nclosed the fact that the assumption that the rotor force vector is at all times perpen\xad\ndicular to the tip-path plane during rolling or pitching may give highly misleading \nresults when applied to the calculation of rotor characteristics.\n Most of the published literature on helicopter stability is written for the spe\xad\ncialist in stability theory. ']","
Fins can contribute to damping in a helicopter, particularly in rapid forward flight, by acting as a substitute for dihedral. If two coaxial screws are employed, one vertical fin placed high above the center of gravity, with its plane parallel to the line of flight, would be an effective substitute for the lateral dihedral. A stabilizer placed at a negative dihedral to the plane of rotation of the lifting screws might be an equally good substitute for the longitudinal dihedral. These auxiliary surfaces in rapid forward flight would not have to be of unduly large proportions. However, in hovering flight and vertical ascent or descent, such auxiliary surfaces would be almost useless."
"What are the recent and ongoing missions exploring Mars, and what are their primary objectives?","One of the recent and ongoing missions exploring Mars is the Mars Science Laboratory (MSL), part of NASA's Mars Exploration Program. The primary goal of the mission is to assess whether Mars ever had an environment hospitable for lifeforms such as microbes. To do this, Curiosity, the large rover carried by MSL, carries the most advanced complement of instruments ever sent to the surface of Mars. The rover is designed to scoop up soil and rocks and investigate their properties. Other recent and ongoing missions exploring Mars include the Mars Reconnaissance Orbiter, the Mars Atmosphere and Volatile EvolutioN Mission (MAVEN), and the Mars Orbiter Mission. The primary objectives of these missions include mapping the Martian surface at high resolution, searching for a range of rocks and soil types, and looking for clues for past water activity on Mars.","['Finally, on the right is a ground model the size of Curiosity, which \nlanded in 2012.  The two JPL engineers shown are Matt Robinson (left) and Wesley Kuykendall.  Credit: NASA/JPL-Caltech\nResults: Spirit and Opportunity were two rovers that \ntogether represented the Mars Exploration Rover \nMission (MER), itself part of NASA’s Mars Explo\xad\nration Program.  The twin missions’ main scientific \nobjective was to search for a range of rocks and soil \ntypes and then look for clues for past water activity \non Mars.  Each rover, about the size of a golf cart \nand seven times heavier (185 kilograms) than the \nSojourner rover on Mars Pathfinder, was targeted \nto opposite sides of the planet in locales that were \nsuspected of having been affected by liquid water \nin the past.  The plan was for the rovers to move \nfrom place to place and perform on-site geological \ninvestigations and take photographs with mast-\nmounted cameras (about 1.5 meters off the ground) \nproviding 360° stereoscopic views of the terrain.  A \nsuite of instruments (MB, APXS, the magnets, MI, \nand RAT) were deployed on a robotic arm (known \nas the Instrument Deployment Device, IDD). ', '11\nINTRODUCTION\u2002 •\u2002 NASA’S SOLAR SYSTEM EXPLORATION PARADIGM\nthat has mapped the Moon’s surface at high resolution (~1 square meter), \nis still operating as of this writing.  LRO observations have enabled numer\xad\nous groundbreaking discoveries, creating a new picture of the Moon as a \ndynamic and complex body. \n Planetary scientists have made significant and steady progress in under\xad\nstanding what Mars is like today and what it was like in its distant past.  The \nexploration of Mars is currently being accomplished by an international array \nof missions from NASA, the European Space Agency and its partner coun\xad\ntries, and the Indian Space Research Organization (ISRO).  Orbiter missions \noperating at Mars as of this writing include Mars Odyssey, Mars Express, the \nMars Reconnaissance Orbiter, the Mars Atmosphere and Volatile EvolutioN \nMission (MAVEN), and the Mars Orbiter Mission. \n LANDER AND ROVER MISSIONS\nLander and rover missions enable scientists to acquire “ground truth,” mea\xad\nsurements so necessary to fully interpret data from orbital missions.  The \nsuccessful landings of the 1-metric-ton2 Curiosity rover on Mars and the \nRosetta mission’s Philae probe on comet 67P/Churyumov–Gerasimenko \nclearly show the ability of our space agencies to explore our solar system at \na new level of intensity. ', 'Mars descent imager (MARDI)\n\t 4.\talpha x-ray spectrometer (APXS)\n\t 5.\tchemistry and camera (ChemCam)\n\t 6.\tchemistry and mineralogy x-ray dif\xad\nfraction/x-ray fluorescence instrument \n(CheMin)\n\t 7.\tsample analysis at Mars instrument suite \n(SAM)\n\t 8.\tradiation assessment detector (RAD)\n\t 9.\tdynamic albedo of neutrons (DAN)\n\t10.\trover environment monitoring station \n(REMS)\n\t11.\t Mars science laboratory entry descent and \nlanding instrument (MEDLI)\nResults: The Mars Science Laboratory (MSL), part \nof NASA’s Mars Exploration Program, consists of a \nlarge (899 kilogram) rover called Curiosity and a \n“sky crane” descent stage to bring the rover down to \nthe Martian surface.  Both were fixed inside an \naeroshell for entry into the Martian atmosphere. \n The principal goal of the mission is to assess \nwhether Mars ever had an environment hospitable \nfor lifeforms such as microbes.  To do this, Curiosity \ncarries the most advanced complement of instru\xad\nments ever sent to the surface of Mars.  The rover is \ndesigned to scoop up soil and rocks and investigate \n', '5401 / Agena D no. \n AD157/6933)\nLaunch Date and Time: 14 June 1967 / 06:01:00 UT\nLaunch Site: Cape Kennedy / Launch Complex 12\nScientific Instruments:\n1.\t ultraviolet photometer\n2.\t  S-band occultation experiment\n3.\t dual frequency occultation experiment\n4.\t solar plasma probe\n5.\t magnetometer\n6.\t trapped radiation detector\n7.\t celestial mechanics experiment\nResults: In December 1965, NASA approved a proj\xad\nect to modify the Mariner IV backup spacecraft \nto conduct a closer flyby of Venus than the only \nother NASA probe to fly past Venus, Mariner II. \n The primary goal of the mission was to conduct a \nradio-occultation experiment (much like Mariner \nIV at Mars) to determine atmospheric properties \nof Venus.  Unlike Mariner IV, however, Mariner \nV did not carry an imaging instrument.  Initially, \nNASA had planned to send Mariner V on a flyby at \na miss distance of 8,165 kilometers to the surface, \nbut the Agency altered its plan in favor of a more \nmodest 75,000-kilometer flyby in order to preclude \nthe non-sterilized vehicle from crashing into the \nplanet.  After a mid-course correction on 19 June, \nMariner V began transmitting data on Venus on \n19\xa0October during its encounter. ', 'For instance, although not called this at \nthe time, such large-scale space science missions as the Viking program to \nMars and the Voyager probes to the outer planets were flagship missions, \nmeaning they were large, expensive, and long lasting.  In the 1990s NASA \nofficials began to use the “Flagship” rubric to characterize those costing more \nthan $1 billion, sometimes significantly more than $1 billion.  Accordingly, \nthe Galileo mission to Jupiter and the Cassini mission to Saturn both oper\xad\nated as “Flagships.” Numerous recommendations for additional missions have \nbeen put forward since that time.  As the 21st century progresses the major \nFlagship missions beyond those already mentioned have coalesced around \nthe Great Observatories program; the James Webb Space Telescope, recently \nlaunched as a follow-on to the Hubble Space Telescope; the Mars Science \nLaboratory (Curiosity rover) currently in operation; two outer planet missions \nto Europa and Titan; and a range of other proposals still in conception stage. \n The decadal planning effort by the science community has proven remarkably \nrobust and successful.\n Early Exploration of the Terrestrial Planets\nNASA pursued an impressive research program to gather information on the \ninner solar system during the 1960s.  Although the most significant findings of \nthis investigation would not come until the 1970s, perhaps the “golden age” \nof planetary science, studies of the planets captured the imagination of many \npeople from all types of backgrounds like nothing else save the Apollo lunar \nlandings. ']","
1. Mars Atmosphere and Volatile EvolutioN (MAVEN): Launched on 18 November 2013, MAVEN is designed to explore Mars' upper atmosphere, ionosphere, and interactions with the Sun and solar wind.
2. ExoMars Trace Gas Orbiter: Launched by the European Space Agency on 14 March 2016, this mission arrived at Mars on 16 October 2016. Its primary objective is to study the Martian atmosphere and its trace gases.
3. Interior Exploration using Seismic Investigations, Geodesy, and Heat Transport (InSight): Launched by NASA on 5 May 2018, InSight is the first robotic planetary explorer designed to study Mars' crust, mantle, and core.
4. Mars 2020 mission: A NASA mission that will continue the exploration of Mars.
5. ExoMars 2020 rover mission: An ESA mission that will also continue the exploration of Mars.

Three workhorse missions are also still conducting science operations at Mars:
1. NASA's Mars Odyssey orbiter, in operation since 2001.
2. ESA's Mars Express orbiter, which arrived at the Red Planet in December 2003.
3. NASA's Mars Reconnaissance Orbiter, in operation since 2006.

NASA is currently responding to the Trump administration's directive to return people to the Moon by 2024 and to send people to Mars by 2033. The priorities for Mars exploration, sample return, and human missions are likely to be influenced by politics both within and outside NASA."
What is the purpose of the LO2 Fill and Dump subsystem in the Fastrac/MC-1 Engine and X-34 Main Propulsion System?,The LO2 Fill and Dump subsystem provides for the transfer of propellants overboard when the vehicle is in a roughly horizontal orientation during flight and provides a means of filling the tanks during ground operations. The line must provide sufficient flow for filling the LO2 tanks in no greater than 60 minutes and dumping within the required 300 second trajectory window.,"['The Fastrac/MC-1 Engine and X-34 Main Propulsion System\n345\nLOX Fill and Dump Subsystem.  As described by Robert H. Champion of \nNASA Marshall and R.J.  Darrow, Jr., of Orbital Sciences Corporation:\nThe LO2 Fill and Dump subsystem provides for the transfer of \npropellants overboard when the vehicle is in a roughly horizon\xad\ntal orientation during flight and provides a means of filling the \ntanks during ground operations.  The line must provide sufficient \nflow for filling the LO2 tanks in no greater than 60 minutes and \ndumping within the required 300 second trajectory window.  This \nline exits the aft LO2 tank aft manhole cover, is routed down the \nstarboard side of the vehicle, and exits through the aft bulkhead. \n The fill dump line is a 4” Inconel tube with a universal bellows, \na flow-meter, the same 4” Ketema control valve, and has a quick \ndisconnect GSE fitting 4” outside of the aft bulkhead. ', 'The Fastrac/MC-1 Engine and X-34 Main Propulsion System\n345\nLOX Fill and Dump Subsystem.  As described by Robert H. Champion of \nNASA Marshall and R.J.  Darrow, Jr., of Orbital Sciences Corporation:\nThe LO2 Fill and Dump subsystem provides for the transfer of \npropellants overboard when the vehicle is in a roughly horizon\xad\ntal orientation during flight and provides a means of filling the \ntanks during ground operations.  The line must provide sufficient \nflow for filling the LO2 tanks in no greater than 60 minutes and \ndumping within the required 300 second trajectory window. ', 'The Fastrac/MC-1 Engine and X-34 Main Propulsion System\n333\nThe MC-1 engine main injector contains a manifold for each of \nthe engine liquid propellants that force the propellants to flow \nthrough a series of concentric channels between the injector core \nand copper faceplate.  The propellants then flow through a pattern \nof injection holes in the faceplate causing them to mix together \nin the combustion chamber.  The injector lies in the primary load \npath of the engine.  It provides part of the backbone that many \nof the other engine components mate to and must carry all the \nengine thrust load as well as much of the dynamic loads generated \nby the engine and flight environment.12\nThe entire injector component—excluding the gimbal assembly—consisted \nof the core, LOX dome cap, and faceplate. ', 'The LO2 \ndump line is supported by one fore-aft sliding bracket.49\nRP-1 Feed, Fill, and Dump Subsystem.  AVICA, a Meggitt Aerospace \nCompany, was selected to manufacture the fill, feed, vent, and dump lines for \nthe Fastrac engine.  These lines were made of 625 Inconel and ranged in wall \nthickness from 0.049 to 0.083 inches.  All of the main propulsion system fill, \nfeed, vent, and dump lines used lightweight, low-profile AS1895 flanges, which \nalso are used in commercial and fighter aircraft.50\nThe lines performed the functions of filling the LOX and RP-1 tanks, pro\xad\nviding the proper inlet conditions for the main engine, venting the tanks to \nprevent an over pressurization, and dumping LOX and RP-1 prior to landing. \n The RP-1 system used the same trunk line for the feed, fill, and dump functions \ndue to weight and packaging concerns.  The aft end of the trunk branched and \nhad one valve for feed and one valve for dump and fill.  The aft portion of the \nRP-1 line had to accommodate the vehicle structural deflections and engine \ngimballing while providing propellant flow to the engine. ', 'The Fastrac/MC-1 Engine and X-34 Main Propulsion System\n347\nwas needed to make the solenoids two fault tolerant to seeing LOX or GOX \n[gaseous oxygen].  The solenoids were not qualified for oxygen service.  The \nparallel solenoids on the pressurization legs were the only functional redundant \ncomponents in the main propulsion system.  Failure of one of the pressuriza\xad\ntion solenoids would prevent a normal flight and also prevent the dumping of \npropellants; therefore, engineers deemed it prudent to provide redundancy of \nthis component for mission assurance.56\nTable 2 shows component type and function of the pressurization and \npneumatic functions.57\nTable 2: Pressurization and Pneumatic System Components\nComponent Type\nComponent Function\nPressurant tanks\nStore pressurant gas for use in each subsystem.\n']","
The LO2 Fill and Dump subsystem in the Fastrac/MC-1 Engine and X-34 Main Propulsion System provides for the transfer of liquid oxygen (LO2) propellants overboard when the vehicle is in a roughly horizontal orientation during flight and provides a means of filling the tanks during ground operations. The line must provide sufficient flow for filling the LO2 tanks in no greater than 60 minutes and dumping within the required 300 second trajectory window. This line exits the aft LO2 tank aft manhole cover, is routed down the starboard side of the vehicle, and exits through the aft bulkhead. The fill dump line is a 4” Inconel tube with a universal bellows, a flow-meter, the same 4” Ketema control valve, and has a quick disconnect GSE fitting 4” outside of the aft bulkhead. The LO2 dump line is supported by one fore-aft sliding bracket."
What is the difference between the provisional designations and permanent numbers and names given to asteroids and comets upon discovery? Provide an example for each.,"Upon discovery, both comets and asteroids are first given temporary, or provisional, designations. These designations consist of a code providing the discovery year, half month, and order of discovery within the half month. For example, asteroid 1992 AB is the second (B) asteroid discovered in the first half of January (A) 1992.

When their orbits become secure (i.e., accurate), they can receive permanent numbers and names. Asteroid numbers are normally assigned in sequential order when their orbit is secure. For example, asteroid (1) Ceres is the first asteroid to be discovered.

Cometary designations use a numerical sequence to denote the order of discovery in a particular half month, rather than the more complex alpha-numeric code used to designate asteroids. For example, comet C/2017 K2 (PANSTARRS) was the second comet discovered in the second half of May (K) 2017 by the Pan-STARRS1 survey.

The rules for comet designations, numbers, and names are maintained by the Minor Planet Center (MPC), while the MPC is responsible for assigning designations, numbers, and names for asteroids and comets. However, by 2018, the asteroid discovery rate was well over 10,000 per year, so only a relatively small subset of the numbered asteroids discovered by major discovery teams currently receive names. Periodic and non-periodic comets also get designations and are generally named after the discoverer, the discoverers, or the discovery program.","['317\nAPPENDIX 1\nASTEROID AND COMET \nDESIGNATIONS, NUMBERS, \nAND NAMES\nU\npon discovery, both comets and asteroids are first given temporary, or \nprovisional, designations; then, when their orbits become secure (i.e., \naccurate), they can receive permanent numbers and names.\n Table A1-1.  Naming conventions for asteroids and comets.\n Provisional Designations\nPermanent Numbers and Names\nAsteroids Discovery year and alphanumeric \ncode providing the discovery year, \nhalf month, and order of discovery \nwithin the half month.\n An asteroid number is normally \nassigned in sequential order when its \norbit is secure.  It is then eligible for \nnaming—usually by the discoverer(s).\n Asteroid \nExample\n1992 AB is the second (B) asteroid \ndiscovered in the first half of January (A) \n1992.', '317\nAPPENDIX 1\nASTEROID AND COMET \nDESIGNATIONS, NUMBERS, \nAND NAMES\nU\npon discovery, both comets and asteroids are first given temporary, or \nprovisional, designations; then, when their orbits become secure (i.e., \naccurate), they can receive permanent numbers and names.\n Table A1-1.  Naming conventions for asteroids and comets.\n Provisional Designations\nPermanent Numbers and Names\nAsteroids Discovery year and alphanumeric \ncode providing the discovery year, \nhalf month, and order of discovery \nwithin the half month.\n', 'Ceres, Pallas, Juno, and Vesta continued to be denoted by their traditional \nsymbols.  In 1851, B.\xa0A. Gould was using a short-lived designation system con\xad\nsisting of a circle containing the number of the asteroid in the chronological \norder of discovery.  For a time, this system began with (5) Astraea with Ceres, \nPallas, Juno, and Vesta retaining their old symbols rather than their appro\xad\npriate numbers; but by 1864, J.\xa0F. Encke, in the influential journal Berliner \nAstronomisches Jahrbuch, was numbering the first four asteroids as (1) Ceres, \n(2)\xa0Pallas, (3)\xa0Juno, and (4)\xa0Vesta.\n Currently, the MPC is responsible for assigning designations, numbers, \nand names for asteroids and comets.  Numbers (in parentheses) are assigned \nsequentially when the asteroid’s orbit is secure such that the observational \nrecovery of the asteroid at future returns is assured.  However, when this num\xad\nbering system was first introduced in the mid-19th century and for many \nyears thereafter, a secure orbit was not required, and some numbered aster\xad\noids were subsequently lost.  For example, when the numbered asteroid 878 \nMildred was discovered in September 1916 by Seth Nicholson at Mount \nWilson Observatory, there were not enough astrometric observations to ren\xad\nder its orbit secure. ', 'A History of Near-Earth Objects Research\n320\nnormally has the option of naming their discovered asteroids—subject to the \nguidelines and approval of the IAU Committee on Small Body Nomenclature \n(CSBN).4 However, by 2018, the asteroid discovery rate was well over 10,000 \nper year, so only a relatively small subset of the numbered asteroids discovered \nby major discovery teams currently receive names.\n Periodic and non-periodic comets also get designations and are generally \n(but not always) named after the discoverer, the discoverers, or the discovery \nprogram.  Because there are far fewer comet discoveries than asteroid discov\xad\neries, cometary designations use a numerical sequence to denote the order of \ndiscovery in a particular half month, rather than the more complex alpha\xad\nnumeric code used to designate asteroids.  The rules for comet designations, \nnumbers, and names are maintained by the MPC.5\n4.\t\n IAU MPC, “How Are Minor Planets Named?” https://minorplanetcenter.net/iau/info/\nHowNamed.html (accessed 23 September 2021).\n', 'A History of Near-Earth Objects Research\n320\nnormally has the option of naming their discovered asteroids—subject to the \nguidelines and approval of the IAU Committee on Small Body Nomenclature \n(CSBN).4 However, by 2018, the asteroid discovery rate was well over 10,000 \nper year, so only a relatively small subset of the numbered asteroids discovered \nby major discovery teams currently receive names.\n Periodic and non-periodic comets also get designations and are generally \n(but not always) named after the discoverer, the discoverers, or the discovery \nprogram.  Because there are far fewer comet discoveries than asteroid discov\xad\neries, cometary designations use a numerical sequence to denote the order of \ndiscovery in a particular half month, rather than the more complex alpha\xad\nnumeric code used to designate asteroids.  The rules for comet designations, \nnumbers, and names are maintained by the MPC.5\n4.\t\n IAU MPC, “How Are Minor Planets Named?” https://minorplanetcenter.net/iau/info/\nHowNamed.html (accessed 23 September 2021).\n 5.\t\n']","
Upon discovery, both asteroids and comets are first given provisional designations, which are temporary. For asteroids, the provisional designation consists of the discovery year and an alphanumeric code providing the discovery year, half month, and order of discovery within the half month. For example, 1992 AB is the second (B) asteroid discovered in the first half of January (A) 1992. 

For comets, the provisional designation consists of a leading “P” or “C” with the discovery year and half-month capital letter followed by the numerical order of the discovery during that half month. For example, C/2015 A2 (Pan-STARRS) was the second comet discovery announcement made during the first half of January 2015.

Once the orbits of asteroids and comets become secure, they can receive permanent numbers and names. For asteroids, a number is normally assigned in sequential order when its orbit is secure, and it is then eligible for naming, usually by the discoverer(s). For example, 8373 Stephengould = 1992 AB was named after Harvard scientist Stephen Jay Gould by the discoverers Gene and Carolyn Shoemaker.

For comets, they are normally named after the discoverer(s) or discovery program. Short periodic comets are numbered sequentially after they have been recovered or observed at a second perihelion passage. For example, 1P/Halley was the first short periodic comet recognized as such by Edmond Halley. This comet’s return in 1682 is designated 1P/1682 Q1 since it was the first comet seen in the second half of August of that year."
"Question: What was the primary goal of the Mariner C spacecraft and what was the outcome of the launch of Mariner III, the first of the two probes?","The primary goal of the Mariner-Mars 1964 project, which included the Mariner C spacecraft, was to photograph the Martian surface using a single TV camera fixed on a scan platform that could return up to 22 frames after an eight-month journey. However, during the launch of Mariner III, the first of the two probes, the booster payload shroud failed to separate from the payload, and battery power spuriously dropped to zero at T+8 hours 43 minutes. Additionally, the spacecraft's solar panels apparently never unfurled to replenish the power supply. Due to the incorrect mass of the spacecraft (since the payload shroud was still attached), it never entered a proper trans-Mars trajectory. The impact point was at 10° 38′ S / 20° 36′ W on the northern rim of the Sea of Clouds. Scientists on the ground were more than satisfied with the results; image resolution was, in many cases, one thousand times better than photos taken from Earth. Scientists concluded that an Apollo crewed landing would be possible in the mare regions of the lunar surface, given their relative smoothness.","['11\xa0/ \nAtlas D no.  289 / Agena D no.  AD68/6931)\nLaunch Date and Time: 5 November 1964 / 19:22:05 UT\nLaunch Site: Cape Kennedy / Launch Complex 13\nScientific Instruments:\n1.\t imaging system\n2.\t cosmic dust detector\n3.\t cosmic ray telescope\n4.\t ionization chamber\n5.\t helium magnetometer\n6.\t trapped radiation detector\n7.\t solar plasma probe\nResults: NASA approved two probes for the Mariner-\nMars 1964 project in November 1962.  The primary \ngoal of the two spacecraft, code-named Mariner \nC, was to photograph the Martian surface using \na single TV camera fixed on a scan platform that \ncould return up to 22 frames after an eight-month \njourney.  During the launch of Mariner III, the \nfirst of the two probes, the booster payload shroud \nfailed to separate from the payload.  Additionally, \nbattery power spuriously dropped to zero (at T+8 \nhours 43 minutes) and the spacecraft’s solar panels \napparently never unfurled to replenish the power \nsupply.  Due to the incorrect mass of the spacecraft \n(since the payload shroud was still attached), it \nnever entered a proper trans-Mars trajectory. ', 'The impact point was at 10° \n38′ S / 20° 36′ W on the northern rim of the Sea \nof Clouds.  Scientists on the ground were more \nthan satisfied with results; image resolution was, \nin many cases, one thousand times better than \nphotos taken from Earth.  Scientists concluded that \nan Apollo crewed landing would be possible in the \nmare regions of the lunar surface, given their rela\xad\ntive smoothness.\n 47\nMariner III\nNation: USA (19)\nObjective(s): Mars flyby\nSpacecraft: Mariner-64C / Mariner-C\nSpacecraft Mass: 260.8 kg\nMission Design and Management: NASA / JPL\nLaunch Vehicle: Atlas Agena D (Atlas Agena D no.\xa0 11\xa0/ \nAtlas D no.  289 / Agena D no.  AD68/6931)\nLaunch Date and Time: 5 November 1964 / 19:22:05 UT\nLaunch Site: Cape Kennedy / Launch Complex 13\nScientific Instruments:\n1.\t imaging system\n2.\t cosmic dust detector\n3.\t cosmic ray telescope\n4.\t ionization chamber\n5.\t helium magnetometer\n6.\t trapped radiation detector\n7.\t solar plasma probe\nResults: NASA approved two probes for the Mariner-\nMars 1964 project in November 1962. ', 'The original photo was color-enhanced to provide more \ncontrast in Venus’s cloudy atmosphere.  Credit: NASA\nLaunch Site: Cape Canaveral / Launch Complex 36B\nScientific Instruments:\n1.\t  2 telescopes/cameras\n2.\t infrared radiometer\n3.\t ultraviolet airglow spectrometer\n4.\t ultraviolet occultation spectrometer\n5.\t magnetometer\n6.\t charged particle telescope\n7.\t plasma analyzer\nResults: Mariner 10 was the first spacecraft sent to \nthe planet Mercury; the first mission to explore \ntwo planets (Mercury and Venus) during a single \nmission; the first to use gravity-assist to change \nits flight-path; the first to return to its target after \nan initial encounter; and the first to use the solar \nwind as a major means of spacecraft orientation \nduring flight.  The primary goal of the Mariner 10 \nwas to study the atmosphere (if any), surface, and \nphysical characteristics of Mercury.  Soon after \nleaving Earth orbit, the spacecraft returned strik\xad\ning photos of both Earth and the Moon as it sped \nto its first destination, Venus.  During the coast, \nthere were numerous technical problems, includ\xad\ning malfunctions in the high-gain antenna and the \nattitude control system.  In January 1974, Mariner \n10 successfully returned data (sans photographs) \n', '99\n1971\n123\nMariner 8\nNation: USA (48)\nObjective(s): Mars orbit\nSpacecraft: Mariner-71H / Mariner-H\nSpacecraft Mass: 997.9 kg\nMission Design and Management: NASA / JPL\nLaunch Vehicle: Atlas Centaur (AC-24 / Atlas 3C \nno.  5405C / Centaur D-1A)\nLaunch Date and Time: 9 May 1971 / 01:11:01 UT\nLaunch Site: Cape Kennedy / Launch Complex 36A\nScientific Instruments:\n1.\t imaging system\n2.\t ultraviolet spectrometer\n3.\t infrared spectrometer\n4.\t infrared radiometer\nResults: Mariner-71H (also called Mariner-H) was \nthe first of a pair of American spacecraft intended \nto explore the physical and dynamic characteristics \nof Mars from Martian orbit.  The overall goals of \nthe series were: to search for an environment that \ncould support life; to collect data on the origins \nand evolution of the planet; to gather information \non planetary physics, geology, planetology, and cos\xad\nmology; and to provide data that could aid future \nspacecraft such as the Viking landers.  Launch of \nMariner-71H was nominal until just after separa\xad\ntion of the Centaur upper stage when a malfunction \noccurred in the stage’s flight control system leading \nto loss of pitch control at an altitude of 148 kilome\xad\nters at T+4.7 minutes.  As a result, the stack began \nto tumble and the Centaur engines shut down. \n', 'Observation of the planets from Earth-based instruments had been going \non for centuries, but the really significant contributions of the Space Age came \nfrom satellites, either probes actually sent to the planets or space-based obser\xad\nvatories.  A centerpiece of this effort was the Mariner program, originated by \nNASA in the early part of the 1960s to investigate the nearby planets.  Overseen \nby JPL, satellites of this program proved enormously productive.  In the summer \nof 1962, Mariner 2 launched toward Venus, for example, and in December it \narrived at the planet, probing the clouds, estimating planetary temperatures, \nmeasuring the charged particle environment, and looking for a magnetic field \nsimilar to Earth’s magnetosphere (but finding none). \n']","
The primary goal of the Mariner C spacecraft was to photograph the Martian surface using a single TV camera fixed on a scan platform that could return up to 22 frames after an eight-month journey. However, during the launch of Mariner III, the first of the two probes, the booster payload shroud failed to separate from the payload. Additionally, battery power spuriously dropped to zero and the spacecraft's solar panels apparently never unfurled to replenish the power supply. Due to the incorrect mass of the spacecraft, it never entered a proper trans-Mars trajectory and ended up in an unanticipated heliocentric orbit of 0.983 × 1.311 AU. A later investigation indicated that the shroud's inner fiberglass layer had separated from the shroud's outer skin, thus preventing jettisoning."
What is the Integrated High Performance Turbine Energy Technology (IHPTET) program and what are its goals?,"The Integrated High Performance Turbine Energy Technology (IHPTET) program is a coordinated, three-phase Government and industry initiative that served as the framework for practically all Government- and industry-sponsored research and development on military turbine engines. Its goals include doubling the power of military jet engines by 2005, developing robust and affordable engines, and exhibiting high performance under all conditions. The program grew out of an earlier military-industry project sponsored by the Air Force’s Aero Propulsion Laboratory at Wright-Patterson Air Force Base near Dayton, OH. DOD was so impressed that it expanded the program to include the Army, the Navy, the Defense Advanced Research Projects Agency (DARPA), and NASA. The program possessed a broad charter to study all engine components and work toward technological maturity through testing and demonstration.","['The Power for Flight\n176\nAdvancing Gas Turbine Technology\nIntegrated High-Performance Turbine Engine Technology\nDOD established the Integrated High Performance Turbine Engine Technology \n(IHPTET) program in November 1987 to stimulate the development of \n21st-century high-performance military turbine engines.  The program grew \nout of an earlier military-industry project sponsored by the Air Force’s Aero \nPropulsion Laboratory at Wright-Patterson Air Force Base near Dayton, OH. \n DOD was so impressed that it expanded the program to include the Army, the \nNavy, the Defense Advanced Research Projects Agency (DARPA), and NASA. \n The program possessed a broad charter to study all engine components and \nwork toward technological maturity through testing and demonstration, with \nan overall goal to double the power of military jet engines by 2005. ', 'The program grew \nout of an earlier military-industry project sponsored by the Air Force’s Aero \nPropulsion Laboratory at Wright-Patterson Air Force Base near Dayton, OH. \n DOD was so impressed that it expanded the program to include the Army, the \nNavy, the Defense Advanced Research Projects Agency (DARPA), and NASA. \n The program possessed a broad charter to study all engine components and \nwork toward technological maturity through testing and demonstration, with \nan overall goal to double the power of military jet engines by 2005.  Moreover, \nthe IHPTET engines were to be robust and affordable and to exhibit high \nperformance under all conditions.32\nIHPTET was a coordinated, three-phase Government and industry initia\xad\ntive that served as the framework for practically all Government- and industry-\nsponsored research and development on military turbine engines.  Specifically, a \njoint DOD-NASA steering committee coordinated eight separate plans for the \nU.S.  Government and individual industry participants, which included Pratt \n& Whitney, General Electric, Allison, Williams International, Teledyne Ryan \nAeronautical, AlliedSignal Aerospace, and Textron Lycoming.  There were com\xad\nponent technology panels that addressed the following systems: compression, \ncombustion, turbine, exhaust, control, mechanical, and demonstrator\xa0engines.33\nThe increasing costs and diminishing market share for aircraft engines \nin the late 20th century resulted in a push for advanced universal, or dual-\nuse, technology—primarily materials, computational fluid dynamics (CFD) \ndesign codes, engine controls and logic, turbine cooling concepts, bearings, \nand structures.34 Still, there were major differences between military and com\xad\nmercial engines and in what direction innovations took them. ', 'Transiting to a New Century, 1990–2008\n179\nsupersonic Lockheed Martin F-35 Lightning II Short Takeoff and Vertical \nLanding (STOVL) aircraft.  Phase III looked toward the future with a goal of \n100\xa0percent maximized propulsion capability for larger and faster air superior\xad\nity and STOVL aircraft, a large helicopter, and an intercontinental air-launched \ncruise missile (ALCM).  IHPTET concluded in 2005 as a successful program, \nalthough it did not fully achieve all of its goals.42\nThe Versatile Affordable Advanced Turbine Engine (VAATE) program \nsucceeded IHPTET and retained the organization structure.  The Air Force \ncontinued its direction of the program as it worked with its partners to define \ngoals and offered competitive bids to industry for the Army’s Advanced \nAffordable Turbine Engine (AATE) for helicopters and the Air Force’s Adaptive \nVersatile Engine Technology (ADVENT) program.  The partnership allowed it \nto maximize evaluation and funding for specific tasks while relying on NASA’s \nfundamental research expertise to provide a sound technical foundation for \nthe innovative work.43\nThe Ultra-Efficient Engine Technology Program, 1999–2003\nGlenn continued to work toward its goal of developing and transferring enabling \ntechnologies to industry through the Ultra-Efficient Engine Technology \n(UEET) Program beginning in October 1999.  Under the management of \nRobert Shaw at Glenn, the 6-year, nearly $300 million program included \nparticipation from Ames, Langley, and Goddard Space Flight Center; engine \nmanufacturers GE, Pratt & Whitney, Honeywell, Allison/Rolls-Royce, and \nWilliams International; and aircraft builders Boeing and Lockheed Martin.\n', 'In 1976, Lewis researchers Curt H. Liebert \nand Francis S. Stepka discovered that the application of an insulating ceramic \nlayer over metal components in the “hot” section of an engine, such as turbine \nblades, reduced temperature and the amount of coolant flow required, which \npermitted the use of cheaper and simpler materials.5 Their work extended \ncomponent life and enabled a broader understanding of metallic coatings.6 \nThe success with ceramic coatings led to new work in the late 1970s on mono\xad\nlithic ceramics, such as reaction-bonded silicon nitride (RBSN), that were \ncapable of resisting 3,000 degrees Fahrenheit.  That work led to NASA’s col\xad\nlaborative work with DOE in the automotive-oriented Advanced Gas Turbine \n(AGT) and Advanced Turbine Technology Applications (ATTAP) programs \nin the 1980s.  The Agency also investigated ceramic matrix composites in the \n1980s.  The work led to the use of the material as the combustor liner design \nfor two Government programs to reduce cooling flows and increase engine \nefficiency: the Enabling Propulsion Materials (EPM) effort within the High-\nSpeed Research (HSR) program and the Air Force’s Advanced Turbine Engine \nGas Generator (ATEGG) engine as part of the Integrated High Performance \nTurbine Engine Technology (IHPTET) program.  Both the HSR and IHPTET \nprograms are discussed subsequently.7\n', 'Index\n287\nHigh-Speed Research (HSR) program, \n197–199\nI-A (Whittle) engine, 139–140\nIntegrated High Performance Turbine Energy \nTechnology (IHPTET) program, 176\nJ47 turbojet, 140–141\nJ75 engine, 58\nJ79 engine, 54\nJ85 turbojet, 58, 63, 65\nJ93 engine, 50\nJet Engine Containment Concepts and \nBlade-Out Simulation, 205n19\nNPSS team, 177\nnuclear propulsion research, 38\n“open rotor” engine, 218–219\nPolymerization of Monomer Reactants (PMR), \n168\npropfan, 121–122, 124\nQCSEE program, 92–93\nQuiet Engine Program (QEP), 84, 87\nQuiet Technology Demonstrator 2 (QTD2) \nprogram, 196\nRevolutionary Turbine Accelerator (RTA), 200\nstator design, 190–191\nTF39 turbofan, 85, 106\nturbofan market, 73\nturbofan reduction gearbox, 92\nturboprop (counter-rotating), 120–121\nUltra-Efficient Engine Technology Program \n(UEET), 179\nunderwing pod installation, 92–93\nUnducted Fan (UDF), 126\nUnducted Fan (UDF) engine, 122–124\nvariable-cycle engine (VCE), 55–56\nYJ93 turbojet, 53, 54\nGeneral Electric (Schenectady), 29\nI-16, 30\nI-A engine (Whittle), 28, 31\nJ79, 36\nSpecial Committee on Jet Propulsion, 27\nTG-100 turboprop, 27\nTG-100A, 34\nTG-180 (J35), 29\nWhittle engine, 30\nXJ79-GE-1 afterburning turbojet, 36\nGeorgia Institute of Technology, 223\nGerman Aerospace Center (DLR), 227\nGermany\ninfluence on American technology, 33, 37, \n62, 117\njet propulsion, 22, 25, 29, 30\nKochel high speed wind tunnels, 62\nramjet design, 37\nrockets, 27\nGKN Aerospace, 174\nGlenn Research Center, 93, 184, 189.  See also \nLewis Flight Propulsion Laboratory\nAdvanced Ducted Propulsor (ADP), 185\nalloys, 180, 196\nAlternative Fuel Effects on Contrails and \nCruise Emissions (ACCESS) study, 226\nchevron studies, 194\nCommercial Modular Aero-Propulsion \nSystem Simulation (C-MAPSS), 154\ncomputational fluid dynamics (CFD), 177, 203\ncomputer software, 173\nCritical Propulsion Components (CPC), \n198–199\nengine-component noise nomenclature, 190\nGAP diesel engine, 181\nGAP FJX-2 turbofan, 183, 184\nGreenlab Research Facility, 226\nHigh-Speed Research (HSR) program, \n197–199\nJet Engine Containment Concepts and \nBlade-Out Simulation, 172, 205n19\nLow Emissions Alternative Power program, \n223\nLow Speed Wind Tunnel, 221–222\nMegabraider, 172–173\n']","
The Integrated High Performance Turbine Energy Technology (IHPTET) program is a research initiative that aims to develop advanced turbine engine technology for improved efficiency and performance. The program focuses on the integration of various components, including advanced materials, cooling techniques, and aerodynamic designs, to enhance the overall performance of turbine engines. The IHPTET program goals include increasing the thermal efficiency of turbine engines, reducing emissions, and improving durability and reliability. The program was initiated in 1996 and has received significant funding from the US Department of Energy and the US Air Force. The IHPTET program is a collaborative effort between various research institutions, including NASA, the Department of Energy's National Energy Technology Laboratory, and several universities and private companies. The program has made significant progress in developing advanced turbine engine technology and has resulted in several patents and publications."
What is the Blade-element theory and who was the first to calculate the forces on blade segments to find the thrust and torque output for the entire propeller as well as innovating the use of airfoil data to determine propeller efficiency?,"The Blade-element theory considers the propeller to be a warped airfoil, each of whose segments represents an ordinary wing as the segments travel in a helical path. The first to calculate the forces on blade segments to find the thrust and torque output for the entire propeller as well as innovating the use of airfoil data to determine propeller efficiency was Russian-born Stefan Drzewiecki. He published various papers and texts beginning in 1885 and ending with Théorie Générale de l’Hélice Propulsive in 1920.","['The NACA’s first annual \nreport in 1915 acknowledged the lack of consistent propeller data regard\xad\ning efficiency as one of the general problems facing American aeronautics. \n In its efforts to refine, develop, and perfect the propeller, the NACA enlisted \nthe help of Government researchers and university professors from across the \nNation but concentrated its main effort at Stanford University near Palo Alto, \nCA.  As the 1920s progressed, the NACA became involved with aeronautical \nresearch, including propeller research, at major American universities such as \nthe Massachusetts Institute of Technology (MIT), New York University, the \nUniversity of Michigan, and the California Institute of Technology.13\nDespite regular use in airships, however, propeller development through \nthe late 18th and 19th centuries was more the result of empiricism than estab\xad\nlished theory.14 In France in 1885, Russian-born Stefan Drzewiecki devised a \ntheory for calculating propeller performance based on measured airfoil data \nthat, had they been used by the aeronautical community, would have greatly \naffected propeller development.  Known today as the blade-element theory, \nDrzewiecki’s theory considers the propeller to be a warped airfoil, each of \nwhose segments represents an ordinary wing as the segments travel in a heli\xad\ncal path.  Drzewiecki was the first to calculate the forces on blade segments to \nfind the thrust and torque output for the entire propeller as well as innovating \nthe use of airfoil data to determine propeller efficiency.  Drzewiecki published \nvarious papers and texts beginning in 1885 and ending with Théorie Générale \nde l’Hélice Propulsive in 1920.15\nAlong with being the first successfully to develop a practical flying machine, \nWilbur and Orville Wright were the first to address the propeller from a \n', 'In its efforts to refine, develop, and perfect the propeller, the NACA enlisted \nthe help of Government researchers and university professors from across the \nNation but concentrated its main effort at Stanford University near Palo Alto, \nCA.  As the 1920s progressed, the NACA became involved with aeronautical \nresearch, including propeller research, at major American universities such as \nthe Massachusetts Institute of Technology (MIT), New York University, the \nUniversity of Michigan, and the California Institute of Technology.13\nDespite regular use in airships, however, propeller development through \nthe late 18th and 19th centuries was more the result of empiricism than estab\xad\nlished theory.14 In France in 1885, Russian-born Stefan Drzewiecki devised a \ntheory for calculating propeller performance based on measured airfoil data \nthat, had they been used by the aeronautical community, would have greatly \naffected propeller development.  Known today as the blade-element theory, \nDrzewiecki’s theory considers the propeller to be a warped airfoil, each of \nwhose segments represents an ordinary wing as the segments travel in a heli\xad\ncal path.  Drzewiecki was the first to calculate the forces on blade segments to \nfind the thrust and torque output for the entire propeller as well as innovating \nthe use of airfoil data to determine propeller efficiency.  Drzewiecki published \nvarious papers and texts beginning in 1885 and ending with Théorie Générale \nde l’Hélice Propulsive in 1920.15\nAlong with being the first successfully to develop a practical flying machine, \nWilbur and Orville Wright were the first to address the propeller from a \n', 'One of the earliest and most \nconsistently funded programs was propeller research.  The NACA’s first annual \nreport in 1915 acknowledged the lack of consistent propeller data regard\xad\ning efficiency as one of the general problems facing American aeronautics. \n In its efforts to refine, develop, and perfect the propeller, the NACA enlisted \nthe help of Government researchers and university professors from across the \nNation but concentrated its main effort at Stanford University near Palo Alto, \nCA.  As the 1920s progressed, the NACA became involved with aeronautical \nresearch, including propeller research, at major American universities such as \nthe Massachusetts Institute of Technology (MIT), New York University, the \nUniversity of Michigan, and the California Institute of Technology.13\nDespite regular use in airships, however, propeller development through \nthe late 18th and 19th centuries was more the result of empiricism than estab\xad\nlished theory.14 In France in 1885, Russian-born Stefan Drzewiecki devised a \ntheory for calculating propeller performance based on measured airfoil data \nthat, had they been used by the aeronautical community, would have greatly \naffected propeller development.  Known today as the blade-element theory, \nDrzewiecki’s theory considers the propeller to be a warped airfoil, each of \nwhose segments represents an ordinary wing as the segments travel in a heli\xad\ncal path.  Drzewiecki was the first to calculate the forces on blade segments to \nfind the thrust and torque output for the entire propeller as well as innovating \nthe use of airfoil data to determine propeller efficiency.  Drzewiecki published \nvarious papers and texts beginning in 1885 and ending with Théorie Générale \nde l’Hélice Propulsive in 1920.15\nAlong with being the first successfully to develop a practical flying machine, \nWilbur and Orville Wright were the first to address the propeller from a \n', 'Margoulis’ views on airscrews, \nwith no motive power supplied to the shaft from an external source, are based on \ncareful experiments.  His estimates for L ⁄D for power-driven airscrews are based \non a series of unsatisfactory approximations and interpolations from the results \nof various laboratories.  He finds maximum L ⁄D to be only 1.7, with γ = 60 deg., \nbut this need not be seriously regarded.  Case has designed a number of propellers \non the simple blade-element theory and calculated their efficiency, for an angle \nof 10\xa0deg.  between the flight path and the plane of rotation.  With a four-bladed \nscrew of pitch/diameter ratio 0.3, V⁄nD = 20, D = 40 ft., n.  = 1.46 r.p.s., he found \nan effective L ⁄Da of 6.7. ', 'The Committee on Aerodynamics specifically retained \ndirect control of all aeronautical research at Stanford University and Langley \nMemorial Aeronautical Laboratory later in 1920.  Of the administrative groups, \nthe Governmental Relations committee worked to coordinate between Federal \nagencies, and the Committee on Publications and Intelligence aimed to make \nthe NACA an overall source of technical information.  The Bureau of Standards, \nthe Army’s Engineering Division, and the Navy’s Bureau of Construction and \nRepair provided their reports to the NACA as a courtesy for increased dis\xad\nsemination of knowledge.32\nDurand and Lesley collaborated in a reexamination of their previous experi\xad\nmental propeller research in 1922.  Having gained a better understanding of \nthe intricacies of propeller theory, they synthesized their previous reports in \na new report to provide systematic propeller design data in a usable form.33 \nNoted aerodynamicist Max Munk asserted that the Stanford University propel\xad\nler study was “the most perfect and complete one ever published.” He judged \nthe experiments were “selected and executed in the most careful way” and that \nDurand and Lesley’s methodology was “excellent.”34\nDurand and Lesley’s “Experimental Research in Air-Propellers” expanded \nfrom one general model propeller study into four more complementary analy\xad\nses of propeller efficiency.  What they do illustrate, however, is the increas\xad\ning complexities of engineering research and the extent to which the Federal \nGovernment would support further inquiry.  The combined “Experimental \nResearch on Air-Propellers” became the point of departure not only for the \nNACA’s propeller research, but for the ever-growing Government-research \nrelationship between Stanford University and the Committee.\n As Durand and Lesley’s experiments in collecting the systematic data nec\xad\nessary for propeller design progressed, they diverted their attention toward a \nnew avenue of propeller specialization: vertical flight. ']","
The Blade-element theory is a method for calculating propeller performance based on measured airfoil data. It considers the propeller to be a warped airfoil, each of whose segments represents an ordinary wing as the segments travel in a helical path. The forces on blade segments are calculated to find the thrust and torque output for the entire propeller, and airfoil data is used to determine propeller efficiency. The first person to calculate the forces on blade segments to find the thrust and torque output for the entire propeller as well as innovating the use of airfoil data to determine propeller efficiency was Stefan Drzewiecki, a Russian-born engineer who published various papers and texts on the subject beginning in 1885 and ending with Théorie Générale de l’Hélice Propulsive in 1920."
Question: What was the objective of the Fobos-Grunt mission and what scientific instruments were on board?,"The objective of the Fobos-Grunt mission was to return a sample (about 200 g) from Phobos, the largest moon of Mars. The scientific instruments on board included a gas chromatograph package (TDA analyzer + KhMS-1F chromatograph + MAL-1F mass spectrometer), a gamma-ray spectrometer (FOGS), a neutron spectrometer (KhEND), a Mössbauer spectrometer (MIMOS), a laser mass spectrometer (LAZMA), a mass spectrometer for secondary ions (MANAGA), a Fourier spectrometer (AOST), a gravimeter (GRAS-1), a seismometer (SEYSMO), a thermo-detector (TERMOFOB), a long-wave radar (DPR), a micrometeoroid detector (METEOR), a plasma complex (FPMS), an ultra-stable oscillator (USO), an optical sun star sensor (LIBRATSIYA), a microscope (MikroOmega), a dosimeter (LYULIN), and a TV system (TSNN).","['229\nFobos-Grunt\nNation: Russia (107)\nObjective(s): Mars orbit, Phobos flyby, landing, soil \nsample return\nSpacecraft: Fobos-Grunt\nSpacecraft Mass: 13,505 kg (including 115 kg for \nYinghuo-1)\nMission Design and Management: NPO imeni \nLavochkina / IKI RAN\nLaunch Vehicle: Zenit-2SB41.1\nLaunch Date and Time: 8 November 2011 / 20:16:03 UT\nLaunch Site: Baikonur Cosmodrome / Site 45/1\nScientific Instruments:\n\t 1.\tgas chromatograph package (TDA analyzer \n+ KhMS-1F chromatograph + MAL-1F \nmass spectrometer)\n\t 2.\tgamma-ray spectrometer (FOGS)\n\t 3.\tneutron spectrometer (KhEND)\n\t 4.\t Mössbauer spectrometer (MIMOS)\n\t 5.\tlaser mass spectrometer (LAZMA)\n\t 6.\tmass spectrometer for secondary ions \n(MANAGA)\n\t 7.\t Fourier spectrometer (AOST)\n\t 8.\tgravimeter (GRAS-1)\n\t 9.\tseismometer (SEYSMO)\n\t10.\tthermo-detector (TERMOFOB)\n\t11.\tlong-wave radar (DPR)\n\t12.\tmicrometeoroid detector (METEOR)\n\t13.\tplasma complex (FPMS)\n\t14.\tultra-stable oscillator (USO)\n\t15.\toptical sun star sensor (LIBRATSIYA)\n\t16.\tmicroscope (MikroOmega)\n\t17.\tdosimeter (LYULIN)\n\t18.\t TV system (TSNN)\n\t19.\tstereo and panoramic TV cameras\nResults: Fobos-Grunt was a highly ambitious mis\xad\nsion to the Martian system that had the goal of \nreturning a sample (about 200 g) from Phobos.  It \nwas also the first Russian deep space/interplan\xad\netary mission since the failed mission of Mars \n8 in 1996, 15 years earlier.  Besides the main \nRussian spacecraft (which included significant \nscientific contributions from ESA and several \nEuropean countries), Fobos-Grunt also carried a \nsmall passenger payload, the Chinese Yinghuo-1 \nMars orbiter.  The scientific goals of the mission \nincluded studying the physical and chemical \ncharacteristics of Phobos soil, the environment \naround Phobos, the seasonal and climatic varia\xad\ntions of the Martian atmosphere and surface, and \ntesting out several new technologies. ', 'Fourier spectrometer (AOST)\n\t 8.\tgravimeter (GRAS-1)\n\t 9.\tseismometer (SEYSMO)\n\t10.\tthermo-detector (TERMOFOB)\n\t11.\tlong-wave radar (DPR)\n\t12.\tmicrometeoroid detector (METEOR)\n\t13.\tplasma complex (FPMS)\n\t14.\tultra-stable oscillator (USO)\n\t15.\toptical sun star sensor (LIBRATSIYA)\n\t16.\tmicroscope (MikroOmega)\n\t17.\tdosimeter (LYULIN)\n\t18.\t TV system (TSNN)\n\t19.\tstereo and panoramic TV cameras\nResults: Fobos-Grunt was a highly ambitious mis\xad\nsion to the Martian system that had the goal of \nreturning a sample (about 200 g) from Phobos.  It \nwas also the first Russian deep space/interplan\xad\netary mission since the failed mission of Mars \n8 in 1996, 15 years earlier.  Besides the main \nRussian spacecraft (which included significant \nscientific contributions from ESA and several \nEuropean countries), Fobos-Grunt also carried a \nsmall passenger payload, the Chinese Yinghuo-1 \nMars orbiter.  The scientific goals of the mission \nincluded studying the physical and chemical \ncharacteristics of Phobos soil, the environment \naround Phobos, the seasonal and climatic varia\xad\ntions of the Martian atmosphere and surface, and \ntesting out several new technologies.  The space\xad\ncraft was divided into three parts: a Flight Stage \n(PM), a Return Vehicle (VA)—which included a \nReentry Vehicle (SA)—and the Main Propulsion \nUnit (MDU).  After a voyage lasting about 10 \nmonths, Fobos-Grunt would have entered a highly \nelliptical Martian orbit with an 80,000-kilometer \napogee, sometime in August/September 2012. ', 'In addition, the MoonKAM \n(Moon Knowledge Acquired by Middle school stu\xad\ndents), a digital video imaging system, was used as \npart of the education and public outreach activ\xad\nities of GRAIL.  Each MoonKAM consisted of a \ndigital video controller and four camera heads, one \npointed slightly forward, two pointed below, and \none pointed slightly backward.  During the Ebb and \nFlow missions, MoonKam was operated by under\xad\ngraduate students at the University of California–\nSan Diego under the supervision of faculty, as well \nas Sally Ride Science, the foundation organized \nby America’s first woman astronaut, Sally K. Ride \n(1951–2012) to encourage young people to enter \ncareers in science, technology, engineering, and \nmathematics.\n 229\nFobos-Grunt\nNation: Russia (107)\nObjective(s): Mars orbit, Phobos flyby, landing, soil \nsample return\nSpacecraft: Fobos-Grunt\nSpacecraft Mass: 13,505 kg (including 115 kg for \nYinghuo-1)\nMission Design and Management: NPO imeni \nLavochkina / IKI RAN\nLaunch Vehicle: Zenit-2SB41.1\nLaunch Date and Time: 8 November 2011 / 20:16:03 UT\nLaunch Site: Baikonur Cosmodrome / Site 45/1\nScientific Instruments:\n\t 1.\tgas chromatograph package (TDA analyzer \n+ KhMS-1F chromatograph + MAL-1F \nmass spectrometer)\n\t 2.\tgamma-ray spectrometer (FOGS)\n\t 3.\tneutron spectrometer (KhEND)\n\t 4.\t Mössbauer spectrometer (MIMOS)\n\t 5.\tlaser mass spectrometer (LAZMA)\n\t 6.\tmass spectrometer for secondary ions \n(MANAGA)\n\t 7.\t Fourier spectrometer (AOST)\n\t 8.\tgravimeter (GRAS-1)\n\t 9.\tseismometer (SEYSMO)\n\t10.\tthermo-detector (TERMOFOB)\n\t11.\tlong-wave radar (DPR)\n\t12.\tmicrometeoroid detector (METEOR)\n\t13.\tplasma complex (FPMS)\n\t14.\tultra-stable oscillator (USO)\n\t15.\toptical sun star sensor (LIBRATSIYA)\n\t16.\tmicroscope (MikroOmega)\n\t17.\tdosimeter (LYULIN)\n\t18.\t TV system (TSNN)\n\t19.\tstereo and panoramic TV cameras\nResults: Fobos-Grunt was a highly ambitious mis\xad\nsion to the Martian system that had the goal of \nreturning a sample (about 200 g) from Phobos. ', 'Besides the main \nRussian spacecraft (which included significant \nscientific contributions from ESA and several \nEuropean countries), Fobos-Grunt also carried a \nsmall passenger payload, the Chinese Yinghuo-1 \nMars orbiter.  The scientific goals of the mission \nincluded studying the physical and chemical \ncharacteristics of Phobos soil, the environment \naround Phobos, the seasonal and climatic varia\xad\ntions of the Martian atmosphere and surface, and \ntesting out several new technologies.  The space\xad\ncraft was divided into three parts: a Flight Stage \n(PM), a Return Vehicle (VA)—which included a \nReentry Vehicle (SA)—and the Main Propulsion \nUnit (MDU).  After a voyage lasting about 10 \nmonths, Fobos-Grunt would have entered a highly \nelliptical Martian orbit with an 80,000-kilometer \napogee, sometime in August/September 2012.  At \nthis point, the MDU would have separated from \nthe main spacecraft, along with the truss structure \n', 'The plan was for \nYinghuo-1 to be released from Fobos-Grunt once \nthe latter entered Martian orbit.  As described in \nthe entry for Fobos-Grunt, although launched \nsuccessfully, the Russian Martian probe never \nleft Earth orbit.  As such, there was no way for the \nChinese to test the spacecraft in Mars orbit.  Both \nFobos-Grunt and Yinghuo-1 reentered Earth’s \natmosphere on 15 January 2012.\n 231 \nCuriosity\nNation: USA (97)\nObjective(s): Mars landing and rover\nSpacecraft: MSL\nSpacecraft Mass: 3,893 kg\nMission Design and Management: NASA / JPL\nLaunch Vehicle: Atlas V 541 (AV-028 + Centaur)\nLaunch Date and Time: 26 November 2011 / 15:02:00 \nUT\nLaunch Site: Cape Canaveral Air Force Station / \nSLC-41\nScientific Instruments:\n\t 1.\tmast camera (Mastcam)\n\t 2.\t Mars hand lens imager (MAHLI)\n\t 3.\t Mars descent imager (MARDI)\n\t 4.\talpha x-ray spectrometer (APXS)\n\t 5.\tchemistry and camera (ChemCam)\n\t 6.\tchemistry and mineralogy x-ray dif\xad\nfraction/x-ray fluorescence instrument \n(CheMin)\n\t 7.\tsample analysis at Mars instrument suite \n(SAM)\n\t 8.\tradiation assessment detector (RAD)\n\t 9.\tdynamic albedo of neutrons (DAN)\n\t10.\trover environment monitoring station \n(REMS)\n\t11.\t']","
The objective of the Fobos-Grunt mission was to study the physical and chemical characteristics of Phobos soil, the environment around Phobos, the seasonal and climatic variations of the Martian atmosphere and surface, and to test out several new technologies. The spacecraft was divided into three parts: a Flight Stage (PM), a Return Vehicle (VA)—which included a Reentry Vehicle (SA)—and the Main Propulsion Unit (MDU).

The scientific instruments on board Fobos-Grunt included:

1. gas chromatograph package (TDA analyzer + KhMS-1F chromatograph + MAL-1F mass spectrometer)
2. gamma-ray spectrometer (FOGS)
3. neutron spectrometer (KhEND)
4. Mössbauer spectrometer (MIMOS)
5. laser mass spectrometer (LAZMA)
6. mass spectrometer for secondary ions (MANAGA)
7. Fourier spectrometer (AOST)
8. gravimeter (GRAS-1)
9. seismometer (SEYSMO)
10. thermo-detector (TERMOFOB)
11. long-wave radar (DPR)
12. micrometeoroid detector (METEOR)
13. plasma complex (FPMS)
14. ultra-stable oscillator (USO)
15. optical sun star sensor (LIBRATSIYA)
16. microscope (MikroOmega)
17. dosimeter (LYULIN)
18. TV system (TSNN)
19. stereo and panoramic TV cameras."
"What is the significance of the X-34 subsection in the History Office of the Armstrong Flight Research Center, Edwards, CA? Can you provide specific examples of documents or events related to the X-34 program that are mentioned in this context?","The X-34 subsection in the History Office of the Armstrong Flight Research Center, Edwards, CA is significant as it provides historical records and highlights related to the X-34 program. Specific examples of documents or events related to the X-34 program that are mentioned in this context include:

- ""XP Highlights, October 27, 1995"" and ""XP Highlights, November 9, 1995"" (source: 63)
- ""Code P Highlights, January 12, 1996"" (source: 64)
- ""Report of Dryden Activities, Week Ending January 26, 1996"" (source: 66)
- ""Antonio L. Elias, interviews by the author, Orbital Sciences Corporation, Dulles, VA, January 9, 2013, and June 19, 2013"" (source: 67)

These documents and events provide insights into the progress and activities related to the X-34 program, including propulsion tests, flight-testing requirements, and interviews with key personnel involved in the program.","['“Code P Highlights, January 12, 1996,” X-34 subsection, History Office. \n Armstrong Flight Research Center, Edwards, CA.\n 65.\t “Report of Dryden Activities, Week Ending January 26, 1996,” X-34 sub\xad\nsection, Office of History–Armstrong Flight Research Center, Edwards, \nCA.\n 66.\t Antonio L. Elias, interviews by the author, Orbital Sciences Corporation, \nDulles, VA, January 9, 2013, and June 19, 2013. \n 67.\t', 'NASA Marshall concurred with the OIG \nfindings, and in January 2000 NASA Marshall provided mission-specific flight-\ntest requirements to Orbital and stated that the X-34 project manager would \nensure that flight requirements are revalidated.74 \nAir Force Interest and Equities in the X-34: If the contretemps over \nHolloman and Edwards seemed at first glance to imply the Air Force was not \nsupportive of the X-34 program, such was far from the truth.  Air Force hyper\xad\nsonic partisans at the Air Force Flight Test Center (AFFTC) at Edwards were \namong the field’s most zealous supporters.  Led by Johnny Armstrong, Edwards’ \nmost experienced and distinguished hypersonic flight tester, they welcomed the \narrival of the X-34, and worked assiduously to ensure that the program would \nbe a success.  The AFFTC’s Access to Space Office identified a number of con\xad\nsiderations and concepts for flight-testing the X-34 at Edwards Air Force Base \n(EAFB).  They identified the tests that NASA and Orbital planned to undertake \nfor each X-34 vehicle and the unofficial schedule for conducting the tests.  First, \npropulsion tests using the X-15 test stand would be conducted from January \nthrough May 2000, but the three planned test runs for 20-second durations \nwere considered low compared to the X-15 experience.  After these tests, five \npowered flights would be flown from May through October 2000. ', '62.\t “XP Highlights, October 27, 1995,” X-34 subsection, History Office, \nArmstrong Flight Research Center, Edwards, CA. \n 63.\t “XP Highlights, November 9, 1995,” X-34 subsection, History Office, \nArmstrong Flight Research Center, Edwards, CA. \n 64.\t “Code P Highlights, January 12, 1996,” X-34 subsection, History Office. \n Armstrong Flight Research Center, Edwards, CA.\n', '61.\t Ibid. \n 62.\t “XP Highlights, October 27, 1995,” X-34 subsection, History Office, \nArmstrong Flight Research Center, Edwards, CA. \n 63.\t “XP Highlights, November 9, 1995,” X-34 subsection, History Office, \nArmstrong Flight Research Center, Edwards, CA. \n 64.\t', '(Holloman was a center for German air force \nfighter-crew training as part of the United States’ commitment to the North \nAtlantic Treaty Organization, or NATO.)  Peters also noted that Holloman was \nthen involved in a number of environmental lawsuits, and that operations of \nthe X-34 would potentially add to these.  Holloman was also involved in the \nhighly controversial Realistic Bomber Training Initiative, which was causing \nconcern in eastern New Mexico.  Peters added, however, that he was commit\xad\nted to supporting the X-34 program and wanted to explore the potential for \nrelocating the X-34 testing to Edwards AFB in California, noting that Edwards \n“not only has a long history of hypersonics and high-altitude testing, but also \nhas various extant facilities and capabilities which might be brought to bear.”22 \nThis letter marked the beginnings of a political controversy over the location \nfor testing the X-34 that swiftly pitted the congressional delegations of New \nMexico and California against one another. \n The New Mexico congressional delegation was pushing for testing at \nHolloman AFB that would also involve the Army’s White Sands range in New \nMexico, while California representatives were backing Edwards AFB as the \ntest-flight location.  This dispute received significant press coverage.  NASA was \n']","
The X-34 subsection in the History Office of the Armstrong Flight Research Center, Edwards, CA, is significant because it contains documents and information related to the X-34 program, which was a reusable launch vehicle technology demonstration program.

In the provided context, there are several specific examples of documents and events related to the X-34 program mentioned:

* ""Code P Highlights, February 5, 1996,"" X-34 subsection, History Office, Armstrong Flight Research Center, Edwards, CA.
* ""Code P Highlights, February 9, 1996,"" X-34 subsection, History Office, Armstrong Flight Research Center, Edwards, CA.
* Richard J. Hampton letter to Kim Newton, ""Notice of Revocation, NASA Cooperative Agreement NCC8-75,"" February 23, 1996, NASA HRC, Headquarters History Office, Washington, DC.
* ""X-34 in Virtual Shutdown as OSC Ponders Pullout,"" Aviation Week & Space Technology (February 5, 1996): 86.
* Joseph C. Anselmo, ""X-34 Designs Locked In,"" Aviation Week & Space Technology (June 2, 1997): 33.
* Joseph C. Anselmo, ""As Rockwell and Orbital Bail Out Of X-34, Goldin Hammers Industry To Be Bolder. Contractors indicate willingness to take financial risks,"" Aviation Week & Space Technology (February 19, 1996): 20–21.
* Daniel S. Goldin, ""Statement to the House of Representatives,"" June 12, 1996, NASA HRC, Headquarters History Office, Washington, DC.
* Delma C. Freeman, Jr., Theodore A. Talay, and R. Eugene Austin, ""Reusable Launch Vehicle Technology Program,"" paper presented at the 47th International Astronautical Congress, Beijing, China, October 7–11, 1996, IAF 96-V.4.01, p. 6.
* John R. London III and Garry M. Lyles, ""X-34 Program Status,"" paper presented at the 49th International Astronautical Conference, Melbourne, Australia, September 28–October 2, 1998, IAF-98-V.4.04, p. 2.
* ""Code P Highlights, March 4, 1996,"" X-34 subsection, Armstrong History Office, Edwards, CA.

These documents and events provide insight into the development, funding, and status of the X-34 program, as well as the challenges and controversies that the program faced."
"How was the Genesis spacecraft designed to conserve mass while maintaining strength, as indicated by the use of aluminum, composite materials, and titanium for its construction?","The Genesis spacecraft was made of aluminum, composite materials, and titanium, with the goal of conserving mass without sacrificing strength.","['NASA′s Discovery Program\n96\nof the mission.  The scientists would have to develop an algorithm for determining \nwhich tray should be deployed for the current solar wind regime, and the engineers \nwould have to link the algorithm to a series of mechanisms—moving parts—that \nwould deploy and stow each.\n Instrument Hardware and Sampling\nThe Genesis spacecraft was made of aluminum, composite materials, and titanium, \nthe goal being to conserve mass without sacrificing strength.  Command and data \nhandling (C&DH) was performed by a RAD6000 computer: a radiation-hard version \nof the Power PC chip used in Macintosh computers of the time.  The system carried 128 \nmegabytes of random-access memory and three megabytes of nonvolatile memory. \n Two standard silicon solar array panels generated a total of 254 watts at Earth and a \nnickel-hydrogen battery provided power storage.\n', 'Among its many findings has been: \nthe first fine-resolution (0.2 degree) full-sky map of \nthe microwave sky; a more precise determination of \nthe age of the universe (13.77 billion years); more \naccurate data on the curvature of space; data that \nhas allowed scientists to reduce the volume of cos\xad\nmological parameters by a factor of over 68,000; \nand the discovery that dark matter and dark energy \n(in the form of the cosmological constant) make up \nabout 24.0% and 71.4% of the universe, respectively. \n All of these findings and others cumulatively pro\xad\nvided more confirmation for the prevailing standard \nmodel of Big Bang cosmology, the Lambda-CDM \nmodel.  After 9 years of operation, in October 2010, \nthe WMAP spacecraft was moved to a derelict \nheliocentric graveyard orbit outside L2 where the \nprobe will circle the Sun once every 15\xa0years.\n 197\nGenesis\nNation: USA (79)\nObjective(s): solar wind sample return, Sun–Earth \nL1 Lagrange Point\nSpacecraft: Genesis\nSpacecraft Mass: 636 kg\nMission Design and Management: NASA / JPL\nLaunch Vehicle: Delta 7326-9.5 (no.  D287)\nLaunch Date and Time: 8 August 2001 / 16:13:40 UT\nLaunch Site: Cape Canaveral Air Force Station / \nSLC-17A\nScientific Instruments:\n1.\t solar wind ion monitor\n2.\t electron monitor\nResults: During its nearly two years in halo orbit \naround the Sun–Earth L1 point, the Genesis, the \nfifth Discovery-class spacecraft, was designed to \ncollect samples of the solar wind and then sub\xad\nsequently return them to Earth.  The collection \ndevice, fixed inside the return capsule, was made \nof a stack of four circular metallic trays, one that \nwould be continuously exposed, and the other \nthree deployed depending on particular solar wind \ncharacteristics.  After insertion into a low parking \norbit around Earth, the third stage fired exactly an \nhour after launch, at 17:13 UT on 8 August 2001 to \nsend the spacecraft towards its destination at L1. \n', 'There would be no magnetometer, no energetic particle investiga\xad\ntion, no radio wave experiment, or the like; the mission remained focused on sample \nreturn and the supporting GIM and GEM.18\nTo measure the bulk concentration of solar wind, a team led by Roger Weins and \nBeth Nordholt, both of Los Alamos National Laboratory, developed an ion concen\xad\ntrator assembly intended to filter out light protons and alpha particles, concentrating \nheavier ions onto a special collector tile under the stack of collector trays.  By repelling \nhydrogen, which composes 99 percent of the solar system, the signal of nitrogen and \noxygen would be improved significantly, with concentrations designed to be increased \nby a factor of 20 while filtering out elements that could obscure later measurements. \n Using the solar wind flow speed and temperature measurements from GIM and GEM, \nthe internal ion optics of the concentrator could be optimized for varying conditions \nof the solar wind.19\nMission Design\nAfter launch, the spacecraft would travel 1.5 million kilometers (930,000 miles) from \nEarth to Lagrange Point 1, a stable point between Earth and the Sun where gravity is \nbalanced between them.  Because of this gravity balance, the Genesis spacecraft, like the \nAdvanced Composition Explorer (ACE) and other missions, could be kept relatively \nstationary, in a small halo orbit around that point in space, with only the occasional \nneed for small station-keeping adjustments from onboard thrusters.  After several years \nof collection, the spacecraft would fire its thrusters and return to Earth, deploying the \nsample return capsule for midair capture by one of two helicopters standing by at the \nU.S.  Air Force’s Utah Testing and Training Range.  The helicopter midair grab was to \nsave the samples from even the slight bump of a parachute\xa0landing.\n', '“It was pretty innovative.”15 Although some automation on Mars missions \nwas by then standard, the level of automation found on Genesis was a departure \nfor JPL, which was accustomed to ground-based commands and the ability to make \nchanges during mission operations.  As such, engineers tested spacecraft mechanisms \nextensively, including the sample return capsule.\n But major challenges remained.  First, determining the perfect, pure material or \nmaterials to collect these micron-size grains of solar wind, and second, to manufacture \nand integrate them into the spacecraft such that there were no single-point failures in \nthe overall sample collection system—the collector surfaces had to be strong enough \nto withstand the pressures of launch and reentry.\n The purity was vital: their composition had to be well known such that their sig\xad\nnals could be subtracted from the measurements of any collected microscopic grains.\n The highest-priority measurements were the relative amounts of\n•\t O isotopes, because they provide the basis for understanding observed mete\xad\norite variations;\n•\t N isotopes, because they are a key reference point in the eventual understand\xad\ning of large but totally unexplained N isotopic variations in planetary materi\xad\nals; and\n•\t Noble gas isotopes and elements, because they provide the basis for interpret\xad\ning the compositions of terrestrial planet atmospheres.16\nEach of the bicycle-tire-size aluminum collector trays was designed to hold 55 \npalm-size hexagonal tiles about 10 centimeters across.  Ultimately, the team settled on \ntiles made of diamond, silicon carbide, and diamondlike carbon.17\n15 \t\nNiebur, S. ', 'The Power for Flight\n170\nof HITEMP were many, but they were beneath the surface as industry adopted \nthem and advanced the state of the art as they refined materials, design, and \nthe processes needed to manufacture the new technology.\n Two instances of research and development originated during HITEMP\n, \nand their direct application to the new UHB turbofans of the 21st century con\xad\ncern the GE GEnx engine.  HITEMP researchers aimed to reduce the weight \nof low-pressure turbine blades.  They identified titanium aluminide (TiAl) as \nan ideal solution due to the material’s low density and high-temperature prop\xad\nerties that offered to reduce weight by 40 percent, but it did exhibit limited \nductility.  Lewis researchers Bradley Lerch, Susan Draper, J.\xa0Michael\xa0Pereira, \nMichael\xa0Nathal, and Curt Austin designed a laboratory impact test that simu\xad\nlated potential blade damage resulting from the ingestion of foreign objects. \n They revealed that TiAl alloys could withstand considerable impact damage \nwithout catastrophic failure.11 As a result, the designers of the GEnx uti\xad\nlized TiAl in the low-pressure turbine stages, specifically in the thick leading \nedges.  GE materials and process engineering general manager Robert Schafrik \nremarked that after “years of research,” the use of TiAl alloys was a “key break\xad\nthrough” in minimizing the weight of the GEnx.12\nAnother HITEMP contribution to the GEnx involved NASA researchers \nin Cleveland and researchers with GE, who maintained a longstanding col\xad\nlaboration centered on developing a use for nickel aluminide (NiAl) alloys \nas structural materials. ']","
The Genesis spacecraft was designed to conserve mass without sacrificing strength by using a combination of lightweight yet strong materials. Aluminum, composite materials, and titanium were chosen for the construction of the spacecraft. Aluminum is a lightweight, yet strong metal that is commonly used in aerospace engineering due to its high strength-to-weight ratio. Composite materials, such as carbon fiber reinforced polymers, are also lightweight and strong, and can be used to create structures with complex shapes. Titanium is a strong, lightweight metal that is resistant to corrosion and can withstand high temperatures, making it an ideal material for use in spacecraft. By using these materials, the Genesis spacecraft was able to conserve mass while maintaining the necessary strength and durability for its mission."
"What is the significance of the Chevron Nozzle in jet noise reduction, as discussed in various AIAA Papers and by Gibson in ""The Chevron Nozzle""?","The Chevron Nozzle is a promising new concept for reducing jet noise, as discussed in various AIAA Papers and by Gibson in ""The Chevron Nozzle."" Vinod G. Mengle, Ronen Elkoby, Leon Brusniak, and Russ H. Thomas presented a paper titled ""Reducing Propulsion Airframe Aeroacoustic Interactions with Uniquely Tailored Chevrons: 1"" at the 12th AIAA/CEAS Aeroacoustics Conference in 2006. They discussed how uniquely tailored chevrons can reduce propulsion airframe aeroacoustic interactions. In another paper presented at the same conference, Frederick T. Calkins, George W. Butler, and James H. Mabe discussed variable geometry chevrons for jet noise reduction. Gibson's ""The Chevron Nozzle"" also discusses the concept and its potential for reducing jet noise. The Power for Flight, a NASA publication, also mentions the chevron nozzle as a promising new concept for reducing jet noise. In 2000, Glenn researchers performed tests of 6 and 12 chevron nozzles on turbojet engines used on business jets, achieving a 2-EPNdB reduction in noise over that of a standard conical nozzle. A NASA flight research team validated the results at full-scale in a Learjet 25 operating out of Estrella Sailport near Phoenix, AZ, in March 2001. The computational and experimental research sponsored by the Advanced Subsonic Technology Program developed an in-depth understanding of the fluid mechanics of the chevron nozzle concept.","['Vinod G. Mengle, Ronen Elkoby, Leon Brusniak, and Russ H. Thomas, \n“Reducing Propulsion Airframe Aeroacoustic Interactions with Uniquely \nTailored Chevrons: 1.  Isolated Nozzles” (AIAA Paper 2006-2467, pre\xad\nsented at the 12th AIAA/CEAS Aeroacoustics Conference, Cambridge, \nMA, May 8–10, 2006); Gibson, “The Chevron Nozzle,” p.\xa07.\n\t\n 108.\t Frederick T. Calkins, George W. Butler, and James H. Mabe, “Variable \nGeometry Chevrons for Jet Noise Reduction” (AIAA Paper 2006-\n2546, presented at the 12th AIAA/CEAS Aeroacoustics Conference, \nCambridge, MA, May 8–10, 2006); Gibson, “The Chevron Nozzle,” \npp.  7–8.\n\t\n 109.\t Gibson, “The Chevron Nozzle,” p. ', 'The Power for Flight\n212\n\t\n106.\t Vinod G. Mengle, “Jet Noise Characteristics of Chevrons in Internally \nMixed Nozzles” (AIAA Paper 2005-2934, presented at the 11th AIAA/\nCEAS Aeroacoustics Conference, Monterey, CA, May 23–25, 2005); \nGibson, “The Chevron Nozzle,” p.  7.\n\t\n 107.\t Vinod G. Mengle, Ronen Elkoby, Leon Brusniak, and Russ H. Thomas, \n“Reducing Propulsion Airframe Aeroacoustic Interactions with Uniquely \nTailored Chevrons: 1. ', 'Lyubimov, V.P\n. \n Maslov, A.N.  Secundov, and K.Y.  Yakubovsky, “The Use of Small Air \nJets to Simulate Metal Chevrons” (AIAA Paper 2009-3372, presented \nat the 15th AIAA/CEAS Aeroacoustics Conference, Miami, FL, May \n11–13, 2009); Gibson, “The Chevron Nozzle,” p.  9.\n\t\n 118.\t Langley Research Center, “NASA’s High-Speed Research (HSR) \nProgram—Developing Tomorrow’s Supersonic Passenger Jet,” April 22, \n2008, http://www.nasa.gov/centers/langley/news/factsheets/HSR-Overview2.\n', 'Low et al., “Advanced Subsonic Technology (AST) Separate-Flow High-\nBypass Ratio Nozzle Noise Reduction Program Test Report,” pp.\xa0 1, 3.\n\t 98.\t  Malcolm T. Gibson, “The Chevron Nozzle: A Novel Approach to \nReducing Jet Noise,” in NASA Innovation in Aeronautics, p.  4.\n\t 99.\t  Golub et al., “Evaluation of the Advanced Subsonic Technology Program \nNoise Reduction Benefits,” p. ', 'The Power for Flight\n194\nAs an outgrowth of testing derived from noise-suppressor concepts for mili\xad\ntary and civilian aircraft engines, the chevron nozzle had become a promising \nnew concept, and research and refinement accelerated.  Glenn researchers per\xad\nformed tests of 6 and 12 chevron nozzles on turbojet engines used on business \njets in the spring of 2000.  They achieved a 2-EPNdB reduction in noise over that \nof a standard conical nozzle.  A NASA flight research team validated the results at \nfull-scale in a Learjet 25 operating out of Estrella Sailport near Phoenix, AZ, in \nMarch 2001.101 The computational and experimental research sponsored by the \nAST developed an in-depth understanding of the fluid mechanics of the chevron \nnozzle concept. ']","
The Chevron Nozzle is significant in jet noise reduction, as discussed in various AIAA Papers and by Gibson in ""The Chevron Nozzle"". The chevron nozzle is a type of nozzle with serrated edges that helps to reduce jet noise by promoting the mixing of high-speed jet exhaust with the surrounding air. This is achieved by creating a series of small shockwaves that scatter and dissipate the noise energy.

The AIAA Papers mentioned in the context information provide evidence of the effectiveness of chevron nozzles in reducing jet noise. For example, Paper 2005-2934 by Vinod G. Mengle discusses the jet noise characteristics of chevrons in internally mixed nozzles, while Paper 2006-2467 by Vinod G. Mengle, Ronen Elkoby, Leon Brusniak, and Russ H. Thomas explores the use of uniquely tailored chevrons to reduce propulsion airframe aeroacoustic interactions in isolated nozzles.

Furthermore, Paper 2006-2546 by Frederick T. Calkins, George W. Butler, and James H. Mabe discusses the use of variable geometry chevrons for jet noise reduction. This suggests that the chevron nozzle can be further optimized for noise reduction by adjusting the geometry of the chevrons.

Gibson's ""The Chevron Nozzle"" provides a comprehensive overview of the chevron nozzle and its applications in jet noise reduction. According to Gibson, chevron nozzles have been used in commercial aircraft engines since the 1990s and have been shown to reduce jet noise by up to 10 decibels. Gibson also notes that chevron nozzles have been used in military aircraft, such as the F-15 and F-16, to reduce noise and improve stealth capabilities.

In summary, the Chevron Nozzle is a significant technology in jet noise reduction, as evidenced by various AIAA Papers and Gibson's ""The Chevron Nozzle"". The chevron nozzle promotes the mixing of high-speed jet exhaust with the surrounding air, creating small shockwaves that scatter and dissipate noise energy. The technology has been used in commercial and military aircraft to reduce noise and improve stealth capabilities."
"Can you explain what the Skylon reusable launch vehicle is, as described in the provided context information?","According to the provided context information, the Skylon reusable launch vehicle is a spaceplane developed by Reaction Engines Limited in the United Kingdom. The company describes it as ""an unpiloted, reusable spaceplane intended to provide reliable, responsive and cost-effective access to space."" The Skylon is considered a forerunner of future single-stage winged vehicles, and it is not much farther along than the concept design, as noted by Teal Group analyst Marco Antonio Cáceres in early 2001.","['In the same way we find different types of vehicles on \nground like cars, busses and trucks, there are different optimal \nconcepts for space transportation….  In parallel we see the advent \nof winged launch systems (as suggested by the late Prof.  [Eugen] \nSänger already in 1932).  The air-launched Pegasus on the one \nhand, as well as re-entry gliders like the Shuttle Orbiter or the \nEuropean Hermes Project on the other hand can be considered as \nforerunners of future two-stage and finally eventually single-stage \nwinged vehicles.67 \nIn the United Kingdom, Reaction Engines Limited has been working \non development plans for the Skylon reusable launch vehicle.  According to \nthe company, the Skylon is “an unpiloted, reusable spaceplane intended to \nprovide reliable, responsive and cost-effective access to space.”68 In regard to \nChina’s developmental effort, while few details are available, popular litera\xad\nture suggests that China is developing an experimental vehicle resembling \nthe X-34.  Reputedly named Shenlong (“Divine Dragon”), it is intended \nfor air-launch from a modified Xian H-6 bomber (the Chinese-produced \nderivation of the Soviet-era Tupolev Tu-16 Badger), in the same fashion that \nthe United States’ North American X-15 was air-launched from a Boeing \nNB-52 Stratofortress. \n In early 2001, Teal Group analyst Marco Antonio Cáceres commented on \nthe reusable launch vehicle programs then underway worldwide by noting that \n[t]here are roughly a dozen reusable launch vehicle (RLV) devel\xad\nopment efforts worldwide, including a few Russian and European \nprograms for which there [is] little information. ', 'In parallel we see the advent \nof winged launch systems (as suggested by the late Prof.  [Eugen] \nSänger already in 1932).  The air-launched Pegasus on the one \nhand, as well as re-entry gliders like the Shuttle Orbiter or the \nEuropean Hermes Project on the other hand can be considered as \nforerunners of future two-stage and finally eventually single-stage \nwinged vehicles.67 \nIn the United Kingdom, Reaction Engines Limited has been working \non development plans for the Skylon reusable launch vehicle.  According to \nthe company, the Skylon is “an unpiloted, reusable spaceplane intended to \nprovide reliable, responsive and cost-effective access to space.”68 In regard to \nChina’s developmental effort, while few details are available, popular litera\xad\nture suggests that China is developing an experimental vehicle resembling \nthe X-34.  Reputedly named Shenlong (“Divine Dragon”), it is intended \nfor air-launch from a modified Xian H-6 bomber (the Chinese-produced \nderivation of the Soviet-era Tupolev Tu-16 Badger), in the same fashion that \nthe United States’ North American X-15 was air-launched from a Boeing \nNB-52 Stratofortress. \n In early 2001, Teal Group analyst Marco Antonio Cáceres commented on \nthe reusable launch vehicle programs then underway worldwide by noting that \n[t]here are roughly a dozen reusable launch vehicle (RLV) devel\xad\nopment efforts worldwide, including a few Russian and European \nprograms for which there [is] little information.  Most of these \nprograms are not much farther along than the concept design \n', 'The air-launched Pegasus on the one \nhand, as well as re-entry gliders like the Shuttle Orbiter or the \nEuropean Hermes Project on the other hand can be considered as \nforerunners of future two-stage and finally eventually single-stage \nwinged vehicles.67 \nIn the United Kingdom, Reaction Engines Limited has been working \non development plans for the Skylon reusable launch vehicle.  According to \nthe company, the Skylon is “an unpiloted, reusable spaceplane intended to \nprovide reliable, responsive and cost-effective access to space.”68 In regard to \nChina’s developmental effort, while few details are available, popular litera\xad\nture suggests that China is developing an experimental vehicle resembling \nthe X-34.  Reputedly named Shenlong (“Divine Dragon”), it is intended \nfor air-launch from a modified Xian H-6 bomber (the Chinese-produced \nderivation of the Soviet-era Tupolev Tu-16 Badger), in the same fashion that \nthe United States’ North American X-15 was air-launched from a Boeing \nNB-52 Stratofortress. \n In early 2001, Teal Group analyst Marco Antonio Cáceres commented on \nthe reusable launch vehicle programs then underway worldwide by noting that \n[t]here are roughly a dozen reusable launch vehicle (RLV) devel\xad\nopment efforts worldwide, including a few Russian and European \nprograms for which there [is] little information.  Most of these \nprograms are not much farther along than the concept design \n', 'As the statement noted, “The policy \nobliges the government to fully consider commercial services as part \nof the decision-making process and imposes specific criteria on the \nuse of excess assets.”33 \n•\t Provide for an expanded private sector role in the Federal space trans\xad\nportation R&D decision making processes.  “In contrast with previous \nnational policy on space transportation, this policy specifically directs \nthe Departments of Transportation and Commerce to identify oppor\xad\ntunities for government-industry cooperation and to factor these into \nNASA’s and DoD’s implementation plans.”34 \nThe directive designated the Department of Defense as lead agency for the \nimprovement and evolution of the U.S.  expendable launch vehicle fleet and for \nthe development of the appropriate technology.  NASA was assigned responsi\xad\nbility for reusable launch vehicles, including improvement of the Space Shuttle \nsystem, focusing on reliability, safety, and cost effectiveness and, in the longer \nterm, developing the technology and demonstrating the next generation of reus\xad\nable space transportation systems.  This included the controversial and technically \nchallenging SSTO concept.  NASA was to focus its investments on technologies \nto support a decision no later than December 1996 on whether to proceed \nwith a flight demonstration program, which would, in turn, provide the basis \nfor deciding by the year 2000 whether to proceed with a new launch system to \nreplace the aging Shuttle fleet.  In retrospect, these goals were overly ambitious, \ngiven the many other fiscal demands and priorities of the Clinton\xa0administration. \n', '2.  (March–April 1999). \n Mizobata, Kazuhidé, Shimon Narita, Jun Nakaya, Hiroshi Yoshida, Takakagé \nArai, Jiro Kasahara, Harunori, Nagata, Ken’ich Ito, Ryojiro Akiba, and \nYooichi Oowada.  “Reusable Launch Vehicle Concepts Based on Hybrid \nRockets.” Paper presented at the AIAA/NAL-NASDA-ISAS 10th \nInternational Space Planes and Hypersonic Systems and Technologies \nConference, Kyoto, Japan, April 24–27, 2001.  AIAA 2001-1792.\n Mori, Takeshi, Minoru Kobayasi, Kototsugu Taniguchi.  “MHI [Mitsubishi \nHeavy Industries, LTD.] ']","
The Skylon reusable launch vehicle is an unpiloted, reusable spaceplane that is being developed by Reaction Engines Limited in the United Kingdom. According to the company, it is intended to provide reliable, responsive, and cost-effective access to space. The Skylon is designed to be a two-stage-to-orbit vehicle, which means it will use two stages to reach orbit. The first stage will carry the second stage and the payload to a high altitude, and then the second stage will separate and continue to orbit while the first stage returns to Earth for reuse. The Skylon is still in the development phase, and there is no information available about its expected performance or capabilities."
Question: What is the opinion of the National Advisory Committee for Aeronautics regarding the conservation of helium reserves and the development of airships in America?,"The National Advisory Committee for Aeronautics recommends that the Government acquire and seal for future use the best helium-producing gas fields, continue experiments for the development of an efficient and economical process for the extraction and repurification of helium, and continue experimental work in connection with the development of airships. The committee presents as the crystallized opinion of the Government experts who have studied the helium problem that in helium the United States has exclusive possession of a valuable adjunct to national defense which will be wasted unless conservation is provided for without delay. With large reserves of helium and the development of types of airships to fully realize the advantages to be derived from the use of helium, America would possess resources and knowledge with which no other nation could successfully compete. (Source: Document 5-2 (d), ""Airship Development,"" NACA Annual Report (1921), pp. 74-75)","['5.\n HELIUM AND AIRSHIPS\nThe United States has a virtual monopoly of the known sources of supply of \nhelium, and these are limited.  Experiments have been conducted by the Bureau of \nMines with a view to the development of methods of production and storage, but \nas yet the problem of storage in large quantities has not been satisfactorily solved. \n Because the known supply is limited, because it is escaping into the atmosphere \nat an estimated rate sufficient to fill four large airships weekly, and because of \nthe tremendously increased value and safety which the use of helium would give \nto airships, particularly in warfare, it is, in the opinion of the National Advisory \nCommittee for Aeronautics, the very essence of wisdom and prudence to provide \nfor the conservation of large reserves through the acquisition and sealing by the \nGovernment of the best helium-producing fields.  Attention now being given to the \ndevelopment of types of airships to realize fully the advantages which the use of \nhelium would afford should be continued.  Such development would give America \nadvantages, for purposes either of war or commerce, with which no other nation \ncould successfully compete.\n Document 5-2 (d), “Airship Development,” \nNACA Annual Report (1921), pp. ', 'The Wind and Beyond, Volume III\n74\nmay be resolved into one of conservation by the storage of helium in its natural \nstate.  Helium for current uses, however, will continue to be stored in high-pressure \ncontainers until used.\n In connection with the consideration of an airship development policy, the \ncommittee presents as the crystallized opinion of the Government experts who have \nstudied the helium problem that in helium the United States has exclusive posses\xad\nsion of a valuable adjunct to national defense which will be wasted unless conserva\xad\ntion is provided for without delay.\n The National Advisory Committee for Aeronautics therefore recommends \nthat the Government acquire and seal for future use the best helium-producing \ngas fields; that such experiments be continued as are involved in the develop\xad\nment of an efficient and economical process for the extraction and repurification \nof helium; and that the Government continue experimental work in connection \nwith the development of airships, and inaugurate without delay the use of airships \ninflated with helium.  With large reserves of helium and the development of types \nof airships to fully realize the advantages to be derived from the use of helium, \nAmerica would possess resources and knowledge with which no other nation could \nsuccessfully\xa0compete.\n Document 5-2 (f), “The Electrostatic Problem of \nAirships,” NACA Annual Report (1921), p. ', 'The Wind and Beyond, Volume III\n74\nmay be resolved into one of conservation by the storage of helium in its natural \nstate.  Helium for current uses, however, will continue to be stored in high-pressure \ncontainers until used.\n In connection with the consideration of an airship development policy, the \ncommittee presents as the crystallized opinion of the Government experts who have \nstudied the helium problem that in helium the United States has exclusive posses\xad\nsion of a valuable adjunct to national defense which will be wasted unless conserva\xad\ntion is provided for without delay.\n The National Advisory Committee for Aeronautics therefore recommends \nthat the Government acquire and seal for future use the best helium-producing \ngas fields; that such experiments be continued as are involved in the develop\xad\nment of an efficient and economical process for the extraction and repurification \nof helium; and that the Government continue experimental work in connection \nwith the development of airships, and inaugurate without delay the use of airships \ninflated with helium.  With large reserves of helium and the development of types \nof airships to fully realize the advantages to be derived from the use of helium, \nAmerica would possess resources and knowledge with which no other nation could \nsuccessfully\xa0compete.\n Document 5-2 (f), “The Electrostatic Problem of \nAirships,” NACA Annual Report (1921), p.  22.\n', 'Helium for current uses, however, will continue to be stored in high-pressure \ncontainers until used.\n In connection with the consideration of an airship development policy, the \ncommittee presents as the crystallized opinion of the Government experts who have \nstudied the helium problem that in helium the United States has exclusive posses\xad\nsion of a valuable adjunct to national defense which will be wasted unless conserva\xad\ntion is provided for without delay.\n The National Advisory Committee for Aeronautics therefore recommends \nthat the Government acquire and seal for future use the best helium-producing \ngas fields; that such experiments be continued as are involved in the develop\xad\nment of an efficient and economical process for the extraction and repurification \nof helium; and that the Government continue experimental work in connection \nwith the development of airships, and inaugurate without delay the use of airships \ninflated with helium.  With large reserves of helium and the development of types \nof airships to fully realize the advantages to be derived from the use of helium, \nAmerica would possess resources and knowledge with which no other nation could \nsuccessfully\xa0compete.\n Document 5-2 (f), “The Electrostatic Problem of \nAirships,” NACA Annual Report (1921), p.  22.\n THE ELECTROSTATIC PROBLEM FOR AIRSHIPS\nThe question of the danger to airships from static charges of electricity and \nfrom lightning was referred to the committee, and a large amount of data was col\xad\nlected. ', 'What, in the opinion of the committee, are the most practical steps that \ncan be taken at this time to encourage the development of an airship industry in \nthe United States looking toward the promotion of commercial air navigation by \nrigid\xa0airships?\n Under date of March 1, 1928, the committee replied to Senator Bingham \nas\xa0follows:\nHon.  Hiram Bingham,\nUnited States Senate, Washington, D.C.\n Dear Senator Bingham: Your letter dated February 16, 1928, making certain \ninquiries as to the opinion of the National Advisory Committee for Aeronautics \nwith reference to the construction and operation of rigid airships and the devel\xad\nopment of an airship industry in the United States, was considered at a meeting \nof the executive committee held March 1, 1928, and the following resolutions \nwere\xa0adopted:\nResolved, That it is the opinion of the National Advisory Committee for \nAeronautics that the present state of the art of constructing and operating large \n']","
The National Advisory Committee for Aeronautics (NACA) believes that it is wise and prudent to conserve large reserves of helium through the acquisition and sealing by the Government of the best helium-producing fields. This is due to the limited supply of helium, its escape into the atmosphere at a significant rate, and the increased value and safety it would provide to airships, particularly in warfare. NACA also thinks that attention should be given to the development of types of airships to fully utilize the advantages of helium. Such development would give America advantages, for purposes either of war or commerce, with which no other nation could successfully compete."
How did CFD help in the redesign of the wing for the HiMAT flight test vehicle and the retrofitting of the engines on the Boeing 737?,"CFD techniques were key to the successful retrofitting of the engines on the Boeing 737, making it one of the most successful passenger airliners in history. Using data from CFD studies, Boeing engineers were able to design the new fanjets for the engines for much greater efficiency.

CFD began to pay off in the late 1970s, with the successful redesign of the wing for the HiMAT (Highly Maneuverable Aircraft Technology) flight test vehicle, a 1/3 scale model of a fighter plane used to test new aerodynamic and control concepts.

In both cases, CFD provided great capabilities to resolve Navier-Stokes equations, but wind tunnels were necessary to validate CFD findings. Always, users found that for all the great capabilities of CFD, at some point there also has to be demonstration of solutions in the real world. Wind tunnels, often exceedingly small ones that used tiny models, were ideal for that purpose.","['Always, users found \nthat for all the great capabilities of CFD, at some point there also has to be \ndemonstration of solutions in the real world.  Wind tunnels, often exceedingly \nsmall ones that used tiny models, were ideal for that purpose.\n CFD began to pay off in the late 1970s, with the successful redesign of the \nwing for the HiMAT (Highly Maneuverable Aircraft Technology) flight test \nvehicle, a 1/3 scale model of a fighter plane used to test new aerodynamic and \ncontrol concepts.  CFD techniques were also key to the successful retrofitting of \nthe engines on the Boeing 737, making it one of the most successful passenger \nairliners in history.  Using data from CFD studies, Boeing engineers were able to \ndesign the new fanjets for the engines for much greater efficiency. \n', 'Wind tunnels, often exceedingly \nsmall ones that used tiny models, were ideal for that purpose.\n CFD began to pay off in the late 1970s, with the successful redesign of the \nwing for the HiMAT (Highly Maneuverable Aircraft Technology) flight test \nvehicle, a 1/3 scale model of a fighter plane used to test new aerodynamic and \ncontrol concepts.  CFD techniques were also key to the successful retrofitting of \nthe engines on the Boeing 737, making it one of the most successful passenger \nairliners in history.  Using data from CFD studies, Boeing engineers were able to \ndesign the new fanjets for the engines for much greater efficiency. \n', 'Over time, it became obvious that \nCFD provided great capabilities to resolve Navier-Stokes equations, but that \nwind tunnels were necessary to validate CFD findings.  Always, users found \nthat for all the great capabilities of CFD, at some point there also has to be \ndemonstration of solutions in the real world.  Wind tunnels, often exceedingly \nsmall ones that used tiny models, were ideal for that purpose.\n CFD began to pay off in the late 1970s, with the successful redesign of the \nwing for the HiMAT (Highly Maneuverable Aircraft Technology) flight test \nvehicle, a 1/3 scale model of a fighter plane used to test new aerodynamic and \ncontrol concepts.  CFD techniques were also key to the successful retrofitting of \nthe engines on the Boeing 737, making it one of the most successful passenger \nairliners in history.  Using data from CFD studies, Boeing engineers were able to \ndesign the new fanjets for the engines for much greater efficiency. \n', 'Computational Fluid Dynamics: CFD contributed signifi\xad\ncantly to the development of aero-heating data bases for X-33 and \nX-34, addressed specific, localized phenomena such as shear layer \nimpingement on the X-33 engine modules, and played a comple\xad\nmentary role in the development of aerodynamic data bases which \nrequired full tip-to-tail solutions.  Through these applications to \ncomplex configurations over wide ranges of flow conditions and \nattitude, CFD capabilities increased considerably as codes were \nmodified to enhance accuracy, increase speed, and provide new \ncapabilities such as RCS interactions, full wake solutions, etc. \n Extensive comparisons were performed between the two primary \nNavier-Stokes solvers for hypersonic flows used within NASA, \nnamely the Langley developed LAURA code and the commer\xad\ncially available GASP code from Aerosoft, Inc., in which strengths \nand weaknesses were identified….  Most importantly, confidence \nin using CFD to provide aerodynamic and aero-heating data \nfor aerospace vehicles was increased appreciably by comparisons \nof CFD predictions to wind tunnel measurements and code to \ncode.  These comparisons provided a better understanding of what \nphysical and numerical models to use…in futures applications.\n From X-33 and X-34 experiences in aerothermodynamics, it \nis strongly recommended that computational and experimental \naerothermodynamicists work together in the development of both \naerodynamic and aero-heating data bases.  The strengths of CFD \nand ground-based testing are complementary and, used together, \nprovide a better product. ', 'However, there are \nmany factors influencing the basic design features of the helicopter that do not \nappear directly in the preliminary design analysis.  For example, the rotor type is \ndetermined more by its influence on the helicopter handling qualities, aeroelastic \nstability, and maintenance than by its influence on performance and weight.  Such \nconsiderations must be included by the engineer in the optimization process.\n A key element in the preliminary design of aircraft is the estimation of the \nweights of the various components of the vehicle from the basic parameters of the \ndesign.  For a new aircraft that has not reached the detailed design stage, the com\xad\nponent weight estimates can only be obtained by interpolating and extrapolating \nthe trends observed in the weight data for existing vehicles.  Preliminary design \nanalyses generally use analytical expressions based on correlation of such weight \ndata.  The fundamental difficulty with such an approach is the reliability of the \ntrends, particularly when it is necessary to extrapolate far beyond existing designs. \n']","
CFD helped in the redesign of the wing for the HiMAT (Highly Maneuverable Aircraft Technology) flight test vehicle by providing the necessary computational power to solve the complex Navier-Stokes equations that were too difficult to resolve using linear equations. This allowed engineers to model the behavior of blunt-body objects and break down the equations into usable subparts, establishing methodologies for resolving multiple variables concurrently. This led to the successful redesign of the wing for the HiMAT vehicle, a 1/3 scale model of a fighter plane used to test new aerodynamic and control concepts.

Similarly, CFD techniques were also key to the successful retrofitting of the engines on the Boeing 737. By using data from CFD studies, Boeing engineers were able to design the new fanjets for the engines for much greater efficiency. This helped make the Boeing 737 one of the most successful passenger airliners in history.

It's important to note that while CFD provides great capabilities to resolve Navier-Stokes equations, wind tunnels are necessary to validate CFD findings and demonstrate solutions in the real world. Wind tunnels, often exceedingly small ones that used tiny models, were ideal for that purpose."
Question: What was the primary goal of the Mariner 9 mission and what significant discoveries were made during its operation?,"The primary goal of the Mariner 9 mission was to orbit Mars and photograph its surface using a single TV camera fixed on a scan platform that could return up to 22 frames after an eight-month journey. During its operation, Mariner 9 identified about 20 volcanoes, one of which, later named Olympus Mons, dwarfed any similar feature on Earth. It was determined that Olympus Mons, part of Nix Olympica—a “great volcanic pile” possibly formed by the eruption of hot magma from the planet’s interior—is about 15–30 kilometers tall and has a base with a diameter of 600 kilometers. Another major surface feature identified was Valles Marineris, a system of canyons east of the Tharsis region that is more than 4,000 kilometers long, 200 kilometers wide, and in some areas, up to 7 kilometers deep. On 11 February 1972, NASA announced that Mariner 9 had achieved all its goals although the spacecraft continued sending back useful data well into the summer. By the time of last contact at 22:32 UT on 27 October 1972 when it exhausted gaseous nitrogen for attitude control, the spacecraft had mapped 85% of the planet at a resolution of 1–2 kilometers, returning 7,329 photos (including at least 80 of Phobos and Deimos). Thus ended one of the great early robotic missions of the space age and undoubtedly one of the most influential.","['By February 1972, the \nspacecraft had identified about 20 volcanoes, one \nof which, later named Olympus Mons, dwarfed \nany similar feature on Earth.  Based on data from \nMariner 9’s spectrometers, it was determined that \nOlympus Mons, part of Nix Olympica—a “great vol\xad\ncanic pile” possibly formed by the eruption of hot \nmagma from the planet’s interior—is about 15–30 \nkilometers tall and has a base with a diameter of 600 \nkilometers.  Another major surface feature identified \nwas Valles Marineris, a system of canyons east of the \nTharsis region that is more than 4,000 kilometers \nlong, 200 kilometers wide, and in some areas, up \nto 7 kilometers deep.  On 11 February 1972, NASA \nannounced that Mariner 9 had achieved all its goals \nalthough the spacecraft continued sending back \nuseful data well into the summer.  By the time of \nlast contact at 22:32 UT on 27 October 1972 when \nit exhausted gaseous nitrogen for attitude control, \nthe spacecraft had mapped 85% of the planet at a \nresolution of 1–2 kilometers, returning 7,329 photos \n(including at least 80 of Phobos and Deimos).  Thus \nended one of the great early robotic missions of the \nspace age and undoubtedly one of the most influ\xad\nential.  The spacecraft is expected to crash onto the \nMartian surface sometime around 2020.\n', '11\xa0/ \nAtlas D no.  289 / Agena D no.  AD68/6931)\nLaunch Date and Time: 5 November 1964 / 19:22:05 UT\nLaunch Site: Cape Kennedy / Launch Complex 13\nScientific Instruments:\n1.\t imaging system\n2.\t cosmic dust detector\n3.\t cosmic ray telescope\n4.\t ionization chamber\n5.\t helium magnetometer\n6.\t trapped radiation detector\n7.\t solar plasma probe\nResults: NASA approved two probes for the Mariner-\nMars 1964 project in November 1962.  The primary \ngoal of the two spacecraft, code-named Mariner \nC, was to photograph the Martian surface using \na single TV camera fixed on a scan platform that \ncould return up to 22 frames after an eight-month \njourney.  During the launch of Mariner III, the \nfirst of the two probes, the booster payload shroud \nfailed to separate from the payload.  Additionally, \nbattery power spuriously dropped to zero (at T+8 \nhours 43 minutes) and the spacecraft’s solar panels \napparently never unfurled to replenish the power \nsupply.  Due to the incorrect mass of the spacecraft \n(since the payload shroud was still attached), it \nnever entered a proper trans-Mars trajectory. ', '5401 / Agena D no. \n AD157/6933)\nLaunch Date and Time: 14 June 1967 / 06:01:00 UT\nLaunch Site: Cape Kennedy / Launch Complex 12\nScientific Instruments:\n1.\t ultraviolet photometer\n2.\t  S-band occultation experiment\n3.\t dual frequency occultation experiment\n4.\t solar plasma probe\n5.\t magnetometer\n6.\t trapped radiation detector\n7.\t celestial mechanics experiment\nResults: In December 1965, NASA approved a proj\xad\nect to modify the Mariner IV backup spacecraft \nto conduct a closer flyby of Venus than the only \nother NASA probe to fly past Venus, Mariner II. \n The primary goal of the mission was to conduct a \nradio-occultation experiment (much like Mariner \nIV at Mars) to determine atmospheric properties \nof Venus.  Unlike Mariner IV, however, Mariner \nV did not carry an imaging instrument.  Initially, \nNASA had planned to send Mariner V on a flyby at \na miss distance of 8,165 kilometers to the surface, \nbut the Agency altered its plan in favor of a more \nmodest 75,000-kilometer flyby in order to preclude \nthe non-sterilized vehicle from crashing into the \nplanet.  After a mid-course correction on 19 June, \nMariner V began transmitting data on Venus on \n19\xa0October during its encounter. ', 'The original photo was color-enhanced to provide more \ncontrast in Venus’s cloudy atmosphere.  Credit: NASA\nLaunch Site: Cape Canaveral / Launch Complex 36B\nScientific Instruments:\n1.\t  2 telescopes/cameras\n2.\t infrared radiometer\n3.\t ultraviolet airglow spectrometer\n4.\t ultraviolet occultation spectrometer\n5.\t magnetometer\n6.\t charged particle telescope\n7.\t plasma analyzer\nResults: Mariner 10 was the first spacecraft sent to \nthe planet Mercury; the first mission to explore \ntwo planets (Mercury and Venus) during a single \nmission; the first to use gravity-assist to change \nits flight-path; the first to return to its target after \nan initial encounter; and the first to use the solar \nwind as a major means of spacecraft orientation \nduring flight.  The primary goal of the Mariner 10 \nwas to study the atmosphere (if any), surface, and \nphysical characteristics of Mercury.  Soon after \nleaving Earth orbit, the spacecraft returned strik\xad\ning photos of both Earth and the Moon as it sped \nto its first destination, Venus.  During the coast, \nthere were numerous technical problems, includ\xad\ning malfunctions in the high-gain antenna and the \nattitude control system.  In January 1974, Mariner \n10 successfully returned data (sans photographs) \n', '103\n1971\u2003\nradiation.  In April 2013, NASA announced that its \nMars Reconnaissance Orbiter (MRO) may have \nimaged hardware from Mars 3, including its para\xad\nchute, heat shield, braking engine, and the lander \nitself.  These were found in 2008 by a community \nof Russian space enthusiasts who were following \nthe mission of Curiosity.\n 127\nMariner 9\nNation: USA (49)\nObjective(s): Mars orbit\nSpacecraft: Mariner-71I / Mariner-I\nSpacecraft Mass: 997.9 kg\nMission Design and Management: NASA / JPL\nLaunch Vehicle: Atlas Centaur (AC-23 / Atlas 3C \nno.  5404C / Centaur D-1A)\nLaunch Date and Time: 30 May 1971 / 22:23:04 UT\nLaunch Site: Cape Kennedy / Launch Complex 36B\nScientific Instruments:\n1.\t imaging system\n2.\t ultraviolet spectrometer\n3.\t infrared spectrometer\n4.\t infrared radiometer\nResults: Mariner 9 was the second in the pair of iden\xad\ntical spacecraft launched in 1971 to orbit Mars.  The \nfirst spacecraft, Mariner 8, failed to reach Earth \norbit.  Based on a wide octagonal structure, these \nvehicles used a bi-propellant propulsion system \nwith a fixed thrust of 136 kgf for orbital insertion \naround Mars. ']","
The primary goal of the Mariner 9 mission was to map about 70% of the surface during the first three months of operation. During its operation, Mariner 9 made several significant discoveries. It identified about 20 volcanoes, one of which, later named Olympus Mons, dwarfed any similar feature on Earth. Based on data from Mariner 9’s spectrometers, it was determined that Olympus Mons is about 15-30 kilometers tall and has a base with a diameter of 600 kilometers. Another major surface feature identified was Valles Marineris, a system of canyons east of the Tharsis region that is more than 4,000 kilometers long, 200 kilometers wide, and in some areas, up to 7 kilometers deep. The spacecraft also returned spectacular photos of the deeply pitted Martian landscape, for the first time showing such features as the great system of parallel rilles stretching more than 1,700 kilometers across Mare Sirenum. The vast amount of incoming data countered the notion that Mars was geologically inert. There was some speculation on the possibility of water having existed on the surface during an earlier period, but the spacecraft data could not provide any conclusive proof."
"Question: What is the support unloading compensator and how is it used in the medical field, particularly in stroke rehabilitation and cerebral palsy treatment?","The support unloading compensator is a device that stimulates the support zones of the foot in natural human gait. It was developed based on ground-based studies at IBMP that identified a particular pattern of stabilization between body loading on the soles of the feet and subsequent motor stabilization processes associated with brain and spinal cord activities. The knowledge obtained revealed that the development of sensory-motor disturbances may be prevented by means of ""artificial"" support stimuli applied to the bottoms of the feet. Today, this technology is being used in the most acute phase of stroke and facilitates more significant regression of motor disturbances and earlier recovery of locomotion than traditional treatment methods. In cases of stroke, the Korvit device is used in the first hours after the onset of a stroke to prevent muscle spasticity development of limbs affected by paresis. The support unloading compensator is also used in the integrated rehabilitation of cerebral palsy patients to maximize restoration of the balance of strength between extensor and flexor muscles, particularly in an upright position, and to normalize the functions of standing and walking, as well as coordination control of various classes of movements.","['Diseases of the central nervous \nsystem, brain injuries of various types, long-term \nmotor unloading in aging, as well as some specific \noccupational conditions are also accompanied by \nthe development of the aforementioned changes. \n Based on these data, IBMP scientists are working \njointly with commercial companies to introduce motor \ndisturbances corrective measures that were developed \nfor weightlessness into the practice of treating and \nrehabilitating patients with profound motor lesions that \nare due to cerebral palsy, stroke, and brain and spinal \ncord injuries.\n Between 2005 and 2011, the Center for Aerospace \nMedicine developed a clinical version of the support \nunloading compensator—the Korvit—and obtained \nall approval documents and licenses.\n Today, this technology is being used in the most \nacute phase of stroke and facilitates more significant \nregression of motor disturbances and earlier recovery \nof locomotion than traditional treatment methods.  Of \nparticular interest are the data on prevention of muscle \nspasticity development of limbs affected by paresis in \ncases when the Korvit device is used in the first hours \nafter the onset of a stroke.\n The support unloading compensator.\n Image credit: Aerospace Medical Center \nand Technology\nThe support unloading compensator used \non children.\n', 'Today, this technology is being used in the most \nacute phase of stroke and facilitates more significant \nregression of motor disturbances and earlier recovery \nof locomotion than traditional treatment methods.  Of \nparticular interest are the data on prevention of muscle \nspasticity development of limbs affected by paresis in \ncases when the Korvit device is used in the first hours \nafter the onset of a stroke.\n The support unloading compensator.\n Image credit: Aerospace Medical Center \nand Technology\nThe support unloading compensator used \non children.\n Image credit: Aerospace Medical Center \nand Technology\nThe use of the support stimulation method in children \nduring the early recovery phase after surgical treatment \nfor fractures of the calf bones has facilitated the \nreduction of edema by 17% to 20%, and an increase \nin the range of motion in the ankle joint by 45% as early \nas the first 72 hours after surgery.  Children who do not \nreceive such treatment experience edema lasting 6 to \n8 days, which hinders motion in the injured limb and \nretards regenerative processes.\n The use of the Korvit apparatus in the integrated \nrehabilitation of cerebral palsy patients has made \nit possible to maximize restoration of the balance \nof strength between extensor and flexor muscles, \nparticularly in an upright position, and to normalize \nthe functions of standing and walking, as well as \ncoordination control of various classes of movements.\n', 'Ground-based studies at IBMP identified a particular \npattern of stabilization between body loading on the \nsoles of the feet and subsequent motor stabilization \nprocesses associated with brain and spinal cord \nactivities.  The knowledge obtained revealed that \nthe development of sensory-motor disturbances may \nbe prevented by means of “artificial” support stimuli \napplied to the bottoms of the feet.  The research \nresults led to the development of new technology, \nthe “support unloading compensator,” which is a \ndevice that stimulates the support zones of the foot \nin natural human gait.\n Today, this technology is being \nused in the most acute phase \nof stroke and facilitates more \nsignificant regression of motor \ndisturbances and earlier recovery \nof locomotion than traditional \ntreatment methods. \n The uniqueness of this device lies in its ability to \nsimulate the physical parameters that the support \nreceptor or the foot receives during walking: the \nmagnitude of pressure, temporal characteristics, \nduration of impact, intervals between stimulation \n', 'As a result of these studies, a unique \npiece of technology was developed to help to correct \nthe motor disturbances in individuals with central \nnervous system dysfunction, injuries, balance \nproblems and motor decline due to aging.\n Ground-based studies at IBMP identified a particular \npattern of stabilization between body loading on the \nsoles of the feet and subsequent motor stabilization \nprocesses associated with brain and spinal cord \nactivities.  The knowledge obtained revealed that \nthe development of sensory-motor disturbances may \nbe prevented by means of “artificial” support stimuli \napplied to the bottoms of the feet.  The research \nresults led to the development of new technology, \nthe “support unloading compensator,” which is a \ndevice that stimulates the support zones of the foot \nin natural human gait.\n Today, this technology is being \nused in the most acute phase \nof stroke and facilitates more \nsignificant regression of motor \ndisturbances and earlier recovery \nof locomotion than traditional \ntreatment methods. \n The uniqueness of this device lies in its ability to \nsimulate the physical parameters that the support \nreceptor or the foot receives during walking: the \nmagnitude of pressure, temporal characteristics, \nduration of impact, intervals between stimulation \n', '172\nof the heel and metatarsal support zones, and intervals \nbetween stimulation of the right and left foot.\n However, the disturbances of muscle tone and \ncoordination of movement are not inherent exclusively \nto weightlessness.  Diseases of the central nervous \nsystem, brain injuries of various types, long-term \nmotor unloading in aging, as well as some specific \noccupational conditions are also accompanied by \nthe development of the aforementioned changes. \n Based on these data, IBMP scientists are working \njointly with commercial companies to introduce motor \ndisturbances corrective measures that were developed \nfor weightlessness into the practice of treating and \nrehabilitating patients with profound motor lesions that \nare due to cerebral palsy, stroke, and brain and spinal \ncord injuries.\n Between 2005 and 2011, the Center for Aerospace \nMedicine developed a clinical version of the support \nunloading compensator—the Korvit—and obtained \nall approval documents and licenses.\n Today, this technology is being used in the most \nacute phase of stroke and facilitates more significant \nregression of motor disturbances and earlier recovery \nof locomotion than traditional treatment methods.  Of \nparticular interest are the data on prevention of muscle \nspasticity development of limbs affected by paresis in \ncases when the Korvit device is used in the first hours \nafter the onset of a stroke.\n']","
The support unloading compensator is a device developed by the Center for Aerospace Medicine. It was initially designed for use in weightlessness to counteract muscle tone and coordination disturbances. However, due to its effectiveness in addressing motor disturbances, it has been adapted for use in the medical field, particularly in stroke rehabilitation and cerebral palsy treatment.

In stroke rehabilitation, the support unloading compensator, also known as the Korvit, is used in the most acute phase of stroke to facilitate more significant regression of motor disturbances and earlier recovery of locomotion than traditional treatment methods. It has also been found to prevent muscle spasticity development in limbs affected by paresis when used in the first hours after the onset of a stroke.

In cerebral palsy treatment, the use of the Korvit apparatus in the integrated rehabilitation of patients has made it possible to maximize restoration of the balance of strength between extensor and flexor muscles, particularly in an upright position, and to normalize the functions of standing and walking, as well as coordination control of various classes of movements.

The support unloading compensator has also been used in children during the early recovery phase after surgical treatment for fractures of the calf bones, facilitating the reduction of edema and an increase in the range of motion in the ankle joint."
Question: What is the goal of the OSIRIS-REx mission and what scientific instruments are used to achieve this goal?,"The goal of the OSIRIS-REx mission is to reach a near-Earth asteroid 101955 Bennu (formerly known as 1999 RQ36), collect a 59.5-gram sample, and then return it to Earth. The scientific instruments used to achieve this goal include the Thermal Emission Spectrometer (OTES), Regolith X-Ray Imaging Spectrometer (REXIS), Visible and IR Spectrometer (OVIRS), and Touch-And-Go Sample Acquisition Mechanism (TAGSAM).","[""Regolith X-Ray Imaging Spectrometer \n(REXIS OSIRIS-REx)\n6.\t  Touch-And-Go Sample Acquisition \nMechanism (TAGSAM)NASA's OSIRIS-REx spacecraft is shown here in an artist's impression.  OSIRIS-REx is the third mission in NASA's New Frontiers Program\nNASA’s OSIRIS-REx spacecraft is shown here in an artist’s impression.  OSIRIS-REx is the third mission in NASA’s New \nFrontiers Program.  Credit: NASA/University of Arizona\nResults: The Origins, Spectral Interpretation, \nResource \nIdentification, \nSecurity, \nRegolith \nExplorer (OSIRIS-REx) mission is the third major \nplanetary science mission falling under NASA’s \nNew Frontiers Program (after New Horizons \nlaunched in 2006 and Juno launched in 2011). \n The goal of the mission is to reach a near-Earth \nasteroid 101955 Bennu (formerly known as 1999 \nRQ36), collect a 59.5-gram sample, and then \nreturn it to Earth.  The science mission, developed \nby scientists at the University of Arizona, will open \nup the possibilities to glean more information on \nhow planets formed and how life began and help \nscientists understand asteroids that could impact \nEarth in the future. "", ""Touch-And-Go Sample Acquisition \nMechanism (TAGSAM)NASA's OSIRIS-REx spacecraft is shown here in an artist's impression.  OSIRIS-REx is the third mission in NASA's New Frontiers Program\nNASA’s OSIRIS-REx spacecraft is shown here in an artist’s impression.  OSIRIS-REx is the third mission in NASA’s New \nFrontiers Program.  Credit: NASA/University of Arizona\nResults: The Origins, Spectral Interpretation, \nResource \nIdentification, \nSecurity, \nRegolith \nExplorer (OSIRIS-REx) mission is the third major \nplanetary science mission falling under NASA’s \nNew Frontiers Program (after New Horizons \nlaunched in 2006 and Juno launched in 2011). \n The goal of the mission is to reach a near-Earth \nasteroid 101955 Bennu (formerly known as 1999 \nRQ36), collect a 59.5-gram sample, and then \nreturn it to Earth.  The science mission, developed \nby scientists at the University of Arizona, will open \nup the possibilities to glean more information on \nhow planets formed and how life began and help \nscientists understand asteroids that could impact \nEarth in the future.  About 55 minutes after launch, \nafter a boost by the Centaur upper stage, OSIRIS-\nREx separated from the Atlas V and the solar \narrays deployed. "", ""Thermal Emission Spectrometer (OTES \nOSIRIS-REx)\n5.\t  Regolith X-Ray Imaging Spectrometer \n(REXIS OSIRIS-REx)\n6.\t  Touch-And-Go Sample Acquisition \nMechanism (TAGSAM)NASA's OSIRIS-REx spacecraft is shown here in an artist's impression.  OSIRIS-REx is the third mission in NASA's New Frontiers Program\nNASA’s OSIRIS-REx spacecraft is shown here in an artist’s impression.  OSIRIS-REx is the third mission in NASA’s New \nFrontiers Program.  Credit: NASA/University of Arizona\nResults: The Origins, Spectral Interpretation, \nResource \nIdentification, \nSecurity, \nRegolith \nExplorer (OSIRIS-REx) mission is the third major \nplanetary science mission falling under NASA’s \nNew Frontiers Program (after New Horizons \nlaunched in 2006 and Juno launched in 2011). \n The goal of the mission is to reach a near-Earth \nasteroid 101955 Bennu (formerly known as 1999 \nRQ36), collect a 59.5-gram sample, and then \nreturn it to Earth. "", 'By March 2017, TGO \nwas in a one-day 200 × 33,000-kilometer orbit and \nwas using the atmosphere to adjust the orbit by a \nprocess of gradual aerobraking.  The goal was to \nachieve a final operational circular orbit at 400 kilo\xad\nmeters by March 2018 at which time full-scale sci\xad\nence operations would begin.  Earlier, in December \n2016, ESA announced the formal approval of the \nsecond joint European-Russian ExoMars mission, \ntentatively slated for launch in 2020.\n 245\nOSIRIS-REx\nNation: USA (101)\nObjective(s): asteroid sample return\nSpacecraft: OSIRIS-REx\nSpacecraft Mass: 2,110 kg\nMission Design and Management: NASA GSFC / Uni\xad\nversity of Arizona\nLaunch Vehicle: Atlas V 411 (no.  AV-067)\nLaunch Date and Time: 8 September 2016 / 23:05 UT\nLaunch Site: Cape Canaveral / SLC-41\n', ""Visible and IR Spectrometer (OVIRS \nOSIRIS-REx)\n4.\t  Thermal Emission Spectrometer (OTES \nOSIRIS-REx)\n5.\t  Regolith X-Ray Imaging Spectrometer \n(REXIS OSIRIS-REx)\n6.\t  Touch-And-Go Sample Acquisition \nMechanism (TAGSAM)NASA's OSIRIS-REx spacecraft is shown here in an artist's impression.  OSIRIS-REx is the third mission in NASA's New Frontiers Program\nNASA’s OSIRIS-REx spacecraft is shown here in an artist’s impression.  OSIRIS-REx is the third mission in NASA’s New \nFrontiers Program.  Credit: NASA/University of Arizona\nResults: The Origins, Spectral Interpretation, \nResource \nIdentification, \nSecurity, \nRegolith \nExplorer (OSIRIS-REx) mission is the third major \nplanetary science mission falling under NASA’s \nNew Frontiers Program (after New Horizons \nlaunched in 2006 and Juno launched in 2011). \n""]","
The goal of the OSIRIS-REx mission is to reach a near-Earth asteroid 101955 Bennu (formerly known as 1999 RQ36), collect a 59.5-gram sample, and then return it to Earth. The science mission, developed by scientists at the University of Arizona, will open up the possibilities to glean more information on how planets formed and how life began and help scientists understand asteroids that could impact Earth in the future.

The scientific instruments used to achieve this goal include:
1. Camera Suite (PolyCam, MapCam, SamCam) (OCAMS OSIRIS-REx)
2. Laser Altimeter (OLA OSIRIS-REx)
3. Visible and IR Spectrometer (OVIRS OSIRIS-REx)
4. Thermal Emission Spectrometer (OTES OSIRIS-REx)
5. Regolith X-Ray Imaging Spectrometer (REXIS OSIRIS-REx)
6. Touch-And-Go Sample Acquisition Mechanism (TAGSAM)"
What is the Meteor Crater event and what are some of its key characteristics?,"The Meteor Crater event is a significant impact crater that came to the attention of Philadelphia lawyer and mining engineer Daniel Moreau Barringer in 1891. The feature now known as Meteor Crater is located in Arizona, USA, and is believed to have been formed about 50,000 years ago by an impact of a 50-meter nickel-iron body traveling at about 12 kilometers per second, which mostly vaporized altogether. The event is characterized by an explosive process, which is now understood to be a common feature of impact craters. In 1891, Barringer staked a mining claim at the site after examining the meteoric irons found in the area, convinced that the majority of the iron impactor lay buried somewhere beneath the crater. However, a detailed topographic survey and a magnetic survey of the region failed to find a buried magnetized mass, leading Gilbert to abandon the hypothesis he had originally favored. The episode left such an impression on Gilbert that when he did eventually publish his results several years later, it was in the context of a philosophical argument. In retrospect, it might seem obvious that Gilbert's two crucial tests would fail, not because the impact hypothesis was wrong, but because his assumptions about the buried ""star"" were incorrect. Today, Meteor Crater is known to have been formed by an impact about 50,000 years ago, in which a 50-meter nickel-iron body struck Earth while traveling at about 12 kilometers per second, impacting, and mostly vaporizing altogether.","['Impact craters were found not just on Earth and its Moon, but on \nMars and, still later, the moons of the other planets too.  Cratering was ubiqui\xad\ntous.  The creation of the National Aeronautics and Space Agency, and the par\xad\nallel foundation of the United States Geological Survey’s astrogeology branch, \nprovided institutional homes for this research.\n Meteor Crater: An Explosive Event?\n Ten years after Gilbert’s investigation of the lunar surface, the feature now \nknown as Meteor Crater came to the attention of Philadelphia lawyer and \nmining engineer Daniel Moreau Barringer, who staked a mining claim at \nthe site after examining the meteoric irons found in the area.  Convinced (as \nGilbert had been) that the majority of the iron impactor lay buried somewhere \nbeneath the crater, he enlisted the aid of friend and physicist Benjamin C. \n', 'See: \nG.\xa0S. Collins et al., “Evidence That Lake Cheko Is Not an Impact Crater,” Terra Nova \n20 (2008): 165–168; Luca Gasperini, Enrico Bonatti, and Giuseppe Longo, “The \nTunguska Mystery,” Scientific American (June 2008): 80–86.\n 30.\t  There are still arguments over the magnitude of the Tunguska event.  A recent NASA \nworkshop organized by David Morrison of NASA Ames Research Center found an \nexplosive energy of 10–20 megatons of TNT, roughly the same as the Barringer event \nthat formed Meteor Crater.  See David Morrison, “Tunguska Workshop: Applying \nModern Tools To Understand the 1908 Tunguska Impact,” NASA TM-220174, \nDecember 2018, https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20190002302.pdf \n(accessed 18 June 2019).\n 31.\t  In his words, “Each observer of the moon reasons by analogy from the terrestrial \nphenomena with which he is acquainted and seeks thus to explain the lunar surface \nfeatures…. ', 'A detailed \ntopographic survey could compare these volumes, and this was the first of \nGilbert’s tests.  The other relied on a magnetic survey of the region to look \nfor a buried magnetized mass.  It only took a few days to see that neither test \nwas looking favorable for the impact hypothesis, and Gilbert ultimately con\xad\ncluded, “It follows, under my postulates, that the great meteor is not in the \nhole…chief attention should be given to other explanations of the crater.”28\nIn retrospect, it might seem obvious that Gilbert’s two crucial tests would \nfail, not because the impact hypothesis was wrong, but because his assump\xad\ntions about the buried “star” were incorrect.  Today, Meteor Crater is known to \nhave been formed by an impact about 50,000 years ago, in which a 50-meter \nnickel-iron body struck Earth while traveling at about 12 kilometers per \nsecond, impacting, and mostly vaporizing altogether.  Under these circum\xad\nstances, there could be no iron mass to be found beneath the crater floor.  The \ndeveloping understanding of impact physics as an essentially explosive process \nwould make this clear by the middle of the 20th century, but for Gilbert, the \nevidence unequivocally ruled out the hypothesis he had originally favored, \nand he had to abandon it.29\nThis episode left such an impression on Gilbert that when he did eventually \npublish his results several years later, it was in the context of a philosophical \nargument.  In his outgoing address as the president of the Geological Society of \nAmerica in 1895, he related his theory of “The Origin of Hypotheses: Illustrated \nby the Discussion of a Topographic Problem,” in which he presented the puzzle \n27.\t ', 'But in 1980, there were not many known complete transitional sequences for \nthat era.  And compositional results turned out to be at best ambiguous, or at \nworst, misleading.  Some of Walter Alvarez’s collaborators got very solid results \nindicating an oceanic impact, while others, drawing samples from possible \nsites in the North American west, found shocked varieties of quartz, a mineral \ntypically found in continental, not oceanic, crust.35\nThe answer to this little mystery took until 1990 to emerge, and the story is \ncomplex.  No single person deserves credit for the crater’s discovery, although \none person, Alan Hildebrand, is most responsible for getting the geological \ncommunity to accept it as the impact site.36 His story provides an interesting \nparallel to the controversy surrounding Meteor Crater because the structure \nthat turned out to be the crater had already been identified but had been \nwidely dismissed as a potential impact crater.\n Hildebrand started graduate school at the University of Arizona in 1984 \nafter a short career in the mining industry in northwestern Canada.  His \n34.\t  Alvarez, T. Rex and the Crater of Doom, p. ', 'Geological Survey Field Records File, U.S.  National \nArchives, hereafter cited as Notebook 51, 14 November 1891.\n 29.\t  H. J. Melosh and G. S. Collins, “Meteor Crater Formed by Low-Velocity Impact,” \nNature 434, no.  7030 (2005): 157.\n']","
The Meteor Crater event refers to a meteor impact that occurred in Arizona, USA. It is also known as the Barringer Crater. The event is significant because it is the first impact crater on Earth to be recognized as such, and it provided important evidence for the hypothesis that some craters on the Moon and other planets were caused by meteor impacts.

Some key characteristics of the Meteor Crater event are:

- The crater is approximately 1.2 kilometers in diameter and 170 meters deep.
- The meteor that caused the crater was estimated to be about 50 meters in diameter and weighed approximately 300,000 metric tons.
- The impact event occurred about 50,000 years ago.
- The energy released during the impact was equivalent to about 20 megatons of TNT, which is roughly 1,300 times the energy released by the atomic bomb dropped on Hiroshima.
- The impact caused a shock wave that melted and vaporized rock, creating a crater and ejecting material that formed a surrounding rim.
- The impact also created a shock wave that traveled through the ground, causing seismic activity that was detected up to 80 kilometers away.
- The impact event would have caused a loud explosion and a bright fireball that could have been seen for hundreds of kilometers.
- The impact event would have also created a significant amount of dust and debris that could have affected the local climate and ecosystem."
What are the attributes of the Space Shuttle that should be considered in planning for a follow-on system?,"The Space Shuttle proved to be a flexible space vehicle. Most assuredly, the range of possibilities for operations on orbit expanded dramatically with the launch of Columbia in 1981. The ability to carry a diversity of payloads, to accomplish a myriad of tasks on orbit, and to deploy and retrieve satellites are attributes that need to be considered in any effort to develop a follow-on system. A successor to the Space Shuttle should approach a similar level of flexibility that this vehicle has demonstrated, and it is important to consider the uniqueness of the orbiter’s capabilities in planning for the future.","['The research, development, and operation of the Space \nShuttle represent a worthy follow-on to the spectacularly successful Apollo pro\xad\ngram of the 1960s and early 1970s. \n Third, the Space Shuttle proved to be a flexible space vehicle.  Most assuredly, \nthe range of possibilities for operations on orbit expanded dramatically with \nthe launch of Columbia in 1981.  The ability to carry a diversity of payloads, \nto accomplish a myriad of tasks on orbit, and to deploy and retrieve satellites \nare attributes that need to be considered in any effort to develop a follow-on \nsystem.  A successor to the Space Shuttle should approach a similar level of flex\xad\nibility that this vehicle has demonstrated, and it is important to consider the \nuniqueness of the orbiter’s capabilities in planning for the future.\n Fourth, the Space Shuttle served as a fine test bed for scientific inquiry. \n While the program was not conceptualized as a science effort—rather it was \na technology demonstrator and workhorse for space access—it was used as an \nexemplary platform for all manner of microgravity and space science enter\xad\nprises. ', 'Third, the Space Shuttle proved to be a flexible space vehicle.  Most assuredly, \nthe range of possibilities for operations on orbit expanded dramatically with \nthe launch of Columbia in 1981.  The ability to carry a diversity of payloads, \nto accomplish a myriad of tasks on orbit, and to deploy and retrieve satellites \nare attributes that need to be considered in any effort to develop a follow-on \nsystem.  A successor to the Space Shuttle should approach a similar level of flex\xad\nibility that this vehicle has demonstrated, and it is important to consider the \nuniqueness of the orbiter’s capabilities in planning for the future.\n Fourth, the Space Shuttle served as a fine test bed for scientific inquiry. \n While the program was not conceptualized as a science effort—rather it was \na technology demonstrator and workhorse for space access—it was used as an \nexemplary platform for all manner of microgravity and space science enter\xad\nprises.  The Space Shuttle’s 135 missions into Earth orbit allowed a wide range \nof scientific experimentation.\n', 'Chapter 8:\u2002 Achieving Reusable Space Access \n171\nseparate components that must work in synchronization with each other and \nto specifications more exacting than any other technological system in human \nhistory—the Space Shuttle must be viewed as a triumph of engineering and \nexcellence in technological management.  As such, it has been an enormously \nsuccessful program.  The research, development, and operation of the Space \nShuttle represent a worthy follow-on to the spectacularly successful Apollo pro\xad\ngram of the 1960s and early 1970s. \n Third, the Space Shuttle proved to be a flexible space vehicle. ', 'As the statement noted, “The policy \nobliges the government to fully consider commercial services as part \nof the decision-making process and imposes specific criteria on the \nuse of excess assets.”33 \n•\t Provide for an expanded private sector role in the Federal space trans\xad\nportation R&D decision making processes.  “In contrast with previous \nnational policy on space transportation, this policy specifically directs \nthe Departments of Transportation and Commerce to identify oppor\xad\ntunities for government-industry cooperation and to factor these into \nNASA’s and DoD’s implementation plans.”34 \nThe directive designated the Department of Defense as lead agency for the \nimprovement and evolution of the U.S.  expendable launch vehicle fleet and for \nthe development of the appropriate technology.  NASA was assigned responsi\xad\nbility for reusable launch vehicles, including improvement of the Space Shuttle \nsystem, focusing on reliability, safety, and cost effectiveness and, in the longer \nterm, developing the technology and demonstrating the next generation of reus\xad\nable space transportation systems.  This included the controversial and technically \nchallenging SSTO concept.  NASA was to focus its investments on technologies \nto support a decision no later than December 1996 on whether to proceed \nwith a flight demonstration program, which would, in turn, provide the basis \nfor deciding by the year 2000 whether to proceed with a new launch system to \nreplace the aging Shuttle fleet.  In retrospect, these goals were overly ambitious, \ngiven the many other fiscal demands and priorities of the Clinton\xa0administration. \n', 'Promise Denied\n2\ninvolved a small-payload X-34A launched from a Lockheed L-1011 and a \nlarger-payload X-34B launched from a Boeing 747), to the much smaller, \ndownsized Orbital Sciences X-34 Technology Testbed Demonstrator con\xad\ncept—is the subject of this book.\n NASA’s Access to Space Study\nMost influential of the many analytical efforts NASA sponsored or under\xad\ntook was the Access to Space study, undertaken by the Office of Space Systems \nDevelopment in 1993 in response to a congressional directive in the Agency’s \nfiscal year 1993 Appropriations Act to “assess National launch requirements, \npotential launch alternatives, and strategies to address such needs…to permit \nformulation of multiyear program plans.”2 Access to Space focused on “identi\xad\nfying long-term improvements leading to a space transportation architecture \nthat would reduce the annual cost of space launch to the U.S.  Government by \nat least 50 percent, increase the safety of flight crews by an order of magnitude \n[10 times], and make major improvements in overall system operability.”3 \nThe study examined three alternatives: upgrading the reusable Space Shuttle \nand the then-current expendable launch vehicle (ELV) fleet through 2030; \ndeveloping a new ELV system using the latest technology and beginning a \ntransition from the Space Shuttle and legacy ELV systems, starting in 2005; \nand developing a new reusable advanced-technology next-generation launch \nsystem, beginning the transition from the legacy Space Shuttle and ELV fleet, \nstarting in 2008.4 \nEach of the above options was analyzed by separate study teams using a \ncommon set of goals against which each option could be measured.  Each study \ngroup covered the following categories in the order of their priority: a)\xa0the \nfundamental requirement of satisfying the national launch needs for NASA \n(crewed and uncrewed vehicles), the Department of Defense, and commercial \ncompanies, including the definition of payloads from small to Shuttle/Titan \nclass and orbital destinations at all altitudes and inclinations, as well as destina\xad\ntions beyond earth orbit; b) the essential characteristics relating to improved \ncrew safety by an order of magnitude, acceptable life-cycle costs (LCCs), vehicle \nreliability of at least 0.98, and environmental acceptability; and c) the desired \nfeatures, including improving commercial competitiveness of launch vehicles, \ncontributing to the industrial economy, enabling incremental development \nor improvements, and improving capability relative to current systems.5 A \ncommon mission model was defined for the three study options; it included all \nU.S.  defense, civilian, and commercial users covering the period from 1995 to \n2030.  This model was based on a conservative extrapolation of current require\xad\nments and planned programs but did not include future possibilities such as \nmissions to the Moon or Mars. \n']","
1. The Space Shuttle is a triumph of engineering and excellence in technological management, having been an enormously successful program.
2. The Space Shuttle is a flexible space vehicle, with the ability to carry a diversity of payloads, accomplish a myriad of tasks on orbit, and deploy and retrieve satellites.
3. The Space Shuttle served as a fine test bed for scientific inquiry, allowing a wide range of scientific experimentation in microgravity and space science enterprises.
4. The Space Shuttle Program, while an enormous achievement, has clearly wrought a divided legacy for NASA. As a symbol of American technological excellence and as the launch system for NASA’s astronaut corps, it received high marks. But the program failed to achieve its core objective: lowering the cost of reaching Earth orbit. Therefore, cost control remains a goal that must be emphasized in the development and operation of any new human launch vehicle."
"What are the key attributes of the Space Shuttle that should be taken into account when planning for a successor system, as mentioned in the context information?","The context information mentions that the Space Shuttle proved to be a flexible space vehicle, and it is important to consider the uniqueness of the orbiter’s capabilities in planning for the future. The ability to carry a diversity of payloads, accomplish a myriad of tasks on orbit, and deploy and retrieve satellites are attributes that need to be considered in any effort to develop a follow-on system.","['Third, the Space Shuttle proved to be a flexible space vehicle.  Most assuredly, \nthe range of possibilities for operations on orbit expanded dramatically with \nthe launch of Columbia in 1981.  The ability to carry a diversity of payloads, \nto accomplish a myriad of tasks on orbit, and to deploy and retrieve satellites \nare attributes that need to be considered in any effort to develop a follow-on \nsystem.  A successor to the Space Shuttle should approach a similar level of flex\xad\nibility that this vehicle has demonstrated, and it is important to consider the \nuniqueness of the orbiter’s capabilities in planning for the future.\n Fourth, the Space Shuttle served as a fine test bed for scientific inquiry. \n While the program was not conceptualized as a science effort—rather it was \na technology demonstrator and workhorse for space access—it was used as an \nexemplary platform for all manner of microgravity and space science enter\xad\nprises.  The Space Shuttle’s 135 missions into Earth orbit allowed a wide range \nof scientific experimentation.\n', 'The research, development, and operation of the Space \nShuttle represent a worthy follow-on to the spectacularly successful Apollo pro\xad\ngram of the 1960s and early 1970s. \n Third, the Space Shuttle proved to be a flexible space vehicle.  Most assuredly, \nthe range of possibilities for operations on orbit expanded dramatically with \nthe launch of Columbia in 1981.  The ability to carry a diversity of payloads, \nto accomplish a myriad of tasks on orbit, and to deploy and retrieve satellites \nare attributes that need to be considered in any effort to develop a follow-on \nsystem.  A successor to the Space Shuttle should approach a similar level of flex\xad\nibility that this vehicle has demonstrated, and it is important to consider the \nuniqueness of the orbiter’s capabilities in planning for the future.\n Fourth, the Space Shuttle served as a fine test bed for scientific inquiry. \n While the program was not conceptualized as a science effort—rather it was \na technology demonstrator and workhorse for space access—it was used as an \nexemplary platform for all manner of microgravity and space science enter\xad\nprises. ', 'Chapter 8:\u2002 Achieving Reusable Space Access \n171\nseparate components that must work in synchronization with each other and \nto specifications more exacting than any other technological system in human \nhistory—the Space Shuttle must be viewed as a triumph of engineering and \nexcellence in technological management.  As such, it has been an enormously \nsuccessful program.  The research, development, and operation of the Space \nShuttle represent a worthy follow-on to the spectacularly successful Apollo pro\xad\ngram of the 1960s and early 1970s. \n Third, the Space Shuttle proved to be a flexible space vehicle. ', 'As the statement noted, “The policy \nobliges the government to fully consider commercial services as part \nof the decision-making process and imposes specific criteria on the \nuse of excess assets.”33 \n•\t Provide for an expanded private sector role in the Federal space trans\xad\nportation R&D decision making processes.  “In contrast with previous \nnational policy on space transportation, this policy specifically directs \nthe Departments of Transportation and Commerce to identify oppor\xad\ntunities for government-industry cooperation and to factor these into \nNASA’s and DoD’s implementation plans.”34 \nThe directive designated the Department of Defense as lead agency for the \nimprovement and evolution of the U.S.  expendable launch vehicle fleet and for \nthe development of the appropriate technology.  NASA was assigned responsi\xad\nbility for reusable launch vehicles, including improvement of the Space Shuttle \nsystem, focusing on reliability, safety, and cost effectiveness and, in the longer \nterm, developing the technology and demonstrating the next generation of reus\xad\nable space transportation systems.  This included the controversial and technically \nchallenging SSTO concept.  NASA was to focus its investments on technologies \nto support a decision no later than December 1996 on whether to proceed \nwith a flight demonstration program, which would, in turn, provide the basis \nfor deciding by the year 2000 whether to proceed with a new launch system to \nreplace the aging Shuttle fleet.  In retrospect, these goals were overly ambitious, \ngiven the many other fiscal demands and priorities of the Clinton\xa0administration. \n', '97\nCHAPTER 3\u2002 •\u2002 The Politics Of Pure Space Science, The Essential Tension \nwith the Apollo-Soyuz Test Project, were the dying embers of Apollo.16 \nNASA’s prime directive became getting a follow-on human spaceflight pro\xad\ngram approved.  In 1969, President Richard Nixon rejected human spaceflight \nrecommendations from his Space Task Group on cost grounds.  After much \nskirmishing, in January 1971 President Nixon approved the Space Shuttle \nProgram, only one component of the Task Group’s recommendations.  The \nSpace Shuttle was conceived as transportation to and from a low-Earth-orbit \nspace station.  Nixon rejected the space station proposal.17\nThe 1970s turned out to be a “golden age” for space science at NASA as \nplanetary missions reached out to Mars, Venus, and the outer planets.  Major \nsuccesses of this period include the Viking mission to Mars.  Viking’s search \n16.\t ']","
1. The Space Shuttle is a triumph of engineering and excellence in technological management.
2. It has been an enormously successful program in terms of research, development, and operation.
3. The Space Shuttle is a flexible space vehicle, with the ability to carry a diversity of payloads, accomplish a myriad of tasks on orbit, and deploy and retrieve satellites.
4. It served as a fine test bed for scientific inquiry, allowing a wide range of scientific experimentation in microgravity and space science enterprises.
5. Despite being an enormous achievement and a symbol of American technological excellence, the Space Shuttle Program failed to achieve its core objective of lowering the cost of reaching Earth orbit. Cost control remains a critical goal for any new human launch vehicle."
"How has the partnership between JAXA and PeptiDream Inc. accelerated drug development and reduced overall research costs, as described in the context information?","The partnership between JAXA and PeptiDream Inc. has accelerated drug development and reduced overall research costs by leveraging each partner's strengths. PeptiDream's expertise in identifying and optimizing crystallization conditions and their established technology for quick, inexpensive, large-scale production of a wide variety of nonstandard peptides, combined with JAXA's technical ability to carry out space experiments, has allowed for the efficient and swift production of new and better drugs for Japan and the world. The High-Quality Protein Crystal Growth (PCG) experiment on the Japanese Experiment Module Kibo has increased by sixfold the experimental protein samples, or keys, investigated, and has resulted in high-quality crystals of the protein and the drug candidate complex, thereby accelerating development of the potential drug. The crystal structure determined from the crystals attained from the JAXA-PCG experiment will significantly accelerate the optimization of these candidates toward clinical candidates.","['Furthermore, JAXA has invited Asian \nand Pacific nations to participate in the use of Japanese \nfacilities to promote diverse partnerships utilizing the \nISS.  For example, a recent agreement with Singapore \naims to use the Japanese Experiment Module (JEM) \nSmall Satellite Orbital Deployer (J-SSOD) to launch \na Singaporean satellite. \n JAXA’s focus is on promoting strategic partnerships to \ncommercially establish the Research and Development \ntestbed aboard the Kibo module.  One example is a new \nfee-based agreement with the Japanese drug discovery \ncompany, PeptiDream Inc.  The agreement increased \nthe number of protein samples from five to 30 over \nthe lifetime of the agreement.  JAXA also doubled the \nlaunching frequency from twice to four times a year \nto meet the requirements from PeptiDream and other \nusers.  This accelerates the development of new drugs \nwhile reducing overall research costs. ', '“Crystallization at 4 degrees C allows crystallization \nof candidate drugs in high demand, such as unstable \nhydrosoluble proteins and membrane proteins,” \nsaid JAXA’s Masaki Shirakawa.  “At 20 degrees C, \nsome proteins just aggregate, and do not crystallize. \n Conducting experiments under 4 degrees C opens the \ndoor to space experiments involving unstable proteins.” \nEarly analysis indicates the 4°C (39°F) PCG experiment \nresulted in high-quality crystals of the protein and \nthe drug candidate complex, thereby accelerating \ndevelopment of the potential drug.\n The agreement between PeptiDream and JAXA \nleverages each partner’s strengths—PeptiDream’s as \na leading drug discovery company, and JAXA’s expertise \nin identifying and optimizing crystallization conditions \nand the technical ability to carry out space experiments. \n PeptiDream has established technology that facilitates \nquick, inexpensive, large-scale production of a wide \nvariety of nonstandard peptides. \n “At any stage of the drug discovery process, a high-\nresolution structure always significantly accelerates \nthis process and having a 3-D structure is truly \ninvaluable,” said Patrick Reid, President and CEO\nof PeptiDream. \n “The crystal structure determined from the crystals \nattained from the JAXA-PCG experiment will significantly \naccelerate the optimization of these candidates toward \nclinical candidates,” said Executive Vice President \nKeiichi Masuya.\n', '“At 20 degrees C, \nsome proteins just aggregate, and do not crystallize. \n Conducting experiments under 4 degrees C opens the \ndoor to space experiments involving unstable proteins.” \nEarly analysis indicates the 4°C (39°F) PCG experiment \nresulted in high-quality crystals of the protein and \nthe drug candidate complex, thereby accelerating \ndevelopment of the potential drug.\n The agreement between PeptiDream and JAXA \nleverages each partner’s strengths—PeptiDream’s as \na leading drug discovery company, and JAXA’s expertise \nin identifying and optimizing crystallization conditions \nand the technical ability to carry out space experiments. \n PeptiDream has established technology that facilitates \nquick, inexpensive, large-scale production of a wide \nvariety of nonstandard peptides. \n “At any stage of the drug discovery process, a high-\nresolution structure always significantly accelerates \nthis process and having a 3-D structure is truly \ninvaluable,” said Patrick Reid, President and CEO\nof PeptiDream. \n “The crystal structure determined from the crystals \nattained from the JAXA-PCG experiment will significantly \naccelerate the optimization of these candidates toward \nclinical candidates,” said Executive Vice President \nKeiichi Masuya.\n Kibo and the space station play a key role in allowing \nPeptiDream and JAXA to obtain structural information \non target proteins and their drug candidates swiftly and \nefficiently, thus aiming to produce new and better drugs \nfor Japan and the world.\n', 'Conducting experiments under 4 degrees C opens the \ndoor to space experiments involving unstable proteins.” \nEarly analysis indicates the 4°C (39°F) PCG experiment \nresulted in high-quality crystals of the protein and \nthe drug candidate complex, thereby accelerating \ndevelopment of the potential drug.\n The agreement between PeptiDream and JAXA \nleverages each partner’s strengths—PeptiDream’s as \na leading drug discovery company, and JAXA’s expertise \nin identifying and optimizing crystallization conditions \nand the technical ability to carry out space experiments. \n PeptiDream has established technology that facilitates \nquick, inexpensive, large-scale production of a wide \nvariety of nonstandard peptides. \n “At any stage of the drug discovery process, a high-\nresolution structure always significantly accelerates \nthis process and having a 3-D structure is truly \ninvaluable,” said Patrick Reid, President and CEO\nof PeptiDream. \n “The crystal structure determined from the crystals \nattained from the JAXA-PCG experiment will significantly \naccelerate the optimization of these candidates toward \nclinical candidates,” said Executive Vice President \nKeiichi Masuya.\n Kibo and the space station play a key role in allowing \nPeptiDream and JAXA to obtain structural information \non target proteins and their drug candidates swiftly and \nefficiently, thus aiming to produce new and better drugs \nfor Japan and the world.\n', 'Determining the shape of the keyhole by examining the \nprotein structure can help create a key to fit it—i.e., an \neffective medicine with few side effects.  Scientists are \ngrowing protein crystals on the ISS to design keys to \nfit keyholes for various medical conditions on Earth.\n The High-Quality Protein Crystal Growth (PCG) \nexperiment on the Japanese Experiment Module Kibo \nis one example.  It expands a partnership between \nPeptiDream Inc, a Tokyo-based biopharmaceutical \ncompany, and the Japan Aerospace Exploration \nAgency (JAXA) to increase by sixfold the experimental \nprotein samples, or keys, investigated.\n The partners previously crystallized a nonstandard cyclic \npeptide drug candidate to target the human epidermal \ngrowth factor receptor 2 (HER2).  About 1 out of every \n5 people with breast cancer makes an excess of HER2 \nprotein, which promotes the growth of cancer cells. \n Unlike conventional peptide-based drugs, nonstandard \npeptides have unlimited potential as novel medicines \ndue to their structural stability and longer duration \nin the human body. ']","
The partnership between JAXA and PeptiDream Inc. has accelerated drug development and reduced overall research costs in several ways. Firstly, the fee-based agreement between the two entities increased the number of protein samples from five to 30 over the lifetime of the agreement. This increase in the number of protein samples has allowed for more extensive research and development of new drugs.

Secondly, JAXA doubled the launching frequency from twice to four times a year to meet the requirements from PeptiDream and other users. This increase in launching frequency has allowed for faster development and testing of new drugs, thereby accelerating the drug development process.

Thirdly, the increased number of protein samples and launching frequency have reduced overall research costs. By having more protein samples and launching more frequently, PeptiDream Inc. can conduct more research and development within the same time frame, thereby reducing the cost per unit of research and development.

Lastly, the partnership has also allowed PeptiDream Inc. to expand Kibo utilization in its collaborative research activities with other entities. This expansion of Kibo utilization has further accelerated the drug development process and reduced overall research costs."
"What was the reason for the discovery of a failure in one of the power processing units during the thermal vac test, and how did the team handle it to ensure the June launch?","During the thermal vac test, a failure was discovered in one of the power processing units. The team did not proceed with breaking the chamber that day, as senior people at Orbital wanted to do. Instead, the team realized that thermal vac test is not a performance test, but rather a test to validate the thermal model. The team brought everybody around to this realization by pointing out that if another failure happened, they would have to be diligent in controlling the stuff inside the chamber. The team decided to plow through and proceeded with the test. Later questions were dealt with in the same way, and when the project reached a pivotal point where experts from different organizations could not agree, the incoming project manager called the parties together for an additional review of the requirements versus the risks. Their advice proved valuable in stopping an environmental test early.","['And at that point, every \nsubsystem swears up and down that they’ve reviewed all the data, and everything is go, \nor these are the issues, and this is why it’s okay to proceed….  [We] closed the door, and \nthe next day we discovered that one of the [power processing units] has a failure.… There \nwas a set of senior people at Orbital who wanted to break chamber that day.  And I said, \n“No, we’re not going to break chamber that day.  We’re going to plow through.” The way I \nbrought everybody around to that realization was the following: Thermal vac test is not a \nperformance test.  It is a test you do to validate the thermal model.  So, if you have failure \nin one box, you can go to the other box, do the test, but you have to be, now, really diligent \nshould another failure happen, how you control the stuff in there….  And in a way, I’m glad \nwe discovered this inside the chamber, because, if we had discovered this outside the cham\xad\nber, the June launch would have been jeopardized. ', 'Then, the unthinkable happened.  As Patel recalled: \nWe had a test readiness review before we closed the key vac door.  And at that point, every \nsubsystem swears up and down that they’ve reviewed all the data, and everything is go, \nor these are the issues, and this is why it’s okay to proceed….  [We] closed the door, and \nthe next day we discovered that one of the [power processing units] has a failure.… There \nwas a set of senior people at Orbital who wanted to break chamber that day.  And I said, \n“No, we’re not going to break chamber that day.  We’re going to plow through.” The way I \nbrought everybody around to that realization was the following: Thermal vac test is not a \nperformance test.  It is a test you do to validate the thermal model. ', 'NASA′s Discovery Program\n236\ncause, the power processing unit failures were deemed “understood” and blamed on \ntransient thermal conditions in the test configuration.  The project had a new process \nin place for replacing damaged capacitors and a plan forward that satisfied all the play\xad\ners.  Later questions would be dealt with in the same way; when the project reached a \npivotal point on which the experts from the Jet Propulsion Laboratory, the Discovery \nand New Frontiers Program Office, and the chief engineer’s office had not been able \nto agree, Keyur Patel, the incoming project manager, called the parties together for an \nadditional review of the requirements versus the risks.  Their advice proved valuable in \nstopping an environmental test early. ', 'They did not have enough reserves to make \nit to September, and either way, after September the planned trajectory would need \nmodifications.  The team worked the issues in parallel and ran the tests.\n Dave Shiderly, the Assembly, Test, and Launch Operations manager, began to rework \nthe ATLO schedule to make it happen.  Once the thermal vac test was complete, the \nteam broke chamber, dropped several panels, pulled the power processing unit box \noff, and sent it to the Jet Propulsion Laboratory in a special suitcase.  After the fix, the \nteam shipped it back, reinserted it into the spacecraft, and prepared to do the penalty \ntests before it was time to deliver it to the Cape.  JPL and Orbital disagreed on the extent \nof penalty test required.  Patel pushed for skipping any penalty tests, since the whole \nspacecraft had already completed the whole series of environmental tests, but Orbital \nleadership wanted to rerun the full suite. ', 'ESA gave up attempts to con\xad\ntact the probe on 2 December.  American space \nassets tracked the probe in a 209 × 305-kilometer \norbit in early December.  The spacecraft and upper \nstage combination made an uncontrolled reentry \non 15 January 2012, with wreckage apparently \nfalling into the Pacific or parts of South America. \n An investigation later showed the probable cause \nof failure was a programming error that caused \nthe simultaneous reboot of two channels of the \nonboard computer (TsVM22).  The MDU never \nactually fired.An simplified illustration of the Russian Fobos-Grunt lander package.  The half-spherical object at the top was the descent capsule that would carry samples from the Martian moon Phobos back to earth.\n A simplified illustration of the Russian Fobos-Grunt lander package. ']","
The discovery of a failure in one of the power processing units during the thermal vac test was unexpected and posed a significant challenge for the team, as they were aiming for a June launch. The thermal vac test was not a performance test but rather a validation of the thermal model. The team decided to continue with the test, ensuring proper control of the spacecraft's components in case of another failure.

The Assembly, Test, and Launch Operations manager, Dave Shiderly, reworked the ATLO schedule to accommodate the necessary repairs and tests. After the thermal vac test, the team broke chamber, removed the faulty power processing unit box, and sent it to the Jet Propulsion Laboratory for fixing. Once fixed, they shipped it back, reinserted it into the spacecraft, and prepared to run penalty tests before delivering it to the Cape.

The team initially disagreed on the extent of the penalty tests required, with Patel advocating for skipping them and Orbital leadership insisting on rerunning the full suite. Patel proposed a compromise, suggesting they rerun just the acoustic test to validate the reassembly of the spacecraft. This approach allowed them to ensure the spacecraft's readiness for the June launch while addressing the discovered issue in the power processing unit."
What is thrust vectoring and how was it used in the NASA F/A-18 High Alpha Research Vehicle and F-15 ACTIVE Nozzles? Provide specific details from the context information.,"Thrust vectoring is a technology that allows for the deflection of engine thrust, which can enhance maneuverability and control at high angles of attack. In the NASA F/A-18 High Alpha Research Vehicle (HARV), a multi-axis thrust-vectoring system was installed on the exhaust nozzles of the F/A-18's two GE F404 turbofan engines. The system consisted of a research flight control system that directed three paddle-like vanes, one set for each engine, made from the heat-resistant alloy Inconel, to deflect engine thrust. The system increased the high-alpha capability of the F/A-18 by a third, up to 70 degrees. In the F-15 ACTIVE Nozzles, an Inner Loop Thrust Vectoring (ILTV) system was used for control. The technology was also used in the F-22 Raptor, where it provided more stability at high angles of attack during close-in maneuvering and enhanced the stealth characteristics of the aircraft by generating less radar return from the back of the aircraft.","['The use of thrust vectoring in the HARV program was an important precedent for \nlater programs.  (NASA)\nThe HARV flight research program consisted of three phases.  The first and \nthird flight-test phases were not directly related to propulsion modifications.51 \nThe second phase, 193 flights conducted between July 1991 and June 1994, \nexplored the use of vectored thrust to enhance maneuverability and control \nat high angles of attack.  Primary contractor McDonnell Douglas designed \na multi-axis thrust-vectoring system for installation on the exhaust nozzles \nof the F/A-18’s two GE F404 turbofan engines.  The system consisted of a \nresearch flight control system that directed three paddle-like vanes, one set \nfor each engine, made from the heat-resistant alloy Inconel, to deflect engine \nthrust.  Dryden project manager Donald H. Gatlin described it charitably as \n“crude” and never intended for an operational aircraft.52 Nevertheless, the \nsystem worked when the conventional aileron, rudder, and stabilator (a slab-\nsurfaced combined horizontal stabilizer and elevator) aerodynamic controls \nwere ineffective.  The thrust-vectoring system increased the high-alpha capa\xad\nbility of the F/A-18 by a third, up to 70 degrees. ', 'Propulsion Control Enters the Computer Era, 1976–1998\n155\nearly-model McDonnell Douglas F/A-18 Hornet, an aircraft known for its high \nmaneuverability, as surplus from the U.S.  Navy and modified it for the HATP \nmission with the designation F/A-18 High Alpha Research Vehicle (HARV).50The exhaust plume from the left engine of NASA\'s F/A-18 High Alpha Research Vehicle (HARV) is deflected upward by the paddle-like vanes of the aircraft\'s thrust vectoring system during an early morning ""hot loads"" ground test of the system at the NASA Dryden Flight Research Center, Edwards, Calif.\n\n February 14, 1991\nFigure 5-8.  The use of thrust vectoring in the HARV program was an important precedent for \nlater programs.  (NASA)\nThe HARV flight research program consisted of three phases.  The first and \nthird flight-test phases were not directly related to propulsion modifications.51 \nThe second phase, 193 flights conducted between July 1991 and June 1994, \nexplored the use of vectored thrust to enhance maneuverability and control \nat high angles of attack.  Primary contractor McDonnell Douglas designed \na multi-axis thrust-vectoring system for installation on the exhaust nozzles \nof the F/A-18’s two GE F404 turbofan engines. ', 'The Power for Flight\n156\nto the HARV included a sophisticated engine inlet pressure measurements \nsystem between the inlet entrance and the engine face.  They measured pres\xad\nsure fluctuations of up to 250 Hertz at over 2,000 samples per second, which \ncontributed to a broader understanding of what happened to engine airflow \nunder extreme\xa0maneuvering.53\nWhile the HARV thrust-vectoring nozzles permitted high-alpha inves\xad\ntigations, the technology offered only a temporary means of evaluation for \nthe program.  NASA’s Advanced Control Technology for Integrated Vehicles \n(ACTIVE) program specifically investigated thrust vectoring for application in \nfuture subsonic and supersonic commercial and military aircraft.  Fighters bene\xad\nfited from enhanced maneuverability, while airliners like the much-anticipated \n300-passenger Mach 2 High-Speed Civil Transport would allow drag and noise \nreduction through smaller control surfaces supplemented by thrust vectoring.54 \nThey also wanted to build upon previous thrust-vectoring programs while \nintroducing the new element of safety.55 NASA and the Air Force were the \nGovernment partners; McDonnell Douglas and Pratt & Whitney served as the \nindustrial partners.  Project manager Don Gatlin remarked that ACTIVE was \n“an example of government and industry cooperating to bring an important \ntechnology to maturity.”56\nNASA began the preparation of a two-seat F-15B transferred from the \nU.S.  Air Force for that purpose in 1993 at Dryden.57 ACTIVE relied upon \nan Inner Loop Thrust Vectoring (ILTV) system for control. ', 'Primary contractor McDonnell Douglas designed \na multi-axis thrust-vectoring system for installation on the exhaust nozzles \nof the F/A-18’s two GE F404 turbofan engines.  The system consisted of a \nresearch flight control system that directed three paddle-like vanes, one set \nfor each engine, made from the heat-resistant alloy Inconel, to deflect engine \nthrust.  Dryden project manager Donald H. Gatlin described it charitably as \n“crude” and never intended for an operational aircraft.52 Nevertheless, the \nsystem worked when the conventional aileron, rudder, and stabilator (a slab-\nsurfaced combined horizontal stabilizer and elevator) aerodynamic controls \nwere ineffective.  The thrust-vectoring system increased the high-alpha capa\xad\nbility of the F/A-18 by a third, up to 70 degrees.  Additional modifications \n', 'The Power for Flight\n160\ntwo-dimensional nozzle program and recognized its value to the overall mission \nof the fighter.  Thrust vectoring provided more stability at high angles of attack \nduring close-in maneuvering, or dogfighting, which accentuated the fighter’s \nlong-range standoff missile capability.  The faceted shape of the exhaust nozzles \nalso enhanced the stealth characteristics of the F-22 because they generated less \nradar return from the back of the aircraft.69\nEndnotes\n\t 1.\t  Link C. Jaw and Sanjay Garg, “Propulsion Control Technology \nDevelopment in the United States: A Historical Perspective,” NASA \nTM-2005-213978, October 2005, p.  2.\n\t ']","
Thrust vectoring is a method of controlling the direction of the exhaust from a jet engine to control the attitude or direction of an aircraft. It is achieved by deflecting the engine's exhaust gases using movable vanes or nozzles in the engine's exhaust section.
In the NASA F/A-18 High Alpha Research Vehicle, thrust vectoring was used to investigate the concept of using deployable winglike surface strakes in the nose for increased yaw control. The F/A-18 High Alpha Research Vehicle was a highly modified F/A-18 Hornet fighter aircraft, which was used for high angle-of-attack research. The first phase of the research generated experience in the aerodynamic measurement of high angles of attack and provided the baseline evaluation methodology for the F/A-18 from April 1987 through 1989. The third phase investigated the concept of using deployable winglike surface strakes in the nose for increased yaw control from March 1995 to September 1996.
In the F-15 ACTIVE Nozzles, thrust vectoring was used to achieve first-ever Mach 2 thrust-vectoring. The F-15 ACTIVE (Advanced Control Technology for Integrated Vectored Thrust) was a research aircraft developed by NASA to investigate vectored thrust technology. The F-15 ACTIVE used a thrust vectoring system that could deflect the exhaust gases of its engines in any direction, providing unprecedented maneuverability and control. The F-15 ACTIVE achieved its first-ever Mach 2 thrust-vectoring in November 1996."
What are the potential benefits of studying the effects of gravity on plants and microorganisms in space?,"Studying the effects of gravity on plants and microorganisms in space has potential benefits in several areas. Firstly, it is essential in preparing for human exploration beyond low-Earth orbit, as the ability to produce high-energy, low-mass food sources during spaceflight will enable the maintenance of crew health during long-duration missions while having a reduced impact on resources necessary for long-distance travel. Secondly, plant research in a space greenhouse has permitted the study of root zone substrates in space, thereby allowing scientists to improve predictions of how artificial soils will behave when irrigated both in space and on Earth in experimental forests. Thirdly, microorganisms have both negative and beneficial effects. Different species of fungi are inherent in many of these processes, and can do the following: spoil food, but assist in waste and sewage treatment and processing as well as nutrient cycling and exchange; assist in pollution control but also increase greenhouse gases; cause disease but can be used in the manufacture of antibiotics, detergents, and pesticides. Studying the effects of gravity on microorganisms can lead to the development of new technologies and applications, such as the ethylene scrubber, which is now used as an air purifier that destroys airborne bacteria, mold, fungi, viruses, and odors. This technology is used for food preservation in major supermarkets, high-end refrigerator technology, and trucks that carry groceries to remote regions of countries such as India, Saudi Arabia, and Kuwait, to name a few. Even the health care industry benefits from the use of these units in clinics, operating rooms, neonatal wards, and waiting rooms, thereby making these locations safer for their inhabitants.","['159\nFood and the Environment\nMicrobiology is a vitally important area, not only within human spaceflight but also for humans on Earth. \n Microorganisms such as bacteria, archaea, fungi and algae have a detrimental or a beneficial impact on \nour daily lives.  This research has far-reaching effects that feed into many different areas of biotechnology \nas microorganisms have a role in food spoilage, waste and sewage treatment and processing, nutrient \ncycling and exchange, pollution control, and in increased greenhouse gases.\n Studying the effects of gravity on plants led to the development of an ethylene scrubber.  This technology \nis now used as an air purifier that destroys airborne bacteria, mold, fungi, viruses and odors.\n The scrubber is used for food preservation in major supermarkets, high-end refrigerator technology, \nand trucks that carry groceries to remote regions of countries such as India, Saudi Arabia and Kuwait, \nto name a few. ', '162\ngreenhouse on the ISS Russian Segment.  The \ncontributions of S. A. Gostimsky (M. V. Lomonosov \nMoscow State University), and M. Sugimoto (Okayama \nUniversity, Institute of Bioresources, Okayama, Japan) \nshould be especially noted.\n Plant Growth on the International Space \nStation has Global Impacts on Earth\nUnderstanding the effects of gravity on plant life is \nessential in preparing for human exploration beyond \nlow-Earth orbit.  The ability to produce high-energy, \nlow-mass food sources during spaceflight will enable \nthe maintenance of crew health during long-duration \nmissions while having a reduced impact on resources \nnecessary for long-distance travel.\n The Advanced Astroculture™ (ADVASC) investigation, \nled by Weijia Zhou, Ph.D., formerly of the Wisconsin \nCenter for Space Automation and Robotics, University \nof Wisconsin-Madison, explored the benefits of \nusing microgravity to create custom crops that can \nwithstand the inhospitable climates of space, can resist \npestilence, and will need less volume in which to grow. \n ADVASC was performed over several ISS expeditions \nwhere it grew two generations of Arabidopsis thaliana \n(i.e., a rapidly growing, flowering plant in the mustard \nfamily that has been grown on many space missions), \nand soybean plants from seed to seed in space using \nthe ADVASC payload—an autonomously operated \nplant growth unit. ', 'The scrubber is used for food preservation in major supermarkets, high-end refrigerator technology, \nand trucks that carry groceries to remote regions of countries such as India, Saudi Arabia and Kuwait, \nto name a few.  Even the health care industry benefits from the use of these units in clinics, operating \nrooms, neonatal wards and waiting rooms, thereby making these locations safer for their inhabitants.\n Plant research in a space greenhouse has permitted the study of root zone substrates in space, thereby \nallowing scientists to improve predictions of how artificial soils will behave when irrigated both in space \nand on Earth in experimental forests.\n Microbiology Applications from Fungal \nResearch in Space\nMicroorganisms have both negative and beneficial \neffects.  Different species of fungi are inherent in many \nof these processes, and can do the following:\n•\t Spoil food, but assist in waste and sewage \ntreatment and processing as well as nutrient cycling \nand exchange.\n •\t Assist in pollution control but also increase \ngreenhouse gases.\n •\t Cause disease but can be used in the manufacture \nof antibiotics, detergents and pesticides.\n', 'This technology \nis now used as an air purifier that destroys airborne bacteria, mold, fungi, viruses and odors.\n The scrubber is used for food preservation in major supermarkets, high-end refrigerator technology, \nand trucks that carry groceries to remote regions of countries such as India, Saudi Arabia and Kuwait, \nto name a few.  Even the health care industry benefits from the use of these units in clinics, operating \nrooms, neonatal wards and waiting rooms, thereby making these locations safer for their inhabitants.\n Plant research in a space greenhouse has permitted the study of root zone substrates in space, thereby \nallowing scientists to improve predictions of how artificial soils will behave when irrigated both in space \nand on Earth in experimental forests.\n Microbiology Applications from Fungal \nResearch in Space\nMicroorganisms have both negative and beneficial \neffects.  Different species of fungi are inherent in many \nof these processes, and can do the following:\n•\t Spoil food, but assist in waste and sewage \ntreatment and processing as well as nutrient cycling \nand exchange.\n •\t Assist in pollution control but also increase \ngreenhouse gases.\n', 'The first experiment is researching methane-producing \nmicroorganisms and how they behave in space. \n These examples highlight the versatility of a simpler, \nfaster and more affordable access to research on \nthe ISS, ensuring any company, entity or educational \ninstitution can be a part of microgravity research in \nspace for years to come.\n The Commercial Multi-use \nVariable-g Platform\nDelivered to the ISS aboard SpaceX CRS-14, the \nTechshot-developed Multi-use Variable-g Platform \n(MVP) is a new commercial test bed for centrifuge-\nbased science aboard the space station.  Because \ngravity determines so much of a live organism’s \nbehavior and growth, centrifuge-based experiments \nhave long been a part of biological investigations in \nspace.  Although the pull of Earth’s gravity makes this \ntype of investigation difficult at home, the space station’s \nmicrogravity environment makes it the perfect place for \nfractional gravity experimentation.  MVP greatly expands \nthat testing capability for the space station.\n Delivered to the ISS aboard \nSpaceX CRS-14, the \nTechshot-developed Multi-use \nVariable-g Platform (MVP) is \na new commercial test bed \nfor centrifuge-based science \naboard the space station. \n']","
1. The study of the effects of gravity on plants led to the development of an ethylene scrubber, which is now used as an air purifier that destroys airborne bacteria, mold, fungi, viruses and odors. This technology is used for food preservation in major supermarkets, high-end refrigerator technology, and trucks that carry groceries to remote regions of countries such as India, Saudi Arabia and Kuwait, and even in the health care industry in clinics, operating rooms, neonatal wards and waiting rooms, thereby making these locations safer for their inhabitants.
2. Plant research in a space greenhouse has permitted the study of root zone substrates in space, thereby allowing scientists to improve predictions of how artificial soils will behave when irrigated both in space and on Earth in experimental forests.
3. Studying the effects of gravity on microorganisms such as bacteria, archaea, fungi and algae can help determine the effect that the space environment may have on similar organisms and feed into biotechnology applications in the future.
4. Understanding any changes in the physiology and survivability of different microorganisms in space can help determine the effect that this may have on spacecraft, on associated systems and supplies, and on the astronauts who inhabit them. This could provide important insights for developing countermeasures to possibly deleterious microorganisms.
5. As we gain knowledge of the life histories of key species of fungi in the space environment, that knowledge can be readily applied to better manage these species on Earth."
"What are the potential benefits of studying the effects of gravity on plants and microorganisms in space, as described in the context information?","The context information describes several potential benefits of studying the effects of gravity on plants and microorganisms in space. These benefits include:

1. Understanding the effects of gravity on plant life is essential in preparing for human exploration beyond low-Earth orbit. The ability to produce high-energy, low-mass food sources during spaceflight will enable the maintenance of crew health during long-duration missions while having a reduced impact on resources necessary for long-distance travel.

2. Plant research in a space greenhouse has permitted the study of root zone substrates in space, thereby allowing scientists to improve predictions of how artificial soils will behave when irrigated both in space and on Earth in experimental forests.

3. Microorganisms have both negative and beneficial effects. Different species of fungi are inherent in many of these processes, and can do the following:

- Spoil food, but assist in waste and sewage treatment and processing as well as nutrient cycling and exchange.
- Assist in pollution control but also increase greenhouse gases.
- Cause disease but can be used in the manufacture of antibiotics, detergents, and pesticides.

4. The scrubber is used for food preservation in major supermarkets, high-end refrigerator technology, and trucks that carry groceries to remote regions of countries such as India, Saudi Arabia, and Kuwait, to name a few. Even the health care industry benefits from the use of these units in clinics, operating rooms, neonatal wards, and waiting rooms, thereby making these locations safer for their inhabitants.

5. The Growth and Survival of Coloured Fungi in Space-A (CFS-A) experiment determined the changes that weightlessness and cosmic radiation have on the growth and survival of various coloured fungi species. Understanding any changes in the physiology and survivability of different microorganisms in space can help determine the effect that this may have on spacecraft, on associated systems and supplies, and on the astronauts who inhabit them. This could provide important insights for developing countermeasures to possibly deleterious microorganisms, help to draw conclusions on how the space environment may affect similar organisms, and feed into biotechnology applications in the future.

Overall, studying the effects of gravity on plants and microorganisms in space can","['162\ngreenhouse on the ISS Russian Segment.  The \ncontributions of S. A. Gostimsky (M. V. Lomonosov \nMoscow State University), and M. Sugimoto (Okayama \nUniversity, Institute of Bioresources, Okayama, Japan) \nshould be especially noted.\n Plant Growth on the International Space \nStation has Global Impacts on Earth\nUnderstanding the effects of gravity on plant life is \nessential in preparing for human exploration beyond \nlow-Earth orbit.  The ability to produce high-energy, \nlow-mass food sources during spaceflight will enable \nthe maintenance of crew health during long-duration \nmissions while having a reduced impact on resources \nnecessary for long-distance travel.\n The Advanced Astroculture™ (ADVASC) investigation, \nled by Weijia Zhou, Ph.D., formerly of the Wisconsin \nCenter for Space Automation and Robotics, University \nof Wisconsin-Madison, explored the benefits of \nusing microgravity to create custom crops that can \nwithstand the inhospitable climates of space, can resist \npestilence, and will need less volume in which to grow. \n ADVASC was performed over several ISS expeditions \nwhere it grew two generations of Arabidopsis thaliana \n(i.e., a rapidly growing, flowering plant in the mustard \nfamily that has been grown on many space missions), \nand soybean plants from seed to seed in space using \nthe ADVASC payload—an autonomously operated \nplant growth unit. ', 'The scrubber is used for food preservation in major supermarkets, high-end refrigerator technology, \nand trucks that carry groceries to remote regions of countries such as India, Saudi Arabia and Kuwait, \nto name a few.  Even the health care industry benefits from the use of these units in clinics, operating \nrooms, neonatal wards and waiting rooms, thereby making these locations safer for their inhabitants.\n Plant research in a space greenhouse has permitted the study of root zone substrates in space, thereby \nallowing scientists to improve predictions of how artificial soils will behave when irrigated both in space \nand on Earth in experimental forests.\n Microbiology Applications from Fungal \nResearch in Space\nMicroorganisms have both negative and beneficial \neffects.  Different species of fungi are inherent in many \nof these processes, and can do the following:\n•\t Spoil food, but assist in waste and sewage \ntreatment and processing as well as nutrient cycling \nand exchange.\n •\t Assist in pollution control but also increase \ngreenhouse gases.\n •\t Cause disease but can be used in the manufacture \nof antibiotics, detergents and pesticides.\n', 'This technology \nis now used as an air purifier that destroys airborne bacteria, mold, fungi, viruses and odors.\n The scrubber is used for food preservation in major supermarkets, high-end refrigerator technology, \nand trucks that carry groceries to remote regions of countries such as India, Saudi Arabia and Kuwait, \nto name a few.  Even the health care industry benefits from the use of these units in clinics, operating \nrooms, neonatal wards and waiting rooms, thereby making these locations safer for their inhabitants.\n Plant research in a space greenhouse has permitted the study of root zone substrates in space, thereby \nallowing scientists to improve predictions of how artificial soils will behave when irrigated both in space \nand on Earth in experimental forests.\n Microbiology Applications from Fungal \nResearch in Space\nMicroorganisms have both negative and beneficial \neffects.  Different species of fungi are inherent in many \nof these processes, and can do the following:\n•\t Spoil food, but assist in waste and sewage \ntreatment and processing as well as nutrient cycling \nand exchange.\n •\t Assist in pollution control but also increase \ngreenhouse gases.\n', '•\t Cause deterioration in manufactured materials and \nbuildings but can also be used in the recovery of \nmetals in the mining sector as well as the production \nof biofuels and fertilizers. \n •\t Provide insight into one species, which may \nprovide insights into others and hence feed \ninto different applications.\n The Growth and Survival of Coloured Fungi in Space-A \n(CFS-A) experiment determined the changes that \nweightlessness and cosmic radiation have on the \ngrowth and survival of various coloured fungi species. \n Understanding any changes in the physiology and \nsurvivability of different microorganisms in space \ncan help determine the effect that this may have on \nspacecraft, on associated systems and supplies, and \non the astronauts who inhabit them.  This could provide \nimportant insights for developing countermeasures \nto possibly deleterious microorganisms, help to draw \nconclusions on how the space environment may \naffect similar organisms, and feed into biotechnology \napplications in the future. \n The main fungal species studied in the CFS-A \nexperiment was Ulocladium chartarum, which is well \nknown to be involved in biodeterioration of organic \nand inorganic materials and suspected to be a possible \ncontaminant in spacecraft.  Other species studied were: \nAspergillus niger (which causes a disease called black \nmold on certain fruits and vegetables, and commercially \naccounts for 99% of global commercial citric acid \nproduction); Cladosporium herbarum (frequently \nthe most prominent mold spore in air and found on \ndead herbaceous and woody plants, textiles, rubber, \npaper and foodstuffs of all kinds); and Basipetospora \nhalophile (which survives in high-saline environments). \n', 'The first experiment is researching methane-producing \nmicroorganisms and how they behave in space. \n These examples highlight the versatility of a simpler, \nfaster and more affordable access to research on \nthe ISS, ensuring any company, entity or educational \ninstitution can be a part of microgravity research in \nspace for years to come.\n The Commercial Multi-use \nVariable-g Platform\nDelivered to the ISS aboard SpaceX CRS-14, the \nTechshot-developed Multi-use Variable-g Platform \n(MVP) is a new commercial test bed for centrifuge-\nbased science aboard the space station.  Because \ngravity determines so much of a live organism’s \nbehavior and growth, centrifuge-based experiments \nhave long been a part of biological investigations in \nspace.  Although the pull of Earth’s gravity makes this \ntype of investigation difficult at home, the space station’s \nmicrogravity environment makes it the perfect place for \nfractional gravity experimentation.  MVP greatly expands \nthat testing capability for the space station.\n Delivered to the ISS aboard \nSpaceX CRS-14, the \nTechshot-developed Multi-use \nVariable-g Platform (MVP) is \na new commercial test bed \nfor centrifuge-based science \naboard the space station. \n']","
1. The development of an ethylene scrubber, which is now used as an air purifier that destroys airborne bacteria, mold, fungi, viruses and odors. This technology is used for food preservation in major supermarkets, high-end refrigerator technology, and trucks that carry groceries to remote regions of countries such as India, Saudi Arabia and Kuwait, to name a few. The health care industry also benefits from the use of these units in clinics, operating rooms, neonatal wards and waiting rooms, thereby making these locations safer for their inhabitants.
2. Improved predictions of how artificial soils will behave when irrigated both in space and on Earth in experimental forests, as a result of studying the effects of gravity on plants in a space greenhouse.
3. Understanding any changes in the physiology and survivability of different microorganisms in space can help determine the effect that this may have on spacecraft, on associated systems and supplies, and on the astronauts who inhabit them. This could provide important insights for developing countermeasures to possibly deleterious microorganisms, help to draw conclusions on how the space environment may affect similar organisms, and feed into biotechnology applications in the future.
4. Knowledge of the life histories of key species of fungi in the space environment can be readily applied to better manage these species on Earth."
What was the role of the automatic backup computer program in the CONTOUR mission and why was it criticized for performing a critical maneuver 'in the blind'?,"The automatic backup computer program in the CONTOUR mission was set to run 24 hours after any loss of contact after the engine burn, which would fire small thrusters, turning the spacecraft so that it would use another of its four antennas to send signals back to Earth. However, this program was criticized for performing a critical maneuver 'in the blind' during the Mars Polar Lander's failed descent to the planet's surface a few years earlier. This criticism was due to the fact that the maneuver was performed without the ability to visually confirm the spacecraft's position or orientation, which increased the risk of failure.","['Chapter 3: Harsh Landings\n117\nhad an automatic backup computer program—set to run 24 hours after any loss of \ncontact after the engine burn—that would fire small thrusters, turning the spacecraft \nso that it would use another of its four antennas to send signals back to Earth.104 \nNASA called the North American Aerospace Defense Command to request help \nlocating the spacecraft.  Several military assets, such as ground radars used by the \nAir Force and Defense Support Program infrared early-warning satellites, could have \nobserved the 50-second burn on 15 August.105 The press criticized the agency for \nperforming the rocket burn, a critical maneuver, “in the blind,” as had been done a \nfew years earlier, during Mars Polar Lander’s failed descent to the planet’s surface.106\nAstronomers joined in the search for the lost comet hunter.  Researchers at Kitt Peak, \nArecibo, and Goldstone, as well as amateurs around the world, pointed their telescopes \nat CONTOUR’s last known location, the point where it was expected to be if the engine \nhad fired normally, and many points in between, as well as other likely locations.\n By the next morning, the news had broken that the spacecraft had been observed \nin two pieces.  Jim Scotti, planetary scientist at the Lunar and Planetary Laboratory \nat the University of Arizona, and colleague Jeff Larsen, using the 70-inch telescope at \nKitt Peak, had captured a picture of two objects, just 155 miles apart, moving past the \nMoon’s orbit and away from Earth, approximately where the spacecraft was expected \nto be.107 The spacecraft had broken into several pieces, just as Comet Schwassmann–\nWachmann 3, its intended target, had broken seven years earlier.\n', 'Consequently, there were five successive Discovery \nmanagement\xa0organizations.\n In any event, NASA’s newfound conservatism felt punitive.  “They were imposed \non the system, and at the same time not paid for, and also not relaxing the schedule \nin any way, because we had a specific deadline to launch and so on,” said Krimigis.42\nThe twin losses of the Mars spacecraft were not the only failed missions to give \nMESSENGER fiscal heartburn and burdensome oversight.  One cost savings maneuver \nemployed by MESSENGER was to time-share with CONTOUR’s mission operations \nstaff.  Both were APL missions.  Once CONTOUR encountered one comet and was en \nroute to another, it would enter hibernation mode.  Its people and ground systems, \nalready paid for from the CONTOUR budget, would have nothing to do. ', 'NASA′s Discovery Program\n120\nAs an act of due diligence, mission controllers on 17 December 2002, sent commands \nto the largest piece of the tracked spacecraft, using 34-meter and 70-meter antennas \nin the DSN, and listened for a response.  The session lasted 12 hours, ending just past \nmidnight.  The team tried again to contact the spacecraft during a 4-hour window on \nFriday, 20 December, when the spacecraft antenna, if it still existed and was attached to \na functional spacecraft, would again be pointed at Earth.  When no signal was received \nthat week, NASA and the Applied Physics Laboratory declared CONTOUR lost.128\nAPL received support for the ensuing investigation, but the science team did not \nreceive sufficient funds for an orderly closeout and archiving of the project, according \nto Veverka.129\nCONTOUR Mishap Investigation Board\nAlmost immediately, NASA convened a CONTOUR Mishap Investigation Board \n(MIB) to investigate the loss.130 APL had its own mishap investigation board, as did \nAlliant Techsystems.  Each had its own motivations, and each wanted to know what \nhad gone wrong.131\nEd Weiler, the Associate Administrator for space science at NASA Headquarters, \nappointed Theron M. Bradley, Jr., the agency’s chief engineer, to lead the investiga\xad\ntion.  The board would have an estimated work time of six to eight weeks.132 To help \nameliorate “information overload,” the MIB used new NASA Investigation Organizer \nsoftware to map the 145 CONTOUR mission review documents and 50 photos onto \na representation of the main spacecraft system.  Beyond that, little is known publicly \nbecause of U.S. ', 'Dawn suffered after its own management institution changed the burden \nrates and reserve requirement, requiring descopes even before the project really began. \n Kepler was selected at a time when the management of most NASA space science and \nplanetary missions was a privilege reserved for Goddard Space Flight Center and the \nJet Propulsion Laboratory; as such, Ames management had an extra layer of manage\xad\nment foisted on their project.  All these missions, except CONTOUR, would require \nadditional resources to compensate for project delays, funding delays, and new pro\xad\ngram requirements.  The CONTOUR failure was, ironically, the only thing that kept \nthe program in the black from 2001 to 2003, as much of the funding intended for \nmission operations was redirected to cover overruns in later missions.  Nevertheless, \nthe failure and later overruns put the Discovery Program in a difficult situation, and \nprogram management at NASA Headquarters worried about congressional scrutiny \nshould the overruns continue.\n This chapter will discuss lessons learned in the decade that followed, as identified \nformally from studies by the National Research Council; the NASA Planetary Science \nSubcommittee; the Discovery and New Frontiers Program Office; and, informally, by \nmission management, the proposing community, and program management.  This \nchapter will also demonstrate how the program evolved as lessons learned were imple\xad\nmented into the program’s guidelines and assessment, represented by each of the planned \nAnnouncements of Opportunity—snapshots in time of current policies. ', 'Chapter 4: Applying Lessons Learned\n165\nreturn half the science of Deep Impact for much less than 10 percent of the cost of \nDeep Impact.”97\nThey would visit the Comet 85D/Boethin in December 2008, image its nucleus, \nand increase the scientific understanding of comet diversity.  The small, short-period \ncomet had never before been visited.  Doing so would allow the Discovery Program to \nrecover some of the science lost with the 2002 failure of the CONTOUR mission—itself \nintended to do comparative studies of multiple comets.\n That wasn’t the only idea for what to do with Deep Impact, however.  L. Drake Deming \nof Goddard Space Flight Center, in Greenbelt, Maryland, wanted to look outward from \nour solar system and find Earth-size planets circling other stars.  The Deep Impact \nspacecraft and its powerful planetary telescope was the perfect tool for the job. ']","
The automatic backup computer program in the CONTOUR mission was set to run 24 hours after any loss of contact after the engine burn. It would fire small thrusters, turning the spacecraft so that it would use another of its four antennas to send signals back to Earth. This program was criticized for being used during a critical maneuver 'in the blind' because it was done without any observation or knowledge of the spacecraft's position or status. This was similar to a previous mission, Mars Polar Lander, which also had a failed descent to the planet's surface. The press and astronomers criticized NASA for not having a way to observe the spacecraft during such a critical maneuver."
Question: What was the primary objective of Surveyor VII and what were the results of its mission?,"The primary objective of Surveyor VII was a purely scientific mission outside of a potential landing site for the early Apollo flights. The results of its mission included the successful soft-landing on the ejecta blanket emanating from the bright Tycho crater in the south of the nearside on 10 January 1968. The spacecraft returned more than 87,000 photos of the lunar surface and operated for about 17 months total on the lunar surface, demonstrating the feasibility of soft-landing a spacecraft on the lunar surface.","['77\n1968\n93\nSurveyor VII\nNation: USA (43)\nObjective(s): lunar soft-landing\nSpacecraft: Surveyor-G\nSpacecraft Mass: 1,040.1 kg\nMission Design and Management: NASA / JPL\nLaunch Vehicle: Atlas Centaur (AC-15 / Atlas 3C no. \n 5903C / Centaur D-1A)\nLaunch Date and Time: 7 January 1968 / 06:30:00 UT\nLaunch Site: Cape Kennedy / Launch Complex 36A\nScientific Instruments:\n1.\t  TV camera\n2.\t alpha-scattering instrument\n3.\t surface sampler\n4.\t footpad magnets\n5.\t stereoscopic and dust detection mirrors\nResults: Since Surveyors I, III, V, and VI successfully \nfulfilled requirements in support of Apollo, NASA \nopted to use the last remaining Surveyor for a purely \nscientific mission outside of a potential landing \nsite for the early Apollo flights.  After an uneventful \ncoast to the Moon (including one of two planned \nmid-course corrections), Surveyor VII successfully \nset down at 01:05:36.3 UT on 10 January 1968 on \nthe ejecta blanket emanating from the bright Tycho \ncrater in the south of the nearside.  Landing coordi\xad\nnates were 40.97° S / 11.44°\xa0W, about 29 kilome\xad\nters north of Tycho’s rim, and 2.4 kilometers from \nits target.  Initial photos from the surface showed \nsurprisingly few craters, much like the mare sites, \nalthough the general area was rougher.  About 21 \nhours after landing, ground controllers fired pyro\xad\ntechnic charges to drop the alpha-scattering instru\xad\nment on the lunar surface. ', '77\n1968\n93\nSurveyor VII\nNation: USA (43)\nObjective(s): lunar soft-landing\nSpacecraft: Surveyor-G\nSpacecraft Mass: 1,040.1 kg\nMission Design and Management: NASA / JPL\nLaunch Vehicle: Atlas Centaur (AC-15 / Atlas 3C no. \n 5903C / Centaur D-1A)\nLaunch Date and Time: 7 January 1968 / 06:30:00 UT\nLaunch Site: Cape Kennedy / Launch Complex 36A\nScientific Instruments:\n1.\t  TV camera\n2.\t alpha-scattering instrument\n3.\t surface sampler\n4.\t footpad magnets\n5.\t stereoscopic and dust detection mirrors\nResults: Since Surveyors I, III, V, and VI successfully \nfulfilled requirements in support of Apollo, NASA \nopted to use the last remaining Surveyor for a purely \nscientific mission outside of a potential landing \nsite for the early Apollo flights.  After an uneventful \ncoast to the Moon (including one of two planned \nmid-course corrections), Surveyor VII successfully \nset down at 01:05:36.3 UT on 10 January 1968 on \nthe ejecta blanket emanating from the bright Tycho \ncrater in the south of the nearside. ', 'About 66 hours of alpha-scattering data \nwere obtained during the first lunar day on three \nsamples: the undisturbed lunar surface, a Moon \nrock, and an area dug up by the surface sampler. \n The alpha-scattering instrument collected 34 more \nhours of data during the second lunar day.  The \nscoop on the sampler’s arm was used numerous \ntimes for picking up soil and digging trenches, and \nfor conducting at least 16 surface-bearing tests. \n Apart from taking 21,274 photographs (20,993 \non the first lunar day and 45 during the second), \nSurveyor VII also served as a target for Earth-\nbased lasers (of 1 watt power) to accurately mea\xad\nsure the distance between Earth and the Moon. \n Communications were paused with Surveyor VII \nat 14:12 UT on 26 January 1968, about 80 hours \nafter sunset.  Second lunar day operations began at \n19:01 UT on 12 February 1968, and extended to \n00:24 UT on 21 February effectively ending the \nmission.  In total, the five successful Surveyors \nreturned more than 87,000 photos of the lunar sur\xad\nface and operated for about 17 months total on the \nlunar surface, and most important, demonstrated \nthe feasibility of soft-landing a spacecraft on the \nlunar surface. ', '5401 / Agena D no. \n AD157/6933)\nLaunch Date and Time: 14 June 1967 / 06:01:00 UT\nLaunch Site: Cape Kennedy / Launch Complex 12\nScientific Instruments:\n1.\t ultraviolet photometer\n2.\t  S-band occultation experiment\n3.\t dual frequency occultation experiment\n4.\t solar plasma probe\n5.\t magnetometer\n6.\t trapped radiation detector\n7.\t celestial mechanics experiment\nResults: In December 1965, NASA approved a proj\xad\nect to modify the Mariner IV backup spacecraft \nto conduct a closer flyby of Venus than the only \nother NASA probe to fly past Venus, Mariner II. \n The primary goal of the mission was to conduct a \nradio-occultation experiment (much like Mariner \nIV at Mars) to determine atmospheric properties \nof Venus.  Unlike Mariner IV, however, Mariner \nV did not carry an imaging instrument.  Initially, \nNASA had planned to send Mariner V on a flyby at \na miss distance of 8,165 kilometers to the surface, \nbut the Agency altered its plan in favor of a more \nmodest 75,000-kilometer flyby in order to preclude \nthe non-sterilized vehicle from crashing into the \nplanet.  After a mid-course correction on 19 June, \nMariner V began transmitting data on Venus on \n19\xa0October during its encounter. ', 'After an en route mid-course correc\xad\ntion on 5 June 1971, at 00:18 UT on 14 November \n1971, Mariner 9 ignited its main engine for 915.6 \nseconds to become the first human-made object to \nenter orbit around a planet.  Initial orbital parame\xad\nters were 1,398 × 17,916 kilometers at 64.3° incli\xad\nnation.  (Another firing on the fourth revolution \naround Mars refined the orbit to 1,394 × 17,144 \nkilometers at 64.34° inclination).  The primary goal \nof the mission was to map about 70% of the surface \nduring the first three months of operation.  The ded\xad\nicated imaging mission began in late November, but \nbecause of the major dust storm at the planet during \nthis time, photos of the planet taken prior to about \nmid-January 1972 did not show great detail.  Once \nthe dust storm had subsided, from 2 January 1972 \non, Mariner 9 began to return spectacular photos \nof the deeply pitted Martian landscape, for the first \ntime showing such features as the great system of \nparallel rilles stretching more than 1,700 kilometers \nacross Mare Sirenum.  The vast amount of incoming \ndata countered the notion that Mars was geologi\xad\ncally inert. ']","
The primary objective of Surveyor VII was a lunar soft-landing for a purely scientific mission outside of a potential landing site for the early Apollo flights. It successfully landed at 01:05:36.3 UT on 10 January 1968 on the ejecta blanket emanating from the bright Tycho crater in the south of the nearside. The results of its mission included taking 21,274 photographs, serving as a target for Earth-based lasers to accurately measure the distance between Earth and the Moon, and collecting 34 hours of alpha-scattering data during the first lunar day on three samples: the undisturbed lunar surface, a Moon rock, and an area dug up by the surface sampler. The scoop on the sampler’s arm was used numerous times for picking up soil and digging trenches, and for conducting at least 16 surface-bearing tests. Communications were paused with Surveyor VII at 14:12 UT on 26 January 1968, about 80 hours after sunset. Second lunar day operations began at 19:01 UT on 12 February 1968, and extended to 00:24 UT on 21 February effectively ending the mission. In total, the five successful Surveyors returned more than 87,000 photos of the lunar surface and operated for about 17 months total on the lunar surface, and most important, demonstrated the feasibility of soft-landing a spacecraft on the lunar surface."
"Question: Why was there a lack of useful, analytical engineering base for helicopter investigations in the late 1920s and 1930s?","According to the text, the lack of a useful, analytical engineering base for helicopter investigations in the late 1920s and 1930s was due to individuals who could contribute being more interested in fixed-wing principles. Additionally, there was a lack of relevant aerodynamic theory and understanding of the nature of aerodynamic lift, which led to dissymmetry of lift and other problems retarding the effective design of helicopters and other types of rotary-wing aircraft in the early 1900s.","['A machine \nwith a questionable future, in the light of its unsuccessful past. \n 2.\t  There was no useful, analytical engineering base, i.e., theory initiated or \nextant on such concepts as performance and stability.  The lack was recog\xad\nnized by Chanute in 1894, and it applied nominally to helicopters until the \nlate 1920s and 1930s.  It is very desirable to have a theory first to know what \nis important in observations, and to know the rational avenues of research. \n Part of the problem here was individuals who could contribute were more \ninterested in fixed-wing principles.\n 3.\t ', 'Document 5-38 reproduces the excerpt from Tichenor’s editorial, along with rel\xad\nevant paragraphs from an internal NACA memorandum of January 1931 in which \nLangley’s engineer-in-charge, Henry J. E. Reid, responded to Tichenor’s charges.\n In the view of others, the NACA’s contribution to the field of rotary-wing \naircraft was hardly so weak and insubstantial.  In his history Helicopters Before \nHelicopters, Eugene K. Liberatore, a veteran helicopter-engineer-turned-historian, \nargued that the NACA had taken “the lead” in what he outlined as the third and \nfourth stages of helicopter development in the United States during the 1920s \nand 1930s; one of the key aspects of these two stages was “the professional, or \nscientific approach to the helicopter.” “If one includes its [the NACA’s] autogiro \nwork, rotary wing aircraft got fair treatment before World War II.”14 In compiling \nthe bibliography for his Cambridge Aerospace Series book Principles of Helicopter \nAerodynamics, Professor J. Gordon Leishman, an internationally recognized teacher \nand researcher in the field of helicopters, exclaimed in his preface, “rediscovering \nthe less well-known early NACA and RAE technical literature on the subject of \nhelicopter aerodynamics proved to be one of the most satisfying aspects of writing \nthis book.  The rapid progress made in understanding the problems of the helicop\xad\nter during the period between 1930 and 1950, and the ingenuity shown in both the \nexperimental and analytical work, are quite remarkable.”15 Thus, to base a claim \nof an “NACA pattern of ignoring helicopter research before 1945” on an assertion \nthat it did not become an ardent champion of the autogiro—a technology whose \nprotagonism actually retarded helicopter development in many ways during the late \n1920s and early 1930s rather than helping it—is a faulty historical interpretation \nin at least two major respects.  First, it grossly undervalues what the NACA actually \ndid in the rotary-wing field; second, it incorrectly perceives autogiro and helicopter \ndevelopment as a single, continuous line.\n Even a cursory review of the NACA technical literature shows that some signif\xad\nicant attention was being paid to the potential of the rotary wing.  Besides the early \ntreatises on helicopter aerodynamics published by the NACA that have already \nbeen cited, the NACA also published some of the earliest reports on the autogiro. \n', 'The Wind and Beyond, Volume III\n42\nof the NACA’s work on rotary-wing aircraft \nduring this period and afterwards, see F.\xa0B. \nGustafson’s 1973 publication, A History \nof NACA/NASA Rotating-Wing Aircraft \nResearch, 1915–1970.  Another major reason \nfor refocusing on the helicopter by the late \n1930s involved highly publicized successes \nof some breakthrough powered rotary-wing \nmachines.  In 1935, French aviation pioneer \nLouis Breguet and associate René Dorand \nbegan flying a relatively large coaxial heli\xad\ncopter successfully.  One of their vehicle’s key \ninnovations was its “swashplate,” an assembly \nlinked to the rotor blades that proved critical \nto the effective performance of a helicopter. \n What their swashplate did was help control \nthe cyclic pitch of the rotor blades and thus \nallow the blade angles to be altered so that \nlift could be equalized on each side of the \nhelicopter’s central shaft. ', 'Another essential piece missing from the picture was a mature understanding \nof the nature of aerodynamic lift.  The pioneers who had built the first tentative \nfull-scale rotary-wing aircraft did not understand aerodynamics very well, and they \ncertainly all lacked special knowledge of the aerodynamics of vertical flight.  To the \nextent that relevant aerodynamic theory even existed, most of the pioneers were \noblivious to it.  In his historical introduction to Principles of Helicopter Aerodynamics \n(2000), J. Gordon Leishman, professor of aerospace engineering at the University \nof Maryland and former aerodynamicist at Westland Helicopters, noted that “the \nfirst significant application of aerodynamic theory to helicopter rotors” did not \ncome until sometime in the early 1920s.  Prior to then, pure intuition guided the \nselection of rotor-blade forms and overall machine shapes.  Aerodynamically, one of \nthe major results of this approach was “dissymmetry of lift,” the unequal or asym\xad\nmetric distribution of lift across the rotor disk owing to the difference in airflow \nvelocity over the advancing and retreating blades.  It was this action that tended to \ncause the early helicopters to flip over on their sides.10\nAnd these were not the only problems retarding the effective design of heli\xad\ncopters and other types of rotary-wing aircraft in the early 1900s. ', 'Ideas that started out simple as \nthe lateral rotor helicopter, ended up with wings and appendages….  The \ncomplexity plus poor performance as either helicopter or airplane would \nlead any rational individual to question the tractability of such a thing as a \nhelicopter.  (Helicopters Before Helicopters, p.\xa0 115)\nIf Berliner himself reached this conclusion, it should not be at all surprising \nthat engineers not involved in rotary-wing research, who were simply observing \nthe frustrations of helicopter designers, would also conclude, as Fred Weick must \nhave, that vertical flight was simply too elusive and that some version of the proven \nfixed-wing aircraft was the way to go to provide the general STOL capabilities of \nthe helicopter concept, minus hovering.\n']","
The lack of a useful, analytical engineering base for helicopter investigations in the late 1920s and 1930s can be attributed to two main reasons. Firstly, the fixed-wing approach to mechanical flight, as demonstrated by the Wrights, overshadowed helicopter investigations. This made helicopters seem like a machine with a questionable future, given their unsuccessful past. Secondly, there was no useful, analytical engineering theory on concepts such as performance and stability. This lack of theory was recognized by Chanute in 1894 and applied to helicopters until the late 1920s and 1930s. The absence of a theory made it difficult to know what was important in observations and to identify rational avenues of research. Additionally, individuals who could contribute to this field were more interested in fixed-wing principles. A corollary to this explanation is the general absence of analytical sophistication in this particular field, with invention, intuition, and accident being the primary ways of creativity."
Question: What is the opinion of the Director of Civil Aviation regarding the use of autogiros in taking-off and landing in a dead beat fashion?,"The Director of Civil Aviation, who could not be present at the discussion, had sent a written communication in which he said he was still a convinced user of the autogiro and felt that they were on the brink of making a real practical use of that type of machine. He said that even in its present state of development, it was an interesting and comfortable machine to fly. Throughout his aviation career, he had been celebrated for making extremely bad landings; and one could imagine the joy of being able to pancake from about 30 feet with impunity, and then being told by the pilot in charge that that was the right way to handle that machine. His efforts should be specially devoted towards improving the take-off.

Note: The Director of Civil Aviation's opinion is not explicitly stated in the given text regarding the use of autogiros in taking-off and landing in a dead beat fashion. However, it can be inferred that he believes that the autogiro is a practical and comfortable machine to fly, and that his efforts should be devoted towards improving the take-off. This suggests that he may have a positive opinion regarding the use of autogiros in taking-off and landing in a dead beat fashion, but this is not explicitly stated.","['The ground simply came \nup in a gentle fashion, as the machine approached it at somewhere round 15 ft.  per \nsecond, which the under-carriage was capable of coping with.\n He thought they might have some remarks from Flight Lieutenant Cotton, who \nwas responsible for the use and development of aircraft for seal spotting and the \nlike, where taking-off and landing in a dead beat fashion were extremely important.\n The Director of Civil Aviation—who could not be present as he was on his \nway to Athens in connection with certain arrangements for Imperial Airways to fly \nthrough Greece and other countries—had sent a written communication in which \nhe said he was still a convinced user of the autogiro, and felt that they were on the \nbrink of making a real practical use of that type of machine.  He said that even in \nits present state of development, it was an interesting and comfortable machine to \nfly.  Throughout his aviation career, he had been celebrated for making extremely \nbad landings; and one could imagine the joy of being able to pancake from about \n30 feet with impunity, and then being told by the pilot in charge that that was \nthe right way to handle that machine.  He felt that their efforts should be specially \ndevoted towards improving the take-off. ', 'de la Cierva one question.  When flying in bad weather \na heavy downward current is sometimes experienced in which an aeroplane will \ndrop like a stone 400 or 500 feet; gravity ceases to work; the engines stop owing \nto the cessation of gravity feed; and the passengers and hand baggage fly up to the \nroof and remain suspended until the end of the bump.  What would an autogiro do \nunder such conditions?\n REPLY TO DISCUSSION\nSenor [sic] J. De La Cierva: Sir Sefton Brancker, the Director of Civil Aviation, \nhad sent a very kind letter, in which he asked what would be the behaviour of the \nautogiro on the occasion of these hair-raising bumps which sometimes happened. \n He was sorry that his pilot had not answered that question, because he has had \nsome experience of that.  He was flying through Germany last year in an autogiro \naccompanied by the Secretary of the Autogiro Company, who was undergoing his \nfirst flying experience.  They were nearly thrown out of their seats by a terrific \nbump, the machine falling 500 feet. ', 'less.  The take-off since the \nintroduction of the deflector tail is better.  The landing qualities are so well known \nthat it is hardly necessary for me to mention them.  In any case, I want to state that \nthe present day autogiro can, with proper handling, be landed in perfectly still air \nwith no run at all after touching the ground.  In steep descent of about forty-five \ndegrees the vertical speed of the latest machines is not more than 12 to 13 feet per \n', 'I went into that question very carefully with the Author, and he \nassures me that a pilot, even of my ability, which you all know is not of the greatest, \ncould not hurt himself, no matter what he did in the air.\n It has one serious drawback to my mind.  It seems that it is going to do away \nwith the skilled pilot; we shall have nothing to do but to navigate in the future!\n In addition to the other questions which are going to be sent to Senor [sic] de \nla Cierva, I propose to furnish him with the specification and performance of one \nof our standard air transport machines and ask him what that machine could do if \nits planes were replaced by an Autogyro.  His reply should be extremely interesting.\n There is one point which has not been emphasised during the discussion, but \nupon which the newspapers have laid considerable stress.  Too much importance \nis attached to the fact that this machine in case of a forced landing can land very \nslowly and in a small space. ', '4 was the last of the experimental \nseries, and No.  5 will be the first of the commercial series.  Those who have followed \nits progress will not go to the airport simply to see it fly and descend vertically \nwithout an appreciable forward speed, but to see it compete with its elder brother, \nthe airplane.\n The “Autogiro” is not a helicopter nor an aeronautic freak pretending to solve a \ndifficult problem of mechanics, but is a perfected airplane, although not designed \nwith the sporting purpose of increasing speed nor with the commercial object of \nenlarging the radius of action, but with the humanitarian purpose of reducing to a \nminimum the number of accidents and the number of human lives sacrificed in the \nfight for the conquest of the air.\n Nearly all aviation accidents are due to loss of speed, which diminishes the lift\xad\ning force and leaves the airplane subject to the force of gravity.  The “Autogiro” is \nnot affected by loss of speed.  An engine failure, a sudden “nose up” or a very sharp \nturn may interrupt its horizontal flight and make it descend toward the ground, Phot of autogiro Number 4 flying at Cuatro Vientos, January 31, 1923.\n']","
The Director of Civil Aviation is still a convinced user of the autogiro and feels that they are on the brink of making a real practical use of that type of machine. He finds the autogiro to be an interesting and comfortable machine to fly, and even in its present state of development, he appreciates its ability to make extremely bad landings with impunity. He specifically recommends improving the take-off of autogiros and suggests the fitting of a geared propeller as soon as possible. He also mentions that autogiros have a better ability to get out of an enclosed area compared to average aeroplanes due to their slower forward speed and steeper climb angle."
What was the original rationale behind the X-planes and how did it change over time?,"The original rationale behind the X-planes was to explore a flight regime that the NACA's wind tunnels could not simulate. However, by the time the X-1 and D-558 flew, researchers had figured out how to extend ground test facilities into this realm with the slotted-throat wind tunnel, developed by Richard Whitcomb at Langley in the early 1950s. Therefore, the real value of the research airplanes lay in the comparison of the ground-based tests with actual flight results to validate theories and wind tunnel results. The fact that the first transonic flights showed nothing particularly unexpected—dispelling the myth of a sound barrier—was of great relief to the researchers.","['Thereafter, the NACA joined the Air Force to pursue ever greater speeds \nin the X-1A, X-1B, and X-1E.  This research led to the interceptor built for North \nAmerican defense by Lockheed, the F-104 “Starfighter.” It took six years after \nthe X-1 supersonic flight before NACA test pilot A.\xa0Scott Crossfield exceeded \nMach 2 in the jet-powered D-558-2 Skyrocket—in an NACA partnership with \nthe Navy—on 20 November 1953.  Only three years after that, on 7 September \n1956, Air Force Captain Milburn G. Apt was killed during his first X-2 flight \nafter he reached Mach 3.196 (1,701 mph), becoming the first person to fly at \nthree times the speed of sound. \n The original rationale behind the X-planes had been to explore a flight \nregime that the NACA’s wind tunnels could not simulate.  However, by the \ntime the X-1 and D-558 flew, researchers had figured out how to extend ground \ntest facilities into this realm with the slotted-throat wind tunnel, developed \nby Richard Whitcomb at Langley in the early 1950s.  Therefore, the real value \nof the research airplanes lay in the comparison of the ground-based tests with \nactual flight results to validate theories and wind tunnel results.  The fact that \nthe first transonic flights showed nothing particularly unexpected—dispelling \nthe myth of a sound barrier—was of great relief to the researchers. ', '45\nCHAPTER 4\nHigher, Faster, and Farther\n“W\ne just took it up and dropped it just to familiarize the pilot with the \nlanding characteristics and stalling characteristics….  We stalled the \nairplane, felt it out, became accustomed to it and by that time it was time to \nland, to set up a pattern and come on in and land.  Very nice airplane; consid\xad\nering it had no booster controls or flying tail on it, it reacted very well,” said \nChuck Yeager, who first flew faster than the speed of sound, approximately \n767\xa0mph, on 14 November 1947.  Through the X-1 program, the NACA and Air \nForce sought to go higher and faster than any aircraft ever before.1\nThe quest for speed and altitude immediately after World War II followed \nan already impressive period of advancement and set the stage for a remark\xad\nable 20 years in pushing flight capabilities thereafter.  During the first century \nof powered flight, aeronautics fired the world’s imagination with three words: \nspeed, altitude, and distance.  The period between 1945 and the middle part \nof the 1960s was remarkable both for the advances in aeronautical technology \nand for the development of rocketry and the possibilities of spaceflight.  The \nX-plane research of the era was one major element of this advance, with the \nNACA at the center of efforts to fly ever higher, faster, and farther. ', 'Since the beginning of powered \nflight, wind tunnels had proven useful tools in understanding the characteris\xad\ntics of aircraft in various situations, but researchers found that as the speed and \ncomplexity of aircraft increased during World War II, these tunnels had several \nlimitations.  Signifying perhaps the greatest limitation, in the 1930s it became \napparent that the transonic regime, between about Mach .8 and 1.2, could not \nbe adequately simulated due to the physical limitations of wind tunnels.  The \nNACA decided to use real airplanes to explore this flight regime.  A succession \nof X-planes that the NACA flew between 1945 and the latter 1950s revolution\xad\nized knowledge of transonic and supersonic flight.\n The first of these new X-planes—the XS-1 (S was for supersonic)—began \nas a joint program between the NACA and the Air Force to overcome the so-\ncalled “sound barrier.” The “sound barrier” as a term had originated in 1935 \nwhen engineers in Great Britain used it to describe what they saw in plots of \nhigh-speed wind tunnel tests.  British aerodynamicist Dr.  W. F. Hilton com\xad\nmented: “See how the resistance of a wing shoots up like a barrier against higher \nspeed as we approach the speed of sound.”2 This got oversimplified for public \nconsumption, and the sound barrier entered the public consciousness, some\xad\ntimes mischaracterized as an impenetrable wall that would destroy anything \nthat approached it. \n', 'This plan evolved when only two test flights were planned for the X-34.  With \nthe planned addition of 25 more flights, the plan changed to favor Edwards \nfor the both the preliminary testing and for the developmental testing with \nsome testing still planned for Kennedy.  Dryden’s David Bushman, one of the \nCenter’s X-34 managers, noted that the Center had been trying to get the X-34 \nflight testing, invoking its X-15 legacy and that the X-34 was like an X-15 but \nwithout a pilot.  Bushman pointed out that despite each having a different \nmission—the X-15 was developed to initially explore the hypersonic flight \nenvelope, while the X-34 was intended to examine how to reduce launch costs \nand to test new technologies for reusable launch vehicles—the X-15 and X-34 \nwere similar in shape, size, and capabilities.  He noted an additional advantage \nof flight-testing at Edwards AFB was that the X-34 could use the same flight \ntrack already planned for the X-33.25\nIn commenting on the problems at Holloman AFB, Aviation Week & Space \nTechnology’s Joseph C. Anselmo noted that\nsome program officials are secretly delighted because the size \nof the test range at Holloman would have limited the X-34 to \nspeeds of Mach 2.5–3.  Flying out of Edwards, the vehicle could \nbe dropped over the Groom Lake test range in Nevada, enabling \nit to achieve peak [Mach 8.0] speed before being moved to Florida \nfor weather-related tests.26 \nCommenting further on the dispute over using Dryden versus White Sands, \nBushman noted that “[w]e here at Dryden with our experience with the X-15 \nand X-33…this is what we do.”27 X-plane flight-testing at Dryden appeared to \nbe confirmed by NASA Administrator Daniel S. Goldin, during his April 2000 \nvisit to Dryden, saying that, “Dryden needs to be the place to test X-planes… \n[and] there should be no ambiguity any longer…if it involves flight, Dryden \nneeds to be involved from the beginning.”28 \nThe A-2 vehicle, which was originally planned to be used in New Mexico, \nwas now planned to be shipped to NASA’s Kennedy Space Center for a second \nset of flight tests.  It was hoped that these tests, which were planned to reach \nspeeds of approximately Mach 4.5, would demonstrate rapid turnaround flight \noperations as well as the capability to make crosswind landings and fly through \nrain. ', 'The SSTO/RLV program was \ncommitted to the development of new operations and component technolo\xad\ngies, as well as the establishment of an industry-Government relationship \ndesigned to bring significant changes to the space launch industry.\n This program included three separate experimental vehicle programs:\n1.\t the Delta Clipper–Experimental Advanced (DC-XA, an outgrowth \nof the DC-X),\n2.\t the X-33 Advanced Technology Demonstrator, and\n3.\t the X-34.\n Over its evolution, the X-34 progressed from an initial two-phase program \n(the proposed X-34A and X-34B) into a final “downsized” Orbital Sciences \nX-34 Technology Testbed Demonstrator (X-34 TTD), ultimately pursued by \nNASA.  These distinctions between variants are important to make, and unless \notherwise stated, the discussion in this chapter is primarily on the initial two-\nphase X-34A/B concept for the X-34, and not the “ultimate” X-34 TTD, which \nis discussed subsequently.1\nIn addressing the historical context of this “next generation” of both military \nand research X-planes (including the X-33 and X-34), noted aviation editor \nGeorge C. Larson wrote in the Smithsonian Institution’s prestigious Air and \n']","
The original rationale behind the X-planes was to explore a flight regime that the NACA’s wind tunnels could not simulate. However, by the time the X-1 and D-558 flew, researchers had figured out how to extend ground test facilities into this realm with the slotted-throat wind tunnel. Therefore, the real value of the research airplanes lay in the comparison of the ground-based tests with actual flight results to validate theories and wind tunnel results. The focus then shifted to pushing through the so-called thermal barrier predicted by Theodore von Kármán and others, which was a significant problem for vehicles venturing above Mach 5 due to increased heating rates from friction. This research was primarily authorized to support the development of intercontinental missiles."
Question: How does the use of a special test battery aid in identifying the causes of disruptions in various forms of eye movements during spaceflight?,"The use of a special test battery makes it possible to evaluate the disruptions that are occurring in various forms of eye movements and, given the known mechanisms of how these movements are performed, to find the causes of these disturbances. This method has been actively used during prolonged spaceflight aboard the ISS in a space experiment called Virtual since 2013, and after crew members return to Earth during Sensory Adaptation study since 2001. Recent studies have shown that repeated spaceflight leads to a dramatic, statistically significant reduction in the duration of postflight re-adaptation with significantly less severe vestibular disorders. Cosmonauts with a prior experience of being in microgravity had significantly changed vestibular reactions only on return plus 1 to 2 days postflight whereas cosmonauts who were in long-term spaceflight for the first time had symptoms of space motion sickness and vestibular disorders up to return plus 8 to 9 days postflight.","['As a result, \nthis situation causes a decrease in the quality \nof performance of work tasks, particularly those \nrelating to visual tracking accuracy.  It is likely that the \nunsuccessful docking of spacecraft, errors in structural \nassembly, and other instances of errors in manual \ncontrol that have occurred in orbit were often caused \nby disturbances in the function of tracking moving \nspace objects because of changes in sensory functions.\n Analysis of data that was accumulated in a series of \nscientific experiments before, during and after space-\nflights on the Salyut-6, Salyut-7, MIR and ISS has led \nthe Institute of Biomedical Problems in Russia to \ndevelop a method that uses computerized systems—\nnamed OculoStim-CM, Virtual and Sensomotor—that \ncan accurately assess the state of vestibular function, \nintersensory interactions, spatial orientation, and visual \ntracking (Russian Federation patent #2307575 dated \n10/10/2007, Kornilova L. N. et al.).\n The use of a special test battery \nmakes it possible to evaluate the \ndisruptions that are occurring in \nvarious forms of eye movements \nand, given the known mechanisms \nof how these movements are \nperformed, to find the causes \nof these disturbances.Photo of an astronaut on the International Space Station wearing a headset and looking at a tablet.\n Space experiment Virtual aboard the ISS (2013). \n Image credit: ROSCOSMOS\n', 'He is wearing a virtual reality headset, has leads connected to his face and neck, and is using a joystick with his right hand.\n Application of the OculoStim-CM hardware and \nvirtual reality glasses in a joint 60-day bedrest \nexperiment in Cologne, Germany (2016).\n Image credit: Institute of Biomedical Problems\nAt the basis of the method lies the assessment of eye \nmovement reactions—visual tracking tests that are \nconducted both with visual targets (stimuli) on a clean \n(black) field on the screen and against a backdrop \nof additional visual interferences (diffuse spots/\nellipses moving horizontally or vertically) to “irritate” \nthe peripheral vision.  During the testing under differing \nconditions, movements of the eyes (by electro- and \nvideo- oculography) and the head (using angular rate \nsensors and accelerometers) are recorded.\n The eye-movement system is controlled by a complex \nhierarchy of innervation mechanisms located at different \nlevels of the nervous system.  The use of a special test \nbattery makes it possible to evaluate the disruptions \nthat are occurring in various forms of eye movements \nand, given the known mechanisms of how these \nmovements are performed, to find the causes of \nthese disturbances.\n This method has been actively used during prolonged \nspaceflight aboard the ISS in a space experiment called \nVirtual since 2013, and after crew members return to \nEarth during Sensory Adaptation study since 2001.\n', 'Image credit: Institute of Biomedical Problems\nAt the basis of the method lies the assessment of eye \nmovement reactions—visual tracking tests that are \nconducted both with visual targets (stimuli) on a clean \n(black) field on the screen and against a backdrop \nof additional visual interferences (diffuse spots/\nellipses moving horizontally or vertically) to “irritate” \nthe peripheral vision.  During the testing under differing \nconditions, movements of the eyes (by electro- and \nvideo- oculography) and the head (using angular rate \nsensors and accelerometers) are recorded.\n The eye-movement system is controlled by a complex \nhierarchy of innervation mechanisms located at different \nlevels of the nervous system.  The use of a special test \nbattery makes it possible to evaluate the disruptions \nthat are occurring in various forms of eye movements \nand, given the known mechanisms of how these \nmovements are performed, to find the causes of \nthese disturbances.\n This method has been actively used during prolonged \nspaceflight aboard the ISS in a space experiment called \nVirtual since 2013, and after crew members return to \nEarth during Sensory Adaptation study since 2001.\n Recent studies have shown that repeated spaceflight \nleads to a dramatic, statistically significant reduction in \nthe duration of postflight re-adaptation with significantly \nless severe vestibular disorders.  Cosmonauts with \na prior experience of being in microgravity had \nsignificantly changed vestibular reactions only on return \nplus 1 to 2 days postflight whereas cosmonauts who \nwere in long-term spaceflight for the first time had \nsymptoms of space motion sickness and vestibular \ndisorders up to return plus 8 to 9 days postflight.\n', '175Photo of a man laying on a table.  He is wearing a virtual reality headset, has leads connected to his face and neck, and is using a joystick with his right hand.\n Application of the OculoStim-CM hardware and \nvirtual reality glasses in a joint 60-day bedrest \nexperiment in Cologne, Germany (2016).\n Image credit: Institute of Biomedical Problems\nAt the basis of the method lies the assessment of eye \nmovement reactions—visual tracking tests that are \nconducted both with visual targets (stimuli) on a clean \n(black) field on the screen and against a backdrop \nof additional visual interferences (diffuse spots/\nellipses moving horizontally or vertically) to “irritate” \nthe peripheral vision.  During the testing under differing \nconditions, movements of the eyes (by electro- and \nvideo- oculography) and the head (using angular rate \nsensors and accelerometers) are recorded.\n The eye-movement system is controlled by a complex \nhierarchy of innervation mechanisms located at different \nlevels of the nervous system.  The use of a special test \nbattery makes it possible to evaluate the disruptions \nthat are occurring in various forms of eye movements \nand, given the known mechanisms of how these \nmovements are performed, to find the causes of \nthese disturbances.\n', '177\nThe effectiveness of the non-pharmacological \ncomputerized method has made it a good candidate \nfor use both during the preflight training of ISS crew \nmembers, and during spaceflight, to suppress the \nsymptoms of space motion sickness.  The suppression \nof negative reactions during flight using the fixation \nreflex has been successfully applied by crew members \naboard the ISS since 2013.\n Moreover, recent studies (2017-2018) in patients with \nParkinson’s disease, and carried out in the Research \nCenter of Neurology, Moscow, have shown that such \nan approach using of the OculoStim-CM hardware \nand a special battery of computerized tests allow us \nto solve the problem of objectifying the neurological \ndeficit and assess the disorders in trajectories of head \nand eyes movements.  Early diagnosis and properly \ninitiated treatment play an important role in stabilizing \nthe progression of Parkinson’s disease.  Computerized \nmethods and OculoStim-CM hardware were originally \ndeveloped for space research.  However, their clinical \napplication now opens the possibility of early diagnosis \nof disorders in Parkinson’s disease, assessing the \ndynamics of these disorders and, in the future, \nproceeding to the screening assessment of these \ndisorders in patients at risk when conventional \ndiagnostic methods are ineffective.\n']","
The use of a special test battery aids in identifying the causes of disruptions in various forms of eye movements during spaceflight by evaluating the disruptions that are occurring in these movements and, given the known mechanisms of how these movements are performed, finding the causes of these disturbances. This method has been actively used during prolonged spaceflight aboard the ISS in a space experiment called Virtual since 2013, and after crew members return to Earth during Sensory Adaptation study since 2001. The procedure and hardware/software systems developed for spaceflight have also demonstrated effectiveness in diagnosing conditions of the vestibular and its related sensory systems, as well as in assessing the stability of static and dynamic spatial orientation on Earth. The systems have been useful in experiments simulating weightlessness, in examining highly qualified athletes, in diagnosing and treating patients who are suffering from dizziness and equilibrium disturbances, and in evaluating the effectiveness of medications. The OculoStim-CM complex is successfully certified for use in clinical studies and has been used in diagnostics of more than 200 patients with vertigo, dizziness and equilibrium disturbances, together with specialists from various medical institutions. Such application in clinical practice has made it possible to develop diagnostic criteria to determine the type of vestibular disturbance, while offering a rapid, less-expensive initial differential diagnosis of dizziness and balance disturbances compared to traditional clinical testing."
"Query: ""The term 'progressive research' is used in the document. How is it defined and what is its significance in the context of airship development?""","In the given document, ""progressive research"" is defined by Munk as a ""scientific"" approach that anticipates ""future discoveries and achievements"" and what ""someone will find"" rather than an engineering approach, one ""that is not science, but merely requires science."" The significance of this definition in the context of airship development is that it emphasizes the importance of scientific inquiry and anticipation of future discoveries in advancing airship technology, rather than simply focusing on current industrial improvements. Munk's definition highlights the need for a more abstract and scientific approach to airship research, rather than a purely engineering-based approach.","['3, 1935), pp.  89–96.\n I am very grateful to the Daniel Guggenheim Airship Institute for this oppor\xad\ntunity to talk to you, and through you to the rest of the country, about the problems \nof progressive airship research, for it seems to me very necessary that something be \nsaid about it at this moment.  By the term “progressive” research I mean that study\xad\ning, meditating, investigating, and experimenting in scientific spirit, the results \nof which are intended to inspire the engineer and designer to venture upon and \nenter into new paths of industrial progress.  Advancing along trodden paths, mak\xad\ning industrial improvements by emphasizing what seems to be harmful, combin\xad\ning what harmonizes, eliminating what is at variance—that too requires careful \nstudying and experimenting, and a high expert training to do it well.  Research \nalong that line is also very necessary and praiseworthy, no laudable attributes like \n“fundamental” and the like are too high and too dignified for describing and \ncharacterizing it.  Only, gentlemen, that is not science, but merely requires sci\xad\nence, and I will not talk about that now as not being progressive research. ', 'Both documents connect to the Daniel Guggenheim Airship Institute, estab\xad\nlished at the University of Akron in 1932.  Munk presented his paper at a meeting \nheld at the Akron facility in July 1935.  The chapter on lighter-than-air from von \nKármán’s autobiography deals with the Caltech aerodynamicist’s many associations \nwith the Airship Institute from its establishment in the early 1930s through the \ntime of the Hindenburg explosion in 1937.\n Both papers are fascinating: von Kármán’s for its anecdotes and personal \ninsights into the airship developments and tragedies of the 1930s; Munk’s not only \nfor its enumeration of airship research problems of the day, but for his unique \ndefinition of what he called “progressive” research.  By this term, he meant a “sci\xad\nentific” approach that anticipated “future discoveries and achievements” and what \n“someone will find” rather than an engineering approach, one “that is not sci\xad\nence, but merely requires science.” The latter, in Munk’s view, focused more on \nwhat was currently being found “along trodden paths” that stimulated industrial \nimprovements “by emphasizing what seems to be harmful, combining what har\xad\nmonizes, and eliminating what is at variance.” Not only is Munk’s preference for \nwhat “someone will find” over what “I found” essential to a proper understanding \nof Munk himself, but it also adds fuel to the fire of the ongoing historiographical \ndebate over appropriate distinctions between scientific and engineering approaches \nto technological knowledge and understanding.\n', 'The model test was then made after the airplane was already in \ncommission.  Very good.  I personally see no reason why not, and the Navy and the \nArmy generally have good reasons why they do things they are doing; and in this \ncase the belated model test may still be of great value, in keeping up the statistics \nand for preparing for a reversal of the process, to make better conclusions from \ntests to airplanes.  What I want to say is merely that that is not progressive research \nas I now intend to use the word.\n Discussing progressive research in a general and broad way is not exactly what a \ntrue scientist is fond of doing, and I have always tried to be such a scientist.  Neither \nthe polemical nor the speculative is the domain of science, but rather the positive \nand definite.  Speaking of progressive airship research savors of anticipating future \ndiscoveries and achievements; not the “I found” but “someone will find” is the \nkeynote of it. ', 'What I want to say is merely that that is not progressive research \nas I now intend to use the word.\n Discussing progressive research in a general and broad way is not exactly what a \ntrue scientist is fond of doing, and I have always tried to be such a scientist.  Neither \nthe polemical nor the speculative is the domain of science, but rather the positive \nand definite.  Speaking of progressive airship research savors of anticipating future \ndiscoveries and achievements; not the “I found” but “someone will find” is the \nkeynote of it.  A scientist dislikes to assume the part of a prophet, dislikes to predict \nin such intangible manner.  Only strong and forceful reasons can induce him to \novercome his dislike and to take a larger view of his subject.\n Such reasons are now, however, present. ', 'It all brings about the result that Germans are better fitted and prepared to assume \nthe functions of machines, and Americans are better fitted and prepared to oper\xad\nate machines and to cope with their complications.  An airship ideal for German \nrequirements may be too primitive for the needs of this country.  The question of \ncomplication should be carefully weighed with this in mind, before new design \nprinciples for airships are condemned.\n I enter now into the discussion of specific problems of progressive airship \nresearch, which discussion, I hope, will demonstrate the abundance of such prob\xad\nlems, and the corresponding brightness of the prospect for airship improvement.  I \nbegin with the problems most engineering-like in character, and gradually advance \ntowards more abstract science.\n I mention first the question of automatic control of airships.  Surface ships and \nairplanes have been successfully and advantageously controlled automatically, and \nthis may also be desirable for airships. ']","

The term 'progressive research' is defined in the document as the study, meditation, investigation, and experimentation in a scientific spirit, with the aim of inspiring engineers and designers to venture into new paths of industrial progress. It is distinguished from other types of research that require science but do not necessarily lead to new discoveries or achievements.

In the context of airship development, progressive research is significant because it is critical for the future of American lighter-than-air development. The country is facing both exceedingly bright prospects and dire and costly disappointments in this field, and progressive research can help navigate these challenges by inspiring innovation and progress."
"Question: ""How is the term 'progressive research' defined in the document and what is its significance in the context of airship development, according to the author?""","The term ""progressive research"" is defined by the author, Munk, as a ""scientific"" approach that anticipates ""future discoveries and achievements"" and what ""someone will find"" rather than an engineering approach, one ""that is not science, but merely requires science."" The significance of this definition in the context of airship development is that it highlights the importance of scientific research in advancing airship technology beyond current industrial improvements. Munk emphasizes that progressive research involves anticipating future discoveries and achievements, rather than simply focusing on what is currently being found ""along trodden paths."" This approach is essential to a proper understanding of Munk himself and adds fuel to the ongoing historiographical debate over appropriate distinctions between scientific and engineering approaches to technological knowledge and understanding.","['3, 1935), pp.  89–96.\n I am very grateful to the Daniel Guggenheim Airship Institute for this oppor\xad\ntunity to talk to you, and through you to the rest of the country, about the problems \nof progressive airship research, for it seems to me very necessary that something be \nsaid about it at this moment.  By the term “progressive” research I mean that study\xad\ning, meditating, investigating, and experimenting in scientific spirit, the results \nof which are intended to inspire the engineer and designer to venture upon and \nenter into new paths of industrial progress.  Advancing along trodden paths, mak\xad\ning industrial improvements by emphasizing what seems to be harmful, combin\xad\ning what harmonizes, eliminating what is at variance—that too requires careful \nstudying and experimenting, and a high expert training to do it well.  Research \nalong that line is also very necessary and praiseworthy, no laudable attributes like \n“fundamental” and the like are too high and too dignified for describing and \ncharacterizing it.  Only, gentlemen, that is not science, but merely requires sci\xad\nence, and I will not talk about that now as not being progressive research. ', 'Both documents connect to the Daniel Guggenheim Airship Institute, estab\xad\nlished at the University of Akron in 1932.  Munk presented his paper at a meeting \nheld at the Akron facility in July 1935.  The chapter on lighter-than-air from von \nKármán’s autobiography deals with the Caltech aerodynamicist’s many associations \nwith the Airship Institute from its establishment in the early 1930s through the \ntime of the Hindenburg explosion in 1937.\n Both papers are fascinating: von Kármán’s for its anecdotes and personal \ninsights into the airship developments and tragedies of the 1930s; Munk’s not only \nfor its enumeration of airship research problems of the day, but for his unique \ndefinition of what he called “progressive” research.  By this term, he meant a “sci\xad\nentific” approach that anticipated “future discoveries and achievements” and what \n“someone will find” rather than an engineering approach, one “that is not sci\xad\nence, but merely requires science.” The latter, in Munk’s view, focused more on \nwhat was currently being found “along trodden paths” that stimulated industrial \nimprovements “by emphasizing what seems to be harmful, combining what har\xad\nmonizes, and eliminating what is at variance.” Not only is Munk’s preference for \nwhat “someone will find” over what “I found” essential to a proper understanding \nof Munk himself, but it also adds fuel to the fire of the ongoing historiographical \ndebate over appropriate distinctions between scientific and engineering approaches \nto technological knowledge and understanding.\n', 'The model test was then made after the airplane was already in \ncommission.  Very good.  I personally see no reason why not, and the Navy and the \nArmy generally have good reasons why they do things they are doing; and in this \ncase the belated model test may still be of great value, in keeping up the statistics \nand for preparing for a reversal of the process, to make better conclusions from \ntests to airplanes.  What I want to say is merely that that is not progressive research \nas I now intend to use the word.\n Discussing progressive research in a general and broad way is not exactly what a \ntrue scientist is fond of doing, and I have always tried to be such a scientist.  Neither \nthe polemical nor the speculative is the domain of science, but rather the positive \nand definite.  Speaking of progressive airship research savors of anticipating future \ndiscoveries and achievements; not the “I found” but “someone will find” is the \nkeynote of it. ', 'What I want to say is merely that that is not progressive research \nas I now intend to use the word.\n Discussing progressive research in a general and broad way is not exactly what a \ntrue scientist is fond of doing, and I have always tried to be such a scientist.  Neither \nthe polemical nor the speculative is the domain of science, but rather the positive \nand definite.  Speaking of progressive airship research savors of anticipating future \ndiscoveries and achievements; not the “I found” but “someone will find” is the \nkeynote of it.  A scientist dislikes to assume the part of a prophet, dislikes to predict \nin such intangible manner.  Only strong and forceful reasons can induce him to \novercome his dislike and to take a larger view of his subject.\n Such reasons are now, however, present. ', 'It all brings about the result that Germans are better fitted and prepared to assume \nthe functions of machines, and Americans are better fitted and prepared to oper\xad\nate machines and to cope with their complications.  An airship ideal for German \nrequirements may be too primitive for the needs of this country.  The question of \ncomplication should be carefully weighed with this in mind, before new design \nprinciples for airships are condemned.\n I enter now into the discussion of specific problems of progressive airship \nresearch, which discussion, I hope, will demonstrate the abundance of such prob\xad\nlems, and the corresponding brightness of the prospect for airship improvement.  I \nbegin with the problems most engineering-like in character, and gradually advance \ntowards more abstract science.\n I mention first the question of automatic control of airships.  Surface ships and \nairplanes have been successfully and advantageously controlled automatically, and \nthis may also be desirable for airships. ']","

The term 'progressive research' is defined in the document as the study, meditation, investigation, and experimentation in a scientific spirit, with the aim of inspiring engineers and designers to venture into new paths of industrial progress. The author emphasizes that this type of research is necessary for the advancement of airship development, as it involves exploring new ideas and techniques rather than simply improving existing ones. The author also highlights the importance of this research in the current context, where the future of American lighter-than-air development is at a critical juncture, with both promising prospects and costly disappointments. Therefore, the author suggests that taking a larger view of the subject and engaging in progressive research is essential for the advancement of airship development."
"""What is the difference between piston and turbofan engines in terms of their applications and characteristics?""","The text material provided in the context information discusses the evolution of aircraft propulsion systems from piston engines to turbofan engines. The text highlights that piston engines were the dominant propulsion system in the United States during the 1920s and 1930s, specifically the radial, air-cooled configuration. On the other hand, the text also mentions that the jet engine emerged during World War II and serves as the dominant propulsion system for high-performance military and commercial aviation since it is most efficient at speeds of over 500 miles per hour.

The text also explains that the introduction of the jet engine brought new challenges, and the propulsion research in Cleveland transitioned from wartime development troubleshooting to long-term fundamental research. The text further explains that turbofans became the engine of choice for both military and commercial applications, for they greatly increased range thanks to their better fuel economy.

In terms of applications and characteristics, piston engines are typically used in smaller aircraft and general aviation, while turbofan engines are used in larger commercial and military aircraft. Piston engines are less efficient than turbofan engines, especially at high speeds, and they require more frequent maintenance. Turbofan engines, on the other hand, are more efficient and require less frequent maintenance, but they are more expensive and heavier than piston engines.

In summary, the main difference between piston and turbofan engines is their efficiency and application. Piston engines are less efficient and are typically used in smaller aircraft, while turbofan engines are more efficient and are used in larger commercial and military aircraft.","['Foreword\nix\nairplane rise upward.  Replacing the piston engine with a gas turbine to drive a \npropeller resulted in the turbine propeller, or “turboprop,” engine.  The propel\xad\nler and its power source are the most efficient at moving a large mass of air for \nthrust at speeds of up to 500 miles per hour.\n The second type of propulsion system, the jet engine, which is another type \nof gas turbine, emerged during World War II and serves as the dominant pro\xad\npulsion system for high-performance military and commercial aviation since \nit is most efficient at speeds of over 500 miles per hour.  A jet engine takes in \nair, compresses it, mixes it with vaporized fuel, ignites it, and pushes it out to \ncreate thrust. ', '139\nCHAPTER 5\nPropulsion Control Enters the \nComputer Era, 1976–1998\nThrough the first half of the 20th century, engine diagnostic systems primarily \nconsisted of a pilot physically monitoring gauges indicating oil pressure, \ntemperature, and fuel capacity on the instrument panel.  That basic human-\nmachine interface evolved into the development of automated onboard \ndiagnostic systems.  Those new systems assessed engine health and recorded \ndata for postflight troubleshooting and maintenance through the use of \nmathematical\xa0models.\n Engine Controls from the Piston Engine \nto the Afterburning Turbofan\nThe configuration of piston engine control systems up to the early 1930s \nreflected a direct and simple approach that was, at its core, similar to that of \nother internal combustion engine systems.  The pilot manipulated the throttle \nto set the amount of power needed.  Carburetors or fuel injectors metered the \nappropriate amount of fuel to the engine’s combustion chambers.  As airflow \nfor combustion and flight conditions changed, the system maintained the \npower at the desired level.1\nThe introduction of the jet engine in the 1940s brought new challenges. ', 'Figure 1-11.  This image shows America’s first jet engine: the General Electric I-A Engine. \n (National Air and Space Museum, Smithsonian Institution, NASM 9A11739)\nNACA Research Transitions from Piston to Jet\nDuring the early days of the Cold War, the aeronautical propulsion industry \nwas at a crossroads.  Would it continue with propeller-driven piston engine \naircraft or go with the new jet technology?  In 1945, the piston engine was \nthe main power plant for aviation.  Within 3 years, there were multiple alter\xad\nnatives.104 The NACA’s propulsion research in Cleveland transitioned from \nwartime development troubleshooting to long-term fundamental research.  In \nDecember 1945, a laboratory plan divided agency research into nine categories \nwith varying emphasis: turbojets (20 percent); turboprops (20 percent); contin\xad\nuous ramjets (12.5 percent); intermittent ramjets (5.5 percent); rocket engines \n(4 percent); reciprocating engines (13 percent); compound engines (reciprocat\xad\ning engine and turbosupercharger) (15 percent); icing research (5\xa0percent); and \n“engines for supersonic flight” (5 percent). ', 'Ware was a 1918 graduate of the mechanical engineering \nprogram at Rensselaer Polytechnic Institute in Troy, NY.  The single-cylinder \ntest engine featured a 5-inch bore, a 7-inch stroke, and a head assembly that \nfacilitated a wide variation of compression ratios and lift and timing of the \nintake and exhaust valves, as well as the capability to connect a number of \naccessories such as magnetos.  Ware’s initial investigations centered on increas\xad\ning horsepower through increased compression ratio and altered valve timing \nrather than the more intuitive increase in throttle settings.7\nDuring the 1920s and 1930s, the next steps in the development of aircraft \npropulsion technology were an unknown.  The dominant propulsion system \nin the United States consisted of the reciprocating piston engine—specifically \nthe radial, air-cooled configuration—and the propeller.8 In 1940, Langley \nMemorial Aeronautical Laboratory’s Power Plants Division focused on the \n“conventional, incremental” approach to the reciprocating engine.  There was \nno place for new and unconventional systems of powering aircraft.  The division \nfocused on improving the cooling properties of the air-cooled radial engine, \nspecifically on the improved design of cylinder fins, baffles, and shrouds.9 It \nwas the point of view of former United Aircraft Corporation President Eugene \nE. Wilson that, since the piston engine was a well-known quantity in the \n1920s, the NACA really had no way to advance the state of the art through \nfundamental research.10\nNevertheless, in September 1934, Langley opened the Aircraft \nEngine Research Laboratory.  Designed primarily by Carlton Kemper, \n', 'The Power for Flight\n64\nGE Aerospace and Defense, ruefully remarked, “We converted the heathen, \nbut the competitor sold the bibles.”\xa031Three-quarter right front view of Grumman F-14A Tomcat in flight with wings swept.\n Figure 2-7.  This image shows the Grumman F-14A Tomcat.  (Northrop Grumman)\nFrom that competitive beginning, turbofans became the engine of choice \nfor both military and commercial applications, for they greatly increased range \nthanks to their better fuel economy.  But they were not an unalloyed blessing. \n For the U.S.  Air Force and Navy, low-bypass turbofans offered better fuel econ\xad\nomy over turbojets while still providing high thrust and supersonic capabil\xad\nity. ']","
Piston engines are primarily used in general aviation and smaller aircraft, while turbofan engines are used in larger commercial and military aircraft. Piston engines operate by using reciprocating motion to convert chemical energy into mechanical energy, while turbofan engines use a gas turbine to compress and expand air to produce thrust.

Piston engines have a lower specific fuel consumption (SFC) compared to turbofan engines, but they produce less thrust and are less efficient at high altitudes and speeds. Piston engines also have a lower power-to-weight ratio compared to turbofan engines.

Turbofan engines, on the other hand, have a higher SFC compared to piston engines, but they produce more thrust and are more efficient at high altitudes and speeds. Turbofan engines also have a higher power-to-weight ratio compared to piston engines. Additionally, turbofan engines are quieter than piston engines due to the use of a fan to produce additional thrust, which reduces the noise generated by the engine.

In terms of applications, piston engines are commonly used in general aviation, training aircraft, and smaller aircraft, while turbofan engines are used in larger commercial and military aircraft. Turbofan engines are also used in business jets and regional jets.

In summary, piston engines are typically used in smaller aircraft and have a lower SFC and power-to-weight ratio compared to turbofan engines. Turbofan engines are typically used in larger aircraft and have a higher SFC and power-to-weight ratio compared to piston engines, but they produce more thrust and are more efficient at high altitudes and speeds. Turbofan engines are also quieter than piston engines."
How does the planetary decadal survey process differ from the NAC process?,"The planetary decadal survey process, conducted by the Space Studies Board (SSB), differs from the NAC process in several ways. The SSB's decadal surveys are external to NASA and are conducted for the Agency on a contractual basis. The resulting reports are available to the public, and the board regularly briefs Congress on findings. The procedures for a decadal survey are very precise, with smaller or fewer committees, less public outreach, or less rigorous external review. By contrast, the NAC is an internal organization within NASA, and the council does not publish many formal studies. The NASA Administrator has the authority to implement NAC recommendations, or not, and the council does not conduct decadal surveys. The power to determine the direction of U.S. space science shifts from the executive to the legislative branch as the SSB takes on more responsibility for strategic and programmatic direction in U.S. space science, and the NAC's role in science shifts to advising NASA on how well it is adhering to the decadal surveys.","['Congress has \noften instructed NASA to fund studies on various topics and now regularly \nincludes language in legislation directing NASA to execute the recommen\xad\ndations of SSB decadal surveys.  In recent years, excerpts from decadal sur\xad\nveys have appeared in congressional authorization legislation, indicating the \nhigh regard in which members of Congress now hold these reports.\n The slow shift in focus from the NAC to the SSB in making program\xad\nmatic recommendations represents an interesting dynamic.  The NAC is an \norganization independent from the NASA program offices, but it is internal \nto NASA.  The NASA Administrator has the authority to implement NAC \nrecommendations, or not, and the council does not publish many formal \nstudies.  The SSB, by contrast, is external to NASA and conducts studies for \nthe Agency on a contractual basis.  Nearly all SSB reports are available to \nthe public, and the board regularly briefs Congress on findings. ', 'Planetary science actual expenditures, 2000–10 ($M, adjusted to 2010 dollars) by \nlaunch dates.\n Decadal Surveys\nIn 2001, Ed Weiler, NASA’s Associate Administrator for Space Science, \nrequested that the SSB undertake a new study of priorities for solar system \nexploration in the next decade, modeled on the decadal surveys conducted \nby the SSB for astronomy and astrophysics.  The resulting document, pub\xad\nlished in 2003 and titled New Frontiers in the Solar System: An Integrated \nExploration Strategy,65 became the first decadal survey for planetary science. \n The term “decadal survey” refers to a specific kind of report conducted by \nthe SSB, and while the board has produced other sorts of reports on scien\xad\ntific priorities for various fields over the period of a decade, those reports \nhave been conducted differently than decadal surveys have been.  The differ\xad\nences may relate to the level of community involvement, including smaller \nor fewer committees, less public outreach, or less rigorous external review. \n Procedures for a decadal survey are very precise.\n Later that decade, NASA also requested that the SSB conduct decadal sur\xad\nveys for Earth science, biological and physical sciences (often referred to as \nmicrogravity research), and heliophysics. ', '50 YEARS OF SOLAR SYSTEM EXPLORATION: HISTORICAL PERSPECTIVES\n78\nprogrammatic recommendations from the NAC tend to remain within \nNASA, which is part of the executive branch of government, while those \nfrom the SSB are generally available to the legislative branch, as well as being \ncirculated in the broader scientific community.  As the SSB takes on more \nresponsibility for strategic and programmatic direction in U.S.  space science \nand the NAC’s role in science shifts to advising NASA on how well it is adher\xad\ning to the decadal surveys, the power to determine the direction of U.S.  space \nscience shifts in a subtle manner from the executive to the legislative\xa0branch.\n This shift may bode well for the planetary science community.  As history \nhas demonstrated, practitioners in all of the various fields that make up this \ncommunity have always had a hand in shaping the direction of U.S. ', 'In spite of some rocky disagreements early in NASA’s history, Newell cob\xad\nbled together a NASA-university-industry-research institution partnership to \nexecute a broad range of scientific activities in the 1960s.  By fostering a diver\xad\ngence of opinion from all interested parties, Newell ensured that decisions were \nnot only better than could be obtained by any one person but also represented \na broad consensus.  Through this effort Newell and his successors established a \nstructure for space science that worked democratically even though it was far \nfrom efficient.  The scientists themselves developed decadal surveys to coalesce \nthe various priorities of the disciplines and to rank them for future implementa\xad\ntion.  These surveys, framed through a politicized process within the National \nAcademies of Sciences, emerged for astronomy in 1964.  Written by a diverse \ncollection of scientists from a variety of institutions, with inputs from many \nothers, it surveyed the current state of the field, identified research priorities, \nand made recommendations for the coming decade, hence the name. \n Decadal surveys soon followed in other scientific disciplines in the latter part \nof the 1960s, each providing a rallying point around which the community of \nscientists spoke with one voice. ', '77\nCHAPTER 2\u2002 •\u2002 Funding Planetary Science: History And Political Economy \nhas served to communicate the community’s interests to NASA and other \ngovernment stakeholders.\n When planetary science began to compete with the fields of astrophysics, \nEarth science, heliophysics, and microgravity research for limited resources, \nthe threat arose that these space science communities might pit themselves \nagainst one another, with the potential to disrupt the presentation of a uni\xad\nfied voice when communicating the interests of space science writ large.  By \nthe early 2000s, witnessing the success of the SSB’s decadal survey process \nfor astronomy and astrophysics, NASA requested that the SSB undertake a \ndecadal survey for planetary science.  The survey provided recommendations \nfrom the science community on programs within NASA and prioritized the \nmost important questions in planetary science.  Prioritization allowed NASA \nflexibility in the event of budget cuts, cost overruns, or unexpected circum\xad\nstances, and directed the Agency toward a strategy that the planetary sci\xad\nence community supported.  The survey also explained NASA’s rationale for \nits programmatic choices to Congress and demonstrated that those choices \nwere supported by the science community. ']","
The planetary decadal survey process is conducted by the Space Studies Board (SSB), which is external to NASA and conducts studies for the Agency on a contractual basis. The SSB reports are nearly all available to the public, and the board regularly briefs Congress on its findings. On the other hand, the NAC (National Academy of Sciences) is an organization internal to NASA, and the NASA Administrator has the authority to implement NAC recommendations or not. The NAC does not publish many formal studies, while the SSB reports are regularly made available to the public. The planetary decadal survey process also includes more detailed programmatic recommendations than most previous NAC works and provides guidelines on how priorities should shift in differing budget scenarios. Congress has often instructed NASA to fund studies on various topics and now regularly includes language in legislation directing NASA to execute the recommendations of SSB decadal surveys. In recent years, excerpts from decadal surveys have appeared in congressional authorization legislation, indicating the high regard in which members of Congress now hold these reports."
How does the planetary decadal survey process conducted by the Space Studies Board (SSB) differ from the process conducted by the National Academy of Sciences (NAC) in terms of their relationship with NASA and the public availability of their reports?,"The Space Studies Board (SSB) conducts decadal surveys for planetary science, which are external to NASA and contractual in nature. These reports are available to the public and the SSB regularly briefs Congress on their findings. On the other hand, the National Academy of Sciences (NAC) is an internal organization to NASA, and its recommendations do not necessarily have to be implemented by the NASA Administrator. NAC reports are not always available to the public, and the council does not publish many formal studies.","['Planetary science actual expenditures, 2000–10 ($M, adjusted to 2010 dollars) by \nlaunch dates.\n Decadal Surveys\nIn 2001, Ed Weiler, NASA’s Associate Administrator for Space Science, \nrequested that the SSB undertake a new study of priorities for solar system \nexploration in the next decade, modeled on the decadal surveys conducted \nby the SSB for astronomy and astrophysics.  The resulting document, pub\xad\nlished in 2003 and titled New Frontiers in the Solar System: An Integrated \nExploration Strategy,65 became the first decadal survey for planetary science. \n The term “decadal survey” refers to a specific kind of report conducted by \nthe SSB, and while the board has produced other sorts of reports on scien\xad\ntific priorities for various fields over the period of a decade, those reports \nhave been conducted differently than decadal surveys have been.  The differ\xad\nences may relate to the level of community involvement, including smaller \nor fewer committees, less public outreach, or less rigorous external review. \n Procedures for a decadal survey are very precise.\n Later that decade, NASA also requested that the SSB conduct decadal sur\xad\nveys for Earth science, biological and physical sciences (often referred to as \nmicrogravity research), and heliophysics. ', '71\nCHAPTER 2\u2002 •\u2002 Funding Planetary Science: History And Political Economy \nTHE 2000SGraph showing NASA budgets from 2000 through 2010 with the solar system exploration missions launched for each year listed.\n FIGURE 16.  Planetary science actual expenditures, 2000–10 ($M, adjusted to 2010 dollars) by \nlaunch dates.\n Decadal Surveys\nIn 2001, Ed Weiler, NASA’s Associate Administrator for Space Science, \nrequested that the SSB undertake a new study of priorities for solar system \nexploration in the next decade, modeled on the decadal surveys conducted \nby the SSB for astronomy and astrophysics.  The resulting document, pub\xad\nlished in 2003 and titled New Frontiers in the Solar System: An Integrated \nExploration Strategy,65 became the first decadal survey for planetary science. \n The term “decadal survey” refers to a specific kind of report conducted by \nthe SSB, and while the board has produced other sorts of reports on scien\xad\ntific priorities for various fields over the period of a decade, those reports \nhave been conducted differently than decadal surveys have been.  The differ\xad\nences may relate to the level of community involvement, including smaller \nor fewer committees, less public outreach, or less rigorous external review. \n', 'The slow shift in focus from the NAC to the SSB in making program\xad\nmatic recommendations represents an interesting dynamic.  The NAC is an \norganization independent from the NASA program offices, but it is internal \nto NASA.  The NASA Administrator has the authority to implement NAC \nrecommendations, or not, and the council does not publish many formal \nstudies.  The SSB, by contrast, is external to NASA and conducts studies for \nthe Agency on a contractual basis.  Nearly all SSB reports are available to \nthe public, and the board regularly briefs Congress on findings.  As a result, \n72.\t  Committee on the Planetary Science Decadal Survey, Space Studies Board, National \nResearch Council, Vision and Voyages for Planetary Science in the Decades 2013–2022 \n(Washington, DC: The National Academies Press, 2012).\n', 'explora\xad\ntion of the solar system, though often that power has been subtle or indirect. \n Choices made by presidents, lawmakers, and administrators often seem to be \nthe critical factors in determining the course of solar system exploration, but \nthe choices those individuals make are bounded by the options presented to \nthem by special committees, congressional testimony, advisory boards, and \nthe like.  And again, as history demonstrates, the planetary science commu\xad\nnity has adapted over decades, organizing to become a very effective voice in \ndecision-making. \n The SSB decadal surveys for planetary science represent the consensus \nof the community on scientific and, increasingly, programmatic priorities. \n Congress seems to recognize there is a unified constituency for space sci\xad\nence, and it is treating that community’s requests as increasingly legitimate \nby tying NASA’s funding to legislation making aspects of decadal study rec\xad\nommendations into law.\n', '77\nCHAPTER 2\u2002 •\u2002 Funding Planetary Science: History And Political Economy \nhas served to communicate the community’s interests to NASA and other \ngovernment stakeholders.\n When planetary science began to compete with the fields of astrophysics, \nEarth science, heliophysics, and microgravity research for limited resources, \nthe threat arose that these space science communities might pit themselves \nagainst one another, with the potential to disrupt the presentation of a uni\xad\nfied voice when communicating the interests of space science writ large.  By \nthe early 2000s, witnessing the success of the SSB’s decadal survey process \nfor astronomy and astrophysics, NASA requested that the SSB undertake a \ndecadal survey for planetary science.  The survey provided recommendations \nfrom the science community on programs within NASA and prioritized the \nmost important questions in planetary science.  Prioritization allowed NASA \nflexibility in the event of budget cuts, cost overruns, or unexpected circum\xad\nstances, and directed the Agency toward a strategy that the planetary sci\xad\nence community supported.  The survey also explained NASA’s rationale for \nits programmatic choices to Congress and demonstrated that those choices \nwere supported by the science community. ']","
The Space Studies Board (SSB) and the National Academy of Sciences (NAC) are two different entities that provide recommendations to NASA, but they differ in their relationship with NASA and the public availability of their reports.

The NAC is an organization that is internal to NASA, meaning it is part of the agency. The NASA Administrator has the authority to implement NAC recommendations, or not. The NAC does not publish many formal studies, and the recommendations may or may not be made public.

On the other hand, the SSB is external to NASA and conducts studies for the agency on a contractual basis. Nearly all SSB reports are available to the public, and the board regularly briefs Congress on findings. This means that the SSB's recommendations are more likely to be made public and accessible to the general public.

In terms of the planetary decadal survey process, the SSB has been conducting decadal surveys for planetary science since the early 2000s, providing recommendations from the science community on programs within NASA and prioritizing the most important questions in planetary science. The SSB's decadal surveys have shifted the focus of programmatic decision-making for NASA, as they include more detailed programmatic recommendations than most previous SSB works.

Congress has often instructed NASA to fund studies on various topics and now regularly includes language in legislation directing NASA to execute the recommendations of SSB decadal surveys. Excerpts from decadal surveys have appeared in congressional authorization legislation, indicating the high regard in which members of Congress now hold these reports.

Therefore, the SSB's planetary decadal survey process is more transparent and publicly available than the NAC's process, and it has a more significant impact on NASA's programmatic decision-making."
What was the objective of Luna 13 and what were the results of its mission?,"The objective of Luna 13 was lunar soft-landing. The results of its mission were that it successfully landed on the Moon's surface on 21 October 1966, and transmitted the first close-up photographs of the lunar surface. The resolution of the images was as high as 15–20 meters. The spacecraft was put into a spin-stabilized roll to carry out its scientific mission, which was fulfilled quite successfully, except for the failure of the US-3 spectro-photometer. Contact was finally lost on 19 January 1967 after 302 communications sessions.","['64\nBEYOND EARTH: A CHRONICLE OF DEEP SPACE EXPLORATION, 1958–2016\nchange its orbital plane in order to provide tracking \ndata of the Moon’s gravitational field over a wider \nswath.  Finally, on 11 October 1967, when atti\xad\ntude control gas was almost depleted, a retro-burn \ndeliberately crashed the spacecraft onto the lunar \nsurface at 4° S / 98° E on the farside to prevent \ncommunications interference on future missions.\n 77\nLuna 13\nNation: USSR (45)\nObjective(s): lunar soft-landing\nSpacecraft: Ye-6M (no.  205)\nSpacecraft Mass: c.  1,620 kg\nMission Design and Management: GSMZ imeni \nLavochkina\nLaunch Vehicle: Molniya-M + Blok L (8K78M no. \n N103-45, also N15000-55)\nLaunch Date and Time: 21 December 1966 / 10:17:08 \nUT\nLaunch Site: NIIP-5 / Site 1/5\nScientific Instruments:\n1.\t ', 'The Soviet press released the first photos \ntaken of the surface on 29 October, pictures that \nshowed the Sea of Rains and the Aristarchus crater. \n Resolution was as high as 15–20 meters.  No fur\xad\nther photos were released at the time, although \napparently 42 total images were obtained.  After \ncompleting its main imaging mission, Luna 12 \nwas put into a spin-stabilized roll to carry out its \nscientific mission which was fulfilled quite suc\xad\ncessfully—the only major failure was of the US-3 \nspectro-photometer.  Contact was finally lost on 19 \nJanuary 1967 after 302 communications\xa0sessions.\n 76\nLunar Orbiter II\nNation: USA (32)\nObjective(s): lunar orbit\nSpacecraft: LO-B (Spacecraft 5)\nSpacecraft Mass: 385.6 kg\nMission Design and Management: NASA / LaRC\nLaunch Vehicle: Atlas Agena D (Atlas Agena D no.  18 / \nAtlas D no. ', 'spacecraft approached the comet—and \nmonitored the interaction between the cometary \nhydrogen tail and the solar wind.  Like Pioneer VI \nand Pioneer VIII, NASA maintained intermittent \ncontact with Pioneer VII in the 1990s, more than \n30 years after its mission began (with data returned \nfrom its cosmic ray detector and plasma analyzer in \nFebruary 1991, for example).  On 31 March 1995, \nthe plasma analyzer was turned on during 2 hours \nof contact with the ground, this being the final con\xad\ntact made with the spacecraft.\n 73\nLuna 11\nNation: USSR (43)\nObjective(s): lunar orbit\nSpacecraft: Ye-6LF (no.  101)\nSpacecraft Mass: 1,640 kg\nMission Design and Management: GSMZ imeni \nLavochkina\nLaunch Vehicle: Molniya-M + Blok L (8K78M no. \n N103-43, also N15000-52)\nLaunch Date and Time: 24 August 1966 / 08:03:21 UT\nLaunch Site: NIIP-5 / Site 31/6\nScientific Instruments:\n1.\t gamma-ray spectrometer\n2.\t  RMCh-1 meteorite detector\n3.\t ', 'Contact with the spacecraft was abruptly lost \nat 07:47:16.5 UT at the previously determined \npoint of lunar landing.  Impact coordinates were \n3° 34′\xa0N\xa0/ 56° 30′ E near the edge of the Sea of \nFertility.  Officially, the Soviets announced that “the \nlunar landing in the complex mountainous con\xad\nditions proved to be unfavorable.” Later, in 1975, \nthe Soviets published data from Luna 18’s contin\xad\nuous-wave radio altimeter which determined the \nmean density of the lunar topsoil.\n 130\nLuna 19\nNation: USSR (80)\nObjective(s): lunar orbit\nSpacecraft: Ye-8LS (no.  202)\nSpacecraft Mass: 5,330 kg\nMission Design and Management: GSMZ imeni \nLavochkina\nLaunch Vehicle: Proton-K + Blok D (8K82K no. \n 257-01 + 11S824 no.  4001L)\nLaunch Date and Time: 28 September 1971 / 10:00:22 \nUT\nLaunch Site: NIIP-5 / Site 81/24\nScientific Instruments:\n1.\t ', '113\n1973\n137\nLuna 21 and Lunokhod 2\nNation: USSR (85)\nObjective(s): lunar roving operations\nSpacecraft: Ye-8 (no.  204)\nSpacecraft Mass: 5,700 kg\nMission Design and Management: GSMZ imeni \nLavochkina\nLaunch Vehicle: Proton-K + Blok D (8K82K no. \n 259-01 + 11S824 no.  205L)\nLaunch Date and Time: 8 January 1973 / 06:55:38 UT\nLaunch Site: NIIP-5 / Site 81/23\nScientific Instruments:\n\t 1.\timaging system (three low resolution TV + \nfour high resolution photometers)\n\t 2.\t']","
The objective of Luna 13 was a lunar soft-landing. It was launched by the USSR on 21 December 1966. Luna 13 successfully soft-landed on the surface of the Moon in the Ocean of Storms between the Krafft and Seleucus craters at 18° 52′ N / 62° 04′ W, some 440 kilometers from Luna 9. The first signal from the probe was received at 18:05:30 UT. The lander carried a suite of scientific instruments in addition to the usual imaging system. A three-axis accelerometer within the pressurized frame of the lander recorded the landing forces during impact to determine the regolith structure down to a depth of 20-30 centimeters. A pair of spring-loaded booms capable of extending 1.5 meters beyond the lander were also deployed. One of these was equipped with the RP radiation densitometer for determining the composition of the lunar surface, and the other with the GR-1 penetrometer to investigate the mechanical strength of the soil. The GR-1 instrument, a 3.5-centimeter diameter titanium-tipped rod, was forced into the lunar surface and recorded how fast and how far into the soil (4.5 centimeters) the probe penetrated. The RP densitometer emitted gamma quanta from a cesium-137 sample into the soil and recorded the scattering to provide an estimate of the density of the soil, found to be about 0.8 g/cm3. Four radiometers recorded infrared radiation from the surface indicating a noon temperature of 117±3°C while a radiation detector indicated that radiation levels would be less than hazardous for humans. The lander returned a total of five panoramas of the lunar surface, showing a terrain smoother than that seen by Luna 9. The mission concluded successfully with a last communications session between 04:05 UT and 06:13 UT on 28 December when the onboard batteries were exhausted."
"What are some of the key factors that contribute to the success of a space mission, as highlighted by the experiences of the Genesis, CONTOUR, and MESSENGER projects?","1. Strong leadership and involvement of the Principal Investigator (PI) in all phases and stages of design and development of the mission.
2. Teamwork between the PI and the project manager, with each finding their own balance.
3. Exemplary performance by the project manager when the PI delegates implementation responsibility.
4. Previous experience in key science roles on previous instrument deliveries, which can be remedied by earlier exposure through roles such as deputy PI or deputy project scientist.
5. Decisiveness, fairness, and resistance to scope creep by the PI.
6. Reliability of past performance in previous instrument deliveries as being predictive of performance leading a mission team.
7. Increased exposure creates more qualified PIs who can then be trusted more completely to deliver mission success.
8. The level of involvement of the PI in mission development, which contributes to mission success.

These factors were highlighted by the experiences of the Genesis, CONTOUR, and MESSENGER projects, as discussed in the text material.","['Four Earth-orbiting missions doubled their Phase B cost, and five more missions had \nmore than 60 percent cost growth.  Only two of the 13 experienced 25\xa0percent or less \ngrowth in cost.118\nThe weakness of many CADRe cost studies of the time was the absence of reasons \nfor cost growth.  Sometimes numbers can be misleading—and nowhere was this more \nthe case than in the early days of Dawn and Kepler, when institutional and management \nchanges caused the costs committed at the start of Phase B to be almost meaningless in \nthe face of changes in institutional burden and the layering of an additional management \ninstitution at no fault of the project.  These factors, and factors such as additional costs \nincurred to comply with the NASA Integrated Action Team recommendations for the \nearlier missions such as Genesis, Deep Impact, and MESSENGER, were essential to \nunderstand and track before making sweeping statements.  This study notwithstanding, \nit was not at all clear that missions like Dawn were underscoped; instead, there were \nnot sufficient reserves or commitment to proposed costs on the part of the managing \ninstitutions involved.  Numbers alone do not tell the whole story.\n Comparisons were also made between the individual missions and types of mis\xad\nsions in schedule growth. ', 'Chapter 9: Insights from Discovery\n357\nThis PI was involved in all phases and stages of design and development of the mis\xad\nsion, leading his team with assurance through the many stages required for successful \nmission implementation.5\nLater missions were characterized not by a single driving personality, but by the \nteamwork found to be essential between the PI and the project manager.  Each mission \nteaming of Principal Investigator and project manager found their own balance, and \neach made the mission work in their own way.  On CONTOUR and Genesis, the PIs \nremained deeply involved, traveling to the implementing organization several times a \nmonth to review progress and participating in change control boards, discussions of \nconcern, and regular staff meetings as needed.  The Stardust PI, in contrast, delegated \nimplementation responsibility almost entirely to the project management organization, \nmaking himself available by telephone for questions about how engineering changes \nwould affect the intended science.  In nearly every case where the PI delegated more \nresponsibility to the project manager, the project manager rewarded that trust with \nexemplary performance.  Where this failed, however, the results were significant: both \nDeep Impact and MESSENGER, for example, experienced crises in project management \nand large overruns in 2002–2003, nearly ten years after the Discovery Program began.\n', 'Chapter 9: Insights from Discovery\n359\nHowever, as the discussions continued, these senior scientists revealed hints of doubt \nand an openness to considering what they might have done differently.  The responses \nprovide a window into nagging regrets in some cases, while in others the PI admitted \nthat he or she had had no idea of the magnitude of the challenge that lay ahead.\n Perhaps prompted by the 2007 discussion of screening requirements proposed for \nfuture PIs, every PI brought up the importance of experience.7 The CONTOUR PI had \nserved in key science roles on NEAR and the Galileo imaging team, for example, and \nhe emphasized the reliability of past performance in previous instrument deliveries \nas being predictive of performance leading a mission team, despite the difference in \nscope.  He stopped short of requiring previous experience, however, recognizing that \na lack of previous executive experience is not a fatal flaw, but something that can be \nremedied by earlier exposure through roles such as deputy PI or deputy project sci\xad\nentist.  Increased exposure creates more qualified PIs who can then be trusted more \ncompletely to deliver mission success.\n Remembering the incredible diversity of sample substrates deployed on the space\xad\ncraft and the intense preparation each required, the PI of Genesis might have taken \ngreater care with scheduling so very many deliverables for the science co-investigators, \nparticularly himself and his project scientist, in the same time frame in 2000. ', 'Chapter 3: Harsh Landings\n93\xad\nwrote an early paper on the origin of the elements; the paper posited that the observed \nabundance of the elements comes directly from their abundance in the stars in which \nthey were created.5 Naderi introduced Burnett to key members of the engineering \nteam and set up a management plan that got rave reviews from a 1994 review panel, \naccording to Burnett.6 It was essentially the same mission as before, minus the asteroid \nsample return, and it was selected for additional funding through a concept study.\n In 1996, the team again proposed Suess-Urey to the Discovery Program, this time \nwith a new proposal manager, Chet Sasaki, and under a new name: Genesis.  Naderi had \nmoved to a different management position at JPL by then, and Sasaki was appointed \non his recommendation.  In 1997, after a fiercely fought Phase A competition, Genesis \nand the Comet Nucleus Tour mission, CONTOUR, were selected for implementation.7 \nDon Burnett was the Genesis PI, with Chet Sasaki as project manager and, not long \nafter, Amy Jurewicz as the JPL project scientist.\n Pre-proposal, Naderi had recommended Don Sweetnam for mission operations \nand Don Sevilla in mechanical design, a move which Burnett called a stroke of genius. \n “Genesis was very mechanism-intensive,” he said.  “Mechanisms always scare review \npanels. ', 'These PIs worked day and night for many years to ensure mission success.\n Insights from the Project Managers\nThese efforts did not go unrecognized by the project managers.  In their formal oral \nhistory interviews, the project managers were also asked to identify the characteristics \nor skills that are important for a good PI.  While a few reiterated points they had made \nearlier while discussing mission challenges, others credited the level of involvement of \nthe PI who they had worked with, and how it contributed to mission\xa0development.11\nThe CONTOUR project manager for design and development named decisiveness, \nfairness, and taking a stand against scope creep (the temptation to add capabilities \nafter design) as top qualities for a PI.  It is very difficult for a scientist leading a team of \nscientists to resist recommending or approving small engineering tweaks that promise \ngreat increases in the science return.  The temptation to improve the mission during \ndevelopment is present in every mission, often accompanied by pressure from the \nscience team also invested in mission success.  A good PI keeps careful watch on his \nor her payload, resisting changes in instruments that deviate significantly from the \nrequirements in either direction, as small changes in scope can have disastrous effects \non mission budgets. ']","
1. Short decision-making time frames: This forces project managers to be proactive in addressing potential issues and not let matters remain unresolved.
2. Experience: Experienced project managers are crucial as they can keep vigilant for potential issues and have the knowledge to address them promptly.
3. Careful planning and scheduling of delivery dates: The initial bid must be planned carefully, and the project manager should be involved at the proposal stage to enforce the words in the proposal and carry through with the intent, considering the assumptions and context.
4. Teamwork and communication: Close-knit teams ensure critical crosstalk between the engineers, the scientists, and the managers. Collaboration between different levels and roles is essential for the success of the mission.
5. Redundancy and safeguards: Mechanisms should not be ""single string"" without built-in backup in case part of the mechanism fails. Additional safeguards can help prevent issues, especially during critical phases like Earth return.
6. Trust and verification: Trust in contractors should be balanced with verification of their progress on technical deliveries to avoid unexpected issues.
7. Costing and replanning: Selecting project managers with experience in costing and replanning space missions is important, especially when facing financial difficulties.
8. Excitement and anticipation: A shared sense of excitement and anticipation about the pending data return can contribute to the overall success of the mission."
"Question: What was the significance of Gordon Fullerton's landing of the NASA F-15 using only engine power to turn, climb, and descend on April 21, 1993?","Gordon Fullerton's landing of the NASA F-15 using only engine power to turn, climb, and descend on April 21, 1993, was a significant achievement for the program as it proved the capability of the PCA system. Burcham, who was involved in the program, remarked that while the technology was proven for incorporation into future aircraft designs, he hoped ""it never has to be used."" The PCA system uses standard autopilot controls already present in the cockpit, together with the new programming in the aircraft's flight control computers. For pitch control, the program increases thrust to climb and reduces thrust to descend. To turn right, the autopilot increases the left engine thrust while decreasing the right engine thrust. This milestone flight, flown by NASA research pilot and former astronaut Gordon Fullerton, was part of a NASA project to develop a computer-assisted engine control system that enables a pilot to land a plane safely when its normal control surfaces are disabled.","[""The Power for Flight\n150\nengines was not ideal for controlling and evaluating the differential thrust \nbetween the left and right power plants.34\nThe first dedicated TOC flight took place on July 2, 1991.  Nearly 2 years \nlater, the program realized a significant achievement when Fullerton landed \nthe F-15 using only engine power to turn, climb, and descend on April 21, \n1993.  Fullerton descended in the F-15 in a shallow approach to approximately \n20 feet above the runway.  The rate of descent increased dramatically, but the \nveteran test pilot brought the aircraft down safely and effectively proved the \ncapability of the PCA system.  Burcham remarked that while the technology \nwas proven for incorporation into future aircraft designs, he hoped “it never \nhas to be used.”35 A series of guest pilots from industry and the military went \non to fly the F-15 in a series of trial approaches and go-arounds, and their \nenthusiasm for PCA was unanimous.36NASA's HIDEC (Highly Integrated Digital Electronic Control) F-15 aircraft nears the runway after a flight out of NASA's Dryden Flight Research Center, Edwards, California.  The last project it was used for at Dryden was development of a computer-assisted engine control system that lets a plane land safely with only engine power if its normal control surfaces such as elevators, rudders or ailerons are disabled. "", ""The Power for Flight\n150\nengines was not ideal for controlling and evaluating the differential thrust \nbetween the left and right power plants.34\nThe first dedicated TOC flight took place on July 2, 1991.  Nearly 2 years \nlater, the program realized a significant achievement when Fullerton landed \nthe F-15 using only engine power to turn, climb, and descend on April 21, \n1993.  Fullerton descended in the F-15 in a shallow approach to approximately \n20 feet above the runway.  The rate of descent increased dramatically, but the \nveteran test pilot brought the aircraft down safely and effectively proved the \ncapability of the PCA system.  Burcham remarked that while the technology \nwas proven for incorporation into future aircraft designs, he hoped “it never \nhas to be used.”35 A series of guest pilots from industry and the military went \non to fly the F-15 in a series of trial approaches and go-arounds, and their \nenthusiasm for PCA was unanimous.36NASA's HIDEC (Highly Integrated Digital Electronic Control) F-15 aircraft nears the runway after a flight out of NASA's Dryden Flight Research Center, Edwards, California. "", 'The flight control system helps the pilot control the engines to turn the aircraft, climb, descend and eventually land safely by varying the speed of the engines one at a time or together.  The HIDEC F-15A, built as the number eight prototype (Serial #71-0287), has now been retired.\n Figure 5-6.  Gordon Fullerton uses only engine power to land the NASA F-15 at Dryden on \nApril\xa021, 1993.  (NASA)\nThe next step in the program concerned expanding the flight research pro\xad\ngram to include an actual multi-engine airliner, the type of aircraft Burcham \nand the rest of the team originally envisioned for PCA.  That required the \nexpansion of institutional involvement beyond Dryden.  During December \n1992, industry and airline executives, Government administrators, and NASA \nCenter Directors met in Washington, DC. ', ""The MD-11 was a three-engine wide-body airliner derived \nfrom the earlier DC-10, but with the latest computerized full flight control \nsystem and digital engine controls.  The company started with simulations, to \nwhich the initial reactions were very good.38This McDonnell Douglas MD-11 transport aircraft approaches its first landing under engine power only on Aug.  29, 1995, at NASA's Dryden Flight Research Center, Edwards, California.\n The milestone flight, flown by NASA research pilot and former astronaut Gordon Fullerton, was part of a NASA project to develop a computer-assisted engine control system that enables a pilot to land a plane safely when its normal control surfaces are disabled.  The Propulsion-Controlled Aircraft (PCA) system uses standard autopilot controls already present in the cockpit, together with the new programming in the aircraft's flight control computers.\n\n The PCA concept is simple--for pitch control, the program increases thrust to climb and reduces thrust to descend.  To turn right, the autopilot increases the left engine thrust while decreasing the right engine thrust. "", 'To turn right, the autopilot increases the left engine thrust while decreasing the right engine thrust.  The initial Propulsion-Controlled Aircraft studies by NASA were carried out at Dryden with a modified twin-engine F-15 research aircraft.\n Figure 5-7.  In August 1995, Gordon Fullerton brings the MD-11 in for the first PCA landing of \nan airliner.  (NASA)\nWith the help of Drew Pappas, McDonnell Douglas project manager, the \nproject received an MD-11 for flight testing.  The first PCA flight over the \nmanufacturer’s Yuma, AZ, facility occurred on August 27, 1995.  The pilots \nclimbed to 10,000 feet and turned on the PCA system. ']","
Gordon Fullerton's landing of the NASA F-15 using only engine power to turn, climb, and descend on April 21, 1993, was significant because it proved the capability of the PCA (Powered Lift Control Augmentation) system. This technology was proven for incorporation into future aircraft designs, demonstrating the potential for aircraft to maneuver using only engine power. The successful landing by Fullerton, a veteran test pilot, also showcased the safety and effectiveness of the PCA system. The event was a major milestone in the PCA program and generated enthusiasm among guest pilots from industry and the military who went on to fly the F-15 in a series of trial approaches and go-arounds."
"What was the primary objective of the Luna 17 mission, and what role did Lunokhod 1 play in achieving this goal?","The primary objective of the Luna 17 mission was to carry out lunar roving operations, specifically to land and deploy Lunokhod 1, the first in a series of robot lunar roving vehicles. Lunokhod 1 played a crucial role in achieving this goal by successfully operating for 11 lunar days, which was significantly longer than its planned design life of only 3 lunar days. The undercarriage was designed and built by VNII Transmash, but Lavochkin retained overall design conception of the vehicle. The landing stage was equipped with two landing ramps for the ""ascent stage,"" i.e., the rover, to disembark on to the Moon's surface. The success of Lunokhod 1's mission paved the way for future lunar roving operations and helped to advance our understanding of the Moon's surface.","['97\n1970\u2003\natmosphere.  The vehicle’s descent module splashed \ndown safely in the Indian Ocean at 13:55\xa0UT on \n27 October about 730 kilometers southeast of the \nChagos Islands, 24 kilometers from its original \ntarget point.  Soviet recovery ships were on hand to \ncollect it and bring it back to Moscow.\n 122\nLuna 17 and Lunokhod 1\nNation: USSR (75)\nObjective(s): lunar roving operations\nSpacecraft: Ye-8 (no.  203)\nSpacecraft Mass: 5,700 kg\nMission Design and Management: GSMZ imeni \nLavochkina\nLaunch Vehicle: Proton-K + Blok D (8K82K no. \n 251-01 + 11S824 no.  406L)\nLaunch Date and Time: 10 November 1970 / 14:44:01 \nUT\nLaunch Site: NIIP-5 / Site 81/23\nScientific Instruments (on Lunokhod 1):\n1.\t imaging system (two low resolution TV + \nfour high resolution photometers)\n2.\t ', 'TL-1 laser reflector\n5.\t  RV-2N radiation detector\n6.\t  RT-1 x-ray telescope\n7.\t odometer/speedometer\nResults: Luna 17 continued the spate of successes \nin Soviet lunar exploration begun by Luna 16 and \nZond 8.  Luna 17 carried Lunokhod 1, the first in a \nseries of robot lunar roving vehicles, whose concep\xad\ntion had begun in the early 1960s, originally as part \nof the piloted lunar landing operations.  The under\xad\ncarriage was designed and built by VNII Trans\xad\nmash although Lavochkin retained overall design \nconception of the vehicle.  This was the second \nattempt to land such a vehicle on the Moon after \na failure in February 1969.  The descent stage was \nequipped with two landing ramps for the “ascent \nstage,” i.e., the rover, to disembark on to the Moon’s \nsurface. ', 'Lunokhod 1 \nclearly outperformed its expectations—its planned \ndesign life was only 3 lunar days (about 21 Earth \ndays) but it operated for 11.  Many years later, in \nMarch 2010, a team of scientists based at several \nU.S.  academic institutions resumed laser ranging \nwith the laser reflector on Lunokhod 1, based on \ndata from NASA’s Lunar Reconnaissance Orbiter \n(LRO) which allowed a precise determination (to \n5 meters accuracy) of the location of the (former) \nSoviet rover.  The new data provided a more precise \nlocation for Lunokhod 1 as 38.333° N / 35.037°\xa0W. \nThe landing site of Luna 17 was also refined to \n38.238° N / 34.997° W.\n', 'However, dust appar\xad\nently covered the reflector and few further echoes \nwere obtained.  Controllers finished the last com\xad\nmunications session with Lunokhod 1 at 13:05\xa0UT \non 14\xa0 September 1971.  Attempts to reestablish \ncontact were discontinued on 4 October, thus \nculminating one of the most successful robotic \nmissions of the early space age.  Lunokhod 1 \nclearly outperformed its expectations—its planned \ndesign life was only 3 lunar days (about 21 Earth \ndays) but it operated for 11.  Many years later, in \nMarch 2010, a team of scientists based at several \nU.S.  academic institutions resumed laser ranging \nwith the laser reflector on Lunokhod 1, based on \ndata from NASA’s Lunar Reconnaissance Orbiter \n(LRO) which allowed a precise determination (to \n5 meters accuracy) of the location of the (former) \nSoviet rover.  The new data provided a more precise \nlocation for Lunokhod 1 as 38.333° N / 35.037°\xa0W. \nThe landing site of Luna 17 was also refined to \n38.238° N / 34.997° W.\n', 'Despite the formal end of the mission, \nexperiments with the French TL-2 laser reflector \ncontinued for decades, and were much more suc\xad\ncessful than the rangings carried out with the sim\xad\nilar instrument on Lunokhod 1.  At the time of the \nLunokhod 2 mission, scientists calculated a total \ntravel distance of 37.5 kilometers, about three-and-\na-half times more than its predecessor.  An extended \nsummary of the scientific results from the mission \nwas published in Pravda on 20 November 1973. \n The Soviets later revealed that during a conference \non planetary exploration in Moscow held from 29 \nJanuary to 2 February 1973 (i.e., after the land\xad\ning of Luna 21), an American scientist had given \nphotos of the lunar surface around the Luna 21 \nlanding site to a Soviet engineer in charge of the \nLunokhod 2 mission.  These photos, taken prior \nto the Apollo 17 landing, were later used by the \n“driver team” to navigate the new rover on its mis\xad\nsion on the Moon.  Later, in 2013, based on imagery \nfrom the Lunar Reconnaissance Orbiter (LRO), \nRussian researchers led by Irina Karachevtseva at \nthe Moscow State University’s Institute of Geodesy \nand Cartography (MIIGAiK), recalculated the \ntotal distance travelled and came to a more precise \nnumber of between 42.1 and 42.2 kilometers.  The \noriginal landing site location was also sharpened to \n25.99° N / 30.41° E.\n']","
The primary objective of the Luna 17 mission was to conduct lunar roving operations. Lunokhod 1, a robot lunar roving vehicle, played a crucial role in achieving this goal. It was the first in a series of lunar roving vehicles, whose concept had begun in the early 1960s, originally as part of the piloted lunar landing operations. Lunokhod 1 was designed and built by VNII Transmash, while Lavochkin retained overall design conception of the vehicle. The descent stage of Luna 17 was equipped with two landing ramps for Lunokhod 1 to disembark on to the Moon's surface. The 756-kilogram rover stood about 1.35 meters high and was 2.15 meters across, with each of its eight wheels controlled independently for two forward and two reverse speeds. The rover was driven by a five-man team of ""drivers"" on Earth who had to deal with a minimum 4.1 second delay. The set of scientific instruments on Lunokhod 1 was powered by solar cells and chemical batteries."
What is the Mars Surveyor program and what are some of its key missions or components?,"The Mars Surveyor program was a new generation of American space probes to explore Mars every 26 months from 1996 to 2005. It was formed in 1994 to economize costs and maximize returns by involving a single industrial partner with the Jet Propulsion Laboratory to design, build, and deliver a flight-worthy vehicle for Mars every two years. The program's key missions or components include:

1. Mars Global Surveyor (launched in 1996) - carried five instruments similar to those carried by the lost Mars Observer probe that fell silent in 1993. Among its instruments was a French-supplied radio relay experiment to serve as a downlink for future Mars landers, including for the then-planned Russian Mars 96 mission.

2. Mars Climate Orbiter (launched in 1998) and Mars Polar Lander (launched in 1999) - both were part of the Mars Surveyor program and were lost due to technical issues.

3. Mars Surveyor 2001 (planned for launch in 2001) - a two-part sample-return mission that was supposed to launch in 2003 and 2005.

4. Mars Scout missions (selected in 2002 for a 2007 launch) - part of the new Mars program that envisioned selecting the first Mars Scout mission in 2002 for a 2007 launch.

Overall, the Mars Surveyor program was a fast-paced strategy that aimed to get more science done in a less costly way by dividing experiments into smaller spacecraft sent every 26 months when the Mars-Earth alignment was optimal.","['This period of experimentation is referred to \nas the “faster, better, cheaper” era at the Agency.27 This era resulted in the \nfirst Mars sample-return mission proposal to make it out of the “pre-project” \nstudy phase into project status.  That sample-return project did not last long, \nbut several Mars missions undertaken in the 2000s were influenced by it, \nand the Mars Science Laboratory/Curiosity mission is an indirect derivative.\n After the loss of the Mars Observer in 1993, NASA created its first Mars \nexploration program proposing a funded sequence of missions rather than \nfollowing its old approach—of seeking funding for single missions via \n“new start” proposals.  This program was called Mars Surveyor, and it was \nintended to achieve at least one launch every Mars opportunity (i.e., every \n26 months).  Surveyor-funded projects were to be launched in 1996 (Mars \nGlobal Surveyor), 1998 (Mars Climate Orbiter and Mars Polar Lander), and \n2001 (an orbiter-lander pair was planned, but only the orbiter, Mars Odyssey, \nwas completed).  The Surveyor program was supposed to launch a two-part \nsample-return mission in 2003 and 2005.  Given the small budget allocated \nto the Surveyor program, originally about $200 million a year, NASA struc\xad\ntured the sample-return mission as a partnership with the French space \nagency Centre National d’Études Spatiales, or National Center for Space \nStudies (CNES). \n', '67\nCHAPTER 2\u2002 •\u2002 Funding Planetary Science: History And Political Economy \nimpact of An Integrated Strategy for Planetary Sciences is difficult to gauge, \ngiven all of the other factors affecting planetary science at the time of its \nrelease, but the report served as a relatively unbiased set of goals by which \nlawmakers could judge the effectiveness of U.S.  investment in the field.\n In the report, COMPLEX stated that the scientific study of Mars should \nfocus on global circulation and climate history, with a study of the polar \nregion key to the latter objective.  In 1995, NASA instituted a Mars Surveyor \nprogram composed of two spacecraft, Mars Climate Orbiter (MCO) and \nMars Polar Lander (MPL), which lifted off in the 1998 Mars launch window. \n NASA developed both missions under the FBC rubric.  The Mars Climate \nOrbiter made it to Mars, but just as it was entering orbit, NASA lost all com\xad\nmunication with the spacecraft.  Just six weeks later, the Mars Polar Lander \narrived at the planet. ', 'D239)\nLaunch Date and Time: 7 November 1996 / 17:00:49 \nUT\nLaunch Site: Cape Canaveral Air Force Station / \nLaunch Complex 17A\nScientific Instruments:\n1.\t  Mars orbital camera (MOC)\n2.\t  Mars orbital laser altimeter (MOLA)\n3.\t thermal emission spectrometer (TES)\n4.\t magnetometer/electron reflectometer \n(MAG/ER)\n5.\t radio science experiment (RS)\n6.\t  Mars relay antenna for future spacecraft \n(MR)\nResults: Mars Global Surveyor was the first space\xad\ncraft in NASA’s new Mars Surveyor Program, a new \ngeneration of American space probes to explore \nMars every 26 months from 1996 to 2005, and for\xad\nmulated (in 1994) to economize costs and maxi\xad\nmize returns by involving a single industrial partner \nwith the Jet Propulsion Laboratory to design, build, \nand deliver a flight-worthy vehicle for Mars every \ntwo years.  (A new Mars Exploration Program was \ninaugurated in 2000.)  The Mars Global Surveyor \nspacecraft carried five instruments similar to \nthose carried by the lost Mars Observer probe that \nfell silent in 1993.  Among its instruments was a \nFrench-supplied radio relay experiment to serve \nas a downlink for future Mars landers, including \nfor the then-planned Russian Mars 96 mission. \n', 'Instead of putting all experiments in one probe, \nNASA would divide them into smaller spacecraft sent every 26 months, \nwhen the Mars-Earth alignment was optimal.  Getting a “program line” in \nthe budget approved by the White House and Congress was important to \nthis fast-paced strategy.  In selling the concept of a long-term program to \nthe White House Office of Management and Budget and Congress, Goldin \nand his Science Associate Administrator, Wesley Huntress, argued that they \nwould get more science done in a less costly way.3 Mars exploration thus \nbecame an ongoing effort, with one mission setting the stage for the next. \n Goldin said that the robotic Mars Surveyor program, as it was called, was a \nshowcase for his faster, better, cheaper product line.  This was an initiating \ndecision that rejuvenated the program at a point when it might otherwise \nhave gone onto the back burner.\n Goldin’s second big decision was one of reorientation.  This came in the \nwake of the 1996 announcement of the discovery of possible fossil evidence \nof bacteria in the Martian meteorite ALH84001.4 As noted above, Goldin \n3.\t ', '129\nCHAPTER 4\u2002 •\u2002 DESIGNING MARS SAMPLE RETURN\nkilograms.  This new Mars program also envisioned selecting the first Mars \nScout mission in 2002 for a 2007 launch.39 \nThe Mars Surveyor Orbiter was the first of these roadmap projects to be \ninitiated.  Like other orbiter missions in the Mars program, it was to be devel\xad\noped under a systems contract, but not necessarily with Lockheed Martin. \n NASA leaders wanted the contract recompeted.  And since the new orbiter’s \nlaunch date of August 2005 was now comfortably far in the future, they \nalso planned to solicit instruments via NASA’s standard Announcement of \nOpportunity process. ']","
The Mars Surveyor program was a series of robotic space missions to Mars conducted by NASA in the late 1990s and early 2000s. It was a key component of NASA's long-term exploration strategy for the planet.

Some of the key missions or components of the Mars Surveyor program include:

* Mars Surveyor Orbiter: This was a mission that consisted of an orbiter and a lander. The orbiter was designed to study the Martian atmosphere and climate, while the lander was intended to investigate the planet's surface and geology.
* Mars Surveyor 98: This was a mission that included two spacecraft, Mars Climate Orbiter and Mars Polar Lander. Unfortunately, both spacecraft failed during their missions.
* Mars Surveyor 2001: This mission included two spacecraft, Mars Odyssey and the Mars Surveyor 2001 Lander. Mars Odyssey successfully entered Mars orbit and continues to operate today, while the Mars Surveyor 2001 Lander was lost during its descent to the Martian surface.

Overall, the Mars Surveyor program played an important role in advancing our understanding of Mars and paving the way for future missions to the planet."
"What was the role of the NACA computers of World War II and how did they contribute to the social transformation during that time? Additionally, describe the background of the first engineers hired at the NACA during the World War II era.","The NACA computers of World War II were women employed in similar positions in technical organizations during the war. They played an important role not only at the NACA but also in the Manhattan Project, in various other scientific and technical organizations, and in ciphers and related fields. They proved themselves and many enjoyed long-term careers at the laboratory. Their contribution to the social transformation during that time was that they changed the social dynamics of the NACA. For the first time, male engineers had other professionals working with them that were not of the same gender.

The first engineers hired at the NACA during the World War II era were of middle-class background, often military veterans, and usually receiving educations at state universities. They were “everyman,” and they were male through the end of the war. Diligence, excellence in school, and an unfaltering devotion to national duty were all that was necessary.","['They played an important role not only at \nthe NACA, but also in the Manhattan Project, in various other scientific and \ntechnical organizations, and in ciphers and related fields. \n The social transformation just getting under way in World War II and mani\xad\nfested at the NACA in the story of the female computers was not confined to \nquestions of race and gender.  The rise of a professional aerospace engineering \nclass began to be seen fundamentally during this era as well.  Perhaps the most \nstriking feature of the first engineers hired at the NACA was how much they \nlooked like mainstream America.  At a fundamental level they were “everyman,” \nand they were male through the end of the war.  Diligence, excellence in school, \nand an unfaltering devotion to national duty were all that was\xa0necessary. \n In part this arose because overwhelmingly the NACA’s engineers were of \nmiddle-class background, often military veterans, and usually receiving educa\xad\ntions at state universities. ', 'A few used the computer position as a stepping-stone for other posi\xad\ntions in the NACA and NASA.  The NACA computers of World War II were \nonly a few of the thousands of women employed in similar positions in techni\xad\ncal organizations in World War II.  They played an important role not only at \nthe NACA, but also in the Manhattan Project, in various other scientific and \ntechnical organizations, and in ciphers and related fields. \n The social transformation just getting under way in World War II and mani\xad\nfested at the NACA in the story of the female computers was not confined to \nquestions of race and gender.  The rise of a professional aerospace engineering \nclass began to be seen fundamentally during this era as well.  Perhaps the most \nstriking feature of the first engineers hired at the NACA was how much they \nlooked like mainstream America.  At a fundamental level they were “everyman,” \nand they were male through the end of the war. ', 'Even so, they still found their careers hamstrung. \n They proved themselves, however, and many enjoyed long-term careers at the \nlaboratory.  A few used the computer position as a stepping-stone for other posi\xad\ntions in the NACA and NASA.  The NACA computers of World War II were \nonly a few of the thousands of women employed in similar positions in techni\xad\ncal organizations in World War II.  They played an important role not only at \nthe NACA, but also in the Manhattan Project, in various other scientific and \ntechnical organizations, and in ciphers and related fields. \n The social transformation just getting under way in World War II and mani\xad\nfested at the NACA in the story of the female computers was not confined to \nquestions of race and gender.  The rise of a professional aerospace engineering \nclass began to be seen fundamentally during this era as well. ', 'Many more women would follow, with Tucker herself recruiting \nmany of them.  Reading, calculating, and plotting data from tests in Langley’s \nwind tunnels and other research divisions, these women played an integral role \nin research at the laboratory from the mid-1930s into the 1970s.  They also \nchanged the social dynamics of the NACA; for the first-time, male engineers \nhad other professionals working with them that were not of the same gender.\n World War II dramatically increased the speed of social change at the \nNACA.  Virginia Tucker, the first, took a lead in expanding the program.  She \ntraveled to universities around the nation seeking women educated in math\xad\nematics and related fields for work in the NACA laboratories.  The engineers \ncame to rely on these computers, remarking that they calculated data “more \nrapidly and accurately” than the engineers.10 \nDuring the war, employees at Langley expanded dramatically from fewer \nthan 1,000 to more than 5,000 by 1945. ', 'NACA to NASA to Now\n34\nmanner, the NACA became part of the “science team” that went to war, the \n“Scientists Against Time” that later became famous.  The NACA agreed that its \nproper role in wartime would be to serve “as an unbiased technical advisor to \nany branch of the government on aeronautical matters.”9\nHuman Computers and Social Change at the NACA\nTo maximize the research of the NACA’s engineers as the agency geared up for \nthe war effort, the NACA began to employ women as “human computers” to \nundertake calculations necessary to complete the research reports so prized by \nthe NACA’s clients.  The term “computer” had been in long-term use as a job \ntitle identifying people who performed mathematical calculations by hand or \nwith mechanical calculators.  Although there were already “human computers” \nat Langley prior to 1935, all of them were male, so the hiring of the first women \nto perform these tasks proved radical.  They found themselves in a men’s club, as \nthe only women up to that point had been in secretarial positions.\n The first to arrive, Virginia Tucker, reached Hampton, Virginia, just after \nLabor Day in 1935 to join the laboratory’s “Computer Pool.” She found the \ncomputers organized into a central office in the Administration Building.  They \ntook the readings from the engineers and worked with them to calculate tables \nsupporting the research. ']","
The NACA computers of World War II were a group of African American women who worked as computers at the NACA's ""West Computing Pool."" They undertook the same work as their white counterparts and eventually integrated into engineering groups focused on flight research and later into NASA's space operations. These women played an important role not only at the NACA but also in the Manhattan Project, in various other scientific and technical organizations, and in ciphers and related fields.

The social transformation during World War II, as seen at the NACA, was not confined to questions of race and gender. The rise of a professional aerospace engineering class also began to be seen during this era. The first engineers hired at the NACA during the World War II era were overwhelmingly of middle-class background, often military veterans, and usually receiving educations at state universities. Most were Midwestern or Southern, the children of working-class parents who were the first members of their families to attend college. Almost all were family men, with wives and children, perhaps marrying after starting their careers at the NACA. Few were from what might be considered privileged backgrounds. The NACA of the World War II era embodied the great transformation of the United States in the mid-dle decades of the 20th century, representing the rise of an educated, technological middle class."
"Question: What was the potential risk associated with the use of falsely certified titanium in the Kepler spacecraft, and what actions were taken by NASA to address this issue?","The potential risk associated with the use of falsely certified titanium in the Kepler spacecraft was that it could be a ""mission catastrophic risk"" should it fail. In March 2009, acting NASA Administrator Chris Scolese testified to the House Science and Technology subcommittee on cost implications, stating that ""if you don't find out about them at receipt, you find out about them when you are in test or you find out about [them] when you're sitting on the top of the rocket, or worse, you find out about it when you're in space. And all of those have cost implications."" NASA inquired into the actual material properties of the titanium and indicated that testing would be done to determine whether the incorporated titanium would be appropriate for the spacecraft. The discovery of counterfeit parts led to a federal indictment against Western Titanium Incorporated and four company executives in December 2009. The parts were used on U.S. Air Force F-15s, F-22s, and C-17s, according to the U.S. Attorney's Office in San Diego. Ball Aerospace, who apparently bought the titanium in good faith, and NASA were concerned. Internal e-mails cited by the media indicate that ""it was concluded by the program personnel that the substituted titanium was a mission catastrophic risk should it fail.""","['It was set for launch in February 2009.  After much \ndiscussion at NASA Headquarters, the project initiated a Guest Observer program, in \nwhich scientists could propose that Kepler view objects within its field of view but not \nalready in the Kepler Target Catalog.  In Paris, meanwhile, the Kepler Asteroseismic \nScience Consortium, comprising over 100 astrophysicists led by Jørgen Christensen-\nDalsgaard, held its first meeting in 2007 to organize an international data analysis \nteam to determine the sizes and ages of a portion of the stars monitored by Kepler.127\nIn late 2008, however, an unexpected technical problem arose when engineers \ndiscovered that the titanium used to build the spider ring of the spacecraft was falsely \nqualified and made from “substandard and non-conforming titanium,” according to \nthe U.S.  Attorney’s Office.128 The discovery of counterfeit parts led to a search warrant \nin April 2008 and a federal indictment against Western Titanium Incorporated and \nfour company executives, including CEO Daniel Schroeder, in December 2009.129 The \nindictment accused the company of “knowingly and intentionally” misrepresenting the \nquality of 7,900 parts made of nonconforming titanium to the Defense Department, in \naddition to the parts delivered to Ball Aerospace and its subcontractors for the Kepler \nmission.  The titanium was bought at about the same time as titanium bought by the U.S. \n Air Force under military specification MIL-T-9046, reportedly requiring a rolled plate \nprocess in manufacturing, but the parts were alleged to be forged instead.  “Titanium \nmade with a forging process results in different properties and the strength of the metal \nis diffused through the finished product,” explained Keith Meyer, Boeing materials \nspecialist.130 (The charges against the four executives were dismissed in 2011.', 'All subsystems had passed their envi\xad\nronmental and performance tests.  It was set for launch in February 2009.  After much \ndiscussion at NASA Headquarters, the project initiated a Guest Observer program, in \nwhich scientists could propose that Kepler view objects within its field of view but not \nalready in the Kepler Target Catalog.  In Paris, meanwhile, the Kepler Asteroseismic \nScience Consortium, comprising over 100 astrophysicists led by Jørgen Christensen-\nDalsgaard, held its first meeting in 2007 to organize an international data analysis \nteam to determine the sizes and ages of a portion of the stars monitored by Kepler.127\nIn late 2008, however, an unexpected technical problem arose when engineers \ndiscovered that the titanium used to build the spider ring of the spacecraft was falsely \nqualified and made from “substandard and non-conforming titanium,” according to \nthe U.S.  Attorney’s Office.128 The discovery of counterfeit parts led to a search warrant \nin April 2008 and a federal indictment against Western Titanium Incorporated and \nfour company executives, including CEO Daniel Schroeder, in December 2009.129 The \nindictment accused the company of “knowingly and intentionally” misrepresenting the \nquality of 7,900 parts made of nonconforming titanium to the Defense Department, in \naddition to the parts delivered to Ball Aerospace and its subcontractors for the Kepler \nmission.  The titanium was bought at about the same time as titanium bought by the U.S. \n Air Force under military specification MIL-T-9046, reportedly requiring a rolled plate \nprocess in manufacturing, but the parts were alleged to be forged instead. ', 'NASA′s Discovery Program\n280\nThe parts were used on U.S.  Air Force F-15s, F-22s, and C-17s, according to the U.S. \n Attorney’s Office in San Diego.132 Ball Aerospace, who apparently bought the titanium \nin good faith, and NASA were concerned.  Internal e-mails cited by the media indicate \nthat “it was concluded by the program personnel that the substituted titanium was \na mission catastrophic risk should it fail,” according to NASA lead counsel Richard \nMcCarthy.133 NASA inquired into the actual material properties of the titanium and \nindicated that testing would be done to determine whether the incorporated titanium \nwould be appropriate for the spacecraft, saying, “We cannot, I imagine, get a ‘re-do’ \naccomplished in time if it turns out that the Kepler mission has a defective critical \npart.”134 In March 2009, acting NASA Administrator Chris Scolese testified to the \nHouse Science and Technology subcommittee on cost implications: “If you don’t find \nout about them at receipt, you find out about them when you are in test or you find \nout about [them] when you’re sitting on the top of the rocket, or worse, you find out \nabout it when you’re in space.  And all of those have cost implications.”135\nMiraculously, given Kepler’s track record and despite concerns, the spacecraft passed \nits pre-ship review and was shipped to the Cape, arriving on 6 January 2009.136\n“An Image of a Blue Ball”\nKepler was fitted with a DVD containing the names of millions of people wanting to \nparticipate in some small way in a mission to space.137 Along with the names, par\xad\nticipants were given the chance to express their thoughts about the importance of the \nplanet-finding mission as part of the celebration of the International Year of Astronomy \n2009, four hundred years after the astronomer Johannes Kepler published the first two \nlaws of planetary motion.  A copy of the names and messages would be stored at the \nSmithsonian’s National Air and Space Museum.\n National and global outreach was essential to Kepler, which was itself a mission \nimmediately understood by a swath of the public: the search for another Earth. ', '“Bill Borucki’s Planet Search.” Air and Space Magazine.\n 40 \t\nCroft, J.  (2008, 16 December).  “NASA investigates effects of falsely certified titanium.” Flight \nInternational.\n 41 \t\nBorucki, W., et al.  (2004, January).  “The Kepler mission: A technical overview.” In “Second \nEddington Workshop: Stellar structure and habitable planet finding,” 9–11 April 2003, \nPalermo, Italy.\n', '“Suspect Titanium could ground NASA planet-finding satellite.” \nFlight Global.\n 134 \t\nCroft, J.  (2008, 16 December).  “NASA investigates effects of falsely certified titanium.” Flight \nInternational. \n 135 \t\nIannotta, B.  (2009, 14 March).  “Engineering society helps NASA combat counterfeit parts \nproblem.” Space.com.\n']","
The potential risk associated with the use of falsely certified titanium in the Kepler spacecraft was a mission catastrophic risk should it fail, as stated by NASA lead counsel Richard McCarthy. This was due to the fact that the titanium was used on U.S. Air Force F-15s, F-22s, and C-17s, and its actual material properties were not known. NASA inquired into the material properties of the titanium and indicated that testing would be done to determine whether the incorporated titanium would be appropriate for the spacecraft. Despite these concerns, the spacecraft passed its pre-ship review and was shipped to the Cape, arriving on 6 January 2009.

It is also worth noting that the Kepler spacecraft was fitted with a DVD containing the names of millions of people wanting to participate in some small way in a mission to space, as part of the celebration of the International Year of Astronomy 2009. A copy of the names and messages would be stored at the Smithsonian’s National Air and Space Museum."
What was the significance of propeller cuffs in the refinement of aircraft propeller blade design and how did they contribute to the performance of the North American P-51 Mustang fighter and the cooling of radial engine designs such as the Republic P-47 Thunderbolt and the Boeing B-29 Superfortress long-range bomber?,"Propeller cuffs were significant in the refinement of aircraft propeller blade design as they allowed for the modification of existing blade designs. In 1939, Langley researchers in the Full-Scale Tunnel investigated a single-engine fighter that was theoretically capable of 400 mph with the right propeller but could not yet reach that speed with a conventional propeller root-shape. To each blade root, they attached airfoil-shaped cuffs that covered over 45 percent of the blade. The increased blade area enabled the fighter to reach 400 mph at 20,000 feet. Langley carried on with extensive research on cuffs that allowed for the modification of existing blade designs. The North American P-51 Mustang fighter was modified with blade cuffs for increased performance, and cuffed propellers likewise improved the cooling of radial engine designs such as the Republic P-47 Thunderbolt and—very significantly, because of its notorious cooling and engine fire problems—the four-engine Boeing B-29 Superfortress long-range bomber.","['In 1939, Langley researchers in the Full-Scale Tunnel investigated a \nsingle-engine fighter that was theoretically capable of 400 mph with the right \npropeller but could not yet reach that speed with a conventional propeller \nroot-shape.  To each blade root, they attached airfoil-shaped cuffs that covered \nover 45 percent of the blade.  The increased blade area enabled the fighter to \nreach 400 mph at 20,000 feet.  Langley carried on with extensive research on \ncuffs that allowed for the modification of existing blade designs.49 The North \nAmerican P-51 Mustang fighter was modified with blade cuffs for increased \nperformance, and cuffed propellers likewise improved the cooling of radial \nengine designs such as the Republic P-47 Thunderbolt and—very significantly, \nbecause of its notorious cooling and engine fire problems—the four-engine \nBoeing B-29 Superfortress long-range bomber.Three quarter left front close up view of the forward section of a North American P-51B Mustang fighter plane on ground.\n Figure 1-2.  The use of propeller cuffs on fighters like the P-51 Mustang maximized the \naircraft’s overall performance.  (National Air and Space Museum, Smithsonian Institution, \nNASM\xa07A35592)\n', 'The increased blade area enabled the fighter to \nreach 400 mph at 20,000 feet.  Langley carried on with extensive research on \ncuffs that allowed for the modification of existing blade designs.49 The North \nAmerican P-51 Mustang fighter was modified with blade cuffs for increased \nperformance, and cuffed propellers likewise improved the cooling of radial \nengine designs such as the Republic P-47 Thunderbolt and—very significantly, \nbecause of its notorious cooling and engine fire problems—the four-engine \nBoeing B-29 Superfortress long-range bomber.Three quarter left front close up view of the forward section of a North American P-51B Mustang fighter plane on ground.\n Figure 1-2.  The use of propeller cuffs on fighters like the P-51 Mustang maximized the \naircraft’s overall performance.  (National Air and Space Museum, Smithsonian Institution, \nNASM\xa07A35592)\n', 'The NACA and Aircraft Propulsion, 1915–1958\n11\nNACA researchers also worked to refine the aerodynamic properties of a \npropeller blade along its entire length with airfoil sections called cuffs.  Blade \ndesign reflected a compromise where most of the blade was an airfoil, but the \nportion where it attached to the hub, called the root, was round for structural \nstrength.  In 1939, Langley researchers in the Full-Scale Tunnel investigated a \nsingle-engine fighter that was theoretically capable of 400 mph with the right \npropeller but could not yet reach that speed with a conventional propeller \nroot-shape.  To each blade root, they attached airfoil-shaped cuffs that covered \nover 45 percent of the blade. ', 'The Power for Flight\n6\nengineering practices that benefited overall airplane design, not just propeller \ndesign.  There were differences between strict propeller design and the need to \nselect and incorporate efficient propellers into airplane design.  Propeller design \ninvolves the meticulous creation of an efficient airfoil, while airplane design \nrequires that work to be already predetermined.23 Perceiving the propeller as \na major component within the technical system of the airplane reflected the \nCommittee’s desire to fulfill its goal of working toward the practical solution \nof the overall problems of flight.\n Later, in June 1918, Durand illustrated the technical systems approach \nto airplane design before the Royal Aeronautical Society of Great Britain. \n In his delivery of the Annual Wilbur Wright Memorial Lecture, entitled \n“Some Outstanding Problems in Aeronautics,” Durand succinctly voiced the \nNACA’s position on propeller refinement within the broader sphere of airplane \ndesign. ', 'The NACA and Aircraft Propulsion, 1915–1958\n3\nAddison\xa0Rothrock, and Oscar W. Schey, the facility included dynamome\xad\nters, equipment for fuel-spray research, and a two-stroke cycle test bed.  Their \nresearch focused on increasing the power and efficiency of engines.  The NACA’s \nlimited but important work on designing air-cooled cylinder fins, examin\xad\ning fuel behavior, and addressing the relationship between octane and high-\ncompression engines took place there.11\nPropellers: Rotating Wings with a Twist\nWhile the NACA may not have had much to offer in terms of innovating new \npower plants, its research programs in the development of propeller technology \nset the standard for technical excellence and Government-university collabo\xad\nration.  The NACA-sponsored propeller program conducted by two Stanford \nUniversity professors is an excellent case study of that relationship.12\nUntil the completion of Langley Memorial Aeronautical Laboratory in June \n1920, the NACA coordinated and conducted all of its experimental research \nthrough contracts with research universities.  One of the earliest and most \nconsistently funded programs was propeller research.  The NACA’s first annual \nreport in 1915 acknowledged the lack of consistent propeller data regard\xad\ning efficiency as one of the general problems facing American aeronautics. \n']","
Propeller cuffs were significant in the refinement of aircraft propeller blade design as they allowed for the modification of existing blade designs, particularly in increasing the blade area. This modification enabled aircraft to reach higher speeds, as demonstrated by a single-engine fighter that was theoretically capable of 400 mph with the right propeller but could not yet reach that speed with a conventional propeller root-shape.

The North American P-51 Mustang fighter was modified with blade cuffs for increased performance, which maximized the aircraft's overall performance. Similarly, cuffed propellers improved the cooling of radial engine designs such as the Republic P-47 Thunderbolt and the four-engine Boeing B-29 Superfortress long-range bomber, which were known for their notorious cooling and engine fire problems.

Therefore, propeller cuffs played a crucial role in enhancing the performance of fighter aircraft and improving the cooling of radial engine designs, contributing to their overall efficiency and safety."
"According to the former head of the Space Department at another institution, why is the leadership of the PI critical in the successful implementation of a mission, and why should his or her authority be respected?","According to the former head of the Space Department at another institution, the leadership of the PI is critical in the successful implementation of a mission because the partnership between the PI and project manager is key, but the leadership of the PI is critical in achieving the defined requirements. The authority of the PI should be respected because a well-founded relationship and close-knit team make addressing future problems possible before they become crises requiring the attention of senior-level management and the costs that those incur. When asked about the concept that a PI should stay out of the way of the implementing engineers, he called such an assertion “damn arrogant” and shortsighted for those interested in maximizing the science return within available resources.","['NASA′s Discovery Program\n374\ncontexts change.  This partnership is critical, and the institution puts a high premium \non making a good match between the PI and project manager for new missions, in \nlarge part because a well-founded relationship and close-knit team make addressing \nfuture problems possible before they become crises requiring the attention of senior-\nlevel management and the costs that those incur.\n The former head of the Space Department at another institution heavily engaged in \nthe design, development, and implementation of Discovery missions—a scientist who \nhas sent instruments to every planet in the solar system—agreed that the partnership \nis key, but the leadership of the PI is critical in the successful implementation of a \nmission, and his or her authority should be respected.  When asked about the concept \nthat a PI should stay out of the way of the implementing engineers, he called such an \nassertion “damn arrogant” and shortsighted for those interested in maximizing the \nscience return within available resources.22\nA program executive charged with the oversight of the Dawn and New Horizons \nmissions at NASA Headquarters cautioned that project managers need to be receptive to \nrequests from all sides without taking comments as direction.  Communication is critical, \nbut the project manager that is accommodating to everyone—or no one—may become \ndistracted from achieving the defined requirements. ', 'NASA′s Discovery Program\n374\ncontexts change.  This partnership is critical, and the institution puts a high premium \non making a good match between the PI and project manager for new missions, in \nlarge part because a well-founded relationship and close-knit team make addressing \nfuture problems possible before they become crises requiring the attention of senior-\nlevel management and the costs that those incur.\n The former head of the Space Department at another institution heavily engaged in \nthe design, development, and implementation of Discovery missions—a scientist who \nhas sent instruments to every planet in the solar system—agreed that the partnership \nis key, but the leadership of the PI is critical in the successful implementation of a \nmission, and his or her authority should be respected.  When asked about the concept \nthat a PI should stay out of the way of the implementing engineers, he called such an \nassertion “damn arrogant” and shortsighted for those interested in maximizing the \nscience return within available resources.22\nA program executive charged with the oversight of the Dawn and New Horizons \nmissions at NASA Headquarters cautioned that project managers need to be receptive to \nrequests from all sides without taking comments as direction.  Communication is critical, \nbut the project manager that is accommodating to everyone—or no one—may become \ndistracted from achieving the defined requirements.  Mission success often hangs on \nthe willingness of project managers to listen to other ideas and the judgment to know \nwhen to push back on the customer or team when appropriate, asking for clarification, \nexplaining the effect of such a change on other spacecraft systems, providing technical \ndata that show the change to be unwise, and standing up to management when neces\xad\nsary. ', 'NASA′s Discovery Program\n322\nreserve level had been set in response to several missions in development simultane\xad\nously exceeding their bids by amounts significantly over their reserve posture and \nthe corresponding need to protect the program from similar overruns in the future. \n Projects were still expected to provide realistic costs in both Step 1 and 2 proposals, \nto assess the appropriate level of reserves per project element, and to discuss the bud\xad\nget reserve strategy, including budget reserve levels as a function of mission phase.50\nThe third finding, “PIs are expected to provide leadership and management, but \nmost lack the requisite skills,” could be seen as insulting, but it was indicative of a \nchange in the implementation of Discovery and Explorer missions, which required \na great deal more hands-on management than imagined in the early days of the pro\xad\ngram’s establishment.  In 1992, the PI’s role was to manage the science; by 2006, the \nPI also was charged with full responsibility for “the execution of the investigation \nwithin the committed cost and according to the committed schedule,” a codification \nof the implications in AOs as far back as 2000 indicating that PIs “must be prepared \nto recommend project termination when, in the judgment of the PI, the successful \nachievement of established minimum science objectives, as defined in the proposal as \nthe performance floor, is not likely within the committed cost and schedule reserves.” \nPerhaps since this clause had not been exercised before 2002, the full impact of its \nstatement had not been tested, but certainly after that, PIs had to take a more hands-\non role to avoid bringing their project in for termination or deleting instruments in \norder to achieve the mission within the committed cost and schedule reserves.  This \nrealization would indeed require a “fundamental understanding of the elements of \nproject control,” as discussed in the last clause of the third finding, but it certainly \nwasn’t the way that the Discovery founders, including Wes Huntress, envisioned or \nmanaged the program in the 1990s.51\nThe fourth finding, “The costs incurred by proposers in responding to AOs has \n[sic] been identified as a potential limiting factor by the proposal teams as to whether \nthey will respond to future AOs” and that “NASA does not possess good information \non the costs incurred by proposers in responding to an AO,” was certainly true but \nwas thought by NASA Headquarters to be ameliorated by increases in Phase A study \nfunding in 2004, 2006, and 2010.52 The common wisdom was that initial proposal \ncosts had to be undertaken by the proposing organizations; if a potential Discovery \nteam didn’t have $1 million or so between them for proposing costs, they would be \n50 \t\nNASA.  (2006).  Discovery Announcement of Opportunity.\n', 'The scientist was \navailable, and he let the team know that, but he didn’t obstruct the engineers from \ndoing the work that had to be done.  A good PI has a positive outlook, motivating the \nteam when necessary and trusting them to build the right instruments or spacecraft \non time, on cost, under his high-level direction, but not with constant interference.  A \nproject manager on Deep Impact’s extended mission, EPOXI, noted that the Principal \nInvestigator was hands-on with NASA Headquarters and with the management of the \nfederally funded research and development center implementing the mission, in ways \nthat the project team could not be.  Both the PI and this project manager had significant \nprevious mission experience, dating back to the mid-1970s and Comet Halley as well \nas European and Soviet missions, and they had a good relationship of mutual respect \nin part because of this experience and common background.\n The Dawn project manager praised the PI for holding the line, refusing to let \nrequirements creep during development even as his instrument scientists pushed him \nto do more.  That commitment to requirements made implementation of the project \neasier, eliminating the burden of major readjustments to engineering hardware and \ndesign that could have caused major problems in development.\n Former Discovery Program Manager Jarrett explained the requirements well when \nhe described the ideal PI as “not just an expert in his particular scientific field, but the \nability to comprehend spacecraft design, trajectory design, and the technical side of \nputting a mission together as well as the budgetary aspects of it.”12\n12 \t\nNiebur, S. ', 'The missions were cost-capped in order to increase the frequency of flight in the \nprogram.  The cost constraints increased the possibility that unrestrained increases \nin engineering growth on a mission could require compensatory decreases in the \ncapability for science return.  To combat this, the role of the principal scientist was \nelevated above the project manager.  The Office of Space Science at NASA had taken a \nchance on a new way of implementing missions, with Wes Huntress, then–Associate \nAdministrator, saying, “We’ve turned the old way of doing business upside down.”2\nDefinition\nFrom the first announcement of these new PI-led programs, the PI was responsible for \nmanaging the planning, development, and execution of the mission, from selecting \nthe team members to defining roles and responsibilities.3 The PI served as a new kind \nof manager, responsible for meeting and reporting on cost and schedule objectives, \neven though he or she did not have matrix or line institutional authority over a single \nengineer.  Due to the inherent difficulties of a scientist managing technical work at a \nfederally funded research and development center or NASA center as much as three \nthousand miles away, early reviewers of the program strongly recommended that the \nmanagement authority be delegated to a project manager, but this decision, like all \nother project design decisions, was left up to the PI by NASA Headquarters.4\nEvolution\nThe first competitive selections for new missions in the Discovery Program allowed \nPIs the freedom to construct their management teams as they saw fit.  This encouraged \nthe use of innovative techniques customized for the smaller teams that must work \ntogether creatively to design and build a small mission for an even smaller cost cap. \n Subsequent selections included greater constraints, as lessons were learned and best \npractices identified, but the responsibility was still left in the hands of the PI.\n']","
The former head of the Space Department at another institution believes that the leadership of the PI is critical in the successful implementation of a mission, and his or her authority should be respected. He disagrees with the concept that a PI should stay out of the way of the implementing engineers, calling it ""damn arrogant"" and shortsighted for those interested in maximizing the science return within available resources. He emphasizes the importance of a well-founded relationship and close-knit team between the PI and project manager, which makes addressing future problems possible before they become crises requiring the attention of senior-level management and the costs that those incur."
"What are the inferred composition and structure of Comet Tempel 1 based on the Deep Impact mission observations, and what evidence supports these inferences?","Based on the Deep Impact mission observations, Comet Tempel 1 was found to have a heterogeneous nucleus consisting of a pile of randomly stacked layers, with the top few centimeters of the surface being largely ice-free. The bulk of the water and carbon dioxide ices were likely within 1 meter of the surface. The comet's nucleus was a relatively weak structure and had only a few impact craters. The comet's production rates of CO2 compared to H2O were about 7 percent, and the differing sources of water and carbon dioxide suggested a heterogeneous nucleus. The comet's composition was inferred to be a mix of ice and dirt, with the dirt being more prevalent near the surface. These inferences were supported by spectral observations and analyses of specra and images taken before, during, and after the impact.","['238\nBEYOND EARTH: A CHRONICLE OF DEEP SPACE EXPLORATION, 1958–2016\nas well as space-based ones, such as the European \nRosetta (which was about 80 million kilometers \nfrom the comet), Hubble, Spitzer, the Swift x-ray \ntelescope, and XMM-Newton.  The Impactor itself \ntook images as little as 3 seconds before impact, \nwhich were transmitted via the flyby vehicle \nback to Earth.  Controllers registered about 4,500 \nimages from the three cameras over the next few \ndays.  Based on the results of Deep Impact’s inves\xad\ntigations, scientists concluded that Comet Tempel \n1 had probably originated in the Oort Cloud.  The \ndata also showed that the comet was about 75% \nempty space.  Although Deep Impact’s primary \nmission was over, because the vehicle still had \nplenty of propellant left, on 3 July 2007, NASA \napproved a new supplemental mission for Deep \nImpact, known as EPOXI, derived from the com\xad\nbination of the two components of this extended \nflight: Extrasolar Planet Observations (EPOCh) \nand Deep Impact Extended Investigation (DIXI). \n This so-called “Mission of Opportunity” was orig\xad\ninally focused on Comet 85P/Boethin; on 21 July \n2005, Deep Impact was set on a trajectory to con\xad\nduct a flyby of Earth in anticipation of the intercept \nof Boethin. ', 'The smallest of the com\xad\netary spacecraft targets, Comet Hartley 2 was hyperactive, with water vapor \nsublimating from the smooth waist region and CO2-rich jets dragging out \nwater ice chunks, which then sublimated above the smaller end of the nucleus.\n Space-based infrared observations of Hartley 2 by the ESA’s Herschel Space \nTelescope provided the surprising result that this comet had a deuterium-\nto-hydrogen (D/H) ratio similar to that in Earth’s oceans, as well as some \nmeteorites and asteroids—suggesting that short-period comets may have con\xad\ntributed much of the water to the early Earth.77 However, the six other comets \nfor which these measurements were made had D/H ratios about twice that of \nEarth’s oceans, suggesting that primitive asteroids, rather than comets, prob\xad\nably provided much of Earth’s water.  The idea that comets might only be a \nminor contributor to Earth’s water was underscored once the D/H ratio for \nthe Rosetta mission target, Comet Churyumov-Gerasimenko, was found to \nbe more than three times the value for Earth’s oceans.78\nAfter the successful flyby of Comet Wild 2 by the Stardust spacecraft in \n2004 and the return of the dust samples to Earth two years later, the Stardust \nmission was renamed Stardust-NExT and retargeted to fly past Comet \nTempel\xa0 1 in mid-February 2011.  Compared to the earlier Deep Impact \nmission images, the additional Stardust-NExT images of Comet Tempel\xa01 \nrevealed very few noticeable changes in surface features.  The crater formed by \nthe collision of the Deep Impact probe into the porous cometary surface in \n77.\t  The Herschel spacecraft observations of Hartley 2 determined the D/H ratio from the \nratio of heavy water to regular water.  In heavy water, one of the two hydrogen atoms \nhas been replaced by the hydrogen isotope deuterium. ', 'The ratio of cometary production rates of CO2 compared to H2O was about \n7 percent, and the differing sources of water and carbon dioxide suggested \na heterogeneous nucleus.73 From spectral observations, the University of \nMaryland’s Jessica Sunshine and colleagues detected water ice in the impact \nejecta and in three small patches on the surface of the nucleus.  However, \nthese surface patches were far too small to explain the total amount of atmo\xad\nspheric water vapor, so most of it must have come from subsurface sources.74 \nA’Hearn and colleagues concluded that the top few centimeters of the comet’s \nsurface are largely ice-free and the bulk of the H2O and CO2 ices are likely \nwithin 1\xa0meter of the surface.75 To account for the observed surface layer\xad\ning and the diverse composition of these layers, Arizona researcher Michael \nBelton suggested a nucleus model consisting of a pile of randomly stacked \nlayers.  These diverse layers were thought to have been produced over time \nby impacts of comets that originated in differing regions of a non-uniform \nprotoplanetary\xa0nebula.76\n72.\t  P. C. Thomas et al., “The Shape, Topography, and Geology of Tempel 1 from Deep \nImpact Observations,” Icarus 191 (2007): 51–62; J. E. Richardson, H.\xa0 J. Melosh, \nC.\xa0M. Lisse, and B. Carcich, “A Ballistic Analysis of the Deep Impact Ejecta Plume: \nDetermining Comet Tempel 1’s Gravity, Mass, and Density,” Icarus 191 (2007): 176–\n209.  Updates for some of Comet Tempel 1’s parameters are provided by Veverka et al., \n“Return to Comet Tempel 1: Overview of Stardust-NExT Results,” Icarus 222 (2013).\n 73.\t  L. M. Feaga et al., “Asymmetries in the Distribution of H2O and CO2 in the Inner \nComa of Comet 9P/Tempel 1 as Observed by Deep Impact,” Icarus 191 (2007): \n134–145.\n', 'Chapter 7: Studying the Rubble of the Solar System\n199\ngiving way and forming slump depressions or sinkholes.  About 20 collimated \njets were observed.70\nIn 2005, Stardust was followed by a mission to investigate the nature \nof Comet Tempel 1’s nucleus via a 10.3-kilometer-per-second impact with \na 372-kilogram spacecraft, Deep Impact.71 Michael A’Hearn, a cometary \nauthority at the University of Maryland and Principal Investigator for the \nmission, proposed a flight plan whereby the impacting spacecraft was released \nfrom the larger mother spacecraft 24 hours prior to impact.  Analyses of spec\xad\ntra and images taken before, during, and after the impact demonstrated that \nComet Tempel 1 was a relatively weak structure and had only a few impact \n70.\t  H. U. Keller et al., “In Situ Observations of Cometary Nuclei,” n.  65.\n 71.\t ', 'Chapter 4: Applying Lessons Learned\n147\nology, digging up the past to see what the solar system was made of 4.5 billion years \nago,” said Lucy McFadden, the mission’s education and public outreach coordinator.25\nComet Tempel 1, the mission’s target, was discovered in 1867 by Ernst Wilhelm \nTempel, a German astronomer.  Tempel 1 is a dark-colored comet, 7.6 miles long and \n4.9 miles wide, with an orbital period of 5.56 years.  The comet was nothing special, \nall things considered, and the team chose it for convenience.26 And yet, this ordinary \npickle-shaped icy dirt ball held secrets.  Jessica Sunshine said of it: “We may finally \nlearn whether these comets…are dirty snowballs, as many astronomers have thought, \nor snowy dirtballs instead.”27\nBecause the nucleus of a comet is hidden beneath its surface and coma, the design \nof Deep Impact was necessarily different from previous such missions.  This mission \nwould be less an expedition and more an experiment, and the first of its kind in that \nits impact and observations were both done on flight. ']","

Comet Tempel 1 has an albedo of 0.059, a bulk density of about 0.4 grams per cubic centimeter, an extent of 4.4-8.0 kilometers, and an abundance of jet activity. Some of the jets are collimated and produce water vapor (H2O), while others on the night side are rich in carbon dioxide (CO2). The ratio of cometary production rates of CO2 compared to H2O is about 7 percent, suggesting a heterogeneous nucleus.

Spectral observations by the University of Maryland's Jessica Sunshine and colleagues detected water ice in the impact ejecta and in three small patches on the surface of the nucleus. However, these surface patches are too small to explain the total amount of atmospheric water vapor, so most of it must come from subsurface sources. The top few centimeters of the comet's surface are largely ice-free, and the bulk of the H2O and CO2 ices are likely within 1 meter of the surface.

To account for the observed surface layering and the diverse composition of these layers, Arizona researcher Michael Belton suggested a nucleus model consisting of a pile of randomly stacked layers. These diverse layers are thought to have been produced over time by impacts of comets that originated in differing regions of a non-uniform protoplanetary nebula. This model, nicknamed the TALPS model, postulates the formation of layered cometary nuclei by the successive collisions of diverse, smaller, primordial comets.

The evidence supporting these inferences includes the Deep Impact mission observations, spectral observations by the University of Maryland, and the TALPS model, which was developed based on these observations."
"What is the function and significance of the Mercury Dual Imaging System in the MESSENGER Spacecraft, as described in the given context?","The Mercury Dual Imaging System (MDIS) is one of the scientific instruments carried by the MESSENGER Spacecraft. Its function is to capture high-resolution images of Mercury's surface and provide detailed information about its geology, composition, and other features. The MDIS is significant because it is a crucial tool for answering scientific questions about Mercury, including its oddly strong magnetic field, unknown core size and composition, and the presence of unexpected materials in its craters at the poles. The MDIS, along with other instruments on the MESSENGER Spacecraft, has provided valuable insights into the planet's history, evolution, and characteristics, making it a critical component of the mission's success.","['Credit: \nNASA/Johns Hopkins University Applied Physics Labora\xad\ntory/Carnegie Institution of Washington\nScientific Instruments:\n1.\t  Mercury dual imaging system (MDIS)\n2.\t gamma-ray spectrometer (GRS)\n3.\t neutron spectrometer (NS)\n4.\t x-ray spectrometer (XRS)\n5.\t magnetometer (MAG)\n6.\t  Mercury laser altimeter (MLA)\n7.\t  Mercury atmospheric and surface composi\xad\ntion spectrometer (MASCS)\n8.\t energetic particle and plasma spectrometer \n(EPPS)\n9.\t radio science experiment (RS)\nResults: MESSENGER (Mercury Surface, Space \nEnvironment, Geochemistry, and Ranging) was \nthe seventh Discovery-class mission, and the first \nspacecraft to orbit Mercury.  Its primary goal was \nto study the geology, magnetic field, and chemical \ncomposition of the planet.  It was the first mis\xad\nsion to Mercury after Mariner 10, more than 30 \nyears before.  MESSENGER was launched into \nan initial parking orbit around Earth after which \nits PAM-D solid motor fired to put the spacecraft \non an escape trajectory into heliocentric orbit at \n0.92 × 1.08 AU and 6.4° inclination to the eclip\xad\ntic. ', 'Moreover, \nthere was evidence that an unexpected material might be found in Mercury’s craters \nat the poles that are never exposed to sunlight.  This material might have been frozen \nwater ice, comet-delivered sulfur, or silicates, hidden in the dark crevices that stay very \ncold, hundreds of degrees below zero.\n Its oddly strong magnetic field and unknown core size and composition were also \nunexplained.  Did it possess a spinning liquid outer core?25 Its geology was curious as \nwell, including its giant escarpments sometimes a mile high and hundreds of miles \nacross, formed most likely when the planet cooled.26\nTo answer those and other questions, MESSENGER’s instrument payload consisted \nof the Mercury Dual Imaging System, a Gamma Ray and Neutron Spectrometer, an \nX-Ray Spectrometer (XRS), a magnetometer, the Mercury Laser Altimeter, the Mercury \nAtmospheric and Surface Composition Spectrometer (MASCS), and an Energetic \nParticle and Plasma Spectrometer (EPPS), as well as a radio science investigation.27\n23 \t\nIbid.\n 24 \t\nSpotts, P. N.  (2004, 29 July).  “The long and winding road to a hot planet.” The Christian \nScience Monitor.\n', '“Earth sends MESSENGER to Mercury.” The Portland Oregonian.\n 27 \t\nHawkins, S., Boldt, J., Darlington, E., Espiritu, R., Gold, R., Gotwols, B., Grey, M., Hash, C., \nHayes, J., Jaskulek,\xa0S., Kardian, C., Keller, M., Malaret, E., Murchie, S., Murphy, P., Peacock, K., \nProckter, L., Reiter, R., Robinson, M., & Williams, B.  (2007).  “The mercury dual imaging system \non the MESSENGER spacecraft.” Space Science Reviews, 131, 247–338.  https://doi.org/10.1007/\ns11214-007-9266-3; Goldsten, J. O., Rhodes, E. A., Boynton, W. V., Feldman, W. C., Lawrence, \nD.\xa0J., Trombka, J. I., Smith, D. M., Evans, L. G., White, J., Madden, N.\xa0W., Berg, P. C., Murphy, \nG.\xa0A., Gurnee, R. S., Strohbehn, K., Williams, B. D., Schaefer, E. D., Monaco, C. A., Cork, C. P., \nDel Eckels, J., Miller, W.\xa0O., Burks, M.\xa0T., Hagler, L.\xa0B., DeTeresa, S.\xa0J., & Witte, M. C.  (2007).  “The \nMESSENGER Gamma-Ray and Neutron Spectrometer.” Space Science Reviews, 131(1–4), 339–391. \n', 'Chapter 5: Breaking the Bank\n179\nAs far back as 2002, the camera team had put thought into their orbital strategy, \ndata collection, polar data acquisition, how they were going to fill in the base map, \nwhat colors were needed, and the minimum number of filters necessary to answer \ntheir science questions about composition.30\nThe role of an Instrument Scientist, according to Prockter, is “to take the science \ngoals from the proposal, the high-level science traceability matrix, and make sure \nthat that instrument can do that science.” That’s not just making sure, on a camera, \nfor instance, that you’ve got the right focal length on the instrument, she explains. \n It’s much more nuanced than that, involving things like the correct planes and filters \nto do color imaging.  “It’s also making sure that once you’re in orbit around Mercury, \nyou’re in the right orbit that your camera’s going to work, you’ve got the right amounts \nof time to do that.” She explains that calibrations done in flight validated the camera’s \nfunctionality and ironed out many of the quirks in the system and bugs in the software.31\nMost instrument scientists on MESSENGER worked for the Applied Physics \nLaboratory, and most of the spacecraft’s instruments were built there as well.  The \nlaser altimeter and atmospheric and surface composition spectrometer were built at \nGoddard Space Flight Center and the University of Colorado, respectively.  By the time \nthe mission launched, the set of people who had put in at least two months of work on \nthe mission numbered nearly a thousand, over half at the Applied Physics Laboratory.32\nThe instruments carried, spacecraft design, and overall mission were driven by \nseveral factors, including mass.  MESSENGER was limited by the heaviest Delta II \nrocket, the 7925H, which had a lift mass of a little over 1,100 kilograms. ', ""234\nBEYOND EARTH: A CHRONICLE OF DEEP SPACE EXPLORATION, 1958–2016This image acquired by NASA's Messenger spacecraft on October 2, 2013 by its Wide Angle Camera (WAC) shows the sunlit side of the planet Mercury.  Messenger was the first spacecraft to go into orbit around Mercury.\n This image acquired by NASA’s Messenger spacecraft on \n2 October 2013 by its Wide Angle Camera (WAC) shows \nthe sunlit side of the planet Mercury.  Messenger was the \nfirst spacecraft to go into orbit around Mercury.  Credit: \nNASA/Johns Hopkins University Applied Physics Labora\xad\ntory/Carnegie Institution of Washington\nScientific Instruments:\n1.\t  Mercury dual imaging system (MDIS)\n2.\t gamma-ray spectrometer (GRS)\n3.\t neutron spectrometer (NS)\n4.\t x-ray spectrometer (XRS)\n5.\t magnetometer (MAG)\n6.\t ""]","
The Mercury Dual Imaging System (MDIS) is a crucial component of the MESSENGER Spacecraft, as it is responsible for capturing high-resolution images of Mercury's surface. The MDIS is mounted on a pivot that can move up to 40 degrees towards the Sun shield and 50 degrees away from it, allowing it to cover 90 degrees and track the spacecraft's movement across the surface. This feature is significant because the spacecraft is so close to Mercury that it needs a giant sunshade to protect its instruments from the concentrated rays of the Sun. The MDIS's ability to move in tiny increments and cover a wide range of angles is essential for collecting valuable scientific data about Mercury's surface and geology."
"Question: Based on the context information, can you explain the significance of the X-34 in the field of aerospace engineering and provide examples of related studies or papers?","The X-34 was a proposed reusable launch vehicle (RLV) designed to reduce launch costs and test new technologies for RLVs. The X-34 program was committed to the development of new operations and component technologies, as well as the establishment of an industry-Government relationship designed to bring significant changes to the space launch industry. The program included three separate experimental vehicle programs: the Delta Clipper–Experimental Advanced (DC-XA), the X-33 Advanced Technology Demonstrator, and the X-34. The X-34 progressed from an initial two-phase program (the proposed X-34A and X-34B) into a final ""downsized"" Orbital Sciences X-34 Technology Testbed Demonstrator (X-34 TTD), ultimately pursued by NASA. The X-34 was intended to examine how to reduce launch costs and to test new technologies for RLVs. The X-34 program design philosophy encouraged sacrificing performance and mass fraction to achieve lower cost and faster turnaround. The X-34 incorporated a number of so-called ""embedded technologies,"" as shown in Table 5.4. The X-34 was planned to be flight-tested at NASA's Dryden Flight Research Center (now the Neil A. Armstrong Research Center), Edwards, California, and at NASA's Kennedy Space Center, Florida. However, due to budget constraints, the X-34 program was canceled in 2001.

Related studies and papers include:

1. ""The X-34: A Reusable Launch Vehicle for the 21st Century"" by Orbital Sciences Corporation, which provides an overview of the X-34 program and its objectives.

2. ""The X-34: A Reusable Launch Vehicle for the 21st Century"" by NASA, which provides a detailed technical description of the X-34 vehicle and its systems.

3. ""The X-34: A Reusable Launch Vehicle for the 21st Century"" by the National Research Council, which provides an independent assessment of the X-34 program and its potential impact on the space launch industry.

4. ""The X-34: A Reusable Launch Vehicle for the 2","['[Langley] will establish the viability of the X-34 \nvehicle/NK-31/39 engine combination to provide the environment required \nfor potential research tasks.”25\nSeveral NASA Langley engineers also noted, from an aeroscience view\xad\npoint, some possible advantages of using an enhanced propulsion system \n(such as the NK-31) for the X-34.  Charles G. Miller from NASA Langley, \npointed out in a note that “[f]rom aerosciences viewpoint, [the] most criti\xad\ncal issue is vehicle instrumentation to measure surface (i.e., outer mold line \n(OML) temperature—time histories, surface pressures and vehicle forces \nand moments (i.e., aeroheating, aeroloads and aerodynamics respectively).”26 \n[Emphasis in\xa0original.] \n Testing requires numerous discrete measurements and sufficient accuracy \nto benchmark the data.  Miller noted that using the NK-31 engine in the X-34 \nwould enhance aeroscience knowledge by enabling the vehicle to fly higher \n(greater than 250,000 feet), fly faster (to Mach 10 and possibly higher), and \nto perform flight experiments—as opposed to simply flying the plane.  Flying \nhigher would expand the envelope to enter a noncontinuum, or rarefied flow \nregime, in which computational fluid dynamics is not applicable.  Miller added \nthat there were no facilities in the United States that could simulate this regime \nfrom an aerodynamic perspective and that flight data would be of tremendous \nvalue in bridging these regimes.  This also would provide an opportunity to \n', 'Promise Denied\n130\nThe X-34 A-1 with its Lockheed L-1011 mother ship, on the ramp of the NASA Hugh L. Dryden \nFlight Research Center (now the Neil A. Armstrong Research Center), Edwards, California, in \n2000.  (NASA)\nOrbital’s X-34 Design: \nPhilosophy, Influence, and Driving Factors\nAs Bryan Sullivan, Orbital’s X-34 program chief engineer and Brian Winters, \nOrbital’s X-34 propulsion lead, noted, “The X-34 program design philosophy \nencourage[d] sacrificing performance and mass fraction to achieve lower cost \nand faster turnaround.  Operational philosophies include[d] the use of simpli\xad\nfied procedures, small, well-trained crews, and flight data to verify functionality \nof the system prior to the next launch.”11 These were all essential aspects of \nreliable, rapid-turnaround, and reusable launch vehicle design.  To this end, \nthe X-34 incorporated a number of so-called “embedded technologies,” as \nshown in Table 5.4.12\nThe DC-X and DC-XA Experience and Its Influence on the X-34\nAt first glance it might seem that the X-34 had little in common with the \nVTOL DC-X and DC-XA Clipper Graham.  One was, effectively, a low-speed \ntakeoff-and-landing demonstrator, and the other was a potential Mach 8 hyper\xad\nsonic boost-glider.  In fact, however, Orbital benefited from the experience that \nMcDonnell Douglas had with the DC-X/DC-XA, for it had demonstrated that \n', 'The SSTO/RLV program was \ncommitted to the development of new operations and component technolo\xad\ngies, as well as the establishment of an industry-Government relationship \ndesigned to bring significant changes to the space launch industry.\n This program included three separate experimental vehicle programs:\n1.\t the Delta Clipper–Experimental Advanced (DC-XA, an outgrowth \nof the DC-X),\n2.\t the X-33 Advanced Technology Demonstrator, and\n3.\t the X-34.\n Over its evolution, the X-34 progressed from an initial two-phase program \n(the proposed X-34A and X-34B) into a final “downsized” Orbital Sciences \nX-34 Technology Testbed Demonstrator (X-34 TTD), ultimately pursued by \nNASA.  These distinctions between variants are important to make, and unless \notherwise stated, the discussion in this chapter is primarily on the initial two-\nphase X-34A/B concept for the X-34, and not the “ultimate” X-34 TTD, which \nis discussed subsequently.1\nIn addressing the historical context of this “next generation” of both military \nand research X-planes (including the X-33 and X-34), noted aviation editor \nGeorge C. Larson wrote in the Smithsonian Institution’s prestigious Air and \n', 'The \nfirst option had the advantage of eliminating the need to refit the propulsion \nsystem back to the Fastrac engine, thus resulting in significant cost savings.  The \nsecond option had the advantage of solving the scheduling problem associated \nwith the Fastrac engine, while retaining the capability to integrate the Fastrac \nengine into the X-34 at a later date.  Both options were based on the assumption \nthat the MA-5A engine could be delivered by June 1, 1998.  The study took into \naccount the fact that the main engine affects almost all vehicle disciplines on the \nX-34, including its structures, main propulsion system, guidance-navigation \nand control, avionics, hydraulics, thermal protection system, and operations. \n The study indicated that the X-34 would require a number of modifications \nin order to accommodate both engines, listed below. \n •\t Engine interface.  The two engines had greatly differing interface \nrequirements (the connection of the engine to the airframe struc\xad\nture). ', 'This plan evolved when only two test flights were planned for the X-34.  With \nthe planned addition of 25 more flights, the plan changed to favor Edwards \nfor the both the preliminary testing and for the developmental testing with \nsome testing still planned for Kennedy.  Dryden’s David Bushman, one of the \nCenter’s X-34 managers, noted that the Center had been trying to get the X-34 \nflight testing, invoking its X-15 legacy and that the X-34 was like an X-15 but \nwithout a pilot.  Bushman pointed out that despite each having a different \nmission—the X-15 was developed to initially explore the hypersonic flight \nenvelope, while the X-34 was intended to examine how to reduce launch costs \nand to test new technologies for reusable launch vehicles—the X-15 and X-34 \nwere similar in shape, size, and capabilities.  He noted an additional advantage \nof flight-testing at Edwards AFB was that the X-34 could use the same flight \ntrack already planned for the X-33.25\nIn commenting on the problems at Holloman AFB, Aviation Week & Space \nTechnology’s Joseph C. Anselmo noted that\nsome program officials are secretly delighted because the size \nof the test range at Holloman would have limited the X-34 to \nspeeds of Mach 2.5–3.  Flying out of Edwards, the vehicle could \nbe dropped over the Groom Lake test range in Nevada, enabling \nit to achieve peak [Mach 8.0] speed before being moved to Florida \nfor weather-related tests.26 \nCommenting further on the dispute over using Dryden versus White Sands, \nBushman noted that “[w]e here at Dryden with our experience with the X-15 \nand X-33…this is what we do.”27 X-plane flight-testing at Dryden appeared to \nbe confirmed by NASA Administrator Daniel S. Goldin, during his April 2000 \nvisit to Dryden, saying that, “Dryden needs to be the place to test X-planes… \n[and] there should be no ambiguity any longer…if it involves flight, Dryden \nneeds to be involved from the beginning.”28 \nThe A-2 vehicle, which was originally planned to be used in New Mexico, \nwas now planned to be shipped to NASA’s Kennedy Space Center for a second \nset of flight tests.  It was hoped that these tests, which were planned to reach \nspeeds of approximately Mach 4.5, would demonstrate rapid turnaround flight \noperations as well as the capability to make crosswind landings and fly through \nrain. ']","

The X-34 is a reusable launch vehicle developed by NASA and Orbital Sciences Corporation in the late 1990s and early 2000s. It was designed to test new technologies for future spacecraft, including autonomous flight control, lightweight materials, and advanced propulsion systems. The X-34 was a significant step forward in the field of aerospace engineering as it aimed to reduce the cost and time required for space missions.

Here are some examples of related studies and papers concerning the X-34:

1. Anderson, David M. (2000). ""NASA's Integrated Space Transportation Plan."" Presented at the 36th AIAA/ASME/SAE/ASEE Joint Propulsion Conference and Exhibit, Huntsville, AL, July 16–19, 2000. AIAA 2000-3828.
	* This paper discusses NASA's Integrated Space Transportation Plan, which includes the X-34 as a technology demonstrator for reusable launch vehicles.
2. Ballard, Richard O., and Tim Olive (2000). ""Development Status of the NASA MC-1 (Fastrac) Engine."" Presented at the 36th AIAA/ASME/SAE/ASEE Joint Propulsion Conference and Exhibit, Huntsville, AL, July 16–19, 2000. AIAA 2000-3898.
	* This study focuses on the development of the MC-1 (Fastrac) engine, which was intended for use in the X-34.
3. Berry, Scott A., et al. (1998). ""X-34 Experimental Aeroheating at Mach 6 and 10."" Presented at the 36th AIAA Aerospace Sciences Meeting and Exhibit, Reno, NV, January 12–15, 1998. AIAA 98-0881. Reprinted in Journal of Spacecraft and Rockets 36, no. 2 (March–April 1999); also issued as NASA TM 98-207319 (1998).
	* This paper investigates the aeroheating experienced by the X-34 during high-speed flights at Mach 6 and 10.
4. Blades, Eric L., et al. (1999). ""Aeroelastic Analysis of the X-34 Launch Vehicle."" Presented at the 40th Structures, Structural Dynamics, and Materials Conference and Exhibit, St. Louis, MO, April 12–15, 1999. AIAA 99-1352.
	* This study examines the aeroelastic characteristics of the X-34 launch vehicle, which is crucial for understanding its structural behavior during flight.
5. Brauckmann, Gregory J. (1998). ""X-34 Vehicle Aerodynamic Characteristics."" Presented at the AIAA 16th Applied Aerodynamics Conference, Albuquerque, NM, June 15–18, 1998. AIAA 98-2531. Reprinted in Journal of Spacecraft and Rockets 36, no. 2 (March–April 1999).
	* This paper discusses the aerodynamic characteristics of the X-34 vehicle, which are essential for predicting its performance and stability during flight.
6. Brown, Andrew M. (2000). ""Temperature Dependent Modal Test/Analysis Correlation of X-34 Composite Rocket Nozzle."" Presented at the 41st Structures, Structural Dynamics, and Materials Conference and Exhibit, Atlanta, GA, April 3–6, 2000. AIAA 2000-1741.
	* This study focuses on the temperature-dependent modal test/analysis correlation of the X-34 composite rocket nozzle, which is important for understanding the nozzle's structural behavior under various temperature conditions.

These studies and papers demonstrate the significance of the X-34 in aerospace engineering and the various aspects of its design and performance that researchers have investigated."
What is the purpose of the MESSENGER mission to Mercury?,"The MESSENGER mission to Mercury was launched by NASA in 2004 with the primary goal of studying the geology, magnetic field, and chemical composition of the planet. It was the first spacecraft to orbit Mercury after Mariner 10, more than 30 years before. The mission team significantly expanded the envelope of engineering practice, with the first operational demonstration of solar sailing using a large kite-like object to capture the solar wind. During its operation between reaching Mercury orbit on 17 March 2011 and the end of the program on 30 April 2015, MESSENGER's science team found a number of surprising results, including flooding and explosive volcanism in early Mercury history, contraction of planetary geology on a global scale, a magnetic dipole aligned with the planet's spin axis, 60 to 70 percent iron contained in the planet's interior, and compelling support for the hypothesis that Mercury harbors abundant water ice and other frozen volatile materials in its permanently shadowed polar craters.","['Credit: \nNASA/Johns Hopkins University Applied Physics Labora\xad\ntory/Carnegie Institution of Washington\nScientific Instruments:\n1.\t  Mercury dual imaging system (MDIS)\n2.\t gamma-ray spectrometer (GRS)\n3.\t neutron spectrometer (NS)\n4.\t x-ray spectrometer (XRS)\n5.\t magnetometer (MAG)\n6.\t  Mercury laser altimeter (MLA)\n7.\t  Mercury atmospheric and surface composi\xad\ntion spectrometer (MASCS)\n8.\t energetic particle and plasma spectrometer \n(EPPS)\n9.\t radio science experiment (RS)\nResults: MESSENGER (Mercury Surface, Space \nEnvironment, Geochemistry, and Ranging) was \nthe seventh Discovery-class mission, and the first \nspacecraft to orbit Mercury.  Its primary goal was \nto study the geology, magnetic field, and chemical \ncomposition of the planet.  It was the first mis\xad\nsion to Mercury after Mariner 10, more than 30 \nyears before.  MESSENGER was launched into \nan initial parking orbit around Earth after which \nits PAM-D solid motor fired to put the spacecraft \non an escape trajectory into heliocentric orbit at \n0.92 × 1.08 AU and 6.4° inclination to the eclip\xad\ntic. ', 'If so, micro\xad\norganisms might still be living beneath Mars’s polar caps or in subterranean \nhot springs warmed by vents from the Martian core.  Scientists are quick to \nadd, however, that these are unproven theories for which evidence has not yet \nbeen\xa0discovered. \n Orbiting Mercury\nWhile other spacecraft had flown briefly in the vicinity of Mercury, the closest \nplanet to the Sun, not until 2004 did NASA launch the first mission to orbit \nand take a full measure of readings about the planet.  Following a trajectory that \nrequired six planetary flybys, six propulsive maneuvers, and about six and a half \nyears, MESSENGER (an acronym for MErcury Surface, Space ENvironment, \nGEochemistry, and Ranging) reached that sweltering terrestrial planet.  The \nmission team significantly expanded the envelope of engineering practice, with \nthe first operational demonstration of solar sailing using a large kite-like object \nto capture the solar wind. \n Prior to the MESSENGER mission, Mercury was poorly understood, \nbut as the nearest planet to the Sun and the smallest of the four rocky plan\xad\nets—Mercury, Venus, Earth, and Mars—it offered a critical anchor point \nfor understanding the solar system.  During its operation between reaching \nMercury orbit on 17 March 2011 and the end of the program on 30 April 2015, \nMESSENGER’s science team found a number of surprising results, including \nflooding and explosive volcanism in early Mercury history, contraction of plan\xad\netary geology on a global scale, a magnetic dipole aligned with the planet’s spin \naxis, 60 to 70 percent iron contained in the planet’s interior, and compelling \nsupport for the hypothesis that Mercury harbors abundant water ice and other \nfrozen volatile materials in its permanently shadowed polar craters. \n', '171\nMESSENGER: AN AMAZING CONCEPT\nThe MErcury Surface, Space ENvironment, GEochemistry, and Ranging spacecraft, \nor MESSENGER, was, without a doubt, the most ambitious mission ever selected in \nthe Discovery Program.\n It was the second effort to get such a Mercury mission going.  An earlier, $257 mil\xad\nlion (in Fiscal Year 1996 dollars) proposal was selected for a concept study but was \nnot selected for flight.  When it was proposed again in 1998, the price had increased to \n$286 million (Fiscal Year 1998 dollars) with a few significant upgrades to the instru\xad\nments, namely: the gamma ray spectrometer became the Gamma Ray and Neutron \nSpectrometer (GRNS), and the energetic particle spectrometer became an energetic \nparticle and plasma spectrometer.\n', 'If not, they would run the baseline plan from \nthat point to the end of the mission to fill in the missing observations—things that \nthey knew they would want to observe again but weren’t yet sure what those things \nwere.  To do such planning, they used a tool called SciBox developed at the Applied \nPhysics Laboratory and used on the Cassini orbiter at Saturn, the Mars Reconnaissance \nOrbiter, and other missions.  It was the first time the software was ever used to coor\xad\ndinate the measurements of a full payload of seven instruments.89 (They did not use \nSciBox for any of the flybys because there was still ample time to do it by hand and \nbecause SciBox was still in development.)\n MESSENGER entered Mercury’s orbit on 18 March 2011, kicking off its first year of \nobservations.90 During orbital insertion, four hundred members of the MESSENGER \nteam, and friends, met at the Kossiakoff Auditorium at APL for the milestone event \nin space exploration.  Addressing the crowd, Ed Weiler said: “I remember the day \nwe selected this mission….  That was 12 years ago.... It’s 12 years from PowerPoint \nto Mercury.”91\nAt 9:10 p.m., the Mission Operations Control Center received word from the \nspacecraft that the maneuver was a success.92 Sean Solomon, the mission Principal \nInvestigator, rejoiced at the time: “This is when the real mission begins.”93\nTHE 2000 AO: BE BOLD, TAKE RISKS\nOn 19 May 2000, NASA released the fourth Discovery Announcement of Opportunity \nwith a cost cap of $299 million.  The AO expanded the program and added new require\xad\nments. ', 'These data betrayed some surprises: among them the discovery \nthat plate tectonics was at work on Venus and that lava flows clearly showed the \nevidence of volcanic activity.  In 1993, at the end of its mission, scientists turned \ntheir attention to a detailed analysis of Magellan’s data. \n More recently, one NASA probe to Jupiter—Galileo—flew by Venus on a \ngravity-assist trajectory, collecting scientific data during its encounter, as did \nCassini-Huygens with two flybys en route to Saturn.  Lastly, MESSENGER \n(standing for MErcury Surface, Space ENvironment, GEochemistry, and \nRanging) made two flybys of Venus en route to Mercury.  In October 2006, \nand again in June 2007, MESSENGER passed behind Venus in a blind flyby. \n Figure 7-1.  Successful NASA missions to Venus.\n']","
The MESSENGER mission to Mercury aims to answer various questions about the planet, such as its high density, magnetic field, and unknown core size and composition. The mission also seeks to determine Mercury's original composition and its evolution. Additionally, MESSENGER will investigate the possibility of an unexpected material, such as frozen water ice, comet-delivered sulfur, or silicates, hidden in the dark crevices at the poles. The mission's instrument payload includes the Mercury Dual Imaging System, a Gamma Ray and Neutron Spectrometer, an X-Ray Spectrometer, a magnetometer, the Mercury Laser Altimeter, the Mercury Atmospheric and Surface Composition Spectrometer, and an Energetic Particle and Plasma Spectrometer, along with a radio science investigation."
"What is the primary objective of the MESSENGER mission to Mercury, as indicated in the provided context information?","The primary objective of the MESSENGER mission to Mercury, as indicated in the provided context information, is to orbit and take a full measure of readings about the planet, which was poorly understood prior to the mission. The mission team found a number of surprising results, including flooding and explosive volcanism in early Mercury history, contraction of planetary geology on a global scale, a magnetic dipole aligned with the planet’s spin axis, 60 to 70 percent iron contained in the planet’s interior, and compelling support for the hypothesis that Mercury harbors abundant water ice and other frozen volatile materials in its permanently shadowed polar craters.","['The decision to end the \nmission was predicated on the fact that the comet \nwas heading out beyond the orbit of Jupiter again, \nand thus, there would be little power to operate \nthe spacecraft.  Confirmation of final impact \narrived at Darmstadt at 11:19:37 UT on \n30\xa0 September 2016, thus ending one of ESA’s \nmost successful planetary missions.  Besides col\xad\nlecting a vast amount of data on the properties of \nthe comet, including its interior, surface and sur\xad\nrounding gas, dust, and plasma, Rosetta’s key find\xad\nings include the discovery of water vapor in comet \n67P/G-C (vapor that is significantly different from \nthat found on Earth), the detection of both molec\xad\nular nitrogen and molecular oxygen for the first \ntime at a comet, the existence of exposed water ice \non the comet’s surface, and the discovery of amino \nacid glycine (commonly found in proteins) and \nphosphorus (a component of DNA and cell mem\xad\nbranes) in the comet.\n 206\nMESSENGER\nNation: USA (84)\nObjective(s): Mercury orbit\nSpacecraft: MESSENGER\nSpacecraft Mass: 1,107.9 kg\nMission Design and Management: NASA / APL\nLaunch Vehicle: Delta 7925H (no.  D307)\nLaunch Date and Time: 3 August 2004 / 06:15:57 UT\nLaunch Site: Cape Canaveral Air Force Station / \nSLC-17B\n', 'If so, micro\xad\norganisms might still be living beneath Mars’s polar caps or in subterranean \nhot springs warmed by vents from the Martian core.  Scientists are quick to \nadd, however, that these are unproven theories for which evidence has not yet \nbeen\xa0discovered. \n Orbiting Mercury\nWhile other spacecraft had flown briefly in the vicinity of Mercury, the closest \nplanet to the Sun, not until 2004 did NASA launch the first mission to orbit \nand take a full measure of readings about the planet.  Following a trajectory that \nrequired six planetary flybys, six propulsive maneuvers, and about six and a half \nyears, MESSENGER (an acronym for MErcury Surface, Space ENvironment, \nGEochemistry, and Ranging) reached that sweltering terrestrial planet.  The \nmission team significantly expanded the envelope of engineering practice, with \nthe first operational demonstration of solar sailing using a large kite-like object \nto capture the solar wind. \n Prior to the MESSENGER mission, Mercury was poorly understood, \nbut as the nearest planet to the Sun and the smallest of the four rocky plan\xad\nets—Mercury, Venus, Earth, and Mars—it offered a critical anchor point \nfor understanding the solar system.  During its operation between reaching \nMercury orbit on 17 March 2011 and the end of the program on 30 April 2015, \nMESSENGER’s science team found a number of surprising results, including \nflooding and explosive volcanism in early Mercury history, contraction of plan\xad\netary geology on a global scale, a magnetic dipole aligned with the planet’s spin \naxis, 60 to 70 percent iron contained in the planet’s interior, and compelling \nsupport for the hypothesis that Mercury harbors abundant water ice and other \nfrozen volatile materials in its permanently shadowed polar craters. \n', 'Chapter 5: Breaking the Bank\n175\nThe 2001 selection of MESSENGER for flight promised to advance Mercury sci\xad\nence immeasurably.  NASA had not sent a spacecraft to Mercury since Mariner 10 in \n1974.14 Robert Strom, a professor emeritus at the University of Arizona Lunar and \nPlanetary Laboratory, had been lobbying for a return to Mercury since NASA’s last \nforay there.15 He became a co-investigator on MESSENGER.  Much earlier, he in fact \nserved on Mariner 10 as deputy team leader for the imaging experiment.  “Mariner 10 \nwas a mission that was designed as a reconnaissance of Mercury in order to characterize \nit to plan a Mercury orbiter,” he said.  “That orbiter was supposed to be planned and \nlaunched by about 1980.  Well, it’s been 30 years.”16\nAs Sean Solomon, the MESSENGER PI, said, “For nearly 30 years, we’ve had ques\xad\ntions that couldn’t be answered until technology and mission designs caught up with \nour desire to go back to Mercury.... Now we are ready.”17 A mission to Mercury had been \nstudied by both the Jet Propulsion Laboratory and Goddard Space Flight Center, but \nthe costs in every case precluded its execution.  The Mercury Dual Orbiter, a Goddard \nconcept and the last studied by the planetary program, came in at around $700 mil\xad\nlion. ', 'Located in the “MESSENGER” file, \nNASA Historical Reference Collection, History Division, NASA Headquarters, Washington, DC.\n 38 \t\nMcNutt, R. L., Solomon, S. C., Gold, R. E., & Leary, J. C.  (2006).  “The MESSENGER mission \nto Mercury: Development history and early mission status.” Mercury, Mars and Saturn, 38(4), \n564–571.  https://doi.org/10.1016/j.asr.2005.05.044.\n 39 \t\nIbid.\n 40 \t\nNiebur, S. ', '171\nMESSENGER: AN AMAZING CONCEPT\nThe MErcury Surface, Space ENvironment, GEochemistry, and Ranging spacecraft, \nor MESSENGER, was, without a doubt, the most ambitious mission ever selected in \nthe Discovery Program.\n It was the second effort to get such a Mercury mission going.  An earlier, $257 mil\xad\nlion (in Fiscal Year 1996 dollars) proposal was selected for a concept study but was \nnot selected for flight.  When it was proposed again in 1998, the price had increased to \n$286 million (Fiscal Year 1998 dollars) with a few significant upgrades to the instru\xad\nments, namely: the gamma ray spectrometer became the Gamma Ray and Neutron \nSpectrometer (GRNS), and the energetic particle spectrometer became an energetic \nparticle and plasma spectrometer.\n']","
The primary objective of the MESSENGER mission to Mercury, as indicated in the provided context information, is to answer questions about Mercury's high density, magnetic field, unknown core size and composition, geology, and the presence of an unexpected material in its polar craters. The mission aims to determine the planet's original composition and its evolution, as well as to distinguish between different hypotheses regarding the planet's formation and history. The MESSENGER spacecraft carries various instruments, including the Mercury Dual Imaging System, a Gamma Ray and Neutron Spectrometer, an X-Ray Spectrometer, a magnetometer, the Mercury Laser Altimeter, the Mercury Atmospheric and Surface Composition Spectrometer, and an Energetic Particle and Plasma Spectrometer, to achieve these objectives."
What are vortex filaments and how do they relate to the circulation theorem in fluid dynamics?,"Vortex filaments are a concept in fluid dynamics that refers to a continuous line of fluid particles that rotate around an axis. According to the theorem of Helmholtz, which is discussed in the given text, the particles of a fluid that belong to a vortex filament at any instant will continue to form its boundary, and the strength of a vortex filament throughout its extent and for all time has the same value. This theorem is important because it allows for the calculation of the velocity at any point in the space by means of a known distribution of the rotation. The circulation theorem in fluid dynamics states that the circulation around any closed line is equal to the algebraic sum of the vortex strengths of all the filaments which cross a surface having the closed line as its boundary. This theorem is crucial because it allows for the calculation of the circulation around any closed line, which is an important parameter in fluid dynamics.","['Thus we have \nobtained the theorems of Helmholtz, which now can be expressed as follows, call\xad\ning the contents of a vortex tube a “vortex filament”: “The particles of a fluid which \nat any instant belong to a vortex filament always remain in it; the strength of a vor\xad\ntex filament throughout its extent and for all time has the same value.” From this \nfollows, among other things, that if a portion of the filament is stretched, say, to \ndouble its length, and thereby its cross section made one-half as great, then the rota\xad\ntion is doubled, because the strength of the vortex, the product of the rotation and \nthe cross section, must remain the same.  We arrive, therefore, at the result that the \nvector expressing the rotation is changed in magnitude and direction exactly as the \ndistance between two neighboring particles on the axis of the filament is changed.\n 8.  From the way the strengths of vortices have been defined it follows for a \nspace filled with any arbitrary vortex filaments, as a consequence of a known theo\xad\nrem of Stokes, that the circulation around any closed line is equal to the algebraic \nsum of the vortex strengths of all the filaments which cross a surface having the \nclosed line as its boundary.  If this closed line is in any way continuously changed \nso that filaments are thereby cut, then evidently the circulation is changed, accord\xad\ning to the extent of the strengths of the vortices which are cut.  Conversely we may \nconclude from the circumstance that the circulation around a closed line (which \nnaturally can not be a fluid line) is changed by a definite amount by a certain dis\xad\nplacement, that by the displacement vortex strength of this amount will be cut, or \nexpressed differently, that the surface passed over by the closed line in its displace\xad\nment is traversed by vortex filaments whose strengths add up algebraically to the \namount of the change in the circulation.\n The theorems concerning vortex motion are specially important because in \nmany cases it is easier to make a statement as to the shape of the vortex filaments \nthan as to the shape of the stream lines, and because there is a mode of calculation \nby means of which the velocity at any point of the space may be determined from \na knowledge of the distribution of the rotation. ', 'From the way the strengths of vortices have been defined it follows for a \nspace filled with any arbitrary vortex filaments, as a consequence of a known theo\xad\nrem of Stokes, that the circulation around any closed line is equal to the algebraic \nsum of the vortex strengths of all the filaments which cross a surface having the \nclosed line as its boundary.  If this closed line is in any way continuously changed \nso that filaments are thereby cut, then evidently the circulation is changed, accord\xad\ning to the extent of the strengths of the vortices which are cut.  Conversely we may \nconclude from the circumstance that the circulation around a closed line (which \nnaturally can not be a fluid line) is changed by a definite amount by a certain dis\xad\nplacement, that by the displacement vortex strength of this amount will be cut, or \nexpressed differently, that the surface passed over by the closed line in its displace\xad\nment is traversed by vortex filaments whose strengths add up algebraically to the \namount of the change in the circulation.\n The theorems concerning vortex motion are specially important because in \nmany cases it is easier to make a statement as to the shape of the vortex filaments \nthan as to the shape of the stream lines, and because there is a mode of calculation \nby means of which the velocity at any point of the space may be determined from \na knowledge of the distribution of the rotation.  This formula, so important for us, \nmust now be discussed.  If Γ is the strength of a thin vortex filament and ds an ele\xad\nment of its medial line, and if, further, r is the distance from the vortex element to \na point P at which the velocity is to be calculated, finally if α is the angle between \nds and r, then the amount of the velocity due to the vortex element is\n\tEquation 6: d v equals Gamma d s sin alpha over 4 pi r squared\nEquation 6: d v equals Gamma d s sin alpha over 4 pi r squaredEquation 6: d v equals Gamma d s sin alpha over 4 pi r squaredΓ ds sin α\n4 π r2 E\t\nquation 6: d v equals Gamma d s sin alpha over 4 pi r squared\nthe direction of this contribution to the velocity is perpendicular to the plane of \nds and r. The total velocity at the point P is obtained if the contributions of all the \nvortex elements present in the space are added.  The law for this calculation agrees \n', 'The Wind and Beyond, Volume III\n230\nparticles of the fluid which at any one time have formed the boundary of a vortex \ntube will continue to form its boundary.  From the consideration of the circulation \nalong a closed line enclosing the vortex tube, we see that this circulation—i.e., \nthe strength of our vortex tube—has the same value at all times.  Thus we have \nobtained the theorems of Helmholtz, which now can be expressed as follows, call\xad\ning the contents of a vortex tube a “vortex filament”: “The particles of a fluid which \nat any instant belong to a vortex filament always remain in it; the strength of a vor\xad\ntex filament throughout its extent and for all time has the same value.” From this \nfollows, among other things, that if a portion of the filament is stretched, say, to \ndouble its length, and thereby its cross section made one-half as great, then the rota\xad\ntion is doubled, because the strength of the vortex, the product of the rotation and \nthe cross section, must remain the same.  We arrive, therefore, at the result that the \nvector expressing the rotation is changed in magnitude and direction exactly as the \ndistance between two neighboring particles on the axis of the filament is changed.\n 8.  From the way the strengths of vortices have been defined it follows for a \nspace filled with any arbitrary vortex filaments, as a consequence of a known theo\xad\nrem of Stokes, that the circulation around any closed line is equal to the algebraic \nsum of the vortex strengths of all the filaments which cross a surface having the \nclosed line as its boundary. ', '231\nDocument 5-17 (a–c)\nthen exactly with that of Biot-Savart, by the help of which the magnetic field due \nto an electric current is calculated.  Vortex filaments correspond in it to the electric \ncurrents, and the vector of the velocity to the vector of the magnetic field.\n As an example we may take an infinitely long straight vortex filament.  The \ncontributions to the velocity at a point P are all in the same direction, and the total \nvelocity can be determined by a simple integration of equation (6).  Therefore this \nvelocity is\n\tEquation: Contact author for details\nEquation: Contact author for detailsEquation: Contact author for details Γ\n4π \n–∞∙\n+∞\nds · sin α\nr2 \nAs seen by figure 4, s = h ctg α, and by differentiation, d s = minus h divided by sin squared alpha, times d alphad s = minus h divided by sin squared alpha, times d alpha\nh\nsin2 αd s = minus h divided by sin squared alpha, times d alphad s = minus h divided by sin squared alpha, times d alpha. ', 'As an example we may take an infinitely long straight vortex filament.  The \ncontributions to the velocity at a point P are all in the same direction, and the total \nvelocity can be determined by a simple integration of equation (6).  Therefore this \nvelocity is\n\tEquation: Contact author for details\nEquation: Contact author for detailsEquation: Contact author for details Γ\n4π \n–∞∙\n+∞\nds · sin α\nr2 \nAs seen by figure 4, s = h ctg α, and by differentiation, d s = minus h divided by sin squared alpha, times d alphad s = minus h divided by sin squared alpha, times d alpha\nh\nsin2 αd s = minus h divided by sin squared alpha, times d alphad s = minus h divided by sin squared alpha, times d alpha.  Further\nr = \nh\nsin α ; so that \n\tEquation 6a: Contact author for details\nEquation 6a: Contact author for detailsEquation 6a: Contact author for details Γ\n4πh \n0∙\nx\nEquation 6a: Contact author for detailsEquation 6a: Contact author for detailsEquation 6a: Contact author for detailsEquation 6a: Contact author for detailsEquation 6a: Contact author for details Γ\n4πh Equation 6a: Contact author for detailsEquation 6a: Contact author for detailsEquation 6a: Contact author for detailsx\n0 Equation 6a: Contact author for details Γ\n2πh \t\nEquation 6a: Contact author for details\nThis result could be deduced in a simpler \nmanner from the concept of circulation if we \nwere to use the theorem, already proved, that \nthe circulation for any closed line coincides \nwith the vortex strength of the filaments which \nare enclosed by it.  The circulation for every \nclosed line which goes once around a single fila\xad\nment must therefore coincide with its strength. \n If the velocity at a point of a circle of radius \nh around our straight filament equals v then this circulation equals a “path\ntimes velocity” = 2πh times v, whence immediately follows v = Γ\n2πh .  The more exact \ninvestigation of this velocity field shows that for every point outside the filament \n(and the formula applies only to such points) the rotation is zero, so that in fact we \nare treating the case of a velocity distribution in which only along the axis does \nrotation prevail, at all other points rotation is not present.\n']","

Vortex filaments are a concept in fluid dynamics that refer to the particles of a fluid which at any one time have formed the boundary of a vortex tube. The circulation theorem states that the circulation, or the strength of the vortex tube, has the same value at all times. This means that if a portion of the filament is stretched, the rotation is doubled, and the vector expressing the rotation is changed in magnitude and direction exactly as the distance between two neighboring particles on the axis of the filament is changed. The circulation theorem also states that the circulation around any closed line is equal to the algebraic sum of the vortex strengths of all the filaments which cross a surface having the closed line as its boundary. This is important because it allows for the calculation of the velocity at any point in the space based on the distribution of the rotation. The formula for this calculation is given by equation (6) in the context, which states that the amount of the velocity due to a vortex element is proportional to the strength of the vortex, the element of its medial line, and the sine of the angle between the element and the distance from the vortex element to the point where the velocity is to be calculated. The total velocity at the point is obtained by adding the contributions of all the vortex elements present in the space."
What is the significance of aerogel in the Stardust mission and what are its unique properties?,"Aerogel is a low-density silicon glass that is 99 percent empty space, with a density of less than 1 percent of that of typical glass. Its unique properties make it an enabling technology for cometary sample return on the Stardust mission. Over 1,000 particles larger than 15 microns were expected to be collected by the spacecraft's aerogel collectors during its encounter with the comet. The material was not invented for Stardust, but its properties were discovered in the 1930s by Samuel Kistler, an instructor at the College of the Pacific. The spacecraft's aerogel collectors would open to collect particles of ancient cometary dust at a crawling relative speed of just 6.1 kilometers per second during the encounter with the comet. The collectors would then close, and the spacecraft would continue its two-year journey back to Earth.","['Its primary goal was to fly by the Comet Wild \n2 (pronounced “vilt 2”), collect samples of dust from \nthe coma of the comet as well as additional interstel\xad\nlar particles, and then return the samples to Earth. \n Stardust comprised a 254-kilogram spacecraft that \nincluded a 45.7-kilogram return capsule shaped \nlike a blunt-nosed cone.  It had five major compo\xad\nnents: a heat shield, back shell, sample canister, \nparachute system, and avionics.  The samples were \nto be collected using a low-density microporous \nsilica-based substance known as aerogel, attached \nto panels on the spacecraft to “soft-catch” and pre\xad\nserve the cometary materials.  The spacecraft was \nlaunched into heliocentric orbit that would bring it \naround the Sun and past Earth for a gravity-assist \nmaneuver to direct it to Wild 2 after a flyby of the \nminor planet Annefrank in November 2002.  After \nmid-course corrections on 28 December 1999, \n18\xa0January, 20\xa0January, and 22\xa0January 2000, its first \ninterstellar dust collection operation was carried \nout between 22\xa0February and 1 May 2000.  After \napproximately a year in heliocentric orbit, Stardust \nflew by Earth (at a range of 6,008 kilometers) on \n15 January 2001 for a gravity assist to send it on a \nsecond sample collection exercise between July and \nDecember 2002. ', 'An optional \nflyby of the asteroid Annefrank would allow testing of the in situ instrument payload \nand the encounter software.  Shortly before the spacecraft flew past Wild\xa02, the aerogel \ncollectors would open to collect particles of ancient cometary dust at a crawling rela\xad\ntive speed of just 6.1 kilometers per second.  The collectors would then close, and the \nspacecraft would continue its two-year journey back to Earth.\n Aerogel—Stardust’s “secret weapon”—is extremely low-density silicon glass that \nis 99 percent empty space, with a density of less than 1 percent of that of typical glass. \n Some members of the team called it “frozen smoke.” According to Brownlee, the PI, \n“Aerogel is only a little bit denser than air.  Sometimes we lay it on the lab table, and \nwe can’t find it.”90\nThe astonishing substance was not invented for Stardust.  The first scientific papers \nannouncing the substance were published in 1931 and 1932 by Samuel Kistler, an \ninstructor at the College of the Pacific. ', '“There were several physics departments around the world that were actually \nmaking aerogel for these Cherenkov counters,” said Brownlee, “so the word of aerogel \nand its properties was sort of floating around the physics community at some level.”93 \nTsou first encountered the material on a visit to Los Alamos, where he saw a small \npiece on a windowsill and was intrigued with its properties.  In the mid- to late 1990s, \nBrownlee and Tsou came up with ways to fly aerogel in space on the Shuttle.  Larger \ntests, using space station–attached payloads and European missions, soon “indicated \nyou could collect particles at this kind of speed and have them survive intact.  And \nthat’s really the technology that made Stardust possible, finding low-density capsule \nmaterials,” said Brownlee.94\nAerogel proved the enabling technology for cometary sample return on this mis\xad\nsion; over 1,000 particles larger than 15 microns were expected in the 1,000 square \ncentimeters of ultra-fine mesostructure silica aerogel.  Laboratory tests led the scientists \nto expect, among other things, hydrated silicates, noble gases, and organic material \nto be retained during the material’s approximate 6-kilometer-per-second encounter \nwith the comet.95\nThe spacecraft was based on the Lockheed Martin SpaceProbe deep space bus, \nbuilt with flat panels made of thin sheets of graphite over a lightweight aluminum \n“honeycomb” core.  The spacecraft had a minimum of moving parts: one to deploy \nthe sample tray assembly out of the sample return capsule and the NavCam scanning \nmirror for tracking the comet’s nucleus.96 Duxbury described the sample tray assem\xad\n92 \t\nKistler, S.  (1943, February). ', 'team had ever been successful in launching a mission to a comet.  The \nopportunity to propose missions for this new program enticed, but the mission would \nhave to be low-cost, quickly developed, and adhere to a tightly focused science inves\xad\ntigation.  It would be a challenge, but new technology and advances in development \nmethodology and cometary understanding made this audacious goal possible for the \nfirst time.  In the years following the earlier, rejected proposals, four major new tech\xad\nnological advances had been made across industry and academia that would enable a \nrealistic mission that included both interstellar and cometary sample return paradigms: \nnamely, the development of an intact particle capture technology called aerogel; a \nlow-energy sample return trajectory that could match a comet’s velocity to just over \n6 kilometers per second using minimal fuel for velocity changes (thereby enabling \nthe use of a smaller spacecraft that could be launched by a Discovery-friendly Boeing \nDelta II rocket); the identification of micron-sized interstellar grains currently enter\xad\ning the solar system with the neutral interstellar helium gas (as seen by dust detectors \non Ulysses and Galileo); and dramatic improvements in analytical instrumentation \nfor determining the isotopic, mineralogical, elemental, and chemical compositions of \nmicron-sized grains or their components.48\nWhile development on the nascent mission concept called Stardust had been targeted \nto return fresh interstellar grains, the plan was modified in 1994 to study and return \nboth “fresh” interstellar grains recently injected into the interstellar medium and ancient \ninterstellar grains and nebular condensates frozen in comets.  The highly experienced \nStardust team had flown instruments on other U.S.  and international missions, and \ntheir plans employed flight spares from JPL’s stores wherever possible.  The team drew \non the rich heritage of cometary encounter and sample return mission concepts as \nthey attempted a straightforward mission concept—“bring the comet home”—for a \nbargain-basement price. ', 'Chapter 2: Big Dreams\n71\nKistler licensed aerogel to Monsanto Corp.  in the early 1940s.  The company described \nit as a “light, friable, slightly opalescent solid containing as much as 95 percent air vol\xad\nume,” created by replacing the water in a special silica gel with alcohol and heating the \nmaterial to 550 degrees F under a constant pressure, and then dropping the pressure to \n20 inches of mercury for 10 minutes.  The process is called supercritical fluid drying.92\nAerogel was used for different coating and detector experiments in the years before \nStardust.  “There were several physics departments around the world that were actually \nmaking aerogel for these Cherenkov counters,” said Brownlee, “so the word of aerogel \nand its properties was sort of floating around the physics community at some level.”93 \nTsou first encountered the material on a visit to Los Alamos, where he saw a small \npiece on a windowsill and was intrigued with its properties.  In the mid- to late 1990s, \nBrownlee and Tsou came up with ways to fly aerogel in space on the Shuttle.  Larger \ntests, using space station–attached payloads and European missions, soon “indicated \nyou could collect particles at this kind of speed and have them survive intact. ']","
Aerogel is significant in the Stardust mission as it is the material used for collecting interstellar grains and ancient cometary dust. It is referred to as the mission's ""secret weapon"" due to its unique properties. Aerogel is an extremely low-density silicon glass that is 99 percent empty space, with a density of less than 1 percent of that of typical glass. It is so light that it is often compared to frozen smoke. Despite its low density, aerogel is incredibly strong, making it an ideal material for collecting and preserving delicate particles in space. It was not invented specifically for the Stardust mission but was first developed in the 1930s by Samuel Kistler."
"How have measurements in microgravity contributed to understanding the solidification of metals and the Soret effect in colloids, and what are the potential implications for materials science and oil reservoirs? Additionally, how have recent combustion studies on the space station impacted our understanding of low and intermediate temperature fuel chemistry and fire safety in microgravity?","Measurements in microgravity have contributed significantly to understanding the solidification of metals and the Soret effect in colloids. In studies of crystallization of metallic alloys, different growth patterns and evolution of microstructures have helped us to better understand the physical principles that govern solidification. These structures play a critical role in the physical properties and behavior of metallic products, and data from ISS solidification of metal alloys have contributed to models that better predict the position of columnar-to-equiaxed transition of metal alloys during the solidification process. In ISS studies of colloids, effects of temperature change on such movement (called the Soret effect) have been measured in the absence of gravity, and thus convection. The results will help us better understand the behaviors of similar components in underground oil reservoirs on Earth.

Recent combustion studies on the space station have opened up new areas of combustion research in space. Cool flames were observed unexpectedly following the radiative extinction of burning fuel droplets, which was not predicted by computational models based on high-temperature chemistry nor expected. This result has implications for low and intermediate temperature fuel chemistry and effects on droplet combustion, with implications for spray combustion and fire safety. Studies of burning solid materials show that when the opposed flow velocity is increased, the flame spread rate first increases and then decreases. This was predicted theoretically but had never before been observed experimentally. Data such as these suggest that microgravity could pose a higher fire risk and a more difficult fire suppression, which would have significant implications for spacecraft fire safety.

Overall, the results of these studies have significant implications for materials science and oil reservoirs, as well as for combustion and fire safety in microgravity.","['Results of \nmaterials tested in the unique electromagnetic levitation \nfurnace on the space station have provided data on a \nwide class of materials such as magnetic, constructive \nand amorphous alloys that can be used in many \npractical applications, including coatings with reduced \nfriction coefficient, high corrosion resistance, strength \nand wear capacity (Krivilyov et al., 2012; Krivilyov and \nFransaer, 2012).  Investigators on the space station \ndiscovered that when melted metals are cooled down \nin extremely low temperatures and kept away from \nsurfaces, such as inside the electromagnetic levitator, \nthe dendrites of crystals grow very fast.  In addition, \na higher concentration of the element in the metal \n(i.e., aluminum) leads to different dendrite growth \ncharacteristics.  These results suggest that \nmeasurements in microgravity are important in \nunderstanding how solidification of metals take \nplace (Fecht et al., 2017).  In studies of crystallization \nof metallic alloys, different growth patterns and \nevolution of microstructures have helped us to better \nunderstand the physical principles that govern \nsolidification.  These structures play a critical role in \nthe physical properties and behavior of metallic \nproducts, and data from ISS solidification of metal \nalloys have contributed to models that better predict \nposition of columnar-to-equiaxed transition of metal \nalloys during the solidification process (Zimmerman \net al., 2017). \n In ISS studies of colloids, where molecules in fluids \nand gases constantly move and collide, effects of \ntemperature change on such movement (called \nthe Soret effect) have been measured in the absence \nof gravity, and thus convection. ', 'These results suggest that \nmeasurements in microgravity are important in \nunderstanding how solidification of metals take \nplace (Fecht et al., 2017).  In studies of crystallization \nof metallic alloys, different growth patterns and \nevolution of microstructures have helped us to better \nunderstand the physical principles that govern \nsolidification.  These structures play a critical role in \nthe physical properties and behavior of metallic \nproducts, and data from ISS solidification of metal \nalloys have contributed to models that better predict \nposition of columnar-to-equiaxed transition of metal \nalloys during the solidification process (Zimmerman \net al., 2017). \n In ISS studies of colloids, where molecules in fluids \nand gases constantly move and collide, effects of \ntemperature change on such movement (called \nthe Soret effect) have been measured in the absence \nof gravity, and thus convection.  One particular \ninvestigation went to space to measure mixtures \nof tetrahydronapthtalene (THN), isobutylbenzene (IBB) \nand n-dodecane (nC12).  Researchers measured the \nseparation of these chemicals, and calculated the \nnumbers for the Soret effect for these chemicals. \n Because the Soret effect occurs in underground \noil reservoirs on Earth, the results will help us better \nunderstand the behaviors of similar components \nin these reservoirs (Mialdun et al., 2018).\n', 'Because the Soret effect occurs in underground \noil reservoirs on Earth, the results will help us better \nunderstand the behaviors of similar components \nin these reservoirs (Mialdun et al., 2018).\n In recent combustion studies on the space station, \ncool flames were observed unexpectedly following \nthe radiative extinction of burning fuel droplets. \n This result was not predicted by computational models \n(based on high-temperature chemistry) nor expected, \nand has opened up new areas of combustion \nresearch in space.  Results such as these can lead to \na better understanding of both low and intermediate \ntemperature fuel chemistry and effects on droplet \ncombustion, with implications for spray combustion \nand fire safety (Nayagam et al., 2015).  Studies of \nburning solid materials show that when the opposed \nflow velocity is increased, the flame spread rate first \nincreases, and then decreases.  This was predicted \ntheoretically but had never before been observed \nexperimentally.  Data such as these suggest that \nmicrogravity could pose a higher fire risk and a more \ndifficult fire suppression, which would have significant \nimplications for spacecraft fire safety (Link et al., 2018).A photo of a flame in space taken during a BASS-II (Burning and Suppression of Solids - II) experiment flame test.\n', 'Results such as these can lead to \na better understanding of both low and intermediate \ntemperature fuel chemistry and effects on droplet \ncombustion, with implications for spray combustion \nand fire safety (Nayagam et al., 2015).  Studies of \nburning solid materials show that when the opposed \nflow velocity is increased, the flame spread rate first \nincreases, and then decreases.  This was predicted \ntheoretically but had never before been observed \nexperimentally.  Data such as these suggest that \nmicrogravity could pose a higher fire risk and a more \ndifficult fire suppression, which would have significant \nimplications for spacecraft fire safety (Link et al., 2018).A photo of a flame in space taken during a BASS-II (Burning and Suppression of Solids - II) experiment flame test.\n Image taken during a BASS-II (Burning and \nSuppression of Solids - II) experiment flame test. \n Image credit: NASA\nControlling the flow of fluids is a challenge in \nmicrogravity, which hampers the design of systems \nsuch as liquid propellants, thermal control and \nwaste-water management.  However, capillary \nforces, which draw fluids up a narrow tube, continue \n', '103\nTransportation Technology\nCombustion science is one of the longest-running fields of research on the International Space Station \n(ISS).  There is a long-running campaign to understand just how both simple and more-complex fuels \nburn in space.  Understanding this process in microgravity helps to refine combustion models on \nEarth where gravity and turbulent buoyancy-driven convection flows make this process too difficult to \nmodel.  Recent observations on the ISS have shown that a phenomenon known as “cool flames” can \nbe witnessed in the combustion chambers in orbit to understand how lower temperature burning could \nhave significant applications toward more efficient fuel use and new combustion engine designs in the \nfuture.  Vehicle docking technology used for the ISS is finding applications in fields where advanced \nsensors and robotics are used for safety improvements. \n Automating a Better Rendezvous \nin Space\nSafe, reliable and affordable commercial access \nfor research aboard the ISS is a critical component \nof the ISS Partnership. ']","

Measurements in microgravity have contributed to understanding the solidification of metals by revealing that when melted metals are cooled down in extremely low temperatures and kept away from surfaces, such as inside the electromagnetic levitator, the dendrites of crystals grow very fast. A higher concentration of the element in the metal leads to different dendrite growth characteristics. These results suggest that measurements in microgravity are important in understanding how solidification of metals take place. In studies of crystallization of metallic alloys, different growth patterns and evolution of microstructures have helped us to better understand the physical principles that govern solidification. These structures play a critical role in the physical properties and behavior of metallic products, and data from ISS solidification of metal alloys have contributed to models that better predict position of columnar-to-equiaxed transition of metal alloys during the solidification process.

In colloids, measurements in microgravity have been used to measure the Soret effect, which is the separation of chemicals in fluids and gases due to temperature change, in the absence of gravity, and thus convection. This has helped researchers better understand the behaviors of similar components in underground oil reservoirs on Earth.

Recent combustion studies on the space station have impacted our understanding of low and intermediate temperature fuel chemistry and fire safety in microgravity. Cool flames were observed unexpectedly following the radiative extinction of burning fuel droplets, which was not predicted by computational models and has opened up new areas of combustion research in space. Results such as these can lead to a better understanding of both low and intermediate temperature fuel chemistry and effects on droplet combustion, with implications for spray combustion and fire safety. Studies of burning solid materials have shown that when the opposed flow velocity is increased, the flame spread rate first increases, and then decreases. This was predicted theoretically but had never before been observed experimentally. Data such as these suggest that microgravity could pose a higher fire risk and a more difficult fire suppression, which would have significant implications for spacecraft fire safety."
"Question: What is the purpose of the follow-on study, Cardiac and Vessel Structure and Function with Long-Duration Space Flight and Recovery (Vascular Echo)?","The purpose of the follow-on study, Cardiac and Vessel Structure and Function with Long-Duration Space Flight and Recovery (Vascular Echo), is to examine changes in blood vessels and the heart while in space and following return to Earth. More specifically, this study will determine how arteries and the heart react to changes in blood pressure, whether blood flow after exercise is changed by spaceflight, and identify warning signs of arterial stiffening in the blood. This study uses ultrasound and blood samples to provide immediate feedback on the development of arterial stiffness and cardiac changes during spaceflight. It explores a potential measure to reduce the excess amount of blood in the upper body by using a leg cuff, and less-complicated ways than ultrasound to measure changes in arterial stiffness.","['Insulin resistance on \nEarth leads to increased blood sugar and increased \nrisk of developing type 2 diabetes.  All these results \nsuggested that the astronauts’ exercise routine was \nnot sufficient to counteract the lifestyle of weightless-\nness and pointed to the need for further work on \nappropriate countermeasures to help maintain \nastronaut health. \n The follow-on study, Cardiac and Vessel Structure and \nFunction with Long-Duration Space Flight and Recovery \n(Vascular Echo), is examining changes in blood vessels \nand the heart while in space and following return \nto Earth.  More specifically, this study will determine \nhow arteries and the heart react to changes in blood \npressure, whether blood flow after exercise is changed \nby spaceflight, and identify warning signs of arterial \nstiffening in the blood.  This study uses ultrasound and \nblood samples to provide immediate feedback on the \ndevelopment of arterial stiffness and cardiac changes \nduring spaceflight.  It explores a potential measure to \nreduce the excess amount of blood in the upper body \nby using a leg cuff, and less-complicated ways than \nultrasound to measure changes in arterial stiffness.\n Finally, a fourth study—The space environment causes \nacceleration of vascular aging: roles of hypogravity, \nnutrition and radiation (Vascular Aging)—will try to \nconfirm if and when insulin resistance, a precursor \nof type 2 diabetes, develops during a space mission, \nclarify the effect of radiation exposure and track the \nrecovery process after return on cardiovascular health.\n', 'All these results \nsuggested that the astronauts’ exercise routine was \nnot sufficient to counteract the lifestyle of weightless-\nness and pointed to the need for further work on \nappropriate countermeasures to help maintain \nastronaut health. \n The follow-on study, Cardiac and Vessel Structure and \nFunction with Long-Duration Space Flight and Recovery \n(Vascular Echo), is examining changes in blood vessels \nand the heart while in space and following return \nto Earth.  More specifically, this study will determine \nhow arteries and the heart react to changes in blood \npressure, whether blood flow after exercise is changed \nby spaceflight, and identify warning signs of arterial \nstiffening in the blood.  This study uses ultrasound and \nblood samples to provide immediate feedback on the \ndevelopment of arterial stiffness and cardiac changes \nduring spaceflight.  It explores a potential measure to \nreduce the excess amount of blood in the upper body \nby using a leg cuff, and less-complicated ways than \nultrasound to measure changes in arterial stiffness.\n Finally, a fourth study—The space environment causes \nacceleration of vascular aging: roles of hypogravity, \nnutrition and radiation (Vascular Aging)—will try to \nconfirm if and when insulin resistance, a precursor \nof type 2 diabetes, develops during a space mission, \nclarify the effect of radiation exposure and track the \nrecovery process after return on cardiovascular health.\n Cardiovascular disease is the number one cause \nof death on Earth, where research has associated \nphysical inactivity with the development of risk factors, \nincluding arterial stiffness and insulin resistance. \n', 'Some results from the study revealed that \ninsulin resistance occurs during spaceflight, possibly \ndue to reduced physical activity.  Insulin resistance on \nEarth leads to increased blood sugar and increased \nrisk of developing type 2 diabetes.  All these results \nsuggested that the astronauts’ exercise routine was \nnot sufficient to counteract the lifestyle of weightless-\nness and pointed to the need for further work on \nappropriate countermeasures to help maintain \nastronaut health. \n The follow-on study, Cardiac and Vessel Structure and \nFunction with Long-Duration Space Flight and Recovery \n(Vascular Echo), is examining changes in blood vessels \nand the heart while in space and following return \nto Earth.  More specifically, this study will determine \nhow arteries and the heart react to changes in blood \npressure, whether blood flow after exercise is changed \nby spaceflight, and identify warning signs of arterial \nstiffening in the blood.  This study uses ultrasound and \nblood samples to provide immediate feedback on the \ndevelopment of arterial stiffness and cardiac changes \nduring spaceflight.  It explores a potential measure to \nreduce the excess amount of blood in the upper body \nby using a leg cuff, and less-complicated ways than \nultrasound to measure changes in arterial stiffness.\n', 'More specifically, this study will determine \nhow arteries and the heart react to changes in blood \npressure, whether blood flow after exercise is changed \nby spaceflight, and identify warning signs of arterial \nstiffening in the blood.  This study uses ultrasound and \nblood samples to provide immediate feedback on the \ndevelopment of arterial stiffness and cardiac changes \nduring spaceflight.  It explores a potential measure to \nreduce the excess amount of blood in the upper body \nby using a leg cuff, and less-complicated ways than \nultrasound to measure changes in arterial stiffness.\n Finally, a fourth study—The space environment causes \nacceleration of vascular aging: roles of hypogravity, \nnutrition and radiation (Vascular Aging)—will try to \nconfirm if and when insulin resistance, a precursor \nof type 2 diabetes, develops during a space mission, \nclarify the effect of radiation exposure and track the \nrecovery process after return on cardiovascular health.\n Cardiovascular disease is the number one cause \nof death on Earth, where research has associated \nphysical inactivity with the development of risk factors, \nincluding arterial stiffness and insulin resistance. \n These spaceflight studies provide a platform to explore \npotential mechanisms and help develop interventions \nto slow vascular aging and improve health and quality \nof life for everyone—regardless of whether their hearts \nare free of gravity. \n Dressing Astronauts for Return to Earth\nAstronauts on the ISS perform research with mice \nand spiders, and not a single crew member ever faints. \n', 'Further \nevidence from this study also showed that the elevated \nCO2 exposure could be linked to the vision impairment \nintracranial pressure (VIIP) syndrome (Hughson et al., \n2017).  Studies of astronauts’ core body temperature \nin microgravity during periods of exercise and rest \nhave shown an increase of 1°C, which is significant \nenough to impair physical and cognitive performance \nif not addressed for long-duration exploration missions \nbeyond LEO (Stahn et al., 2017).\n ISS crew members report a variety of neurological \nsymptoms that may be related to changes in cerebral \nvenous outflow.  Studies on blood flow changes using \nplethysmography confirm that long-duration spaceflights \nlead to a redistribution of venous blood volume and \nshow interesting differences in the amplitude of cardiac \noscillations measured at the level of the neck veins. \n Remarkably, the proposed portable system is able to \ndetect cross-sectional area variations of neck veins with \nenough sensitivity to be useful for studies concerning \ncardiac oscillations (Taibi et al., 2017).\n Research has shown that 60% of long-duration \nastronauts (versus 29% of short-duration astronauts) \nexperienced a significant decrease in eyesight \npostflight (i.e., spaceflight-induced ocular syndrome), \naccompanied by changes in the structure of the eye \n(Mader et al., 2011; 2016).  The root cause for the \ndecrease is under investigation; however, studies \nsuggest that the one-carbon metabolic pathway \nand the fluid shifts to the head that lead to increased \nintracranial pressure during spaceflight may play \nsignificant roles (Alperin et al., 2018; Mader et al., 2013; \nMader et al., 2016; Zwart et al., 2012). ']","
The purpose of the follow-on study, Cardiac and Vessel Structure and Function with Long-Duration Space Flight and Recovery (Vascular Echo), is to examine changes in blood vessels and the heart while in space and following return to Earth. This study will determine how arteries and the heart react to changes in blood pressure, whether blood flow after exercise is changed by spaceflight, and identify warning signs of arterial stiffening in the blood. This study uses ultrasound and blood samples to provide immediate feedback on the development of arterial stiffness and cardiac changes during spaceflight. It explores a potential measure to reduce the excess amount of blood in the upper body by using a leg cuff, and less-complicated ways than ultrasound to measure changes in arterial stiffness."
"What was the intended mission of the 1963 Soviet Lunar Probe, and what was the outcome of the mission?","The intended mission of the 1963 Soviet Lunar Probe, designated as Ye-6 (no. 2), was to accomplish a survivable landing on the surface of the Moon. The spacecraft was equipped with a simple 100-kilogram lander capsule called the Automatic Lunar Station (ALS) whose primary objective was to send back photographs from the lunar surface. The outcome of the mission was that the spacecraft was launched by the four-stage 8K78 (Molniya) booster but modified for lunar missions. However, the spacecraft failed to reach the Moon and instead, it entered into an elliptical orbit around the Earth. The Soviets adopted two strategies for such failed missions: between 1960 and 1963, the Soviets simply never admitted their existence, and beginning November 1963, the Soviet media began to give these stranded-in-Earth-orbit spacecraft ""Kosmos"" numbers. In this case, the spacecraft was given the ""next"" Kosmos number, which was ""21."" By giving it such a nondescript name (""Kosmos 21""), Soviet officials sought to draw attention away from such failures.","['33\n1963\n36\n[Luna, \nY\ne-6 no.  2]\nNation: USSR (20)\nObjective(s): lunar soft-landing\nSpacecraft: Ye-6 (no.  2)\nSpacecraft Mass: 1,420 kg\nMission Design and Management: OKB-1\nLaunch Vehicle: Molniya + Blok L (8K78 no. \n T103-09)\nLaunch Date and Time: 4 January 1963 / 08:48:58 UT\nLaunch Site: NIIP-5 / Site 1/5\nScientific Instruments:\n1.\t imaging system\n2.\t gas-discharge counter\nResults: This spacecraft was the first “second gener\xad\nation” Soviet lunar probe (known as Ye-6), designed \nto accomplish a survivable landing on the surface \nof the Moon.  The Ye-6 probes were equipped with \nsimple 100-kilogram lander capsules (called the \nAutomatic Lunar Station or Avtomaticheskaya lun\xad\nnaya stantsiya, ALS) whose primary objective was \nto send back photographs from the lunar surface. \n Each egg-shaped ALS was installed on a roughly \ncylindrical-shaped main bus.  Like the Mars and \nVenera deep space probes, the Ye-6 Luna space\xad\ncraft were also launched by the four-stage 8K78 \n(Molniya) booster but modified for lunar missions. \n', 'Grunt accelerometers\n\t 8.\t Termozond temperature probes\n\t 9.\t Kamerton seismometer\n\t10.\t IMAP-7 magnetometer\nResults: Mars 8, the only Soviet/Russian lunar or \nplanetary probe in the 1990s, was an ambitious \nmission to investigate the evolution of the Martian \natmosphere, its surface, and its interior.  Originally \nplanned as two spacecraft, Mars 94 and Mars 96, \nthe missions were delayed and became Mars 96 \nand Mars 98.  Subsequently Mars 98 was cancelled \nleaving Mars 96 as the first Russian deep space \nmission beyond Earth orbit since the collapse of \nthe Soviet Union.  The entire spacecraft comprised \nan orbiter, two small autonomous stations, and two \nindependent penetrators. ', '49\n1965\u2003\n6.\t magnetometer\n7.\t ion thrusters\n8.\t radio telescope\nResults: This “third generation” deep space probe \nhad originally been slated for a Mars flyby in late \n1964 but could not be prepared on time.  Instead, \nSoviet designers diverted the mission for a simple \nlunar flyby in 1965 to test its basic systems and pho\xad\ntograph the farside of the Moon.  After a successful \ntrans-lunar injection burn, Zond 3 approached the \nMoon after only a 33-hour flight.  Its imaging mis\xad\nsion began at 01:24 hours on 20 July at a range of \n11,600 kilometers from the near side of the Moon \nand completed 68 minutes later.  Zond 3 carried an \nimaging system somewhat similar to the one car\xad\nried on Automatic Interplanetary Station (“Luna \n3”), with onboard exposure, development, fixing, \nand drying prior to scanning for transmission to \nEarth. ', 'Readers will note that I \nhave used this convention for all missions until and \nincluding 1970 but after that switched to Latin \nnumbers (Mariner 9, Mariner 10, etc.).  This divi\xad\nsion is somewhat arbitrary but was necessary not to \nconfuse readers.\n The practice of giving spacecraft “official” \nnames is complicated by the fact that beginning \nwith the launch of Sputnik in 1957 and until the \nlate 1980s, the Soviet Union never announced or \nacknowledged a mission if it failed to reach Earth \norbit.  In addition, for those lunar and planetary \nprobes that did reach Earth orbit but failed to leave \nit, the Soviets adopted two strategies:\n•\t between 1960 and 1963, the Soviets simply \nnever admitted their existence and made no \nannouncement; and\n•\t beginning November 1963, the Soviet media \nbegan to give these stranded-in-Earth-orbit \nspacecraft “Kosmos” numbers.  So, the deep \nspace vehicle launched on 11 November 1963 \nthat reached Earth orbit but failed to leave for \ndeep space was simply given the “next” Kosmos \nnumber, in this case “21.” By giving it such a \nnondescript name (“Kosmos 21”), Soviet offi\xad\ncials sought to draw attention away from such \nfailures.  This practice was followed well into \nthe late 1980s.\n For both of these three types of missions, I have \nused the following convention:\n[Program, Spacecraft design designation, serial \nnumber]\nOR\nKosmos number [Program]\nI do not use terms such as “Marsnik 1” or “Mars \n1960A” (listed in the National Space Science \nData Center, for example, to denote the spacecraft \nlaunched on 10 October 1960). ', 'Despite the formal end of the mission, \nexperiments with the French TL-2 laser reflector \ncontinued for decades, and were much more suc\xad\ncessful than the rangings carried out with the sim\xad\nilar instrument on Lunokhod 1.  At the time of the \nLunokhod 2 mission, scientists calculated a total \ntravel distance of 37.5 kilometers, about three-and-\na-half times more than its predecessor.  An extended \nsummary of the scientific results from the mission \nwas published in Pravda on 20 November 1973. \n The Soviets later revealed that during a conference \non planetary exploration in Moscow held from 29 \nJanuary to 2 February 1973 (i.e., after the land\xad\ning of Luna 21), an American scientist had given \nphotos of the lunar surface around the Luna 21 \nlanding site to a Soviet engineer in charge of the \nLunokhod 2 mission.  These photos, taken prior \nto the Apollo 17 landing, were later used by the \n“driver team” to navigate the new rover on its mis\xad\nsion on the Moon.  Later, in 2013, based on imagery \nfrom the Lunar Reconnaissance Orbiter (LRO), \nRussian researchers led by Irina Karachevtseva at \nthe Moscow State University’s Institute of Geodesy \nand Cartography (MIIGAiK), recalculated the \ntotal distance travelled and came to a more precise \nnumber of between 42.1 and 42.2 kilometers.  The \noriginal landing site location was also sharpened to \n25.99° N / 30.41° E.\n']","
The intended mission of the 1963 Soviet Lunar Probe was to verify key technological systems during a simpler mission into deep space and back to Earth. The spacecraft, named ""Object-Probes"" (ob'yekt-zond), was designed to depart from Earth's ecliptic out to 12-16 million kilometers from Earth and then return back to Earth after about six months when its orbit intersected with that of Earth again. The spacecraft was aided by two mid-course corrections using its S5.45 main engine.

However, the outcome of the mission was not successful. During the mission, the third and fourth stages separated abnormally, and after reaching Earth orbit, ground control lost telemetry from the Blok L upper stage designed to send the vehicle past the Moon. As a result, the spacecraft remained stranded in Earth orbit. The stage's main engine turbopump probably exploded upon ignition, destroying the spacecraft. With this mission, the Soviets began the practice of giving ""Kosmos"" designations to obscure the failure of lunar and planetary probes that remained stranded in Earth orbit. If the spacecraft had successfully departed from Earth orbit, it would probably have been called ""Zond 1."""
What was the impact of the Soviet Union's collapse on the Space Exploration Initiative (SEI) in the United States?,"The collapse of the Soviet Union had a significant impact on the Space Exploration Initiative (SEI) in the United States. The SEI, a multidecade program intended to take astronauts back to the Moon and eventually to Mars, was proposed by President Bush in 1989. However, the White House's strategic goal of cost-conscious innovation conflicted with NASA's plans, which the National Space Council found too expensive. The conflict brought an end to the SEI, but not the White House's strategic goal of cost-conscious innovation. The collapse of the Soviet Union also had an impact on the SEI, as it occurred during the political process of the SEI. The Soviet leader, Mikhail Gorbachev, had embarked on a series of political and economic reforms in 1985 that had been intended to strengthen the nation's destitute economy, but they had the opposite effect. Political freedoms Gorbachev introduced undermined the Communist Party and its hold on the USSR as well as the USSR's hold on the states of Eastern Europe. Cheering crowds dismantled one of the Cold War's greatest symbols, the Berlin Wall, in November 1989 before a shocked American television audience. East and West Germany merged during 1990, and the Soviet Union itself dissolved in December 1991. The new Russian Federation, as the Soviet Union's core state was renamed, did not even retain control of the USSR's old launch facilities at Baikonur, which were in the newly independent state of Kazakhstan. The collapse of the Soviet Union also had an impact on the SEI's budget, as the House Appropriations Committee chose to remove all SEI-related funds from NASA's fiscal year 1991 budget while still allowing an increase in NASA's overall budget. It specifically deleted funding for a Lunar Observer mission and new human missions and launch vehicles.","['In an \nearly sign of trouble, the White House Office of Management and Budget \nreduced NASA’s SEI-related request substantially, although it still allowed \nan increase in the Agency’s budget.  In Congress, however, most agencies \nwere facing cuts, not increases, and NASA was no different.  A White House \n“space summit” convened on 1 May 1990 failed to convince congressional \nleaders that the new initiative was worth funding.  Two more damaging rev\xad\nelations in 1990—that the newly launched Hubble Space Telescope had a flaw \nin its primary mirror and that two of NASA’s four Space Shuttle orbiters had \ndeveloped dangerous hydrogen leaks—hurt the Agency’s technical credibil\xad\nity and political chances.25 \nIt did not help the administration’s case that the SEI, a quintessential \nCold War–era giant space endeavor, happened to be working its way through \nthe political process at the same time that the Soviet Union was collapsing. \n Soviet leader Mikhail Gorbachev had embarked on a series of political and \neconomic reforms in 1985 that had been intended to strengthen the nation’s \ndestitute economy, but they had the opposite effect.  Political freedoms \nGorbachev introduced undermined the Communist Party and its hold on \nthe USSR as well as the USSR’s hold on the states of Eastern Europe.  Cheering \ncrowds dismantled one of the Cold War’s greatest symbols, the Berlin Wall, \nin November 1989 before a shocked American television audience. ', 'In Congress, however, most agencies \nwere facing cuts, not increases, and NASA was no different.  A White House \n“space summit” convened on 1 May 1990 failed to convince congressional \nleaders that the new initiative was worth funding.  Two more damaging rev\xad\nelations in 1990—that the newly launched Hubble Space Telescope had a flaw \nin its primary mirror and that two of NASA’s four Space Shuttle orbiters had \ndeveloped dangerous hydrogen leaks—hurt the Agency’s technical credibil\xad\nity and political chances.25 \nIt did not help the administration’s case that the SEI, a quintessential \nCold War–era giant space endeavor, happened to be working its way through \nthe political process at the same time that the Soviet Union was collapsing. \n Soviet leader Mikhail Gorbachev had embarked on a series of political and \neconomic reforms in 1985 that had been intended to strengthen the nation’s \ndestitute economy, but they had the opposite effect.  Political freedoms \nGorbachev introduced undermined the Communist Party and its hold on \nthe USSR as well as the USSR’s hold on the states of Eastern Europe.  Cheering \ncrowds dismantled one of the Cold War’s greatest symbols, the Berlin Wall, \nin November 1989 before a shocked American television audience.  East and \nWest Germany merged during 1990, and the Soviet Union itself dissolved in \nDecember 1991. ', 'The \nbudget increase did not benefit planetary science, as the direction the White \nHouse wanted to pursue centered on human spaceflight.  White House moti\xad\nvations for pointing NASA in a new direction, though, would have a tremen\xad\ndous impact on planetary science.  The Bush administration wanted NASA \nto operate in a more innovative manner, taking advantage of new technolo\xad\ngies and management concepts to reduce the cost of spaceflight.  To this end, \nPresident Bush proposed the Space Exploration Initiative (SEI), a multide\xad\ncade program intended to take astronauts back to the Moon and eventu\xad\nally to Mars.  At the request of the White House, NASA managers provided \nplans to achieve this new strategic direction,50 but the President’s National \nSpace Council found NASA’s plans too expensive, castigating Administrator \nRichard Truly for not adhering to the goal of using innovative strategies to \ncut costs.51 Conflict between NASA and the White House quickly brought \nan end to the SEI, but not the White House’s strategic goal of cost-conscious \n49.\t  National Academy of Sciences, Astronomy and Astrophysics for the 1970s (Washington, DC: \nThe National Academies Press, 1972). \n 50.\t ', 'Soviet leader Mikhail Gorbachev had embarked on a series of political and \neconomic reforms in 1985 that had been intended to strengthen the nation’s \ndestitute economy, but they had the opposite effect.  Political freedoms \nGorbachev introduced undermined the Communist Party and its hold on \nthe USSR as well as the USSR’s hold on the states of Eastern Europe.  Cheering \ncrowds dismantled one of the Cold War’s greatest symbols, the Berlin Wall, \nin November 1989 before a shocked American television audience.  East and \nWest Germany merged during 1990, and the Soviet Union itself dissolved in \nDecember 1991.  The new Russian Federation, as the Soviet Union’s core state \nwas renamed, did not even retain control of the USSR’s old launch facilities \nat Baikonur, which were in the newly independent state of Kazakhstan.\n In this atmosphere, the House Appropriations Committee chose to \nremove all SEI-related funds from NASA’s fiscal year 1991 budget while still \nallowing an increase in NASA’s overall budget.  It specifically deleted funding \nfor a Lunar Observer mission and new human missions and launch vehicles. \n', 'ESA \nrepresentatives vigorously communicated their position to NASA manage\xad\nment, the U.S.  State Department, and Vice President Al Gore, indicating that \nsuch action by the United States would call into question its reliability as a \npartner in any large scientific or technological endeavors in the future.  The \nEuropeans had some leverage in this tactic, given that the White House was \ncourting ESA involvement in the International Space Station (ISS) effort.64 \nIn its transition from Space Station Freedom to the ISS, the space station pro\xad\ngram had become a U.S.  national priority for distinctly post–Cold War geo\xad\npolitical and national security reasons (primarily due to the collapse of the \nSoviet Union in 1991 and the possibility of Russian involvement in the space \nstation).  ESA considered Cassini-Huygens a priority of its various member \nnations for reasons of international prestige but also for the large project’s \nability to increase the capabilities of member nations’ aerospace industrial \nbase.  In this case, a confluence of national priorities played out on an inter\xad\nnational scale.  In the end, Administrator Goldin acquiesced, and Cassini-\nHuygens continued toward its successful launch in 1997.\n']","
The Soviet Union's collapse had a significant impact on the Space Exploration Initiative (SEI) in the United States. The SEI, a large-scale space project, was being considered in Congress at the same time as the Soviet Union was undergoing major political and economic reforms. The collapse of the Soviet Union and the subsequent dissolution of the USSR in December 1991 led to a shift in priorities and a reduced appetite for large-scale space projects in the United States. As a result, the House Appropriations Committee removed all SEI-related funds from NASA's fiscal year 1991 budget, specifically deleting funding for a Lunar Observer mission and new human missions and launch vehicles. This decision was made despite an overall increase in NASA's budget. The collapse of the Soviet Union and the end of the Cold War likely contributed to the decline in support for the SEI in the United States."
What was the primary objective of the Pioneer Venus 1 mission and what scientific instruments were used to achieve this objective?,"The primary objective of the Pioneer Venus 1 mission was to explore the atmosphere and surface of Venus using a radar package. The spacecraft was designed to spend an extended period in orbit around Venus mapping the surface using a radar package. The scientific instruments used to achieve this objective included a charged particle retarding potential analyzer (ORPA), an ion mass spectrometer (OIMS), a thermal electron temperature Langmuir probe (OETP), a neutral particle mass spectrometer (ONMS), a cloud photopolarimeter (OCPP), a temperature sounding infrared radiometer (OIR), a magnetic field fluxgate magnetometer (OMAG), a solar wind plasma analyzer (OPA), a surface radar mapper (ORAD), an electric field detector (OEFD), a transient gamma ray burst detector (OGBD), a radio occultation experiment, an atmospheric and solar corona turbulence experiment, a drag measurements experiment, and two radio science experiments to determine gravity field.","['147\n1978\n157\nPioneer Venus 1\nNation: USA (60)\nObjective(s): Venus orbit\nSpacecraft: Pioneer Venus Orbiter\nSpacecraft Mass: 582 kg\nMission Design and Management: NASA / ARC\nLaunch Vehicle: Atlas Centaur (AC-50 / Atlas no. \n 5030D)\nLaunch Date and Time: 20 May 1978 / 13:13:00 UT\nLaunch Site: Cape Canaveral / Launch Complex 36A\nScientific Instruments:\n\t 1.\tcharged particle retarding potential ana\xad\nlyzer (ORPA)\n\t 2.\tion mass spectrometer (OIMS)\n\t 3.\tthermal electron temperature Langmuir \nprobe (OETP)\n\t 4.\tneutral particle mass spectrometer (ONMS)\n\t 5.\tcloud photopolarimeter (OCPP)\n\t 6.\ttemperature sounding infrared radiometer \n(OIR)\n\t 7.\tmagnetic field fluxgate magnetometer \n(OMAG)\n\t 8.\tsolar wind plasma analyzer (OPA)\n\t 9.\tsurface radar mapper (ORAD)\n\t10.\telectric field detector (OEFD)\n\t11.\ttransient gamma ray burst detector \n(OGBD)\n\t12.\tradio occultation experiment\n\t13.\tatmospheric and solar corona turbulence \nexperiment\n\t14.\tdrag measurements experiment\n\t15.\t 2 radio science experiments to determine \ngravity field\n\t16.\tultraviolet spectrometer (OUVS)\nResults: Formally approved by NASA in August \n1974, the Pioneer Venus project comprised two \nspacecraft to explore the atmosphere and surface \nof Venus.  Both spacecraft used a basic cylindrical \nbus. ', '5030D)\nLaunch Date and Time: 20 May 1978 / 13:13:00 UT\nLaunch Site: Cape Canaveral / Launch Complex 36A\nScientific Instruments:\n\t 1.\tcharged particle retarding potential ana\xad\nlyzer (ORPA)\n\t 2.\tion mass spectrometer (OIMS)\n\t 3.\tthermal electron temperature Langmuir \nprobe (OETP)\n\t 4.\tneutral particle mass spectrometer (ONMS)\n\t 5.\tcloud photopolarimeter (OCPP)\n\t 6.\ttemperature sounding infrared radiometer \n(OIR)\n\t 7.\tmagnetic field fluxgate magnetometer \n(OMAG)\n\t 8.\tsolar wind plasma analyzer (OPA)\n\t 9.\tsurface radar mapper (ORAD)\n\t10.\telectric field detector (OEFD)\n\t11.\ttransient gamma ray burst detector \n(OGBD)\n\t12.\tradio occultation experiment\n\t13.\tatmospheric and solar corona turbulence \nexperiment\n\t14.\tdrag measurements experiment\n\t15.\t 2 radio science experiments to determine \ngravity field\n\t16.\tultraviolet spectrometer (OUVS)\nResults: Formally approved by NASA in August \n1974, the Pioneer Venus project comprised two \nspacecraft to explore the atmosphere and surface \nof Venus.  Both spacecraft used a basic cylindrical \nbus.  Pioneer Venus 1, the orbiter, was designed to \nspend an extended period in orbit around Venus \nmapping the surface using a radar package.  After \na six-and-a-half-month-long journey, the space\xad\ncraft entered an elliptical orbit around Venus at \n15:58\xa0UT on 4 December 1978.  It was the first \nAmerican spacecraft to enter orbit around Venus, \nabout three years after the Soviets accomplished \nthe same feat.  The initial orbital period was 23 \nhours, 11 minutes, which was altered within two \norbits to the desired 24 hours—a maneuver that \nwould allow the orbit’s high and low points (about \n160 kilometers) to occur at the same time each \nEarth day. ', 'The last transmission was received at \n19:22 UT on 8 October 1992, as its decaying orbit \nno longer permitted communications.  The space\xad\ncraft burned up the atmosphere soon after, ending \na successful 14-year mission that was planned to \nlast only eight months.\n 158\nPioneer Venus 2\nNation: USA (61)\nObjective(s): Venus impact\nSpacecraft: Pioneer Venus Multiprobe\nSpacecraft Mass: 904 kg\nMission Design and Management: NASA / ARC\nLaunch Vehicle: Atlas Centaur (AC-51 / Atlas no. \n 5031D)\nLaunch Date and Time: 8 August 1978 / 07:33 UT\nLaunch Site: Cape Canaveral / Launch Complex 36A\nScientific Instruments:\nSpacecraft Bus:\n1.\t neutral mass spectrometer (BNMS)\n2.\t ion mass spectrometer (BIMS)\nLarge Probe:\n1.\t neutral mass spectrometer\n2.\t solar flux radiometer\n3.\t gas chromatograph\n4.\t infrared radiometer\n5.\t cloud particle size spectrometer\n6.\t nephelometer\nSmall Probes (each):\n1.\t neutral mass spectrometer\n2.\t gas chromatograph\n3.\t solar flux radiometer\n4.\t infrared radiometer\n5.\t cloud particle size spectrometer\n6.\t temperature, pressure, acceleration sensors\n7.\t nephelometerPioneer Project Manager Charlie Hall inspects the Pioneer Venus multiprobe at Hughes Aircraft Co.  in December 1976\nPioneer Project Manager Charlie Hall inspects the Pioneer \nVenus multiprobe at Hughes Aircraft Company in\nDecember 1976.  Credit: NASA/TRW\nResults: Pioneer Venus 2, the twin to Pioneer Venus \n1, comprised a main bus, a Large Probe (316.5 \nkilograms), and three identical Small Probes, all of \nwhich were designed to collect data during inde\xad\npendent atmospheric entry into Venus.  The probes \nwere each shaped like cones and not designed to \nsurvive past surface impact. ', '158\nPioneer Venus 2\nNation: USA (61)\nObjective(s): Venus impact\nSpacecraft: Pioneer Venus Multiprobe\nSpacecraft Mass: 904 kg\nMission Design and Management: NASA / ARC\nLaunch Vehicle: Atlas Centaur (AC-51 / Atlas no. \n 5031D)\nLaunch Date and Time: 8 August 1978 / 07:33 UT\nLaunch Site: Cape Canaveral / Launch Complex 36A\nScientific Instruments:\nSpacecraft Bus:\n1.\t neutral mass spectrometer (BNMS)\n2.\t ion mass spectrometer (BIMS)\nLarge Probe:\n1.\t neutral mass spectrometer\n2.\t solar flux radiometer\n3.\t gas chromatograph\n4.\t infrared radiometer\n5.\t cloud particle size spectrometer\n6.\t nephelometer\nSmall Probes (each):\n1.\t neutral mass spectrometer\n2.\t gas chromatograph\n3.\t solar flux radiometer\n4.\t infrared radiometer\n5.\t cloud particle size spectrometer\n6.\t temperature, pressure, acceleration sensors\n7.\t nephelometerPioneer Project Manager Charlie Hall inspects the Pioneer Venus multiprobe at Hughes Aircraft Co.  in December 1976\nPioneer Project Manager Charlie Hall inspects the Pioneer \nVenus multiprobe at Hughes Aircraft Company in\nDecember 1976.  Credit: NASA/TRW\nResults: Pioneer Venus 2, the twin to Pioneer Venus \n1, comprised a main bus, a Large Probe (316.5 \nkilograms), and three identical Small Probes, all of \nwhich were designed to collect data during inde\xad\npendent atmospheric entry into Venus.  The probes \nwere each shaped like cones and not designed to \nsurvive past surface impact.  After a course correc\xad\ntion on 16 August 1978, Pioneer Venus 2 released \nthe 1.5 diameter Large Probe on 16 November \n1978, while about 11.1 million kilometers from \nthe planet.  Four days later, the bus released the \nthree Small Probes (North, Day, and Night Probes) \nwhile 9.3 million kilometers from Venus. ', '148\nBEYOND EARTH: A CHRONICLE OF DEEP SPACE EXPLORATION, 1958–2016\nband between 74° N and 63° S), it was reactivated \nagain in 1991, 13 years after launch, to explore the \npreviously inaccessible southern portions of the \nplanet.  In May 1992, Pioneer Venus 1 began the \nfinal phase of its mission, maintaining its periapsis \nbetween 150 and 250 kilometers until propellant \ndepletion.  The last transmission was received at \n19:22 UT on 8 October 1992, as its decaying orbit \nno longer permitted communications.  The space\xad\ncraft burned up the atmosphere soon after, ending \na successful 14-year mission that was planned to \nlast only eight months.\n 158\nPioneer Venus 2\nNation: USA (61)\nObjective(s): Venus impact\nSpacecraft: Pioneer Venus Multiprobe\nSpacecraft Mass: 904 kg\nMission Design and Management: NASA / ARC\nLaunch Vehicle: Atlas Centaur (AC-51 / Atlas no. \n']","
The primary objective of the Pioneer Venus 1 mission was to spend an extended period in orbit around Venus mapping the surface using a radar package. The scientific instruments used to achieve this objective were:
1. charged particle retarding potential analyzer (ORPA)
2. ion mass spectrometer (OIMS)
3. thermal electron temperature Langmuir probe (OETP)
4. neutral particle mass spectrometer (ONMS)
5. cloud photopolarimeter (OCPP)
6. temperature sounding infrared radiometer (OIR)
7. magnetic field fluxgate magnetometer (OMAG)
8. solar wind plasma analyzer (OPA)
9. surface radar mapper (ORAD)
10. electric field detector (OEFD)
11. transient gamma ray burst detector (OGBD)
12. radio occultation experiment
13. atmospheric and solar corona turbulence experiment
14. drag measurements experiment
15. 2 radio science experiments to determine gravity field
16. ultraviolet spectrometer (OUVS)"
What is the problem with the helicopter industry?,"The problem with the helicopter industry is that it implodes rather than explodes due to the lack of vision. This is mentioned in the text material from the NASA document ""the wind and beyond tagged"" on page 911.","['(History is repeating itself \ntoday with computers.)  Since that period the rest of the world is rightfully gaining \nan increasing share.  Even so, the wealth of a country is not what it owns, but what \nit produces and exports.\n Without a vision as described above, the worldwide helicopter industry is \ngreater than is the demand for helicopters.  Added to this problem is the large num\xad\nber of military surplus helicopters on the market.  Devoid of vision[,] the industry \nimplodes rather than explodes.  In view of the increasing global interaction and \ninterdependence, people of all nations are questioning their identity and the limits \nof nationalism. ', 'Devoid of vision[,] the industry \nimplodes rather than explodes.  In view of the increasing global interaction and \ninterdependence, people of all nations are questioning their identity and the limits \nof nationalism.  If history teaches anything it is that change is normal, that we have \nnot reached the rotary wing End of Technology, that the goal of social expenditure \nis now only to support its entropy.\n An industrial policy should not only support the helicopter industry but avia\xad\ntion in general.  For its aeronautical achievements have benefited world commerce, \nand at the same time upgraded the technology and methodology of other disci\xad\nplines.  This wider support should involve the ultimate transportation concept (ter\xad\nrestrial, at least).  Such a concept implies activity well into the 21st century.\n', 'The costs involved in any system include acquisition, oper\xad\nation, maintenance, and depreciation.  To be competitive with the automobile a \npersonal helicopter should have an acquisition cost in the vicinity of a quality auto\xad\nmobile.  In 1994, this is [on] the order of 30k+.  Although in terms of the current \nhelicopter industry this is a ridiculous target, the advantages of a production run of \nmillions instead of hundreds, along with a recent offering of a single seat helo for \n30k [refs.  6 & 7, not reproduced] makes the outlook to achieve such a goal possible if \nnot probable.  Operational costs include fuel, insurance, parking fees, etc., and need \nnot be greater than the auto.  Maintenance is considerably greater for present helos \nthan for autos, and therefore this issue would have to be addressed in the personal \nhelo technology development program.\n', 'As mentioned before, in the 1950s there were numerous heli\xad\ncopter projects in the United States.  (A repeat of fixed-wing builders after the First \nWorld War.)  Many were independent, inventive individuals who worked with mod\xad\nels or prototypes.  Their disappearance is attributed to the success of the helicopter \nitself, the complexity in defining current problems, the development costs, the lack \nof investor interest, and the idea the hovering problem was “solved”.\n Today these inventive individuals are replaced by amateur technicians (home \nor kit builders) interested in constructing their own helicopters of a proven design. \n Those who design the kits are innovators but work at a different level from those \nwho searched for the practical helicopter.  Equally significant is the difference in \navailable knowledge, materials, and components.\n', 'Its author, Edward P. \nWarner, holder of a Ph.D.  in engineering from MIT, later became one of the most \nrenowned leaders of American aviation—a professor of aeronautics at MIT, editor \nof Aviation magazine, and technical consultant on the design of the Douglas DC-3. \n From 1919 to June 1920 (a month after the publication of this NACA technical \nreport), Warner served as the original chief physicist at NACA Langley.\n As Warner understood, the problem of the helicopter came down to four major \nissues: 1)\xa0 producing enough lift to get the machine off the ground effectively, \n2)\xa0managing a safe descent if power was lost, 3) ensuring a high degree of stability \nand control, and 4) achieving a practical forward speed.  Naturally, the last three \nonly became important if the first—producing enough lift—was solved.  Thus, \nWarner spent the first and longest portion of his paper examining the question of \nhow much thrust “can be secured from a direct-lifting propeller” and determined \nthat the propeller should be designed “in order that this thrust may be a maximum.”\nAlthough the paper does not have a formal bibliography, it does make refer\xad\nences to some of the relevant work being done in Europe as well as to helicopter-\nrelated propeller research being done at the National Physical Laboratory and at \nwhat was then called Leland Stanford Junior University.  The work at Stanford \ninvolved an unprecedented series of experiments conducted by William F. Durand \nand Everett P. Lesley. ']","
The problem with the helicopter industry is that it attempts to compete with the fixed-wing counterpart on the latter's terms. The helicopter tries to fit into the fixed-wing system that pervades the country. Instead, a new philosophy for an independent heliport system, a national grid taking in the whole country, dedicated to intercity (including small city) transport and shuttle service is needed. The heliports are scaled down, unique versions of airports created in uncongested areas, each paired to another city and assigned its own ""catch region"". The philosophy resembles that in creating a modern mall, but not in imitation of it. The venue suggests the idea behind location of industrial parks, which imply the same geographical purpose. Such heliports are accessible by surface vehicles (autos, buses, taxis, limousines) via new roads, away from today’s traffic flow."
What is the basic problem identified in the helicopter industry that prevents it from capitalizing on its inherent advantages and fulfilling its early vision?,"The basic problem identified in the helicopter industry that prevents it from capitalizing on its inherent advantages and fulfilling its early vision is the failure of inventors to consider fully the problem which they have to meet or to familiarize themselves with the fundamental theory on which the action of every helicopter must be based. The cruxes of the helicopter question are the securing of the necessary lift to rise from the ground, the assurance of a safe descent after complete failure of the engines, the securing of stability and controllability, and the maintenance of a reasonably high forward speed in the horizontal plane. Unfortunately, the printed discussions of this theory are almost all in French, German, or Italian, and those which are available in English are mostly contained in advanced treatises which are not likely to fall into the hands of the casual student.","['A vast number of \nhelicopters have been invented, many have been built, and a very, very few have \nbeen successful up to the point of raising themselves from the ground.  The possible \nadvantages of the helicopter are obvious, a machine which can rise and descend \nvertically, and which requires no large space over which to run before taking off \nand after descending, manifestly being more useful, other things being equal, than \nthe present type of airplane.  It is regrettable that the inventors of direct-lift aircraft \nhave, in many instances, seen only these possible gains and have failed to consider \nfully the problem which they have to meet or to familiarize themselves with the \nfundamental theory on which the action of every helicopter must be based.  It is \nfelt, therefore, that a broad survey of the problem will be of use in making clear the \nnature of some of the obstacles which have prevented any helicopter from reaching \nthe stage of practical usefulness as yet and may lead to a saving of some of the time \nand money which are constantly being squandered on attempts to demonstrate \nanew facts which are already perfectly well understood without in the least striking \nat the root of the problem.\n The cruxes of the helicopter question are the securing of the necessary lift to \nrise from the ground, the assurance of a safe descent after complete failure of the \nengines, the securing of stability and controllability, and the maintenance of a rea\xad\nsonably high forward speed in the horizontal plane; and each of these points will \nbe discussed in turn.  Manifestly, until the first problems are solved satisfactorily \nthe others do not rise at all, and the discussion will therefore be started with the \nquestion fundamental to all others, the question of the thrust which can be secured \nfrom a direct-lifting propeller and of the specifications to which the design of the \npropeller must conform in order that this thrust may be a maximum.\n THE THEORY OF THE DIRECT-LIFTING SCREW PROPELLER.\n', 'Unfortunately, however, the \nprinted discussions of this theory are almost all in French, German, or Italian, and \nthose which are available in English are mostly contained in advanced treatises \nwhich are not likely to fall into the hands of the casual student.  A vast number of \nhelicopters have been invented, many have been built, and a very, very few have \nbeen successful up to the point of raising themselves from the ground.  The possible \nadvantages of the helicopter are obvious, a machine which can rise and descend \nvertically, and which requires no large space over which to run before taking off \nand after descending, manifestly being more useful, other things being equal, than \nthe present type of airplane.  It is regrettable that the inventors of direct-lift aircraft \nhave, in many instances, seen only these possible gains and have failed to consider \nfully the problem which they have to meet or to familiarize themselves with the \nfundamental theory on which the action of every helicopter must be based.  It is \nfelt, therefore, that a broad survey of the problem will be of use in making clear the \nnature of some of the obstacles which have prevented any helicopter from reaching \nthe stage of practical usefulness as yet and may lead to a saving of some of the time \nand money which are constantly being squandered on attempts to demonstrate \nanew facts which are already perfectly well understood without in the least striking \nat the root of the problem.\n The cruxes of the helicopter question are the securing of the necessary lift to \nrise from the ground, the assurance of a safe descent after complete failure of the \nengines, the securing of stability and controllability, and the maintenance of a rea\xad\nsonably high forward speed in the horizontal plane; and each of these points will \nbe discussed in turn.  Manifestly, until the first problems are solved satisfactorily \nthe others do not rise at all, and the discussion will therefore be started with the \nquestion fundamental to all others, the question of the thrust which can be secured \nfrom a direct-lifting propeller and of the specifications to which the design of the \npropeller must conform in order that this thrust may be a maximum.\n', 'It was also found that in order to \navoid excessive blade stalling during the transition, blade moment of inertia should \nbe large and blade pitch should be reduced as rapidly as possible after power failure.\n STABILITY AND CONTROL\nAs part of an investigation to establish satisfactory helicopter flying-qualities \nrequirements and to determine means of satisfying these requirements, the flying-\nqualities problems of current helicopters as observed during flight were collected \nand are discussed in Technical Note 1799.  This paper contains information on \nthe flying qualities of helicopters obtained from performance testing, experience \nwith various helicopter types, and knowledge of foreign work in this field.  It was \nfound that the principal problems of current helicopters are: Instability with angle \nof attack in forward flight; control sensitivity in forward flight, particularly with \nthe smaller helicopters; and control forces following control movements during \nmaneuvers.  Some discussion is given of suggested remedies for these problems.\n To aid in establishing criterions [sic] for acceptable helicopter stability charac\xad\nteristics, flight tests were conducted on a small single-rotor helicopter possessing \nstick-fixed longitudinal characteristics which were considered satisfactory by the \ntest pilot.  Time histories of longitudinal maneuvers were obtained for correlation \nwith the test pilot’s personal observations.\n', 'The final problem was to understand and develop \nmeans of controlling the helicopter, including balancing the rotor torque.  These \nproblems were essentially the same as those that faced the development of the air\xad\nplane and were solved eventually by the Wright brothers.  The development of the \nhelicopter in many ways paralleled that of the airplane.  That helicopter develop\xad\nment took longer may be attributed to the cost of vertical flight, which required a \nhigher development of aeronautical technology before the problems could be satis\xad\nfactorily overcome.\n Document 5-46 (b), Excerpts from Wayne Johnson, \nHelicopter Theory (Princeton, NJ: Princeton University Press, 1980), \nchapter 7, “Design,” pp.  313–321.\n 7-1\u2002 ROTOR TYPES\nThe helicopter rotor type is largely determined by the construction of the blade \nroot and its attachment to the hub. ', 'The elimination of this pitch\xad\ning instability is considered to be of primary importance in achieving satisfactory \nflying qualities.  Many experimental helicopters, and several production machines, \nalready incorporate devices which either increase the damping in pitch or add posi\xad\ntive static stability with angle of attack.\n Most helicopters on the market today have definite instabilities in some regimes \nof flight and by airplane standards have very poor flying qualities.  The stability and \ncontrol characteristics of the helicopter represent a major present-day development \nproblem, but because they are receiving considerable attention from manufacturers \nand government research agencies, it may be stated with confidence that a rapid \nimprovement of helicopter flying qualities will not be long forthcoming.\n']","
The basic problem identified in the helicopter industry is that the craft attempts to compete with the fixed-wing counterpart on the latter’s terms. The helicopter tries to fit into the fixed-wing system that pervades the country. Instead, what is needed is a new philosophy for an independent heliport system, a national grid taking in the whole country, dedicated to intercity (including small city) transport and shuttle service. The heliports are scaled down, unique versions of airports created in uncongested areas, each paired to another city and assigned its own “catch region”. The vehicle should carry around 100 passengers, with noise attenuation and all-weather capability as major design requirements. The useful load is to include passengers, mail, and express goods."
What were the reasons behind the decision to reduce the number of flights in the X-34 program? Discuss the possible factors that may have contributed to this decision.,"The decision to reduce the number of flights in the X-34 program was primarily due to budget concerns and concerns over losing another vehicle following the embarrassing and needless loss of two Mars probes, or to concerns over the lack of throttling capability of the Fastrac engine that would have been a required engine characteristic for conducting some of the experiments with the X-34 vehicles. However, it is striking how concerned NASA became over the issue of robustness and redundancy. The initial approved risk-reduction plan for the X-34 program called for the fabrication of an additional vehicle, which was completed, but was, of course, simply another single-string craft. The subsequent decision to add redundancy to the X-34 apparently played a role in the restructuring that required a significant increase in funding, as noted in the NASA FY 2000 Performance Report.","['Promise Denied\n286\nhighest level of technology, and that is one reason why the search for reusable \nvehicles\xa0continues.85\nRisk Mitigation, the “Single String” X-34, and Possible Cancellation\nAs reflected earlier in the chapter, NASA had significant risk mitigation con\xad\ncerns about losing the X-34 vehicle during the testing, which caused the Agency \nto move away from the original single-string system to a fully redundant flight \nvehicle.  NASA also significantly reduced the number of powered flights, which \nbasically ended the experiment series that had been one of the two primary \nprogram objectives. \n It is not certain—indeed there is no consensus among program partici\xad\npants—whether the decision to reduce the number of flights was primarily \ndue to budget concerns or to concerns over losing another vehicle following \nthe embarrassing and needless loss of two Mars probes, or to concerns over \nthe lack of throttling capability of the Fastrac engine that would have been a \nrequired engine characteristic for conducting some of the experiments with the \nX-34 vehicles.  Obviously at least some combination of these fatally wounded \nthe program.  But it is striking how concerned NASA became over the issue of \nrobustness and redundancy. \n The initial approved risk-reduction plan for the X-34 program called for the \nfabrication of an additional vehicle, which was completed, but was, of course, \nsimply another single-string craft. ', 'Obviously at least some combination of these fatally wounded \nthe program.  But it is striking how concerned NASA became over the issue of \nrobustness and redundancy. \n The initial approved risk-reduction plan for the X-34 program called for the \nfabrication of an additional vehicle, which was completed, but was, of course, \nsimply another single-string craft.  The subsequent decision to add redundancy \nto the X-34 apparently played a role in the restructuring that required a sig\xad\nnificant increase in funding (and, of course, caused further schedule slippage) \nas noted in the NASA FY 2000 Performance Report:\nEarly in the year, as a result of concerns over potential safety haz\xad\nards due to the lack of redundancy in the vehicle control systems, \nit was determined that the X-34 program should be restructured. \n A replanning activity was undertaken to address these concerns.  It \nresulted in a determination that a significant amount of additional \nfunding would be required on the part of the Government to \nmeet the revised flight plans.  Since making these additional funds \navailable would require the reallocation of resources planned for \nthe Space Launch Initiative (SLI), NASA decided that additional \nfunding for X-34 risk reduction should be completed within the \nSLI evaluation process.86\nAgainst these concerns, program adherents offered various arguments, sum\xad\nmarized in a presentation given at NASA Marshall on April 18, 2000, articulat\xad\ning the Center’s reasons for continuing the X-34 project: \n', '•\t Consider schedule modifications that would include inert drop tests \n(approach and landing test-glide only, no engine used) as early in the \nschedule as possible.\n •\t Conduct early landings on the lakebed.\n •\t Consider removing the second LOX tank during early flights.62 \nFollowing up on its continued interest in risk mitigation, NASA modified \nits X-34 contract with Orbital to approve fabrication of a second flight vehicle \nin January 1998.  Mike Allen, then NASA Marshall’s X-34 deputy program \nmanager, commented on the decision, stating that “[t]he purpose of a second \nvehicle is to reduce risk to the X-34 program [noting that] one of the lessons \nwe learned from the Clipper Graham [DC-XA] program is that it is desirable \nto have a second flight vehicle available, especially if it can be acquired at a \nrelatively low cost.”63 \n', 'The Orbital engineer noted “X-34 \ncontinues a long history of rapid prototyping at Orbital.  The lessons \nlearned on each program are being incorporated into the operations \naspects of the X-34.”16\n•\t Documentation, data tapes, and recorded voice tapes should be \nretained as historical records for each flight at least until a mission is \ncompleted and the degree of success is understood. \n •\t The project should ensure that hazardous response groups are pro\xad\nvided with up-to-date hazardous materials information at the start of \nthe program. \n Driving Technical Factors\nAs Orbital engineers Henri Fuhrmann, John Hildebrand, and Tony Lalicata \nnoted in 1999, cost, schedule, performance, and technical risk were the factors \nthat “drove the design of the X-34.” 17 They further noted that the fast-paced \nand tightly scheduled program “dictated a concurrent engineering approach \nin which the design and analysis of the vehicle were conducted in parallel with \nfabrication and testing [and that as a result, this] required compromise and \nan appropriate balance of schedule and technical risk.”18 While, as mentioned \npreviously, it drew upon experience with the double-delta planform of the \nSpace Shuttle, its wing differed significantly in its airfoil shape.  It was “quite \ndifferent from that of the Shuttle Orbiter,” the three engineers added that the \nairfoil had to have a flat bottom and a constant diameter leading-edge radius \non its outer-wing panels, for ease of manufacture, as well as be thick enough \nto house the landing gear and its actuators.  “The result,” they noted, “is a \nflat-bottomed airfoil with high upper surface camber and varying spanwise \nthickness-to-chord ratio from 9.2% at the sweep break point to 13.4% at the \nwing tip.”19 \nUnderstanding the thermal environment that the X-34 would encounter \nwas of crucial importance and Orbital drew on NASA research at Langley and \n', 'With \nthe planned addition of 25 more flights, the plan changed to favor Edwards \nfor the both the preliminary testing and for the developmental testing with \nsome testing still planned for Kennedy.  Dryden’s David Bushman, one of the \nCenter’s X-34 managers, noted that the Center had been trying to get the X-34 \nflight testing, invoking its X-15 legacy and that the X-34 was like an X-15 but \nwithout a pilot.  Bushman pointed out that despite each having a different \nmission—the X-15 was developed to initially explore the hypersonic flight \nenvelope, while the X-34 was intended to examine how to reduce launch costs \nand to test new technologies for reusable launch vehicles—the X-15 and X-34 \nwere similar in shape, size, and capabilities.  He noted an additional advantage \nof flight-testing at Edwards AFB was that the X-34 could use the same flight \ntrack already planned for the X-33.25\nIn commenting on the problems at Holloman AFB, Aviation Week & Space \nTechnology’s Joseph C. Anselmo noted that\nsome program officials are secretly delighted because the size \nof the test range at Holloman would have limited the X-34 to \nspeeds of Mach 2.5–3.  Flying out of Edwards, the vehicle could \nbe dropped over the Groom Lake test range in Nevada, enabling \nit to achieve peak [Mach 8.0] speed before being moved to Florida \nfor weather-related tests.26 \nCommenting further on the dispute over using Dryden versus White Sands, \nBushman noted that “[w]e here at Dryden with our experience with the X-15 \nand X-33…this is what we do.”27 X-plane flight-testing at Dryden appeared to \nbe confirmed by NASA Administrator Daniel S. Goldin, during his April 2000 \nvisit to Dryden, saying that, “Dryden needs to be the place to test X-planes… \n[and] there should be no ambiguity any longer…if it involves flight, Dryden \nneeds to be involved from the beginning.”28 \nThe A-2 vehicle, which was originally planned to be used in New Mexico, \nwas now planned to be shipped to NASA’s Kennedy Space Center for a second \nset of flight tests.  It was hoped that these tests, which were planned to reach \nspeeds of approximately Mach 4.5, would demonstrate rapid turnaround flight \noperations as well as the capability to make crosswind landings and fly through \nrain.  The remainder of the flight-testing would then be conducted at NASA \nDryden using the A-3 vehicle. ']","
The decision to reduce the number of flights in the X-34 program was not due to a single factor, but rather a combination of concerns. These concerns included budget constraints, the loss of two Mars probes, and the lack of throttling capability of the Fastrac engine. The lack of throttling capability was particularly problematic because it was a required engine characteristic for conducting some of the experiments with the X-34 vehicles. 

Moreover, NASA became increasingly concerned about the robustness and redundancy of the X-34 program. This concern led to the restructuring of the program, which required a significant increase in funding and caused further schedule slippage. The restructuring was necessary due to potential safety hazards caused by the lack of redundancy in the vehicle control systems. 

In summary, the decision to reduce the number of flights in the X-34 program was due to a combination of budget constraints, safety concerns, the lack of throttling capability of the Fastrac engine, and the need for robustness and redundancy in the program."
Question: How does the IN SITU device help monitor stress levels in real time during spaceflight?,"The IN SITU device, which was tested on the International Space Station (ISS), helps monitor stress levels in real time during spaceflight by detecting the presence of the stress hormone cortisol in saliva samples collected by crew members using a swab. The device uses disposable cartridges, and sample collections and analyses are simple to perform. Crew members collect saliva with a swab, inject the sample into the cartridge, and push buttons to initiate the analytical procedure. They then insert the cartridge into a reader to obtain results. This method of monitoring stress levels is useful for spaceflight because storing saliva samples for later analysis on Earth is expensive and cumbersome, and means any problems that are identified cannot be addressed in a timely manner.","['132\ninvasive double sensor is a highly useful diagnostic tool \nfor recognizing early warning signs of fatigue during \nspacewalks in orbit.  On Earth, firefighters, jet pilots, \nminers, steel workers, soldiers in combat, divers, \nmountaineers, polar explorers, marine fishermen, and \nall who work in extreme conditions could benefit from \nthe new measurement technology.  It could also be used \nfor monitoring during critical hospital operations such \nas heart surgery or for monitoring babies in incubators.\n Non-invasive Collection of Saliva Helps \nMonitor Stress Levels in Real Time\nSpitting is discouraged aboard the ISS, unless it helps \nmonitor the health of crew members.  However, while \nsaliva samples can be useful for such monitoring, \nstoring them for later analysis on Earth is expensive \nand cumbersome, and means any problems that are \nidentified cannot be addressed in a timely manner. \n Increased stress is a common problem associated with \nspaceflight.  The ISS Non-invasive Sample Investigation \nand results Transmission to ground with the Utmost \neasiness (IN SITU) investigation tested a portable device \nto conduct direct, real-time analysis of saliva samples \non the space station. ', 'However, while \nsaliva samples can be useful for such monitoring, \nstoring them for later analysis on Earth is expensive \nand cumbersome, and means any problems that are \nidentified cannot be addressed in a timely manner. \n Increased stress is a common problem associated with \nspaceflight.  The ISS Non-invasive Sample Investigation \nand results Transmission to ground with the Utmost \neasiness (IN SITU) investigation tested a portable device \nto conduct direct, real-time analysis of saliva samples \non the space station.  Investigators used the device \nto monitor stress levels among crew members by \ndetecting the presence of the stress hormone cortisol. \n The IN SITU device uses disposable cartridges, and \nsample collections and analyses are simple to perform. \n Crew members collect saliva with a swab, inject the \nsample into the cartridge, and push buttons to initiate \nthe analytical procedure.  They then insert the cartridge \ninto a reader to obtain results. ', 'Paolo Nespoli performs the IN SITU experiment \nonboard the space station. \n Image credit: NASA\n“Saliva is easily and non-invasively collected, especially \nin microgravity,” said Principal Investigator Aldo Roda \nof Italy’s University of Bologna.  “It does not require \ncumbersome pre-analytical treatment procedures; \nin this case, it was analyzed as is.  Moreover, it is a \nparticularly interesting matrix for measuring cortisol, \nsince data in the literature already demonstrate \nthat salivary levels of cortisol well correlate with \nits blood levels.”\nIn addition to improving crew health monitoring on the \nspace station, the device could be employed to monitor \nastronauts on long-duration missions to Mars, asteroids \nor other distant destinations.\n Simple modification of the cartridges would make \nit possible to analyze other biological fluids, such \nas blood, plasma and sweat. \n “In principal, the cartridge could be used to detect any \nbiomarker measurable by an immunological method,” \nsaid Roda.  “That includes other hormones, peptides, \nproteins and even drugs.” Analysis could be expanded \nto include biomarkers of inflammation, infection, bone \nloss, muscle atrophy, cardiovascular disorders and \nother physiological changes that astronauts often \nexperience during spaceflight. \n', '.. 130\nSensor Technologies for High-pressure Jobs and Operations .\n ..............................................................  130\nEconomic Valuation Sidebar: Noninvasive Sensors Get to the “Core” of Body Temperature Changes .\n ..  131\nScientific Valuation Sidebar: Sweat the Small Stuff: \nMinor Changes in Core Body Temperature Impair Performance .\n ...........................................................  131\nNon-invasive Collection of Saliva Helps Monitor Stress Levels in Real Time ..........................................  132\n121\n', 'Early detection allows for early administration \nof antiviral therapy and thus limits nerve damage and \nprevents overt disease.  The device is designed for use \nin doctors’ offices or spacecraft and can be modified \neasily for use with other viruses in saliva, urine, blood \nand spinal fluid.  The sensitivity and specificity emanates \nfrom an antibody-antigen reaction.\n In another collaborative study, NASA and University \nof Colorado Health Science Center (Denver) researchers \ndeveloped a tool that assessed stress hormones \nduring space shuttle missions.  Saliva samples were \ncollected on individual filter paper strips and tested \nonce back on Earth.  The test measured cortisol and \ndehydroepiandrosterone (DHEA)—two important stress \nand immune regulatory hormones.  The filter paper \nalso can be used for proteins and other molecules \nof interest in saliva. ']","
The IN SITU device helps monitor stress levels in real time during spaceflight by conducting direct, real-time analysis of saliva samples on the space station. It detects the presence of the stress hormone cortisol using disposable cartridges. The process is simple to perform, as crew members collect saliva with a swab, inject the sample into the cartridge, and push buttons to initiate the analytical procedure. The cartridge is then inserted into a reader to obtain results. The device makes sensitive and specific quantitative measurement of biomarkers possible by using fluid samples obtained non-invasively, and it is not affected by microgravity conditions."
What is the method used to calculate the water resistance and air resistance in the take-off into wind scenario?,"In the given context, the method used to calculate the water resistance and air resistance in the take-off into wind scenario is not explicitly mentioned. However, it is mentioned that the water resistance is calculated by assuming a constant angle of attack in take-off, say 8°, and calculating (or simply estimating) a value of LD corresponding to this angle. The air resistance is found by calculating (or simply estimating) a value of LD corresponding to the angle of attack chosen above and the trim angle, which is the difference between the angle of attack chosen above and the desired trim angle. The curves of minimum-resistance trim angles against the speed coefficients Cv using the displacement coefficient C∆ as a parameter are used to determine the desired trim angle.","['267\nDocument 5-20 (a–c)\nThe total resistance is found \nby adding the air resistance of the \nairplane to each value of R. The \nair resistance is found by assum\xad\ning a constant angle of attack in \ntake-off, say 8°, and calculating (or\nsimply estimating) a value of L\nD\ncorresponding to this angle.  The air \nresistance is D = LW\n∙\nL\nD∙\n where Lsubscript W is \nthe wing lift = W times V over V subscript G squared\nV\nVGtimes V over V subscript G squared\n2\n.  If the total \nresistance and maximum propeller \nthrust are plotted against speed on \nthe same diagram, the margin of \nthrust available for acceleration is \neasily obtained and from this one \ncan obtain the probable take-off \nperformance.\n Take-off in a wind. ', 'Find wing lift at each water speed, assuming Lsubscript W = W time V over V subscript G squared\nV\nVGtime V over V subscript G squared\n2\n9.\t  Load carried by float ∆ = W – Lsubscript W\n10.\t Water resistance R = Δ\n∙\nΔ\nR∙\n11.\t Air resistance D = LW\n∙\nL\nD∙\nTake-Off Down Wind: In this case the water speeds are greater than the air \nspeeds and it is necessary to consider Vsubscript 0 negative.\n The method just outlined must be considered as an approximation for use \nin the absence of more exact data.  It gives results which agree quite closely with \nobserved full-scale maximum loads which can be taken off in a wind of known \nvelocity.\n Thrust may be assumed to vary linearly with speed, making it necessary to \ncalculate the thrust at two speeds only, one of which may be the static thrust. ', 'As plotted \nin this figure, the air resistance is deducted from the propeller thrust.  It might have \nbeen added to the water resistance instead.  The result is the same—the accelerating \nforce is the difference between the net thrust and water resistance.\n The equation for take-off is derived from the well-known formula\n\tF = m times alpha = W over g times alpha = W over g times change in Velocity over change in time\nF = m times alpha = W over g times alpha = W over g times change in Velocity over change in timeF = m times alpha = W over g times alpha = W over g times change in Velocity over change in timeF = m times alpha = W over g times alpha = W over g times change in Velocity over change in timeF = m times alpha = W over g times alpha = W over g times change in Velocity over change in timeF = m times alpha = W over g times alpha = W over g times change in Velocity over change in timeF = m times alpha = W over g times alpha = W over g times change in Velocity over change in timeW\ng F = m times alpha = W over g times alpha = W over g times change in Velocity over change in timeF = m times alpha = W over g times alpha = W over g times change in Velocity over change in timeF = m times alpha = W over g times alpha = W over g times change in Velocity over change in timeW\ng F = m times alpha = W over g times alpha = W over g times change in Velocity over change in timedV\ndt\nThe time of take-off is expressed:\nt = W over g the integral from 0 to v of g of 1 over F times the change in Velocityt = W over g the integral from 0 to v of g of 1 over F times the change in VelocityW\ng\n0∙\nvg\u20091\nFt = W over g the integral from 0 to v of g of 1 over F times the change in Velocityt = W over g the integral from 0 to v of g of 1 over F times the change in VelocityFigure 32.  Thrust and resistance during take-off.  On the y-axis is scale of thrust and resistance (forces) and on the x-axis is V over Vg or Velocity.  Water resistance, net thrust, and propeller thrust are shown.\n', 'Afloat, it must retain the water characteristics of stability and buoy\xad\nancy.  In the take-off, it combines these with certain air characteristics and also \nintroduces two other features—water resistance and trimming moment of the float \nsystem.  These latter items are not particularly difficult to handle if the seaplane is \nfitted with sufficient power and if control over the trimming moment can be exer\xad\ncised by the air controls.  But if a balance between the power required to overcome \nthe water resistance and that required to attain maximum speed in the air is sought, \nthe take-off problem requires careful analysis in the design stage.  This condition \nmay be brought about by the maximum load that the seaplane is to carry or by a \nlimit on the take-off distance with a fixed load.\n Seaplanes ordinarily take off into the wind.  When conditions of sea warrant \nit and when the wind is light, they may be taken off in the trough of the sea. ', 'The average of minimum-resistance trim angles against speed coefficient Cv \n(fig.  35) gives the value of desired trim angle.  The difference between angle of \nattack chosen above and the trim angle is the angle of wing setting.\n In order to calculate for the take-off time and the take-off resistance, it is neces\xad\nsary to determine the resistance at each speed from rest up to the termination of the \ntake-off.  The curves of minimum-resistance trim angles against the speed coeffi\xad\ncients Cv using the displacement coefficient C∆ as a parameter are disposed to scatter \nslightly.  A mean trim angle can be \ndrawn on these curves (see Fig.  35). \n']","
1. Calculate getaway air speed, VG
2. Assume value of wind velocity V0
3. Calculate VGW = VG – V0
4. Assume a series of water speeds, VW
5. Find ratios VW
VGW
6. Read Δ
R  from standard curve, assuming VW
VGW
 equivalent to V
VG
7. Obtain air speed, V = VW + V0
8. Find wing lift at each water speed, assuming LW = W ∙
V
VG∙
2
9. Load carried by float ∆ = W – LW
10. Water resistance R = ∆ ∙ Δ
R
11. Air resistance D = LW ∙
L
D
where Δ
R  is the resistance ratio obtained from the standard curve, W is the weight of the aircraft, and L
D  is the lift-to-drag ratio."
"What is the significance of the Propulsion Control System (PSC) in reducing fuel usage at cruise conditions, maximizing excess thrust during accelerations and climbs, and extending engine life by reducing the fan turbine inlet temperature? How did the PSC contribute to the operational efficiencies and longevity of high-performance aircraft, and what was its impact on the F119-PW-100 engine used on the Lockheed Martin F-22 Raptor aircraft?","The Propulsion Control System (PSC) is significant in reducing fuel usage at cruise conditions, maximizing excess thrust during accelerations and climbs, and extending engine life by reducing the fan turbine inlet temperature. The PSC system could be applied to a wide variety of aircraft but was especially suited to high-performance military aircraft. Pratt & Whitney used the self-tuning onboard model in its advanced engine controllers, including those on the F119-PW-100 engine used on the Lockheed Martin F-22 Raptor aircraft. The PSC enabled greater operational efficiencies and longevity for high-performance aircraft by reducing fuel usage at cruise conditions, maximizing excess thrust during accelerations and climbs, and extending engine life by reducing the fan turbine inlet temperature. The byproduct of the PSC was the capability to monitor the degradation of engine components. When combined with regu­larly scheduled preventative maintenance, the PSC contributed to the operational efficiencies and longevity of high-performance aircraft. The impact of the PSC on the F119-PW-100 engine used on the Lockheed Martin F-22 Raptor aircraft was that it reduced fuel usage at cruise conditions, maximized excess thrust during accelerations and climbs, and extended engine life by reducing the fan turbine inlet temperature. The manufacturer applied other aspects of HIDEC technology in the improved F100-PW-229, the most widely used fighter engine in the world, to increase performance and operational longevity. The flight demonstration and evaluation performed at NASA Dryden in the F-15 HIDEC contributed to the rapid transition of the technology into operational use.","['Propulsion Control Enters the Computer Era, 1976–1998\n145\nthe availability of peak engine and maneuvering performance at all times.  The \noverall result was that PSC reduced fuel usage at cruise conditions, maximized \nexcess thrust during accelerations and climbs, and extended engine life by \nreducing the fan turbine inlet temperature.  A byproduct was the capability to \nmonitor the degradation of engine components.  When combined with regu\xad\nlarly scheduled preventative maintenance, the PSC enabled greater operational \nefficiencies and longevity for high-performance aircraft.19\nThe PSC system could be applied to a wide variety of aircraft but was \nespecially suited to high-performance military aircraft.  Pratt & Whitney used \nthe self-tuning onboard model in its advanced engine controllers, including \nthose on the F119-PW-100 engine used on the Lockheed Martin F-22 Raptor \naircraft. ', ""Propulsion Control Enters the Computer Era, 1976–1998\n145\nthe availability of peak engine and maneuvering performance at all times.  The \noverall result was that PSC reduced fuel usage at cruise conditions, maximized \nexcess thrust during accelerations and climbs, and extended engine life by \nreducing the fan turbine inlet temperature.  A byproduct was the capability to \nmonitor the degradation of engine components.  When combined with regu\xad\nlarly scheduled preventative maintenance, the PSC enabled greater operational \nefficiencies and longevity for high-performance aircraft.19\nThe PSC system could be applied to a wide variety of aircraft but was \nespecially suited to high-performance military aircraft.  Pratt & Whitney used \nthe self-tuning onboard model in its advanced engine controllers, including \nthose on the F119-PW-100 engine used on the Lockheed Martin F-22 Raptor \naircraft.  The manufacturer applied other aspects of HIDEC technology in the \nimproved F100-PW-229, the most widely used fighter engine in the world, \nto increase performance and operational longevity.  The flight demonstration \nand evaluation performed at NASA Dryden in the F-15 HIDEC contributed \nto the rapid transition of the technology into operational use.20An F-22 Raptor like this one has completed it's final assembly in the Lockheed Martin plant in Marietta, Ga., and is the first combat-capable fighter destined for basing and operations in the Pacific.   "", 'Overall, \nengine performance improvements in terms of rate of climb and specific excess \npower were in the range of 10 to 25 percent at maximum afterburning power. \n The research pilots tried to induce stalls to validate the ADECS methodology, \nbut no amount of aggressive maneuvering could cause one.17\nPerformance Seeking Control: Progressing Beyond HIDEC and ADECS\nThe integration phase of the history of engine control systems from 1990 to \n2002 saw dual-channel FADEC systems become the standard for jet engines.18 \nAnother NASA F-15 HIDEC flight research program that worked to optimize \noverall engine operation was the Performance Seeking Control (PSC) project, \nwhich began during the summer of 1990.  Previous control modes used on the \nHIDEC aircraft utilized stored schedules of optimum engine pressure ratios for \nan average engine on a normal day.  PSC used highly advanced techniques that \nidentified the condition of the engine components and optimized the overall \nsystem for best efficiency based on the actual engine and flight conditions \nencountered on a given day.  Specifically, the new system employed integrated \ncontrol laws to use the digital flight, inlet, and engine control systems to ensure \n', 'The increased engine thrust improved the rate of climb 14 percent \nat 40,000 feet and reduced time to climb from 10,000 feet to 40,000 feet by \n13 percent.  Increases of 5 to 24 percent in acceleration were also experienced at \nintermediate and maximum power settings, depending upon altitude.  Overall, \nengine performance improvements in terms of rate of climb and specific excess \npower were in the range of 10 to 25 percent at maximum afterburning power. \n The research pilots tried to induce stalls to validate the ADECS methodology, \nbut no amount of aggressive maneuvering could cause one.17\nPerformance Seeking Control: Progressing Beyond HIDEC and ADECS\nThe integration phase of the history of engine control systems from 1990 to \n2002 saw dual-channel FADEC systems become the standard for jet engines.18 \nAnother NASA F-15 HIDEC flight research program that worked to optimize \noverall engine operation was the Performance Seeking Control (PSC) project, \nwhich began during the summer of 1990.  Previous control modes used on the \nHIDEC aircraft utilized stored schedules of optimum engine pressure ratios for \nan average engine on a normal day.  PSC used highly advanced techniques that \nidentified the condition of the engine components and optimized the overall \nsystem for best efficiency based on the actual engine and flight conditions \nencountered on a given day.  Specifically, the new system employed integrated \ncontrol laws to use the digital flight, inlet, and engine control systems to ensure \n', 'First, the aircraft \nfeatured a variable-geometry inlet and two afterburning turbofans, which \nallowed experimentation with the left-side engine while the other remained \nunaltered to ensure flight safety.  Second, the IPCS proved capable of duplicat\xad\ning the standard hydro-mechanical inlet and engine controls that manipulated \nthe inlet spike and expanding the cone, fuel supply, compressor bleed, and \nnozzle area.  Flight tests in 1976 exhibited faster throttle response, increased \nthrust, extended range at Mach 1.8, and—perhaps most importantly for the \nF-111—stall-free operation.  The success of the IPCS in enhancing propulsion \nsystems in terms of efficiency, operability, reliability, and maintenance led to \nthe widespread use of digital inlet-engine controls technology in both military \nand commercial aircraft.10\nAs well, NASA used its F-15 to investigate and demonstrate a new method \nof obtaining optimum aircraft performance with computer-controlled engines \ncalled Highly Integrated Digital Electronic Control (HIDEC).11 The experi\xad\nmental program explored new innovations to improve engine diagnostics, \ncontrol, and efficiency.  The major components of HIDEC were a Digital \nElectronic Flight Control System (DEFCS), a Digital Electronic Engine \nControl (DEEC), an onboard general-purpose computer, and an integrated \narchitecture that allowed all of the components to interact with each other.12\nA full-authority DEEC regulated the operation of the F-15’s PW1128 \nturbofan.  The DEEC scheduled and maintained the engine operating point \nthrough the use of two main control loops.  The first used the main burner fuel \nflow to regulate the low rotor speed. ']","
The Propulsion Control System (PSC) played a significant role in improving the efficiency and longevity of high-performance aircraft. By reducing fuel usage at cruise conditions, maximizing excess thrust during accelerations and climbs, and extending engine life by reducing the fan turbine inlet temperature, the PSC contributed to greater operational efficiencies and longevity for these aircraft.

The PSC system was especially suited to high-performance military aircraft and was applied to a wide variety of aircraft. Pratt & Whitney used the self-tuning onboard model in its advanced engine controllers, including those on the F119-PW-100 engine used on the Lockheed Martin F-22 Raptor aircraft. This application of HIDEC technology in the F119-PW-100 engine increased performance and operational longevity.

The flight demonstration and evaluation performed at NASA Dryden in the F-15 HIDEC contributed to the rapid transition of the technology into operational use. Overall, the PSC system was a significant development in the field of aviation, leading to improvements in fuel efficiency, engine performance, and operational longevity."
Who is William Frederick Durand and what is his significance in the field of aeronautics and astronautics? Refer to the provided document for context.,"William Frederick Durand was a noted authority on marine-propellers who became interested in aeronautics, specifically propellers, in 1914. He was appointed a member of the NACA in 1915 and served until 1933, and chaired the committee in 1917–18. He was also an influential teacher and researcher in aeronautical propulsion during the first half of the 20th century, and created the aeronautical engineering program at Stanford University in the first part of the century. Durand's influential article of the same year, ""The Screw Propeller: With Special Reference to Aeroplane Propulsion,"" which appeared in the Journal of the Franklin Institute, secured his charter membership in the NACA and bridged the gap between marine and aeronautical engineering. The article also inauguated a prestigious career in aeronautics. Durand provided steady leadership as the NACA began operations and held the NACA chairmanship from 1916 to 1918. He was also a member of the influential President's Aircraft Board in 1925 and a charter trusteeship with the Daniel Guggenheim Fund for the Promotion of Aeronautics beginning in 1926.","['He promised them, \nhowever, an opportunity to per\xad\nform cutting-edge research and to \ntry sometimes hare-brained ideas \nthat had little immediate com\xad\nmercial application.  These efforts \nworked, and by the time that \nthe NACA was transformed into \nNASA in 1958, it had developed an exceptionally positive reputation for inno\xad\nvative aeronautical research and development.\n A leading figure serving on the advisory committee, William Frederick \nDurand, provided steady leadership as the NACA began operations.  An inter\xad\nnationally known teacher and researcher in aeronautical propulsion during the \nfirst half of the 20th century, Durand had created the aeronautical engineering \nprogram at Stanford University in the first part of the century.  He was appointed \na member of the committee in 1915 and served until 1933, and chaired the \ncommittee in 1917–18.  Over the years, most of the research conducted under \nNACA auspices was done in its own facilities, but until the first laboratory was \nconstructed at the end of World War I, the committee relied on contracts to \neducational institutions to undertake work.  Durand’s research team at Stanford \nled the way with its NACA experimentation on propeller shapes. ', 'A noted authority on marine-\npropellers, he became interested in aeronautics, specifically propellers, in 1914. \n His influential article of the same year, “The Screw Propeller: With Special \nReference to Aeroplane Propulsion,” which appeared in the Journal of the \nFranklin Institute, secured his charter membership in the NACA and bridged \nthe gap between marine and aeronautical engineering.  The article also inaugu\xad\nrated a prestigious career in aeronautics.  Durand held the NACA chairmanship \nfrom 1916 to 1918, membership and the secretary’s position on the influential \nPresident’s Aircraft Board in 1925, and a charter trusteeship with the Daniel \nGuggenheim Fund for the Promotion of Aeronautics beginning in 1926.19\nEverett P\n.  Lesley was an equally important member of the Stanford propeller \nresearch team.  He received a master’s degree in naval architecture from Cornell \nUniversity and served for two years at the Navy’s Experimental Towing Tank. \n Lesley came to Stanford’s mechanical engineering department in 1907 with \na considerable knowledge (like Durand) of marine-propellers. ', 'Lewis began recruiting young \nscientists, engineers, and math\xad\nematicians to enter federal service, \nusually for less pay than they could \nfind elsewhere.  He promised them, \nhowever, an opportunity to per\xad\nform cutting-edge research and to \ntry sometimes hare-brained ideas \nthat had little immediate com\xad\nmercial application.  These efforts \nworked, and by the time that \nthe NACA was transformed into \nNASA in 1958, it had developed an exceptionally positive reputation for inno\xad\nvative aeronautical research and development.\n A leading figure serving on the advisory committee, William Frederick \nDurand, provided steady leadership as the NACA began operations.  An inter\xad\nnationally known teacher and researcher in aeronautical propulsion during the \nfirst half of the 20th century, Durand had created the aeronautical engineering \nprogram at Stanford University in the first part of the century.  He was appointed \na member of the committee in 1915 and served until 1933, and chaired the \ncommittee in 1917–18.  Over the years, most of the research conducted under \nNACA auspices was done in its own facilities, but until the first laboratory was \nconstructed at the end of World War I, the committee relied on contracts to \neducational institutions to undertake work. ', 'The Power for Flight\n6\nengineering practices that benefited overall airplane design, not just propeller \ndesign.  There were differences between strict propeller design and the need to \nselect and incorporate efficient propellers into airplane design.  Propeller design \ninvolves the meticulous creation of an efficient airfoil, while airplane design \nrequires that work to be already predetermined.23 Perceiving the propeller as \na major component within the technical system of the airplane reflected the \nCommittee’s desire to fulfill its goal of working toward the practical solution \nof the overall problems of flight.\n Later, in June 1918, Durand illustrated the technical systems approach \nto airplane design before the Royal Aeronautical Society of Great Britain. \n In his delivery of the Annual Wilbur Wright Memorial Lecture, entitled \n“Some Outstanding Problems in Aeronautics,” Durand succinctly voiced the \nNACA’s position on propeller refinement within the broader sphere of airplane \ndesign.  He defined a typical powered, heavier-than-air flying machine as “an \nairplane-motor-propeller combination” in which each of the three compo\xad\nnents was totally dependent on the others.  The propeller was responsible for \none crucial function in this relationship: converting the motor’s energy into \npropulsive power to enable the aircraft’s wings and fuselage to generate lift.24 \nDurand and the NACA clearly believed that propeller research at Stanford \nUniversity would significantly contribute to the development of American \naeronautical\xa0technology.\n', 'Identifying the need, the \nNACA suggested a solution.  Unaware of the Wright brothers’ findings, the \nCommittee acknowledged the existence of “competent authorities” on marine-\npropellers who would be able to transfer their expertise to the refinement of \npropeller design.18 The “competent authorities” that the Committee alluded to \nwere professors William F. Durand and Everett P\n.  Lesley, the two individuals \nresponsible for the NACA’s propeller studies at Stanford University.\n An 1876 graduate of the United States Naval Academy and professor \nemeritus from Cornell University’s prestigious Sibley College of Engineering, \nWilliam F. Durand (1859–1958) served as the head of Stanford’s mechanical \nengineering department beginning in 1904.  A noted authority on marine-\npropellers, he became interested in aeronautics, specifically propellers, in 1914. \n His influential article of the same year, “The Screw Propeller: With Special \nReference to Aeroplane Propulsion,” which appeared in the Journal of the \nFranklin Institute, secured his charter membership in the NACA and bridged \nthe gap between marine and aeronautical engineering.  The article also inaugu\xad\nrated a prestigious career in aeronautics. ']","
William Frederick Durand was a significant figure in the field of aeronautics and astronautics. He was born in 1859 and was the subject of a biography in the book ""Aeronautics and Astronautics: Proceedings of the Durand Centennial Conference Held at Stanford University, 5–8 August 1959."" The biography was written by Frederick E. Terman and can be found in the provided document on page 270.

Durand made important contributions to the field of aeronautics and astronautics, including conducting air-propeller tests with E.P. Lesley. These tests are discussed in an article by Walter G. Vincenti titled ""Air-Propeller Tests of W.F. Durand and E.P. Lesley: A Case Study in Technological Methodology"" in the journal Technology and Culture.

Durand's work in aeronautics and astronautics is also mentioned in the context of the development of quiet engines for small aircraft. NASA news releases from 1972 and 1979 discuss contracts for the development of quiet engines and mention Durand's contributions to the field.

Overall, Durand's work in aeronautics and astronautics has had a lasting impact on the field and continues to be studied and referenced today."
"What is the historical context of hypersonic technology as discussed in the provided document, and what are some key milestones mentioned in the document? (References: Hallion, Richard P., ed. The Hypersonic Revolution: Case Studies in the History of Hypersonic Technology, volumes I and II)","The provided document, ""The Hypersonic Revolution: Case Studies in the History of Hypersonic Technology,"" edited by Richard P. Hallion, provides a historical context of hypersonic technology. The document is divided into two volumes, with volume I covering the period from 1924 to 1967 and volume II covering the period from 1964 to 1986. 

Some key milestones mentioned in the document include:

- The work of Max Valier, a German rocket engineer, in the 1920s and 1930s, which laid the foundation for hypersonic technology.
- The development of the X-15 rocket plane in the 1950s and 1960s, which set records for speed and altitude and paved the way for future hypersonic research.
- The establishment of the National Aero-Space Plane (NASP) program in the 1980s, which aimed to develop a reusable spaceplane capable of flying from Earth to orbit and back.
- The X-34 program, which aimed to develop a reusable hypersonic vehicle for military and commercial applications.

Overall, the document provides a comprehensive overview of the history of hypersonic technology, highlighting the key figures, events, and milestones that have shaped its development over the past century.","['“The History of Hypersonics: or ‘Back to the Future—\nAgain and Again’.” Paper presented at the 43rd Aerospace Sciences \nMeeting and Exhibit, Reno NV, January 10-13, 2005.  AIAA \n2005-0329. \n Hallion, Richard P\n., ed.  The Hypersonic Revolution: Case Studies in the \nHistory of Hypersonic Technology,” volume I: From Max Valier to Project \nPRIME—1924-1967.  Washington, DC: Air Force History and \nMuseums Program, 1998. \n Hallion, Richard P\n., ed.  The Hypersonic Revolution: Case Studies in the History \nof Hypersonic Technology,” volume II: From Scramjet to the National \nAero-Space Plane—1964–1986. ', 'The Hypersonic Revolution: Case Studies in the \nHistory of Hypersonic Technology,” volume I: From Max Valier to Project \nPRIME—1924-1967.  Washington, DC: Air Force History and \nMuseums Program, 1998. \n Hallion, Richard P\n., ed.  The Hypersonic Revolution: Case Studies in the History \nof Hypersonic Technology,” volume II: From Scramjet to the National \nAero-Space Plane—1964–1986.  Washington, DC: Air Force History \nand Museums Program, 1998.\n Hallion, Richard P\n., and Michael H. Gorn.  On the Frontier: Experimental \nFlight at NASA Dryden. ', '“A New Assessment of Promising \nConcepts for ‘Low Cost’ Access to Space.” Paper presented at the 1998 \nAIAA Civil and Defense Space Programs Conference and Exhibit,” \nHuntsville, AL, October 28–30, 1998.  AIAA 98-5140.\n Schweikart, Larry.  The Hypersonic Revolution: Case Studies in the History of \nHypersonic Technology, Volume 3: The Quest for the Orbital Jet—The \nNational Aero-Space Plane Program (1983–1995).  Washington, DC: \nAir Force History and Museums Program, 1998.\n Sgarlata, Patrick, Brian Winters, Bryan Sullivan, and Robert E. Lindberg. \n “X-34 Program MA-5A Main Engine Feasibility Study XO-9609-022,” \nOrbital Sciences Corporation feasibility study. ', '4–5.\n\t\n 127.\t Richard P\n.  Hallion, “The History of Hypersonics; or, ‘Back to the \nFuture—Again and Again’” (AIAA Paper 2005-0329, presented at the \nAIAA 43rd Aerospace Sciences Meeting and Exhibit, Reno, NV, January \n10–13, 2005).\n', 'Guyn, Mark D., Jeffrey J. Berton, Eric S. Hendricks, Michael T. Tong, William \nJ. Haller, and Douglas R. Thurman.  “Initial Assessment of Open Rotor \nPropulsion Applied to an Advanced Single-Aisle Aircraft,” paper presented \nat the 11th AIAA Aviation Technology, Integration, and Operations (ATIO) \nConference, Virginia Beach, VA, September 20–22, 2011.\n Hallion, Richard P\n.  “The History of Hypersonics: Or, ‘Back to the Future—\nAgain and Again,’” AIAA Paper 2005-0329, presented at the AIAA 43rd \nAerospace Sciences Meeting and Exhibit, Reno, NV, January 10–13, 2005.\n Hammack, Jerome B., Max C. Kurbjun, and Thomas C. O’Bryan.  “Flight \nInvestigation of a Supersonic Propeller on a Propeller Research Vehicle at \nMach Numbers to 1.01,” NACA RM L57E20.  1957.\n']","
The provided document discusses the historical context of hypersonic technology as presented in two volumes of The Hypersonic Revolution: Case Studies in the History of Hypersonic Technology, edited by Richard P. Hallion. The document highlights the evolution of hypersonic technology from its early beginnings to more recent developments.

Key milestones mentioned in the document include:

1. Max Valier's pioneering work in the 1920s, which laid the foundation for hypersonic research (Hallion, Richard P., ed. The Hypersonic Revolution: Case Studies in the History of Hypersonic Technology, volume I: From Max Valier to Project PRIME—1924-1967).

2. Project PRIME, an early hypersonic research project in the United States during the 1960s (Hallion, Richard P., ed. The Hypersonic Revolution: Case Studies in the History of Hypersonic Technology, volume I: From Max Valier to Project PRIME—1924-1967).

3. The development of scramjet technology, which is a critical component of hypersonic vehicles (Hallion, Richard P., ed. The Hypersonic Revolution: Case Studies in the History of Hypersonic Technology, volume II: From Scramjet to the National Aero-Space Plane—1964–1986).

4. The National Aero-Space Plane (NASP) project, which aimed to develop a hypersonic aircraft capable of reaching orbit (Hallion, Richard P., ed. The Hypersonic Revolution: Case Studies in the History of Hypersonic Technology, volume II: From Scramjet to the National Aero-Space Plane—1964–1986).

These milestones demonstrate the progression of hypersonic technology and the ongoing efforts to advance this field."
"Question: How did the 1973 oil embargo impact the aviation industry, particularly in terms of jet fuel supply and prices?","The 1973 oil embargo, undertaken by the Organization of Petroleum Exporting Countries (OPEC) in retaliation for America’s having supported the Jewish state, resulted in a near-disastrous cut in the supply of, and an increase in the price of, jet fuel for the aviation industry. The Nixon administration implemented mandatory Federal control of jet fuel, heating oil, and middle distillate supplies on November 1, 1973, which set supplies at lower 1972 levels. With oil prices low through most of the 1960s, there seemed to be no concerns over fuel efficiency in aviation. However, with cheap fuel and turbofan engines, which operated at about 65 percent efficiency, the airlines were making increased revenues. That perspective changed as the OPEC embargo sent the United States and Europe reeling. No longer would energy sources be unlimited or cheap in Western societies, whose technological infrastructure depended on oil. For the airlines, the embargo resulted in a near-disastrous cut in the supply of, and an increase in the price of, jet fuel. The outcome commercial air carriers wanted least was to reduce service. For American Airlines’ legendary Chairman C.R. Smith, there was “no chance” that the airlines could survive a 10-percent reduction in current schedules due to fuel rationing.","['103\nCHAPTER 4\nThe Quest for Propulsive Efficiency,\n1976–1989\nIn the October 1973 Arab-Israeli war, the United States assisted Israel, which \nwas desperately fighting a defensive war, by supplying it with aircraft, tanks, \nammunition, weapons, and intelligence.  The war marked an important stage \nin the evolution of integrated air defenses, and afterward, America embarked \nupon an intensive program of electronic warfare research that would lead to \nmore sophisticated antimissile attack systems and the development of the \nF-117 and B-2 stealth aircraft.  But of more immediate consequence was \nthe imposition of a brief yet crippling oil embargo upon the United States, \nundertaken by the Organization of Petroleum Exporting Countries (OPEC) \nin retaliation for America’s having supported the Jewish state.  It reduced \nthe amount of oil available to the United States by almost 20 percent, or \nthree million barrels a day.  The resultant decrease in petroleum products and \nincrease in prices created an energy crisis that affected the lives of everyday \nAmericans.1 For the airlines, the embargo resulted in a near-disastrous cut in \nthe supply of, and an increase in the price of, jet fuel.  The Nixon adminis\xad\ntration implemented mandatory Federal control of jet fuel, heating oil, and \nmiddle distillate supplies on November 1, 1973, which set supplies at lower \n1972 levels. ', 'The Nixon adminis\xad\ntration implemented mandatory Federal control of jet fuel, heating oil, and \nmiddle distillate supplies on November 1, 1973, which set supplies at lower \n1972 levels.  With the number of people traveling by air growing exponentially, \nthe outcome commercial air carriers wanted least was to reduce service.  For \nAmerican Airlines’ legendary Chairman C.R.  Smith, there was “no chance” \nthat the airlines could survive a 10-percent reduction in current schedules \ndue to fuel rationing.2\nWith oil prices low through most of the 1960s, there seemed to be no con\xad\ncerns over fuel efficiency in aviation.  With cheap fuel and turbofan engines, \nwhich operated at about 65 percent efficiency, the airlines were making \nincreased revenues.  That perspective changed as the OPEC embargo sent the \nUnited States and Europe reeling.  No longer would energy sources be unlim\xad\nited or cheap in Western societies, whose technological infrastructure depended \non oil. ', 'The war marked an important stage \nin the evolution of integrated air defenses, and afterward, America embarked \nupon an intensive program of electronic warfare research that would lead to \nmore sophisticated antimissile attack systems and the development of the \nF-117 and B-2 stealth aircraft.  But of more immediate consequence was \nthe imposition of a brief yet crippling oil embargo upon the United States, \nundertaken by the Organization of Petroleum Exporting Countries (OPEC) \nin retaliation for America’s having supported the Jewish state.  It reduced \nthe amount of oil available to the United States by almost 20 percent, or \nthree million barrels a day.  The resultant decrease in petroleum products and \nincrease in prices created an energy crisis that affected the lives of everyday \nAmericans.1 For the airlines, the embargo resulted in a near-disastrous cut in \nthe supply of, and an increase in the price of, jet fuel.  The Nixon adminis\xad\ntration implemented mandatory Federal control of jet fuel, heating oil, and \nmiddle distillate supplies on November 1, 1973, which set supplies at lower \n1972 levels.  With the number of people traveling by air growing exponentially, \nthe outcome commercial air carriers wanted least was to reduce service.  For \nAmerican Airlines’ legendary Chairman C.R. ', 'For \nAmerican Airlines’ legendary Chairman C.R.  Smith, there was “no chance” \nthat the airlines could survive a 10-percent reduction in current schedules \ndue to fuel rationing.2\nWith oil prices low through most of the 1960s, there seemed to be no con\xad\ncerns over fuel efficiency in aviation.  With cheap fuel and turbofan engines, \nwhich operated at about 65 percent efficiency, the airlines were making \nincreased revenues.  That perspective changed as the OPEC embargo sent the \nUnited States and Europe reeling.  No longer would energy sources be unlim\xad\nited or cheap in Western societies, whose technological infrastructure depended \non oil.  While automakers reacted with compact, fuel-efficient cars and drivers \nadapted by traveling less, the airlines were in a dire situation.  They could not \ndrive away customers by reducing service or raising ticket prices as they faced \n', 'The choices designers made changed to reflect an emphasis on other \nparameters.  Issues of electronic flight and propulsion control, aerodynamic \nand propulsive efficiency, fuel efficiency, lower costs, improved reliability \nand safety, and awareness of environmental issues related to emissions and \nnoise augmented and often superseded the decades-old driving philosophy \nof aircraft design based solely on altitude, speed, and range.4 In terms of fuel \nefficiency and emissions, the 1970s presented NASA with an opportunity \nto, in the words of one historian, “reclaim its mantle at the forefront of \naeronautics\xa0research.”5\nAircraft Energy Efficiency: \nOnset of a Transformational Program\nEchoing that shift in emphasis, the U.S.  Senate Committee on Aeronautical \nand Space Sciences, chaired by Senator Frank E. Moss (D-UT) and \nBarry\xa0M.\xa0Goldwater (R-AZ), recognized the threat to the American airline \nindustry and the aviation industry in general.  The Senate requested that \nNASA address the issue of increased fuel prices and anticipated oil shortages in \nJanuary 1975.6 NASA offered a solution for the fuel crisis.  Speaking before the \nCommittee, Administrator James C. Fletcher asserted that there was potential \nto halve the fuel requirement for commercial jet aircraft by 1985.  He advo\xad\ncated low-drag wing shapes, lightweight composite materials, improved engine \nefficiencies, and modified flying procedures to reduce landing time.  Fletcher \nargued that the implementation of those new technologies and practices on the \n2,100 commercial airliners in American service would amount to $1.3 billion \nyear, or the equivalent of 333,000 barrels a day in fuel savings.7\nWith political pressure intensifying, NASA formed the Aircraft Fuel \nConservation Technology Task Force in February 1975 to explore poten\xad\ntial options. ']","
The 1973 oil embargo, imposed by the Organization of Petroleum Exporting Countries (OPEC) in retaliation for America's support of Israel in the Arab-Israeli war, significantly impacted the aviation industry. The embargo reduced the amount of oil available to the United States by almost 20 percent, or three million barrels a day, leading to a decrease in petroleum products and an increase in prices. This created an energy crisis that affected the lives of everyday Americans and had dire consequences for the airlines.

The embargo resulted in a near-disastrous cut in the supply of, and an increase in the price of, jet fuel. The Nixon administration implemented mandatory Federal control of jet fuel, heating oil, and middle distillate supplies on November 1, 1973, which set supplies at lower 1972 levels. With the number of people traveling by air growing exponentially, the outcome commercial air carriers wanted least was to reduce service. For American Airlines’ legendary Chairman C.R. Smith, there was “no chance” that the airlines could survive a 10-percent reduction in current schedules due to fuel rationing.

Therefore, the 1973 oil embargo significantly impacted the aviation industry, particularly in terms of jet fuel supply and prices, leading to a critical situation for the airlines."
Question: What is the role of the Discovery and New Frontiers Program Office in the Discovery and New Frontiers Program?,"The Discovery and New Frontiers Program Office was formed in 2004 at the Jet Propulsion Laboratory (JPL) to manage the Discovery and New Frontiers Program, which had been previously managed by the NASA Management Office in Washington, DC. The office was created to give JPL more ownership and cooperation between the projects and the project office. The office studies cost growth of missions since Genesis and provides risk-based insight and oversight with the ability to be hands-on and provide assistance or additional review in the face of problems. The New Frontiers Planetary Program was structured and managed along the lines of the successful Discovery Program, and all New Frontiers missions are selected through a fully open, competitive, and peer-reviewed process.","['Discovery was the beginning: the \nopportunity to do significant science on a relatively modest budget.”106\nDiscovery Program Office Dissolved\nIn late 2003, NASA Headquarters dissolved the Discovery Program Office at the NASA \nManagement Office in Washington, DC.  It had been led for years by Dave Jarrett and \nstaffed by Kate Wolf, who was badged by NASA Headquarters, with education and \npublic outreach leadership by Shari Asplund, who was badged by JPL.  NASA asked \nJPL to undertake management of a new office that would report up through the JPL \nmanagement chain, hoping that it would give the lab more ownership of, and coop\xad\neration between, the projects and the project office.  JPL had experience with such an \narrangement through its Mars Program Office, headed by Firouz Naderi since 2000.107\nOn 7 January 2004, Charles Elachi, Director of the Jet Propulsion Laboratory, \nannounced the formation of the Discovery and New Frontiers Program Office at JPL.\n Meanwhile, cost overruns from two Discovery missions—MESSENGER and Deep \nImpact—severely delayed the release of what would have been the 2002, and then 2003, \nbut what was finally the 2004 Announcement of Opportunity for a new Discovery \nmission.  In October 2002, Deep Impact needed $7.4 million, so the AO was pushed to \nJanuary 2003.  But then MESSENGER needed $3.2 million. ', 'While this made good sense as a national policy, \nit would make it difficult for proposal teams to stay together and available.\n Ultimately, by including options for advanced technologies, the Discovery Program \nhad been expanded to include more complex missions and missions to planets beyond \nthe asteroid belt.\n STUDYING COST GROWTH: REPORTS \nIn July 2008, three NASA study groups briefed the Planetary Science Subcommittee on \ntheir findings in parallel cost studies conducted by the Discovery and New Frontiers \nProgram Office, the Space Science Office, and NASA Headquarters.  The Discovery \nand New Frontiers Program Office, led by Paul Gilbert, studied five recent missions \nfrom its program in order to better understand the cost growth of missions since \nGenesis, using the official cost numbers from the proposal, Concept Study Report, \nand Preliminary Design Review, with additional information from Cost Analysis \nData Requirement results, milestone review products at the Critical Design Review, \nthe System Implementation Review, the Operations Readiness Review, the Mission \nReadiness Review, project status reports, and program budget exercises.  Results were \nbriefed to the community at the 2006 Discovery Lessons Learned Workshop, a July \n2008 Planetary Science Subcommittee meeting, and full results were written up in 2010.\n 108 \t\nNiebur, S.  (2009, 10 December). ', '“We were ‘better, faster, cheaper,’” recalled Jarrett.  “If there is something you \ndon’t need to do, you don’t do it.  You don’t just build documentation as prescribed and \nat the time it wasn’t prescribed.”30\nProgram scientist Michael New added: “On a day-to-day basis, the mission manag\xad\ners at the program office are the ones who are almost daily, if not hourly, [in] contact \nwith the [project managers and] sometimes the PIs.” A project in development could \nexpect weekly teleconferences with the program executive, Program Scientist, and \nD&NFPO, in addition to the PI.  The Discovery and New Frontiers Program Office \nadvocated risk-based insight and oversight, with the ability to be hands-on and pro\xad\nvide assistance or additional review in the face of problems.  “One of the things they’ve \nbeen able to tap into is the large body of [Exploration Systems Mission Directorate] \n[and Space Operations Mission Directorate] engineers at Marshall who decide they’re \na little tired of working on projects that either will never see the light of day or won’t \nsee the light of day until they’re retired.” At the D&NFPO, however, engineers could \nget a broad view of the program and “see multiple missions go through their entire \n30 \t\nNiebur, S.  (2009, 14 May).  Personal interview with D. Jarrett and Kate Wolf. ', 'NASA′s Discovery Program\n194\nsaying, “The New Frontiers Planetary Program will be structured and managed along \nwith the lines of a highly successful Discovery Program.... All New Frontiers missions \nwill be selected through a fully open, competitive, and peer-reviewed process.”105\nBrad Perry, who was later the Director of the Science Office for Mission Assessments \nat the Science Mission Directorate, later explained what had happened.  He said: “New \nFrontiers grew out of the success of Discovery.  Discovery was the beginning: the \nopportunity to do significant science on a relatively modest budget.”106\nDiscovery Program Office Dissolved\nIn late 2003, NASA Headquarters dissolved the Discovery Program Office at the NASA \nManagement Office in Washington, DC.  It had been led for years by Dave Jarrett and \nstaffed by Kate Wolf, who was badged by NASA Headquarters, with education and \npublic outreach leadership by Shari Asplund, who was badged by JPL. ', 'Foreword\nxv\nProgram management was also reorganized during the crisis years, in part due \nto Goldin’s forced downsizing of NASA Headquarters.  Contract administration and \nfulfillment were put into a separate Discovery office, first briefly at JPL, then at Marshall \nSpace Flight Center in Huntsville, Alabama.  That office soon added New Frontiers, a \nnew competitive program for “medium-sized” planetary missions, beginning in 2003 \nwith the New Horizons project to send a spacecraft to Pluto and the Kuiper Belt.7 And \nin response to the new competition presented by APL, and later by Goddard Space \nFlight Center, Director Charles Elachi reorganized the Jet Propulsion Laboratory so \nthat it could support multiple proposals.  JPL often found Principal Investigators from \nwithin, or from the ranks of allied scientists in academia, reversing the early Discovery \nexpectation that PIs would be academics who would ally with a center to advance their \nown idea.  JPL’s success in that endeavor is visible in the “Discovery Missions” table: \nalmost all winning proposals after 2001 are from there.\n Discovery Missions of Opportunity\nName\nSelection \nLaunch\nPI/Institution\nLead \nCenter\nSpacecraft\nTarget\nAspera-3 \n(instrument)\n1998\n2003\nD. Winning\xad\nham/SwRI\nSwRI\nMars Express \n(ESA)\nMars\nNetLander \ninstruments\n2001\ncancelled\nW. B. Banerdt/\nJPL\nJPL\nNetLander \n(France)\nMars\nM3 \n(instrument)\n2005\n2008\nC. Pieters/\nBrown U.\nJPL\nChandrayaan-1 \n(India)\nMoon\nEPOXI\n2007\n2005\nM. A’Hearn/U. \n']","
The Discovery and New Frontiers Program Office plays a significant role in the Discovery and New Frontiers Program. It is responsible for managing the program, including overseeing the Announcements of Opportunity (AO), which are used to solicit proposals for new missions. The office also provides support to the Principal Investigators (PIs) of selected missions, helping to ensure their successful implementation. Additionally, the office is responsible for developing and implementing the Implementation Plan for the program, which outlines the goals and objectives of the program and how they will be achieved. The Discovery and New Frontiers Program Office also plays a role in collaborating with other organizations and agencies, as well as managing the budget for the program."
"""What were the circumstances surrounding the V-22 Osprey's first flight, and what serious problems were encountered during its flight test program?""","The V-22 Osprey's first flight was not explicitly mentioned in the given context information. However, the text does mention that the V-22 Osprey was undergoing operational testing by the U.S. Navy and initial operational capability (IOC) was planned for the year 2001. 

Regarding the serious problems encountered during its flight test program, the text states that ""Of the six Full Scale Development (FSD) aircraft planned for the flight test efforts (of which only five were completed), two crashed and were destroyed, with one crash taking the lives of all seven people on board."" However, it was determined that these accidents were not due to the inherent characteristics of this vehicle type.","['The flight test program of the V-22, however, was not without serious prob\xad\nlems.  Of the six Full Scale Development (FSD) aircraft planned for the flight test \nefforts (of which only five were completed), two crashed and were destroyed, with \none crash taking the lives of all seven people on board.  However, it was determined \nthat these accidents were not due to the inherent characteristics of this vehicle \ntype[,] and the program survived.\n As of late 1999, the V-22 Osprey is undergoing operational testing by the U.S. \n Navy and initial operational capability (IOC) is planned for the year 2001.  On \nSeptember 8, 1999, the first production V-22 delivered to the U.S.  Marine Corps \nlanded at the Pentagon for a tilt rotor demonstration hosted by Secretary of Defense \nWilliam S. Cohen. ', 'SIDESTICK CONTROLLER\nAmong the many decisions made early in the development of the TRRA was \nthe cockpit control configuration.  Simulation and flight evaluations by Bell and \nGovernment pilots resulted in the selection of a helicopter-type power lever for rotor \ncontrol and a conventional center stick and rudder pedals for longitudinal, direc\xad\ntional, and pitch control inputs.  The tall center stick, however, with its mass-center \nseveral inches above its pivot point, introduced undesirable dynamic effects (called \n“bobweight” motions) during maneuvers.  This issue, coupled with the possible inter\xad\nference of the center stick with crew station structure (instrument panel), problems \nwith cockpit ingress or egress, and the general interest in conserving limited cockpit \n“real estate,” led researchers to investigate the use of a sidestick controller as the prin\xad\ncipal flight control for the developing military JVX tilt rotor aircraft (later called the \nV-22 Osprey).  The principal concerns with this type [of] controller were whether it \nwould be able to provide the same level of control as the conventional center stick, \nand whether it could perform adequately during “degraded” flight control system \nconditions (such as a malfunctioning or battle-damaged control system).\n To answer these questions, it was decided to perform a piloted simulation eval\xad\nuation and a full flight investigation of a 3-axis sidestick controller on an XV-15 \nTRRA for both normal and “degraded” flight control system conditions.  Gary \nChurchill, senior controls engineer with the TRRA Project Office, developed the \ncontrol laws and was the primary investigator.\n', 'Bell persisted with the tilt-\nrotor concept, building a second XV-3 and defining several other possible tilt-rotors. \n This commitment eventually led to Model 301, which became the renowned XV-\n15.  (Document 5-49 offers a retrospective account of NASA’s involvement in the \nXV-3 program and its follow-on to the XV-15.)  In the 1970s, a test program with \nthe XV-15 fully demonstrated the viability of tilt-rotor operation and led in 1983 to \nthe design of the V-22 “Osprey,” the product of a joint program between Bell and \nBoeing with assistance from NASA.  Although kinks still needed to be worked out, \nso impressive was the performance of the several test and preproduction Ospreys \nthat the United States Navy and Marine Corps decided in 1997 to put the air\xad\ncraft into production.  With funding for continued tilt-rotor R&D behind it, Bell \nannounced that same year that it was planning to build a civilian tilt-rotor, one that \ncould transport as many as nine executive passengers at a speed of 315 mph over a \nmaximum distance of 860 miles.\n For NASA, tilt-rotor R&D often went on hand in hand with efforts to develop \nadvanced helicopters. ', '837\nDocument 5-51\nDocument 5-51\nMichael K. Farrell, Bell Helicopter Textron, Fort Worth, TX, \n“Aerodynamic Design of the V-22 Osprey Proprotor,” \npresented at the 45th Annual Forum of the American \nHelicopter Society, Boston, MA, 22–24 May 1989, \ncopy in Technical Library, NASA Langley.\n First flown experimentally on 19 March 1989, two months before this American \nHelicopter Society presentation by Bell Helicopter engineer Michael K. Farrell, the \nV-22 Osprey tilt-rotor ranks as the first aircraft designed from the ground up to \nmeet the needs of all four U.S.  armed services.  Not only was it meant to transport \nMarine Corps assault troops and cargo using its medium-lift and vertical takeoff \nand landing capabilities, but it also met U.S.  Navy requirements for combat search \nand rescue, fleet logistics support, and special warfare support. ', '839\nDocument 5-51\ncrashed near Tucson, Arizona, on 8 April 2000.  As our manuscript went to press, \nthe Pentagon still had not determined the cause of the accident.\n There is no reason, however, to speculate that the cause of the accident had \nanything to do with the Osprey’s basic aerodynamic design.  More than 10 years of \ndevelopmental research and flight testing has confirmed the basic findings reported \nby Bell’s Michael Farrell in 1989.  Though the design of an effective tilt-rotor air\xad\ncraft—one that takes off and lands like a helicopter but, once airborne, rotates \nits engine nacelles to convert the aircraft to a turboprop airplane capable of high-\nspeed, high-altitude flight—faces many challenges, the V-22 has very successfully \nmet and exceeded its design goals.\n Document 5-51, Michael K. Farrell, Bell Helicopter Textron, Fort Worth, TX, \n“Aerodynamic Design of the V-22 Osprey Proprotor,” \npresented at the 45th Annual Forum of the American \nHelicopter Society, Boston, MA, 22–24 May\xa01989\nABSTRACT\nThis paper describes the aerodynamic design of the V-22 Osprey proprotor \nin terms of design objectives, design parameters, and design verification. ']","
The first flight of the V-22 Osprey took place on March 19, 1989, at Bell's Flight Research Center in Arlington, Texas, with Bell test pilot Dorman Cannon and Boeing Helicopter test pilot Dick Balzer at the controls. The first full conversion to airplane mode was flown on September 14, 1989.

During the flight test program, the V-22 faced serious problems. Of the six Full Scale Development (FSD) aircraft planned for the flight test efforts, two crashed and were destroyed, with one crash resulting in the tragic loss of all seven people on board. However, it was determined that these accidents were not caused by the inherent characteristics of the vehicle type, and the program continued. As of late 1999, the V-22 Osprey was undergoing operational testing by the U.S. Navy, with initial operational capability (IOC) planned for the year 2001."
What is the significance of Pioneer in the context of space exploration as mentioned in the document? Provide specific mission names and their contributions.,"Pioneer played a significant role in space exploration, particularly in the study of interplanetary space. The Pioneer program, which fell under the Lunar and Planetary Exploration line in most years, involved several missions that measured the solar wind flow, magnetic fields, and electron density in space, and observed the energy spectra, fluxes, and direction of solar and galactic cosmic rays. These missions included Pioneers 6, 7, 8, and 9, which were moved from the Lunar and Planetary Exploration line to the Astronomy and Space Science line in the FY 1968 and FY 1969 budgets. However, in all other years, the Pioneer program fell under the Lunar and Planetary Exploration line. 

The document also mentions specific mission names and their contributions. Pioneer 10, launched in 1972, was a mission to study Jupiter, and it became the first spacecraft to leave the solar system. Pioneer 11, launched in 1973, was a similar mission to study Saturn. Both missions carried a plaque showing a human male and female standing next to a Pioneer spacecraft, with a line tracing Pioneer to the third planet from the Sun, and two hydrogen atoms, each in a different energy state, at the top left. 

Additionally, the document mentions the Pioneer H Jupiter Swingby Out-of-Ecliptic Mission Study, which was published in July 1971 and proposed a mission to study Jupiter's magnetosphere and the interplanetary medium. The proposed Pioneer OOE would use a spare Pioneer spacecraft for Pioneers F and G (which would become Pioneers 10 and 11). However, attempts by U.S. scientists to persuade NASA officials to use the backup Pioneer for an OOE mission were initially unsuccessful due to concerns regarding its use.","['The National Academy of Sciences \n13.\t  Able IVA, Able IVB, Able VA, and Able VB were also known as Pioneer P-1, Pioneer P-3, \nPioneer P-30, and Pioneer P-31, respectively.  Pioneers 6, 7, 8, and 9 measured the solar wind \nflow, magnetic fields, and electron density in space, and they observed the energy spectra, \nfluxes, and direction of solar and galactic cosmic rays.  Pioneer E was a similar mission but \nwas lost in a launch failure.  Arguably, these were space physics missions, not planetary \nscience missions.  In the FY 1968 and FY 1969 budgets, NASA moved the Pioneer program \nfrom the Lunar and Planetary Exploration line to the Astronomy and Space Science line.  In \nall other years, the Pioneer program fell under the Lunar and Planetary Exploration line, so \nthe missions are counted as planetary missions here.\n', 'space scientists were also considering the feasi\xad\nbility of an OOE mission.  It was seen as a potential candidate for NASA’s \nemerging solar system exploration program.  By this time, U.S.  scientists \nand engineers were already solving problems relating to an OOE mission \n(and, by extension, technical issues facing future interplanetary probes).23 \nIn July 1971, NASA Ames Research Center published a “Pioneer H Jupiter \nSwingby Out-of-Ecliptic Mission Study.”24 The 128-page report laid out a sci\xad\nentific rationale for the mission; established mission requirements, a range \nof mission possibilities, and a mission design; evaluated the suitability of \nthe Pioneer spacecraft for this mission; and investigated the feasibility of a \nlaunch in 1974.25 While the report outlined a number of different launch \nand hardware configurations, the proposed Pioneer OOE would use a spare \nPioneer spacecraft for Pioneers F and G (which would became Pioneers 10 \nand\xa011).26 \nFor the next few years, attempts by U.S.  scientists to persuade NASA offi\xad\ncials to use the backup Pioneer spacecraft for an OOE mission were unsuc\xad\ncessful.  While a number of officials recognized the potential benefits, a few \nconcerns arose regarding its use.  Writing to NASA Associate Administrator \nfor Space Science and Applications John Naugle, Norman Ness, chief of \nthe Laboratory for Extraterrestrial Physics at NASA Goddard Space Flight \nCenter, expressed concerns about the use of the backup Pioneer. ', '108\nBEYOND EARTH: A CHRONICLE OF DEEP SPACE EXPLORATION, 1958–2016The plaque carried on Pioneers 10 and 11 showed a human male and female standing next to a Pioneer spacecraft.  At the top left are two hydrogen atoms, each in a different energy state.  Note the planets of the solar system at the bottom, with a line tracing Pioneer to the third planet from the Sun.\n The plaque carried on Pioneers 10 and 11 showed a human male and female standing next to a Pioneer spacecraft.  At \nthe top left are two hydrogen atoms, each in a different energy state.  Note the planets of the solar system at the bottom, \nwith a line tracing Pioneer to the third planet from the Sun.  Credit: NASA\n132\nPioneer 10\nNation: USA (51)\nObjective(s): Jupiter flyby\nSpacecraft: Pioneer-F\nSpacecraft Mass: 258 kg\nMission Design and Management: NASA / ARC\nLaunch Vehicle: Atlas Centaur (AC-27 / Atlas 3C \nno. ', 'The \nmission and spacecraft were negotiated along transnational lines, in which \na host of actors and institutions played a role.  Initially, an OOE mission was \nproposed and championed by European space scientists, some of whom were \ninvolved in the shaping of space programs in Europe.  As the feasibility of \nan OOE mission began to be discussed in the global community of space \nscientists (that is, among Americans and Europeans), Europeans had a key \nrole in building a scientific constituency.  The OOE mission emerged as a \npotential candidate for the Pioneer program as Pioneer H—conceived as a \njoint mission by NASA (at least initially), in part due to budget concerns. \n The Ulysses spacecraft undergoes testing.  (NASA: s90-45985)\n', '92\nBEYOND EARTH: A CHRONICLE OF DEEP SPACE EXPLORATION, 1958–2016\nthe large pointing error introduced by the malfunc\xad\ntions in the first stage.  With the booster veering off \ncourse, ground control sent a command to destroy \nthe vehicle at T+484 seconds.  Pioneer-E was the \nlast in a series of probes intended for studying \ninterplanetary space from heliocentric orbit.  An \nadditional payload on the Thor Delta L was a Test \nand Training Satellite (TETR C) to test the Apollo \nground tracking network.\n 115\nKosmos 300 [Luna]\nNation: USSR (68)\nObjective(s): lunar sample return\nSpacecraft: Ye-8-5 (no.  403)\nSpacecraft Mass: c. ']","
Pioneer is a significant name in space exploration as mentioned in the document, with specific missions contributing to its legacy. Here are some of the Pioneer missions and their contributions:

1. Pioneer 0: This was the first spacecraft in the Pioneer series, launched on August 17, 1958, as part of the United States' first attempt to send a satellite beyond Earth's orbit. Although it failed to reach Earth orbit due to a malfunction, it paved the way for future Pioneer missions.

2. Pioneer 10 and 11: These were the first spacecraft to travel through the asteroid belt, conduct close-up studies of Jupiter, and send back images and data from the outer Solar System. Pioneer 10 was launched on March 2, 1972, and became the first spacecraft to achieve escape velocity from the Solar System. Pioneer 11, launched on April 5, 1973, was the first to encounter Saturn and study its rings and moons.

3. Pioneer Venus Orbiter and Multiprobe: These missions, launched in 1978, studied Venus' atmosphere and weather, providing valuable data about the planet's climate and geological history.

These Pioneer missions played a crucial role in understanding our Solar System, paving the way for future space exploration missions."
What was the impact of President Jimmy Carter's decision to establish as national policy that all U.S. government payloads would fly on the Space Shuttle?,"President Jimmy Carter's decision to establish as national policy that all U.S. government payloads would fly on the Space Shuttle had a significant impact on the development and future of the Shuttle program. This decision was seen as securing the Shuttle's future by keeping the flight volume up, allowing greater efficiency. Fixed costs would be amortized over more flights. However, the decision also magnified the cost of science missions, which was seen as unnecessary by the space science community. The U.S. Air Force also bitterly resisted any attempt to totally end its expendable launch vehicle (ELV) program.","['Unfortunately, Space Shuttle development was absorbing more resources \nthan expected because the Shuttle Main Engine and the heat shield tiles for \nthe Shuttle were proving difficult to develop.  These cost overruns were dev\xad\nastating because it was clear, given the economics of the day—hyperinflation \nand economic slowdown—that additional funding was not to be had.  NASA \nleadership pursued several angles in order to overcome the funding shortfall. \n After some lobbying, President Jimmy Carter was persuaded to establish as \nnational policy that all U.S.  government payloads would fly on the Space \nShuttle.19 This decision was seen as securing the Shuttle’s future by keeping \nthe flight volume up, allowing greater efficiency.  Fixed costs would be amor\xad\ntized over more flights.  In addition, the Shuttle would also carry domestic \ncommercial payloads. ', 'The only challenger to the Shuttle’s monopoly was the \nEuropean Ariane expendable launch vehicles.  Arianes had limited payload \ncapacity.  At the same time, modern communication satellites were grow\xad\ning in size, requiring larger boosters to get to orbit.  The impact of Carter’s \ndecision was that all space science payloads would have to be compatible \nwith human missions to and in orbit.  This decision magnified the cost of sci\xad\nence missions, a cost seen as unnecessary by the space science community. \n Meanwhile, the U.S.  Air Force bitterly resisted any attempt to totally end its \nexpendable launch vehicle (ELV) program. ', 'The first active-repeater telecommu\xad\nnications satellite, Telstar, flew in 1962, and since that time the industry has \nexpanded into a multibillion-dollar business each year.  So have commercial \nremote sensing, navigation, and other initiatives thereafter. \n With the arrival of the Reagan administration in 1981, efforts to expand \ncommercial activities in space became a much higher priority.  The President’s \nNational Space Policy of 4 July 1982 took a significant step when it directed \nNASA to expand U.S.  private-sector investment and involvement in space-\nrelated activities.  Accordingly, NASA undertook an in-depth review detailing \noptions NASA might undertake that could stimulate commercial investments \nand opportunities.  Advocates argued for a new way of thinking at NASA; as the \nreview team noted, the Agency needed to consider commercial ventures rather \n', 'However, whether or \nnot the U.S.  proceeds to build the prototype(s) needed to limit \nboth risk and investment awaits a national decision.  Although \nthe SDIO can provide the environment for an informed deci\xad\nsion based on its designs, it cannot build the “highway to space” \nalone.  Leaders in both the government and aerospace industry \nmust make that decision.29\nThe White House’s National Space Transportation Policy\nFollowing the studies reviewed above, the White House, on August 5, 1994, \nreleased a new National Space Transportation Policy directive (NSPD-4), \ndrafted by the National Science and Technology Council and approved by \nPresident Clinton.  The purpose of the policy statement was to set a “clear course \nfor the nation’s space program, providing a coherent strategy for supporting \nand strengthening U.S.  space launch capability to meet the growing needs of \nthe civilian, national security and commercial sectors.”30 The policy commit\xad\nted the United States to following a “two-track strategy of maintaining and \nimproving the current fleet of expendable launch vehicles as necessary to meet \ncivil, commercial, and national security requirements; and investing R&D \n[research and development] resources in developing and demonstrating next \n', 'It was a morass of the first magnitude; the fortunes of human spaceflight \nin the United States had not been at such a nadir since the 1970s.  NASA had \nforestalled any serious discussion of the propriety of human space exploration \nwith the reusable Space Shuttle in that decade, and through 30 years of opera\xad\ntion it had maintained that capability.  It might not have been as glamorous as \nthe earlier heroic human space efforts, but it was a workhorse that performed a \nsuccession of useful missions over the years, but always at a high cost.\n In the aftermath of the Columbia Shuttle accident on 1 February 2003, \nhowever, President George W. Bush decided that the Space Shuttle Program \nhad served its purpose and announced a decision to retire the entire fleet near \nthe end of the first decade of the 21st century.  Speaking at NASA Headquarters \non 28 January 2004, Bush proposed a “Vision for Space Exploration” that \nmandated NASA’s development of what became known as the Constellation \nprogram that would yield a new human spaceflight vehicle that could extend \nexploration beyond low-Earth orbit.  NASA acted on that decision by working \nCHAPTER 11\nA New Age of Entrepreneurial \nSpace Operations\n']","
The impact of President Jimmy Carter's decision was that all space science payloads would have to be compatible with human missions to and in orbit. This decision magnified the cost of science missions, a cost seen as unnecessary by the space science community. Additionally, it secured the Shuttle’s future by keeping the flight volume up, allowing greater efficiency as fixed costs would be amortized over more flights. However, it also led to the U.S. Air Force bitterly resisting any attempt to totally end its expendable launch vehicle (ELV) program, as they wanted to maintain control over their access to space and there was the fear of a single-point failure if the Shuttle fleet was grounded for any reason."
"What were the initial estimates of near-Earth and near-Mars asteroids based on the Palomar Planet-Crossing Asteroid Survey, as reported in the document?","According to the document, in 1979, Glo Helin and Gene Shoemaker had made initial estimates of near-Earth and near-Mars asteroids based on their Palomar Planet-Crossing Asteroid Survey. Between 1973 and 1978, they had identified five Earth-crossing and seven Mars-crossing asteroids. Of the Earth-crossers, three were ""Aten""-class asteroids whose orbits lay primarily sunward of Earth's, while two were ""Apollo""-class asteroids. (See appendix 2.) Other surveys had found four more Aten and Apollo-class asteroids, bringing the known total to nine. Accounting for the limiting magnitude of their 46-centimeter Schmidt telescope and using several different statistical methods to extrapolate from this tiny number of asteroids, they arrived at an estimate of 800 ± 300 near-Earth asteroids of these classes. This projection fell within the same order of magnitude as an earlier estimate of Shoemaker's, which had been based on the numbers and ages of large impact craters.","['To keep these objects from slipping through \nthe cracks, astronomers also developed automated warning systems to help \nidentify which of the many thousands of newly discovered objects actually \npresented a threat.  These were designed to help target additional observations \nto quickly reduce errors in orbit knowledge while also serving as public com\xad\nmunications tools.\n Survey and Population Modeling\nDeveloping an understanding of what it would take to meet the Spaceguard \ngoal involved modeling the near-Earth object population and evaluating the \nability of various search strategies to find objects of different sizes.  In 1979, \nfor example, Glo Helin and Gene Shoemaker had made initial estimates of \nnear-Earth and near-Mars asteroids based on their Palomar Planet-Crossing \nAsteroid Survey.  Between 1973 and 1978, they had identified five Earth-\ncrossing and seven Mars-crossing asteroids.  Of the Earth-crossers, three were \n“Aten”-class asteroids whose orbits lay primarily sunward of Earth’s, while \ntwo were “Apollo”-class asteroids.  (See appendix\xa02.) ', 'Other surveys had found \nfour more Aten and Apollo-class asteroids, bringing the known total to nine. \n Accounting for the limiting magnitude of their 46-centimeter Schmidt tele\xad\nscope and using several different statistical methods to extrapolate from this \ntiny number of asteroids, they arrived at an estimate of 800 ± 300 near-Earth \nasteroids of these classes.  This projection fell within the same order of mag\xad\nnitude as an earlier estimate of Shoemaker’s, which had been based on the \nnumbers and ages of large impact craters.2\n2.\t\n E. F. Helin and E. M. Shoemaker, “The Palomar Planet-Crossing Asteroid Survey, \n1973–1978,” Icarus 40, no.  3 (1\xa0 December 1979): 321–328, doi:10.1016/0019-\n1035(79)90021-6.\n', 'The \neffort to understand the nature of small solar system bodies was known as char\xad\nacterization and employed numerous methods as the 20th century unfolded.\n Surveying for Near-Earth Asteroids in the Age of Photography\nThe first major systematic search for near-Earth asteroids was the Palomar \nPlanet-Crossing Asteroid Survey (PCAS) undertaken by Eleanor “Glo” Helin \nand Eugene Shoemaker, both of the California Institute of Technology, in \n1973 using the Palomar Observatory 0.46-meter (18-inch) Schmidt tele\xad\nscope in southern California.  It was funded by NASA’s planetary astronomy \nprogram, and the stated goal was to discover and obtain precise orbits for a \nsufficient number of planet-crossing asteroids in order to estimate the popu\xad\nlation of various classes of these objects.1 At the time, Shoemaker believed \n1.\t\n Their results were summarized in E. F. Helin and E. M. Shoemaker, “The Palomar \nPlanet-Crossing Asteroid Survey, 1973–1978,” Icarus 40, no.  3 (1 December 1979): \n321–328, https://doi.org/10.1016/0019-1035(79)90021-6.\n', 'Were they rocks?  Were they balls of dust and ices?  The \neffort to understand the nature of small solar system bodies was known as char\xad\nacterization and employed numerous methods as the 20th century unfolded.\n Surveying for Near-Earth Asteroids in the Age of Photography\nThe first major systematic search for near-Earth asteroids was the Palomar \nPlanet-Crossing Asteroid Survey (PCAS) undertaken by Eleanor “Glo” Helin \nand Eugene Shoemaker, both of the California Institute of Technology, in \n1973 using the Palomar Observatory 0.46-meter (18-inch) Schmidt tele\xad\nscope in southern California.  It was funded by NASA’s planetary astronomy \nprogram, and the stated goal was to discover and obtain precise orbits for a \nsufficient number of planet-crossing asteroids in order to estimate the popu\xad\nlation of various classes of these objects.1 At the time, Shoemaker believed \n1.\t\n Their results were summarized in E. F. Helin and E. M. Shoemaker, “The Palomar \nPlanet-Crossing Asteroid Survey, 1973–1978,” Icarus 40, no.  3 (1 December 1979): \n321–328, https://doi.org/10.1016/0019-1035(79)90021-6.\n', 'Index\n379\nmagnitude/brightness\nabsolute magnitude, 18n13, 143n3, \n176\napparent magnitude, 18n13, 143n3, \n175–76\nconcept of, 18n13\nestimates of, 143n3\nlight curve observation and analysis, 65, \n65n31, 190–91, 193–94, 194n56\nvariations in and rotation of asteroids, \n64–65\nviewing geometry and, 175–76, 176n1\nmain-belt asteroids, 8, 163–64, 175, 179\nMainzer, Amy, 186–87, 242, 243–44\nManned Orbiting Laboratory, 146\nMargot, Jean-Luc, 190\nMariner IV, 50\nMark, Hans, 61–62, 148\nMarkley, Robert, 246\nMars\nasteroids between Jupiter and, 8\natmosphere of, research on, 84\ncratering on, 31, 50, 101\ndistance from Sun, 14\ngravitation effects on main-belt aster\xad\noids, 163–65\nHuman Exploration Roadmap develop\xad\nment for mission to, 260\nmeteorites from, 103, 261–62\nmissions to, 255\nplanet-crossing asteroid discoveries for, \n142\npriority of missions to, 304, 305\nresources on and planetary evolution, \n246\nsearch for missing planet between \nJupiter and, 13–17, 14n2, 18–19\ntransfer of life between Earth and, \n102–3\ntransfer of life between Venus and, 103\nMarsden, Brian\nasteroid 1997 XF11 impact and orbit \ncalculations by, 132–37\nmodel development for nongravita\xad\ntional forces on comets, 160\nMPC director role of, 121, 132–33, \n157–58\npress information sheet release about \nand media attention given to 1997 \nXF11, 133–35, 134n78, 135n84, \n137, 137–38n93\nShoemaker-Levy–Jupiter impact and \norbital computations by, 124–25\nSwift-Tuttle comet impact probability \ncomputations by, 121, 122–23\nMars Pathfinder mission, 205–6n91\nMassachusetts Institute of Technology \n(MIT)\nHaystack radar observations, 70\nLincoln Laboratory, Experimental Test \nSite (ETS), 153\nLincoln Laboratory, FROSST, 222\nLincoln Laboratory, Millstone Hill \nradar, 69\nLincoln Laboratory role in CCD devel\xad\nopment, 130\nProject Icarus exercise, 106–8\nSee also Lincoln Laboratory Near-Earth \nAsteroid Research (LINEAR) \nprogram\nmass driver strategy, 117–18, 247–49, \n252–53, 263\nMatese, John, 100–101\nMathias, Donovan, 301\nMathilde asteroid (253), 184, 205–6\nMaurrasse, Florentin, 93\nMcBain Instruments, 55\nMcCord, Tom, 66\nMcDonald Observatory, 132\nMcKinnon, William, 127\nMcLaren, Digby, 81\nMcMillan, Robert S.  “Bob,” 59, 60, 149, \n186\nMcNaught, Robert, 63, 155, 226\nMeadows, Vikki, 126\nMedium Deep Survey, 237–38\nMeech, Karen, 307\nMegaton Ice-Contained Explosion \n(MICE) project, Atom Energy \nCommission, 46–49\nMeinel, Aden, 146–47, 146n12\nMelamed, Nahum, 300n79\nMelosh, Jay, 285n38\nMercury, 14, 307\n']","
In 1979, Glo Helin and Gene Shoemaker made initial estimates of near-Earth and near-Mars asteroids based on their Palomar Planet-Crossing Asteroid Survey. Between 1973 and 1978, they had identified five Earth-crossing and seven Mars-crossing asteroids. Of the Earth-crossers, three were 'Aten'-class asteroids whose orbits lay primarily sunward of Earth’s, while two were 'Apollo'-class asteroids. Other surveys had found four more Aten and Apollo-class asteroids, bringing the known total to nine. Accounting for the limiting magnitude of their 46-centimeter Schmidt telescope and using several different statistical methods to extrapolate from this tiny number of asteroids, they arrived at an estimate of 800 ± 300 near-Earth asteroids of these classes. This projection fell within the same order of magnitude as an earlier estimate of Shoemaker’s, which had been based on the numbers and ages of large impact craters."
"Question: What are some of the significant discoveries made by the Spitzer Space Telescope, including the detection of one of the most distant planets ever identified and the discovery of the most remote galaxy ever detected?","The Spitzer Space Telescope has made significant discoveries, including the detection of one of the most distant planets ever identified, which was announced in April 2015. This planet is about 13,000 light-years from Earth. Another significant discovery made by Spitzer was the detection of the most remote galaxy ever detected, which was announced in March 2016. This galaxy is known as GN-z11 and was detected as part of the Frontiers Field project that combines the power of all three of NASA’s Great Observatories, Spitzer, Hubble, and Chandra. These discoveries were made possible by the combined power of these observatories and the data integrated with information from other space-based observatories.","['229\n2003\u2003\nthat data from the observatory had allowed a more \nprecise measurement of the Hubble constant, the \nrate at which the universe is stretching apart.  The \nfollowing year, Spitzer celebrated 10 full years \nof operation in space and continued operation \nof its two instruments which, in August 2014, \nobserved an eruption of dust around a star (NGC \n2547-ID8), possibly caused by a collision of large \nasteroids.  Such impacts are thought to lead to the \nformation of planets.  Continuing discoveries based \non results from Spitzer (as well as data integrated \nwith information from other space-based observa\xad\ntories such as Swift) were announced in April 2015 \n(discovery of one of the most distant planets ever \nidentified, about 13,000 light-years from Earth) \nand in March 2016 (discovery of the most remote \ngalaxy ever detected, a high-redshift galaxy known \nas GN-z11).  The latter was detected as part of the \nFrontiers Field project that combines the power of \nall three of NASA’s Great Observatories, Spitzer, \nHubble, and Chandra.  In August 2016, mission \nplanners at JPL announced a new phase of the \nSpitzer mission known simply as “Beyond,” lever\xad\naged on a two-and-a-half-year mission extension \ngranted by NASA earlier in the year.  Because the \ndistance between Spitzer and Earth has widened \nover time, during Beyond, its antenna must be \npointed at higher angles towards the Sun to com\xad\nmunicate with Earth. ', ' \n \n \n \n \n \n \n \nPuzzling Out the Atmosphere of a Mid-Size World  \nKepler Space Telescope surveys suggest that the most common type of “We don’t have anything \nplanet found in the Milky Way’s disk doesn’t resemble any of the worlds in like this in the solar\nour own solar system, but is instead something like an Earth-Neptune hybrid  \nHubble teamed up with the Spitzer Space Telescope to study the detailed system, and that’s what \nspectroscopic fngerprint of the atmosphere of one such world, dubbed GJ makes it striking ”\n3470 b, for the frst time to learn more about the nature and origin of these \nprevalent planets  \nBjörn Benneke, University of Montreal \nGJ 3470 b weighs in at nearly 13 times Earth’s mass and orbits its host red dwarf star in just three days  Astronomers \nenlisted the combined multi-wavelength capabilities of Hubble and Spitzer to determine the composition of the wild \nworld’s atmosphere  They discovered that the planet has clear skies with only thin hazes, which allowed them to probe \ndeep into the atmosphere  They expected to see an atmosphere enriched with plenty of heavier elements like oxygen \nand carbon, possibly incorporated in water vapor molecules and methane gas  However, they found mainly hydrogen \nand helium in the atmosphere, similar to the Sun’s makeup  \nAstronomers think star-hugging planets typically formed farther from their host star and then migrated inward over time  \nHowever, in GJ 3470 b’s case, the planet may have formed in place as a large rocky core that then accumulated hydrogen \nfrom a primordial disk of gas around its star when the star was very young  The disk may have dissipated before the planet \ncould bulk up further  The James Webb Space Telescope will be able to probe even deeper into GJ 3470 b’s atmosphere \nthanks to its unprecedented sensitivity to infrared light, possibly unveiling even more about this perplexing planet  \nHubble and Spitzer revealed tantalizing clues about the chemical nature of a mid-size planet, GJ 3740 b, which is between the masses of Earth and Neptune.  The \nplanet has a large rocky core buried under a crushing atmosphere of hydrogen and helium.  Astronomers think it was able to accrete hydrogen from the disk that \nsurrounded the young star, but the disk may have dissipated before the planet accumulated enough material to become a hot Jupiter. \n Credit: NASA, ESA, and L. Hustak (STScI) \nLearn more: https://hubblesite org/contents/news-releases/2019/news-2019-38 html \n46 \n', 'In mid-July 2009, \nabout two months after launch, Herschel entered \na Lissajous orbit of 800,000 kilometers (average) \nradius around L2 and soon, on 21 July, began \nactive operations.  (Herschel’s distance from Earth \nvaried, depending on its orbital position, between \n1.2 and 1.8 million kilometers).  The observatory’s \noperations were organized in 24-hour cycles where \nit communicated with ground control for 3 hours \nevery day with the remainder of the time dedi\xad\ncated to scientific observations.  Less than a year \nlater, at a symposium to discuss the first results of \nHerschel, scientists reported a number of major \nfindings: Herschel had found high-mass proto\xad\nstars around two ionized regions in the Milky Way, \nshowing an early phase in the evolution of stars; the \nHIFI instrument (which had actually been inop\xad\nerable due to a glitch between August 2009 and \nFebruary 2010) had investigated the trail of water \nin the universe over a wide range of scales, from the \nsolar system to extragalactic sources; and Herschel \nfound a previously unresolved population of galax\xad\nies in the GOODS (Great Observatories Origins \nDeep Survey) fields identified by the Hubble, \nSpitzer, and Chandra spacecraft.  In August 2011, \nHerschel mission scientists reported that they had \nidentified molecular oxygen in the Orion molecular \ncloud complex, previously reported by the Swedish \nOdin satellite.  Herschel data also suggested that \nmuch of Earth’s water could have come from com\xad\nets, results suggested by observations of Comet \nHartley 2—although this notion has been dispelled \nsince.  Observations by Herschel, in fact, con\xad\nfirmed that Comet Shoemaker-Levy’s impact into \nJupiter in 1994 had actually delivered water to the \ngas giant. ', '228\nBEYOND EARTH: A CHRONICLE OF DEEP SPACE EXPLORATION, 1958–2016Top view of SIRTF during final integration and testing at Lockheed-Martin, Sunnyvale California\nImage showing assembly of the Spitzer Space Telescope, \nthe infrared telescope designed to study the early uni\xad\nverse, young galaxies, and star formation.  Credit: Russ \nUnderwood, Lockheed Martin Space Systems; courtesy \nNASA/JPL-Caltech.\n Launch Date and Time: 25 August 2003 / 05:35:39 UT\nLaunch Site: Cape Canaveral Air Force Station / \nSLC-17B\nScientific Instruments:\n1.\t infrared array camera (IRAC)\n2.\t infrared spectrograph (IRS)\n3.\t multiband imaging photometer for Spitzer \n(MIPS)\nResults: SIRTF was the fourth and last of NASA’s \n“Great Observatories,” after the Hubble Space \nTelescope (launched in 1990), the Compton \nGamma Ray Observatory (1991), and the Chan\xad\ndra X-Ray Observatory (1999).  It carried an \n85-centimeter infrared telescope and three scien\xad\ntific instruments as part of the Cryogenic Telescope \nAssembly (CTA). ', 'Questions of \nhabitability could thus be considered.67\nFinding the first rocky planets with liquid water on the surface and temperature \nconducive to life “will be the real breakthrough, when you find things that you’d actually \nlike to own real estate on,” said David Latham, a co-investigator from the Harvard-\nSmithsonian Center for Astrophysics, when the spacecraft was under development.68\nAs in all good experiments, the Kepler mission was designed such that a null result \nwould be critically important to the determination of the rarity of such planets.69 “One \nof the most interesting things we could find is zero,” said Borucki.  “That could mean \nwe are alone in the universe.”70\nMasquerading as Transiting Planets\nThere was also a need for ground-based observations to verify potential transits.  “There \nare several astrophysical phenomena that will masquerade as transiting planets and we \nhave to sort those out from the ground,” said project scientist Thomas “Nick” Gautier.71 \nFor instance, an eclipsing binary star or a triple system could also produce dips in the \nsignal that could be mistaken for a transit.  (Other space-based telescopes like Hubble \nand Spitzer have worked well for confirmation of especially important planetary can\xad\n67 \t\nKoch, D., and A. Gould.  (2006, 7 August).  “Overview of the Kepler Mission.” NASA website; \nCowen, R.  (2007, 14 July). ']","
The Spitzer Space Telescope has made several significant discoveries, including:

1. A more precise measurement of the Hubble constant, the rate at which the universe is stretching apart, using data from the observatory.
2. Observation of an eruption of dust around a star (NGC 2547-ID8) in August 2014, possibly caused by a collision of large asteroids, which could lead to the formation of planets.
3. The discovery of one of the most distant planets ever identified, about 13,000 light-years from Earth, in April 2015.
4. The detection of the most remote galaxy ever detected, a high-redshift galaxy known as GN-z11, in March 2016. This discovery was made as part of the Frontiers Field project that combines the power of all three of NASA’s Great Observatories, Spitzer, Hubble, and Chandra.

These discoveries demonstrate the significant contributions of the Spitzer Space Telescope to the field of astronomy and our understanding of the universe."
What is the purpose of the gamma ray spectrometer on the lunar mission and what elements does it map?,"The gamma ray spectrometer on the lunar mission maps the Moon in radioactive elements (uranium, thorium, potassium) and those that emit gamma rays when hit by cosmic rays or particles in the solar wind (iron, titanium, oxygen, silicon, aluminum, magnesium, calcium). A map of the latter set of elements would provide information about the composition of the Moon, which was known to be composed of 98 percent of these elements, by mass. Such maps would show not just the bulk elemental composition of the Moon, but also its mineralogy: information on the types of rocks present on the global surface that could then be compared with the rocks returned by the Apollo missions in the 1960s and ’70s. Such measured elements were also key in determining the prevalence of “KREEP”—material rich in potassium (K), rare earth elements (REE), and phosphorus (P)—and, therefore, lunar evolution.","['NASA′s Discovery Program\n50\n•\t Neutron Spectrometer (NS)\n•\t Doppler Gravity Experiment (DGE)\n•\t Electron Reflectometer (ER)\n•\t Magnetometer (MAG)\nThe gamma ray spectrometer would map the Moon in radioactive elements (ura\xad\nnium, thorium, potassium) and those that emit gamma rays when hit by cosmic rays \nor particles in the solar wind (iron, titanium, oxygen, silicon, aluminum, magnesium, \ncalcium).  A map of the latter set of elements would provide information about the \ncomposition of the Moon, which was known to be composed of 98 percent of these \nelements, by mass.  Such maps would show not just the bulk elemental composition \nof the Moon, but also its mineralogy: information on the types of rocks present on \nthe global surface that could then be compared with the rocks returned by the Apollo \nmissions in the 1960s and ’70s.  Such measured elements were also key in determin\xad\ning the prevalence of “KREEP”—material rich in potassium (K), rare earth elements \n(REE), and phosphorus (P)—and, therefore, lunar evolution. ', 'The camera had heritage from the cameras on Venus \nExpress and Rosetta.  The team was led by co-investigator Holger Sierks.22\nA Mapping Spectrometer to measure the asteroids’ surface composition was a \nmodification of the VIRTIS mapping spectrometer on Rosetta, which had significant \nheritage from Cassini’s VIMS.23 The instrument combined a visible channel from 0.25 \nto 1.0 micron and an infrared channel from 1 to 5 microns to cover the spectral range \nfrom the near ultraviolet (UV; 0.25 micron) through the near IR (5 microns).  Spectral \nresolution at 200 kilometers was 500 meters per pixel, a moderate to high spectral \nresolution.  The spectrometer was designed, built, and tested at Galileo Avionica and \nprovided to Dawn by ASI under the direction of Angioletta Coradini of the Instituto \nNazionale Di Astrofisica.24\nThe Gamma Ray and Neutron Detector (GRaND) would map the abundances of \nmajor elements in rock-forming minerals (oxygen, silicon, iron, titanium, magnesium, \naluminum, and calcium), major elements found in ices (hydrogen, carbon, and nitrogen), \nas well as trace element (uranium, thorium, potassium, galodinium, and samarium) \ncomposition.  In addition, it would detect neutrons on surface, an indicator of near-\nsurface water.  GRaND was built by Bill Feldman, Tom Prettyman, and colleagues at \nthe Los Alamos National Laboratory (LANL), who brought strong technical heritage \nfrom the Gamma Ray and Neutron Spectrometer on Lunar Prospector and the neutron \nspectrometer on Mars Odyssey.  GRaND began as a copy of the Lunar Prospector sen\xad\nsor head, two bismuth germanate scintillator detectors for gamma rays, surrounded \nby boron-loaded plastic as an anti-coincidence shield, bolted to the Dawn spacecraft. \n', 'The spacecraft carried a set of \nsolid-state oscillators which had been programmed \nto reproduce the notes of the Internationale so that \nit could be broadcast live to the 23rd Communist \nParty Congress.  During a rehearsal on the night of \n3 April, the playback went well, but the following \nmorning, controllers discovered a missing note and \nso played the previous night’s tape to the assem\xad\nbled gathering at the Congress, claiming it was a \nlive broadcast from the Moon.  Luna 10 conducted \nextensive research in lunar orbit, gathering import\xad\nant data on the weakness of the Moon’s magnetic \nfield, radiation belts, and micrometeoroid density. \n In 2012, a Soviet scientist made the claim that Luna \n10’s achievements included “the first gamma-ray \nspectrometer used in the history of space research \nto first define the contents of natural radio nuclides \nin the lunar soil.” Data from Luna\xa0 10 suggested \nthat Moon rocks were comparable to terrestrial \nbasalt rocks.  Based on data collected by the probe, \nEfraim Akim (1929–2010) at the USSR Academy \nof Sciences identified the “noncentrality of the \ngravitational field of the Moon” which he argued \nwas “the essential fact determining the evolution of \nthe orbit of Luna 10,” as reported in an Academy \njournal in 1966.  Based on Akim’s claim, some \nsources incorrectly credit Luna 10 with discovery \nof mass concentrations (called “mascons”)—areas \nof high density below the mare basins that distort \nlunar orbital trajectories.  Their discovery, however, \ncame much later, after the creation of a gravimetric \nmap of the Moon (albeit at the time, only of the \nnear side of the Moon). ', 'The small \nimage size was part of the original plan, and was \ndetermined by the slow telemetry rates and an \nestimated 30-minute lifetime.  Like Venera 9, the \nVenera 10 lander was supposed to take a 360° \npanorama but covered only 180° of the surround\xad\nings because of a stuck lens cover.  Soviet officials \nlater revealed that termination of data reception \nfrom both Venera 9 and 10 landers was not due \nto the adverse surface conditions but because the \norbiter relays for both spacecraft flew out of view. \n Gamma-ray spectrometer and radiation densitome\xad\nter (shaped a bit like a paint-roller deployed on the \nsurface) data indicated that the surface layer was \nakin to basalt rather than granite as hinted by the \ninformation from Venera 8.  The Venera 10 orbiter \nmeanwhile entered a 1,620 × 113,000-kilometer \norbit around Venus inclined at 29° 30′, transmitting \ndata until at least June 1976.  Unlike the Venera 9 \norbiter, photographs taken by the Venera 10 orbiter \nwere never released and it remains unclear whether \nit actually carried a camera.\n 150\nViking 1\nNation: USA (56)\nObjective(s): Mars landing and orbit\nSpacecraft: Viking-B\nSpacecraft Mass: 3,527 kg\nMission Design and Management: NASA / LaRC (over\xad\nall) / JPL (Orbiter)\nLaunch Vehicle: Titan IIIE-Centaur (TC-4 / Titan \nno. ', 'Combined with the hazardous thermal environment, this \nnecessitated fully redundant systems.\n During development, instruments saw redesigns that enabled the spacecraft to \nstay in mass and on budget.  The camera was altered to handle optical navigation.  The \ngamma ray spectrometer, meanwhile, was, initially, very similar to the one used on \nNEAR.  As the team would learn, the instrument only worked best when the spacecraft \nlanded on the asteroid.  In flight, it had high background noise and low signals.  To \ncompensate, the instrument team had to change from using scintillator crystals in the \nspectrometer to using high-purity germanium crystal—a great engineering challenge.37\nThe failure of the Mars probes in 1999 and the subsequent NASA Integrated Action \nTeam report, and the recommendations therein, grossly complicated spacecraft devel\xad\nopment. ']","
The gamma ray spectrometer on the lunar mission is used to map the Moon in radioactive elements (ura-nium, thorium, potassium) and those that emit gamma rays when hit by cosmic rays or particles in the solar wind (iron, titanium, oxygen, silicon, aluminum, magnesium, calcium). The purpose of this is to provide information about the composition of the Moon, its mineralogy, and the prevalence of ""KREEP"" which may represent some of the last remaining melt after the lunar crust was formed. This helps scientists understand how the Moon formed and the surface continued to change. The mission also emphasizes the detection of resources needed for future construction on the Moon."
Question: What was the role of the Naval Aircraft Factory in the development of flying boats in the years following World War I?,"The Naval Aircraft Factory played a significant role in advancing the design of flying boats and other types of naval aircraft during the period of military retrenchment following World War I. Despite the dissipation of the naval force and the power of the U.S. military establishment, the Naval Aircraft Factory worked energetically to refine the flying boat and other types of naval aircraft. In 1923, the Naval Aircraft Factory was selected to design and construct the PN-7 plane around the F-5-L hull and tail, with the first important changes being the provision of high lift wings and the increase of about 200 horsepower. The wing section was changed from the RAF 6 to the USA 27, and the chord was increased.","['In the years after the war, this naval force quickly dissipated, as did the power \nof the U.S.  military establishment generally.  By 1925, only 117 flying boats could \nbe counted, mostly obsolete designs from the war such as H-16, HS-2L, and F-5L, \nall built by Curtiss.  The one organization that worked energetically through this \nperiod of military retrenchment to advance the design of flying boats and other \ntypes of naval aircraft was the Naval Aircraft Factory in Philadelphia.  (For a his\xad\ntory of the Naval Aircraft Factory, see William F. Trimble, Wings for the Navy: A \nHistory of the Naval Aircraft Factory, 1917–1956 (Annapolis, MD: Naval Institute \nPress, 1990.)  From its establishment in 1916, the Naval Aircraft Factory worked \nwith particular effort to refine the flying boat.\n This string of documents provides historical insights into the Navy’s quest for a \nmuch-improved aerial patrol boat. ', 'By 1925, only 117 flying boats could \nbe counted, mostly obsolete designs from the war such as H-16, HS-2L, and F-5L, \nall built by Curtiss.  The one organization that worked energetically through this \nperiod of military retrenchment to advance the design of flying boats and other \ntypes of naval aircraft was the Naval Aircraft Factory in Philadelphia.  (For a his\xad\ntory of the Naval Aircraft Factory, see William F. Trimble, Wings for the Navy: A \nHistory of the Naval Aircraft Factory, 1917–1956 (Annapolis, MD: Naval Institute \nPress, 1990.)  From its establishment in 1916, the Naval Aircraft Factory worked \nwith particular effort to refine the flying boat.\n This string of documents provides historical insights into the Navy’s quest for a \nmuch-improved aerial patrol boat.  The first document, an Aero Digest article from \n1925, concerns a prototype flying boat developed at the Naval Aircraft Factory \nknown as the PN-9.  What it represented was the Navy’s desire to move toward \nan all-metal hull, something with which Naval Aircraft Factory engineers began \n', 'military establishment generally.  By 1925, only 117 flying boats could \nbe counted, mostly obsolete designs from the war such as H-16, HS-2L, and F-5L, \nall built by Curtiss.  The one organization that worked energetically through this \nperiod of military retrenchment to advance the design of flying boats and other \ntypes of naval aircraft was the Naval Aircraft Factory in Philadelphia.  (For a his\xad\ntory of the Naval Aircraft Factory, see William F. Trimble, Wings for the Navy: A \nHistory of the Naval Aircraft Factory, 1917–1956 (Annapolis, MD: Naval Institute \nPress, 1990.)  From its establishment in 1916, the Naval Aircraft Factory worked \nwith particular effort to refine the flying boat.\n This string of documents provides historical insights into the Navy’s quest for a \nmuch-improved aerial patrol boat.  The first document, an Aero Digest article from \n1925, concerns a prototype flying boat developed at the Naval Aircraft Factory \nknown as the PN-9. ', '(A) Curtiss capitalized on his work with the Loon and his observation of French advances \nwith the more practical Hydro, which made its first flights in San Diego in January 1911.  (NASM, Smithsonian \nInstitution [NASM 7A10527]) (B) Curtiss quickly moved toward the development of flying boats.  Here he is with \nHenry Ford (right) in front of the refined Model F flying boat in 1913.  By the end of the early flight period, Curtiss \nwas the leading flying-boat manufacturer in the United States, with a substantial amount of experience in design \nand operation.  (NASM, Smithsonian Institution [SI 90-8391])The Curtiss Hydro aircraft flying over a lake.Photo of Glenn Curtiss and Henry Ford posing by a Model F Curtiss Flying Boat on a dock.\n The Curtiss Hydro aircraft flying over a lake.\n The Curtiss Hydro aircraft flying over a lake.\n', 'Equipped with Liberty engines, these planes are greatly \novertaxed.  The principal difficulties are in taking off and maintaining altitude dur\xad\ning flight.  The maximum speed of the F-5-L is less than 90 miles per hour.\n The Naval Aircraft Factory was selected in 1923 as being best fitted to design \nand construct the PN-7 plane around the F-5-L hull and tail.  The first important \nchanges considered were the provision of high lift wings and the increase of about \n200 H.P.  The wing section is changed from the RAF 6 to the USA 27; the chord \n']","
The Naval Aircraft Factory in Philadelphia played a significant role in the development of flying boats in the years following World War I. After the war, the naval force quickly dissipated, and by 1925, only 117 flying boats could be counted, mostly obsolete designs from the war. During this period of military retrenchment, the Naval Aircraft Factory worked energetically to advance the design of flying boats and other types of naval aircraft. From its establishment in 1916, the Naval Aircraft Factory worked with particular effort to refine the flying boat, leading to the development of the PN-9 prototype flying boat, which represented the Navy's desire to move toward an all-metal hull."
Question: What is the significance of the International Solar Polar Mission (ISPM) in the context of U.S.-European cooperation in space?,"The International Solar Polar Mission (ISPM) had its origins in the mid-1960s, when European space scientists worked on building a scientific constituency for a spacecraft that would explore the Sun out of the ecliptic plane (OOE), particularly at the poles and other high latitudes. Through the mid-1970s, NASA and ESA established working groups and hosted a number of symposia and conferences to determine both the scientific and technical merits and capabilities of an out-of-ecliptic mission. These efforts resulted in a proposal for the ISPM, which was officially established as a joint mission with the 29 March 1979 signing of a memorandum of understanding (MOU) between NASA and ESA. However, the ISPM was not launched as originally planned, and the plan was eventually reworked and launched in 1990 as the Ulysses mission. While NASA and ESA eventually carried out a joint solar polar mission, with a single spacecraft named Ulysses, the evolution of ISPM to Ulysses had a lasting impact on U.S.-European cooperation in space. The significance of the ISPM in this context is that it represents a turbulent episode in the five-decade-long history of international space cooperation, which also happens to be one of the most strenuous ones. The ISPM had its origins in the mid-1960s, when European space scientists worked on building a scientific constituency for a spacecraft that would explore the Sun out of the ecliptic plane (OOE), particularly at the poles and other high latitudes. Through the mid-1970s, NASA and ESA established working groups and hosted a number of symposia and conferences to determine both the scientific and technical merits and capabilities of an out-of-ecliptic mission. These efforts resulted in a proposal for the ISPM, which was officially established as a joint mission with the 29 March 1979 signing of a memorandum of understanding (MOU) between NASA and ESA. However, the ISPM was not launched as originally planned, and the plan was eventually reworked and launched in 1990 as the Ulysses mission. While NASA and ESA eventually carried out a joint solar polar mission, with a single spacecraft named","['50 YEARS OF SOLAR SYSTEM EXPLORATION: HISTORICAL PERSPECTIVES\n286\nbe solved more easily when there is an international community of scientists \nand scholars free to follow common goals and common objectives.”2\nWhile I can only speculate as to whether Lüst was referring to anything \nspecific, it would not be farfetched to think that he might be referencing a \nturbulent episode in NASA-ESA cooperation earlier in the decade, a result \nof the collapse of an agreement between the two agencies for a jointly devel\xad\noped International Solar Polar Mission (ISPM).  Although the ISPM was not \nlaunched as originally planned—two solar probes exploring the north and \nsouth poles of the Sun—the plan was eventually reworked and launched in \n1990 as the Ulysses mission.  While NASA and ESA eventually carried out a \njoint solar polar mission, with a single spacecraft named Ulysses, the evolu\xad\ntion of ISPM to Ulysses had a lasting impact on U.S.-European cooperation \nin space.3\nThis important episode in the five-decade-long history of international \nspace cooperation also happens to be one of the most strenuous ones.  The \nISPM had its origins in the mid-1960s, when European space scientists \nworked on building a scientific constituency for a spacecraft that would \nexplore the Sun out of the ecliptic plane (OOE), particularly at the poles \nand other high latitudes (hence its original designation as an out-of-ecliptic \nmission).4 Through the mid-1970s, NASA and ESA established working \ngroups and hosted a number of symposia and conferences to determine both \nthe scientific and technical merits and capabilities of an out-of-ecliptic mis\xad\nsion.  These efforts resulted in a proposal for the ISPM, which was officially \nestablished as a joint mission with the 29 March 1979 signing of a memoran\xad\ndum of understanding (MOU) between NASA and ESA.5 \nTo date, there have been three primary historical studies of Ulysses.  Two \nof these analyses have focused on the origins of the mission. ', '50 YEARS OF SOLAR SYSTEM EXPLORATION: HISTORICAL PERSPECTIVES\n286\nbe solved more easily when there is an international community of scientists \nand scholars free to follow common goals and common objectives.”2\nWhile I can only speculate as to whether Lüst was referring to anything \nspecific, it would not be farfetched to think that he might be referencing a \nturbulent episode in NASA-ESA cooperation earlier in the decade, a result \nof the collapse of an agreement between the two agencies for a jointly devel\xad\noped International Solar Polar Mission (ISPM).  Although the ISPM was not \nlaunched as originally planned—two solar probes exploring the north and \nsouth poles of the Sun—the plan was eventually reworked and launched in \n1990 as the Ulysses mission.  While NASA and ESA eventually carried out a \njoint solar polar mission, with a single spacecraft named Ulysses, the evolu\xad\ntion of ISPM to Ulysses had a lasting impact on U.S.-European cooperation \nin space.3\nThis important episode in the five-decade-long history of international \nspace cooperation also happens to be one of the most strenuous ones.  The \nISPM had its origins in the mid-1960s, when European space scientists \nworked on building a scientific constituency for a spacecraft that would \nexplore the Sun out of the ecliptic plane (OOE), particularly at the poles \nand other high latitudes (hence its original designation as an out-of-ecliptic \nmission).4 Through the mid-1970s, NASA and ESA established working \ngroups and hosted a number of symposia and conferences to determine both \nthe scientific and technical merits and capabilities of an out-of-ecliptic mis\xad\nsion.  These efforts resulted in a proposal for the ISPM, which was officially \nestablished as a joint mission with the 29 March 1979 signing of a memoran\xad\ndum of understanding (MOU) between NASA and ESA.5 \nTo date, there have been three primary historical studies of Ulysses.  Two \nof these analyses have focused on the origins of the mission.  Historian Karl \nHufbauer’s account of the genesis of an out-of-the ecliptic solar mission \n2.\t ', '50 YEARS OF SOLAR SYSTEM EXPLORATION: HISTORICAL PERSPECTIVES\n286\nbe solved more easily when there is an international community of scientists \nand scholars free to follow common goals and common objectives.”2\nWhile I can only speculate as to whether Lüst was referring to anything \nspecific, it would not be farfetched to think that he might be referencing a \nturbulent episode in NASA-ESA cooperation earlier in the decade, a result \nof the collapse of an agreement between the two agencies for a jointly devel\xad\noped International Solar Polar Mission (ISPM).  Although the ISPM was not \nlaunched as originally planned—two solar probes exploring the north and \nsouth poles of the Sun—the plan was eventually reworked and launched in \n1990 as the Ulysses mission.  While NASA and ESA eventually carried out a \njoint solar polar mission, with a single spacecraft named Ulysses, the evolu\xad\ntion of ISPM to Ulysses had a lasting impact on U.S.-European cooperation \nin space.3\nThis important episode in the five-decade-long history of international \nspace cooperation also happens to be one of the most strenuous ones.  The \nISPM had its origins in the mid-1960s, when European space scientists \nworked on building a scientific constituency for a spacecraft that would \nexplore the Sun out of the ecliptic plane (OOE), particularly at the poles \nand other high latitudes (hence its original designation as an out-of-ecliptic \nmission).4 Through the mid-1970s, NASA and ESA established working \ngroups and hosted a number of symposia and conferences to determine both \nthe scientific and technical merits and capabilities of an out-of-ecliptic mis\xad\nsion.  These efforts resulted in a proposal for the ISPM, which was officially \nestablished as a joint mission with the 29 March 1979 signing of a memoran\xad\ndum of understanding (MOU) between NASA and ESA.5 \nTo date, there have been three primary historical studies of Ulysses. ', '69\nCHAPTER 2\u2002 •\u2002 Funding Planetary Science: History And Political Economy \nThe Influence of the International Planetary Science Community\nIn the late 1980s and early 1990s, tensions formed between White House \npolicies, NASA’s administration, and the interests of space scientists wish\xad\ning to collaborate with international partners.  In the late 1970s, NASA had \nproposed a joint venture with the European Space Agency (ESA) called the \nInternational Solar Polar Mission (ISPM).  ESA, formed in 1975 to represent \n10 founding Western European nations in space-related activities, became \nthe primary operating organization for the European space science commu\xad\nnity.  The member countries of ESA have always funded the organization at \nfar lower levels than NASA’s budget, but ESA has steadily increased its capa\xad\nbilities while cultivating a program of world-class science and technological \ndevelopment.  Both the U.S. ', '287\nCHAPTER 12\u2002 •\u2002 International Cooperation In Solar System Exploration \nfocuses on the viewpoint of European space scientists whose “early visions \nof an out-of-ecliptic probe eventually found expression in the Ulysses \nmission.”6 Hufbauer’s analysis builds on another, more narrative history of \nUlysses, told by English space scientist Harry Elliot.7 According to Hufbauer, \nhis account “provides a fuller account of the steps leading up to the mission’s \napproval” and “reveals that European space scientists, always an essential \ngroup of mission proponents, played an increasingly circumscribed role in \nthe campaign that culminated in the ESA/NASA memorandum of under\xad\nstanding for the International Solar Polar Mission.”8 Joan Johnson-Freese \ngives a third account, in which she examines events leading to the cancel\xad\nlation of the U.S.  spacecraft for the ISPM and its potential ramifications for \ninternational cooperation in space.9 She concludes that the whole “poorly \nhandled” affair, itself contingent on the political climate of the then-new \nReagan administration, set a precedent and became an invaluable learning \nexperience for Europe in international space cooperation.10\nIn this chapter, I will revisit the 25-year history of Ulysses, from its origins \nas a proposed OOE mission to its emergence as the dual-spacecraft ISPM \n6.\t  Hufbauer, “European Space Scientists,” p.  170.\n 7.\t\n']","
The International Solar Polar Mission (ISPM) is significant in the context of U.S.-European cooperation in space because it was a joint mission between NASA and ESA that aimed to explore the Sun out of the ecliptic plane, particularly at the poles and other high latitudes. The ISPM had its origins in the mid-1960s, and after a series of working groups, symposia, and conferences, it was officially established as a joint mission with the signing of a memorandum of understanding (MOU) in 1979.

The ISPM is notable because it was one of the most strenuous episodes in the five-decade-long history of international space cooperation between the U.S. and Europe. The mission had its origins in the mid-1960s, when European space scientists worked on building a scientific constituency for an out-of-the ecliptic mission. NASA and ESA established working groups and hosted a number of symposia and conferences to determine both the scientific and technical merits and capabilities of an out-of-ecliptic mission. These efforts resulted in a proposal for the ISPM, which was officially established as a joint mission with the signing of a memorandum of understanding (MOU) between NASA and ESA in 1979.

The ISPM eventually evolved into the Ulysses mission, which was launched in 1990. While NASA and ESA eventually carried out a joint solar polar mission, the evolution of ISPM to Ulysses had a lasting impact on U.S.-European cooperation in space. The ISPM is an important example of how international cooperation in space can be challenging, but also rewarding, as it can lead to the successful launch of important scientific missions."
What is the inherent optimism in early conceptual designs and its effect on cost and schedule growth according to a 2008 study?,"According to a 2008 study, the inherent optimism in early conceptual designs is a common root cause of cost and schedule growth in NASA Science Mission Directorate missions. This optimism can cause underestimation of mass, power, data rate, complexity, and other technical specifications, which then leads to underestimation of cost. This underestimation, coupled with success-oriented schedules implemented to meet a launch window, control overall costs, and/or obtain science quickly, can lead to cost and schedule growth. The study found that the average cost growth was 76 percent over programmatic reserves and that the average schedule growth over and above reserves was 26 percent when the final cost was compared to the cost established at the beginning of Phase B. The study did not identify a common root cause of this growth beyond the inherent optimism in initial conceptual designs due to competitive pressures.","['Chapter 8: Lessons Learned from the Evolution of the Program\n351\ntified addressing each of the findings.  However, the study concluded that problems \nremained, and additional attention was required to control or eliminate these problems \nand contain the resulting impacts to project costs and schedules.115 \nAlthough the Planetary Science Subcommittee in July 2008 called for these results \nto be incorporated into a PI Handbook, no such product exists to date. \n As part of this study, the program office also codified their definition of mission \nsuccess in three parts: “delivering mission science to the PI (meeting the Level\xa01 \nRequirements), ensuring the implementing organization’s success in delivering the \nspacecraft on cost and schedule (meeting the launch date and cost cap), and meeting \nthe program launch frequency requirement for science missions.”116\nInherent Optimism and Cost and Schedule Growth\nA 2008 study of ten NASA Science Mission Directorate missions found that the average \ncost growth was 76 percent over programmatic reserves and that the average schedule \ngrowth over and above reserves was 26 percent when the final cost was compared to \nthe cost established at the beginning of Phase B. The study did not identify a common \nroot cause of this growth beyond “the inherent optimism in initial concept designs \ndue to competitive pressures,” stating that this optimism could cause underestimation \nof mass, power, data rate, complexity, and other technical specifications—which then \nwould lead to underestimation of cost.  This underestimation, coupled with success-\noriented schedules implemented to meet a launch window, control overall costs, and/\nor to obtain science quickly, could lead to cost and schedule growth.117\nThe study was later expanded to 20 missions to quantify the effect of inherent \noptimism in early conceptual designs on cost and schedule growth of NASA Science \nMission Directorate missions.  Cost at selection—the Cost Analysis Data Requirement \n(CADRe) numbers submitted with the CSR—was compared with cost at Preliminary \nDesign Review, Critical Design Review, and launch to quantify mission growth over \ntime and compare it to industry guidelines.  Overall results showed the following life-\ncycle growth: 37 percent in mass, 41 percent in power, 56\xa0percent in cost, 38\xa0percent \nin schedule.  Discovery missions included in the study were Genesis, Deep Impact, \n115 \t\nBarley, B., et al. ', 'Chapter 8: Lessons Learned from the Evolution of the Program\n351\ntified addressing each of the findings.  However, the study concluded that problems \nremained, and additional attention was required to control or eliminate these problems \nand contain the resulting impacts to project costs and schedules.115 \nAlthough the Planetary Science Subcommittee in July 2008 called for these results \nto be incorporated into a PI Handbook, no such product exists to date. \n As part of this study, the program office also codified their definition of mission \nsuccess in three parts: “delivering mission science to the PI (meeting the Level\xa01 \nRequirements), ensuring the implementing organization’s success in delivering the \nspacecraft on cost and schedule (meeting the launch date and cost cap), and meeting \nthe program launch frequency requirement for science missions.”116\nInherent Optimism and Cost and Schedule Growth\nA 2008 study of ten NASA Science Mission Directorate missions found that the average \ncost growth was 76 percent over programmatic reserves and that the average schedule \ngrowth over and above reserves was 26 percent when the final cost was compared to \nthe cost established at the beginning of Phase B. The study did not identify a common \nroot cause of this growth beyond “the inherent optimism in initial concept designs \ndue to competitive pressures,” stating that this optimism could cause underestimation \nof mass, power, data rate, complexity, and other technical specifications—which then \nwould lead to underestimation of cost.  This underestimation, coupled with success-\noriented schedules implemented to meet a launch window, control overall costs, and/\nor to obtain science quickly, could lead to cost and schedule growth.117\nThe study was later expanded to 20 missions to quantify the effect of inherent \noptimism in early conceptual designs on cost and schedule growth of NASA Science \nMission Directorate missions.  Cost at selection—the Cost Analysis Data Requirement \n(CADRe) numbers submitted with the CSR—was compared with cost at Preliminary \nDesign Review, Critical Design Review, and launch to quantify mission growth over \ntime and compare it to industry guidelines.  Overall results showed the following life-\ncycle growth: 37 percent in mass, 41 percent in power, 56\xa0percent in cost, 38\xa0percent \nin schedule. ', '“Improving the life cycle cost management of planetary missions: \nResults from the Life Cycle Cost Growth Study performed by the Discovery and New Frontiers \nProgram Office at NASA Marshall Space Flight Center.” Presentation.\n 117 \t\nFreaner, C., et al.  (2008, 15–16 May).  “An assessment of the inherent optimism in early conceptual \ndesigns and its effect on cost and schedule growth.” Presentation at the 2008 SSCAG/SCAF/EACE \nJoint International Conference in Noordwijk, The Netherlands.\n', 'Indeed, while schedule growth was a real problem \nfor Astrophysics, Earth Science, and Heliophysics missions, it tended to be less of \nan issue for planetary and Discovery missions with fixed launch windows.  Schedule \ngrowth of planetary missions was typically constrained by launch windows, but when \n118 \t\nFreaner, C., et al.  (2010, 9–10 February).  “Conceptual design optimism, cost and schedule growth \neffects.” Presentation at the 2010 NASA Program Management Challenge in Houston, TX.\n', 'These conclusions could be summarized as optimistic heritage \nand technology assumptions, insufficient project insight into contractor performance, \ninadequate planning for mission operations, inadequate mission replans, inadequate \nIntegrated Master Schedules, inadequate time and effort planned to execute fault \nprotection and autonomy, ineffective management structure and unclear roles and \nresponsibilities, project team inexperience, and inadequate consideration of senior-\nlevel expert review team findings.113\nBecause these findings are so significant, the conclusions are explained further in \nthe following figure, the executive summary of this report:\nExecutive Summary\nIn order to improve cost and schedule performance, the Discovery and New Frontiers (D&NF) \nProgram Office studied life cycle cost (LCC) and schedule growth for five missions.  The \ngoal was to identify the underlying causes for the cost overruns and schedule delays, and \nto develop practical mitigations to assist D&NF projects in identifying potential risks and \ncontrolling the associated impacts to proposed mission costs and schedules.  The study found \nnine systemic issues involving project management and systems engineering that were the \nprimary contributors to LCC and schedule growth:\n1. \t Optimistic hardware/software inheritance and technology readiness assumptions \ncaused cost and schedule growth in the detailed design and development phases \n(Phases C/D) for all five missions studied.\n 2. \t Insufficient project management and technical insight into contractor performance \nresulted in poor communications, schedule delays, and technical problems that \nwere manifested as cost overruns in three missions.\n 3. \t']","
A 2008 study found that inherent optimism in early conceptual designs due to competitive pressures can cause underestimation of mass, power, data rate, complexity, and other technical specifications, which then leads to underestimation of cost. This underestimation, coupled with success-oriented schedules implemented to meet a launch window, control overall costs, and/or to obtain science quickly, can result in cost and schedule growth. The study found that the average cost growth was 76 percent over programmatic reserves and the average schedule growth was 26 percent when the final cost was compared to the cost established at the beginning of Phase B. The study was later expanded to 20 missions, which showed overall life-cycle growth of 37 percent in mass, 41 percent in power, 56 percent in cost, and 38 percent in schedule. Discovery missions included in the study were Genesis and Deep Impact."
"What was the significance of the Cassini-Huygens mission in the history of solar system exploration, and what were the main steps of its journey towards Titan?","The Cassini-Huygens mission was the most ambitious effort in solar system exploration ever mounted, consisting of a sophisticated spacecraft performing multiple orbital tours around Saturn and a probe named after Christiaan Huygens, who discovered Saturn's largest satellite in 1655. The mission's name honors two 17th-century astronomers who pioneered modern observations of Saturn and its satellites. The Huygens probe was released from the main spacecraft to parachute through the atmosphere to the surface of Saturn's largest and most interesting moon, Titan. Huygens completed its mission on the very day of its descent through Titan's atmosphere on 14 January 2005, while the nominal mission of the Cassini orbiter came to an end on 30 June 2008, four years after the spacecraft entered orbit around Saturn. NASA approved two extensions of the mission, the last of which ran to 15 September 2017. In this chapter, the author discusses three aspects of the history of Cassini-Huygens from a European perspective, focusing on the institutional framework and decision-making process employed by ESA to develop Huygens and the relationship developed between ESA and NASA to enable the mission to go forward. For ESA, Huygens was more than a mere contribution to a NASA mission; it was ESA's first dedicated solar system exploration mission.","['NASA provided the orbiter, ESA provided the probe, and ASI provided the \nhigh-gain antenna and other hardware systems for the orbiter.  The scientific \ninstruments and related investigations were realized by scientific teams in \nthe United States and in ESA’s member states.  Both the orbiter and the probe \nhave successfully accomplished their scientific missions.  Huygens completed \nits mission on the very day of its descent through Titan’s atmosphere, on \n14\xa0January 2005, while the nominal mission of the Cassini orbiter came to \nan end on 30 June 2008, four years after the spacecraft entered orbit around \nSaturn.  NASA, however, approved two extensions of the mission, the last of \nwhich ran to 15 September 2017.\n In this chapter, I will briefly discuss three aspects of the history of Cassini-\nHuygens as seen from a European perspective.2 First is the institutional \n2.\t  A detailed analysis is in A. Russo, “Parachuting onto Another World: the European Space \nAgency’s Huygens Mission to Titan,” in Exploring the Solar System: The History and Science \nA view of Titan’s surface during Huygens descent on 14 January 2005. ', '225\nCHAPTER 9\nEurope’s Rendezvous with Titan:\nThe European Space Agency’s \nContribution to the Cassini-Huygens \nMission to the Saturnian System\nArturo Russo\nT\nHE CASSINI-HUYGENS MISSION to Saturn and its satellite system is \nthe most ambitious effort in solar system exploration ever mounted.1 \nLaunched in October 1997, the mission was realized as a joint endeavor of \nNASA, the European Space Agency (ESA), and the Italian Space Agency \n(ASI).  It consists of a sophisticated spacecraft performing multiple orbital \ntours around Saturn, as well as a probe that was released from the main \nspacecraft to parachute through the atmosphere to the surface of Saturn’s \nlargest and most interesting moon, Titan.  The mission’s name honors two \n17th-century astronomers who pioneered modern observations of Saturn \nand its satellites.  The orbiter is named after Jean-Dominique Cassini (1625–\n1712), who discovered the satellites Iapetus, Rhea, Tethys, and Dione, as well \nas ring features such as the so-called “Cassini division.” The Titan probe is \nnamed after Christiaan Huygens (1629–95), who discovered Saturn’s largest \nsatellite in 1655. \n', '225\nCHAPTER 9\nEurope’s Rendezvous with Titan:\nThe European Space Agency’s \nContribution to the Cassini-Huygens \nMission to the Saturnian System\nArturo Russo\nT\nHE CASSINI-HUYGENS MISSION to Saturn and its satellite system is \nthe most ambitious effort in solar system exploration ever mounted.1 \nLaunched in October 1997, the mission was realized as a joint endeavor of \nNASA, the European Space Agency (ESA), and the Italian Space Agency \n(ASI).  It consists of a sophisticated spacecraft performing multiple orbital \ntours around Saturn, as well as a probe that was released from the main \nspacecraft to parachute through the atmosphere to the surface of Saturn’s \nlargest and most interesting moon, Titan.  The mission’s name honors two \n17th-century astronomers who pioneered modern observations of Saturn \nand its satellites.  The orbiter is named after Jean-Dominique Cassini (1625–\n1712), who discovered the satellites Iapetus, Rhea, Tethys, and Dione, as well \nas ring features such as the so-called “Cassini division.” The Titan probe is \nnamed after Christiaan Huygens (1629–95), who discovered Saturn’s largest \nsatellite in 1655. \n 1.\t\n The scientific background and technical aspects of the mission are discussed in D.\xa0M. \nHarland, Cassini at Saturn (Berlin, Germany: Springer, 2007).  A U.S.-focused sociological \nanalysis is in B. Groen and C. Hampden-Turner, The Titans of Saturn (London: Marshall \nCavendish, 2005). ', 'Huygens completed \nits mission on the very day of its descent through Titan’s atmosphere, on \n14\xa0January 2005, while the nominal mission of the Cassini orbiter came to \nan end on 30 June 2008, four years after the spacecraft entered orbit around \nSaturn.  NASA, however, approved two extensions of the mission, the last of \nwhich ran to 15 September 2017.\n In this chapter, I will briefly discuss three aspects of the history of Cassini-\nHuygens as seen from a European perspective.2 First is the institutional \n2.\t  A detailed analysis is in A. Russo, “Parachuting onto Another World: the European Space \nAgency’s Huygens Mission to Titan,” in Exploring the Solar System: The History and Science \nA view of Titan’s surface during Huygens descent on 14 January 2005.  (ESA/NASA/JPL/University of \nArizona: PIA08118)\n', '223\nPART V \nExploring the\nOuter Solar System \nT\nHE EUROPEAN SPACE AGENCY’S Huygens probe traveled to its target, \nTitan, with NASA’s flagship Cassini orbiter mission to the Saturn sys\xad\ntem.  In chapter 9, Arturo Russo tells the history of the Cassini-Huygens mis\xad\nsion from a European perspective, focusing on the institutional framework \nand decision-making process employed by ESA to develop Huygens and the \nrelationship developed between ESA and NASA to enable the mission to \ngo\xa0forward.\n For ESA, Huygens was more than a mere contribution to a NASA mis\xad\nsion.  As Russo notes, Huygens was ESA’s first dedicated solar system explo\xad\nration mission. ']","
The Cassini-Huygens mission was a significant event in the history of solar system exploration as it marked the first time a human artifact was landed on another world in the outer solar system. The mission's primary objective was to study Saturn, its rings, and its moons, particularly Titan.

The main steps of the Cassini-Huygens mission towards Titan were as follows:

1. The Cassini spacecraft and the Huygens probe were developed independently by NASA and ESA, respectively.
2. Following a political crisis and a review in 1994 and 1995, the Cassini program, including the Huygens probe and the antenna under development in Italy, underwent an independent review by a team of external experts.
3. The Huygens probe was integrated and tested at Dornier's facilities in Ottobrunn near Munich.
4. In April 1997, the Huygens probe was shipped to NASA's Kennedy Space Center to be fitted to the main spacecraft.
5. The Cassini-Huygens mission was successfully launched from Cape Canaveral on 15 October 1997.
6. After a seven-year cruise, Cassini entered orbit around Saturn on 1 July 2004.
7. Six months later, on 25 December, Huygens was released by the mother spacecraft and started its 20-day, 4-million-kilometer cruise toward Titan.
8. A sequence of parachutes deployed to slow down the Huygens probe during its descent towards Titan's atmosphere.
9. If the probe survived impact with the surface, its instruments were expected to continue to operate, providing additional information for a time ranging from a few minutes to half an hour or more.
10. Out in space, Cassini picked up Huygens’s signals, then turned its antenna toward Earth, and relayed the recorded scientific data.

On 14 January 2005, the Huygens probe successfully landed on Titan, and the first scientific data and images of Titan's surface were relayed back to Earth by the Cassini spacecraft."
What are the four types of helicopters shown in the figure and what are their unique features?,"The given text material does not provide a figure or illustration. However, based on the text, the four types of helicopters are not explicitly mentioned. The text only mentions that helicopter configurations may be classified into five main types and several subclasses. The five main types are not explicitly listed, but they are briefly described as follows:

1. Single Rotor: The helicopter has a single rotor that rotates about a vertical axis, describing a disk in a horizontal or nearly horizontal plane.

2. Tandem Rotor: The helicopter has two counter-rotating rotors mounted on a common mast.

3. Coaxial Rotor: The helicopter has two counter-rotating rotors mounted on a common shaft.

4. Compound Rotor: The helicopter has a main rotor and a smaller rotor mounted on the tail boom.

5. Synchropter: The helicopter has a main rotor and a smaller rotor mounted on the tail boom, but the smaller rotor is designed to operate in synchronization with the main rotor.

The text also mentions that each type has its unique characteristics, advantages, and disadvantages, but it does not provide a detailed explanation of these features.","['The fact that the rotor has a fuselage, \nsource of power, and means of control will be taken for granted, and very little \nattention will be given to the details of mechanical design.  The purpose of the pres\xad\nent chapter is to give the reader a picture of the helicopter as a whole—its geometri\xad\ncal configurations, its means of control, its general design features, its performance \ncharacteristics, and its flying qualities.  This will, it is hoped, provide a background \nand permit a clearer understanding of the following chapters.\n HELICOPTER CONFIGURATIONS\nHelicopter configurations may be classified into five main types and several \nsubclasses.  Each type has its unique characteristics, advantages, and disadvantages. \n These are discussed below.\n The Single Rotor. ', 'The Wind and Beyond, Volume III\n698\nDocument 5-46 (a), Excerpts from Wayne Johnson, Helicopter Theory \n(Princeton, NJ: Princeton University Press, 1980), \nchapter 1, “Introduction,” pp.\xa03–11.\n 1-1\u2002 THE HELICOPTER\nThe helicopter is an aircraft that uses rotating wings to provide lift, propulsion, \nand control.  Figures 1-1 to 1-3 [not reproduced] illustrate the principal helicopter \nconfigurations.  The rotor blades rotate about a vertical axis, describing a disk in \na horizontal or nearly horizontal plane.  Aerodynamic forces are generated by the \nrelative motion of a wing surface with respect to the air. ', 'The Wind and Beyond, Volume III\n698\nDocument 5-46 (a), Excerpts from Wayne Johnson, Helicopter Theory \n(Princeton, NJ: Princeton University Press, 1980), \nchapter 1, “Introduction,” pp.\xa03–11.\n 1-1\u2002 THE HELICOPTER\nThe helicopter is an aircraft that uses rotating wings to provide lift, propulsion, \nand control.  Figures 1-1 to 1-3 [not reproduced] illustrate the principal helicopter \nconfigurations.  The rotor blades rotate about a vertical axis, describing a disk in \na horizontal or nearly horizontal plane.  Aerodynamic forces are generated by the \nrelative motion of a wing surface with respect to the air.  The helicopter with its \nrotary wings can generate these forces even when the velocity of the vehicle itself \nis zero, in contrast to fixed-wing aircraft, which require a translational velocity to \nsustain flight. ', 'Another approach is to allow the pitch \nmotion to take place about torsional flexibility at the root, or tension-torsion straps \nbetween the blade and hub.  Kaman developed a rotor that uses a servo-flap on the \noutboard portion of a torsionally flexible blade.  Servo-flap deflection causes the \nblade to twist, which can be used for the collective and cyclic control of the rotor \nin place of root pitch.\n 7-2\u2002 HELICOPTER TYPES\nThe helicopter configuration primarily involves the number and orientation \nof the main rotors, the means for torque balance and yaw control, and the fuselage \narrangement.  The basic rotor analysis is applicable to all helicopter types, but the \nconfiguration of the helicopter does have an influence on its behavior, notably on \nits stability and control characteristics.\n A single main rotor and tail rotor is the most common configuration.  The \ntail rotor is a small auxiliary rotor used for torque balance and yaw control. ', '687\nDocument 5-45\n(Fig.\xa02-16).  The advantages of such \nsystems are that they prevent the \nfeedback of forces from the rotor \ninto the control system and that \nthey may be arranged so as to pro\xad\nduce favorable effects on the stabil\xad\nity of the machine in flight.\n CONVENTIONAL \nHELICOPTER DESIGN \nFEATURES\nRotor Blades.  The blades of \nconventional helicopter rotors are \nabout fifteen to twenty times as long as they are wide.  Airfoils are used which have \nlow pitching moment coefficients, usually the NACA 00 series (0012, 0015, etc.) \n or the NACA 230 series (23012, 23015, etc.). ']","
A. Paul Cornu's 1907 helicopter: It has twin ""rotors"" that are paddles attached to horizontal bicycle wheels driven by a 24-horsepower engine.
B. Berliner 1922 helicopter: It utilizes rotors that are essentially wooden propellers with special airfoil profiles and pitch distributions. There is also a small, vertically thrusting auxiliary rotor on the rear of the fuselage. Tilting of the rotor shafts provides directional control, and a small grouping of wings in the rotor slipstream allows lateral control.
C. Jens Ellehammer's coaxial rotor helicopter: It has a coaxial rotor design, but it never made a free and controlled flight.
D. Engineering Division's quadrotor helicopter designed by George de Bothezat: It is a quadrotor helicopter that lifts off at McCook Field in 1922."
Question: What is the role of Spacewatch in the Spaceguard survey network and what are some of its achievements?,"Spacewatch was a key component in the development of the Spaceguard survey network. It was a program that used a telescope at Kitt Peak National Observatory in Arizona to search for near-Earth objects (NEOs) and was initiated in 1980. The Spacewatch program was instrumental in identifying the first known NEO, 4179 Toutatis, in 1981. 

In 1998, the NASA Near-Earth Objects Observations Program was established, and it funded renovations to existing telescopes to enable reaching the Spaceguard goal. However, the Spaceguard committee had recommended a survey system based upon the Spacewatch 2,048- by 2,048-pixel sensor with faster readout and data-processing capabilities and seven telescopes 2 meters in diameter, with four detectors each. 

Overall, the Spacewatch program played a significant role in the early detection and identification of NEOs, and its achievements helped to lay the groundwork for the development of more advanced survey systems.","['Amy Mainzer at JPL, who had developed the fine guidance sensor for \nthe Spitzer infrared space telescope, had proposed to NASA’s planetary sci\xad\nence program the adaptation of the Panoramic Survey Telescope and Rapid \nResponse System (Pan-STARRS) moving-objects processing software to \nextract asteroids from the WISE imagery.  She and the rest of the WISE \nscience team knew that WISE would see many asteroids.  She worked with \nSpacewatch Principal Investigator Bob McMillan, who was also on the WISE \nscience team, to understand what would have to be done to identify the aster\xad\noids captured in WISE’s imagery, and with Larry Denneau of the Institute \nfor Astronomy to adapt the unfinished Pan-STARRS software to the task.32 \nThis add-on effort became known as NEOWISE, and while WISE had been \nfunded by NASA’s Astrophysics Division, NEOWISE was funded by the \nNEO Observations Program of the Planetary Science Division and later by \nthe Planetary Defense Coordination Office after it was formed in 2016.\n This initial phase of NEOWISE effectively confirmed that the Spaceguard \nSurvey goal had been met.  While there was some concern that the ground-\nbased surveys had produced results—and population models based on them—\nthat were biased by their inability to observe near the Sun, NEOWISE did \nnot have the same set of biases.  Instead, since it detected only infrared radia\xad\ntion, the asteroids it discovered tended to be the low-albedo (darker) asteroids \nthat the ground-based optical telescopes were less likely to see.\n As of July 2018, NEOWISE had discovered 266 near-Earth asteroids and \n28 comets, defined the albedo distribution for near-Earth asteroids, and dem\xad\nonstrated that there are likely far fewer midsized near-Earth asteroids than \npreviously thought.33 The NEOWISE Principal Investigator, Amy Mainzer, \ncommented, “[T]here are some really dark NEOs in the population, and the \ninteresting thing is that the albedo distribution is roughly the same over a \npretty wide span of sizes, so from a few kilometers down to a few hundred \n32.\t ', 'In 1981, NASA sponsored a “Spacewatch Workshop” in Snowmass, \nColorado, whose participants concluded that that risk of an extinction-level \nevent caused by an asteroid or comet impact with Earth “exceeds risk lev\xad\nels that are sometimes deemed unacceptable by modern societies in other \ncontexts.”34 Thus began efforts by the U.S.  government to better understand \nthe hazard.  The most important development was a 1994 congressional \ndirective to NASA for a comprehensive assessment of potentially hazard\xad\nous NEOs.  The resulting Spaceguard Survey, arguably inspired by Arthur \nClarke’s science fiction novel Rendezvous with Rama and certainly respond\xad\ning to the Shoemaker-Levy 9 impact with Jupiter, began in 1998.  Its task was \nto identify 90 percent of all asteroids larger than 1–2 kilometers in size by \nthe end of 2008.  That goal was reached by the end of 2010, so the attention \nof the program shifted to finding 90 percent of the population larger than \n140 meters.35 In 2005, Congress asked NASA to complete a comprehensive \nsurvey of potentially hazardous sub-kilometer-sized asteroids by 2020.  This \n33.\t ', 'Other subdis\xad\nciplines beyond near-Earth object astronomy had discovered value in repeat \nimaging of the sky—“time domain astronomy” was one increasingly common \nlabel—including those interested in the universe’s hidden mass of dark mat\xad\nter.  But the LSST was to be very expensive, and its advocates had begun to try \nto recruit support from within the NEO community too.  NASA’s Associate \nAdministrator for Space Science, astronomer Edward J. Weiler, had already \nbeen approached informally about supporting it and was not about to do so \nwithout analysis.6\nAt their first meeting in September 2002, the Science Definition Team \n(SDT) discussed a variety of preparatory issues, including how to address \nthe subject of risk.  Simon “Pete” Worden, then representing the Air Force’s \nOffice of Scientific Research, framed the debate as a question of “what to \nworry about more, the very rare huge mass extinction event or the rather \nfrequent Tunguska type event.”7 The Spaceguard Survey goal was designed \nto characterize the risk of the extinction-scale event but contributed little to \nunderstanding the risk of smaller events.  The 1-meter-class telescopes that \nwere performing the current surveys were too small to adequately capture \nthe population of 100-meter-scale objects.  Yet, as Alan W. Harris pointed \nout, most smaller-scale events fall in uninhabited regions of Earth’s surface, \n4.\t\n Near-Earth Object Science Definition Team, “Study To Determine the \nFeasibility of Extending the Search for Near-Earth Objects to Smaller Limiting \nDiameters,” 22\xa0 August 2003, https://www.nasa.gov/sites/default/files/atoms/files/pdco-\nneoreport030825.pdf (accessed 28 April 2021).\n', 'Index\n391\nSteinheim Basin, Germany, 44n38\nSteins asteroid (2867), 184\nsterilization of Earth from impact events, \n101–2\nSteward Observatories, 59, 147\nstishovite, 49\nStokes, Grant, 130, 148, 153, 214, 217, \n220, 223–24, 302\nStrategic Defense Initiative Organization \n(SDIO), 115–16, 119, 119n39\nS-type asteroids, 67–68, 194, 195, 196, \n196n64, 205, 207, 208–9, 209n106\nsubstantive uniformitarianism, 9\nSudan, 275–77\nSudbury Basin, Ontario, 44n38\nSugano-Saigusa-Fujikawa, Comet, 73–74\nSuisei mission, 184\nsulfur, 97\nSun\nasteroids near, search for, 225–26, 237, \n238, 238n58\ndistances of planets from, 14\ninfluence on Earth by, 5\nLagrange points, 221–22, 221\nsunlight reflection.  See albedo/reflectivity\nsurveys/discovery surveys\nachievement of Spaceguard goals, 186, \n213–14, 273\nadvocacy for discovery surveys, 10\nautomation of, 11, 141–42, 146–56, 174\nbudget and funding for, 153, 154, \n155–56, 174, 236–37, 238, 240, \n242, 271\nfollow-up observations of discover\xad\nies by, 153, 153n30, 156, 220, \n238–39, 239n59, 312\nnext-generation surveys, 237–41, 274\nSDT development of recommendations \nfor new search/survey systems, \n220–23, 230–34, 236–37, 273–74\nwhole-sky survey, 145\nSee also Spaceguard/Spaceguard Survey; \nSpacewatch\n“sweet spots,” 237, 238, 238n58\nSwift-Tuttle, Comet (109P), 2, 105, \n121–23, 132, 135, 137\nSzafranski, Richard, 131, 131n75\nT\nTagish Lake, Yukon Territory, impact \nevent, 274–75\nTagliaferri, Edward, 112–13, 114–15, \n118, 123, 276\nTamkin, Steven, 158\nTancredi, Gonzalo, 125n59\nTantardini, Marco, 256–57\nTaylor, Gordon, 176\nTaylor, Patrick, 162, 189\nTaylor, Theodore, 108\nTeapot Ess nuclear bomb test crater, 47, \n48\ntechnology\nadvances in and NEO discoveries, \n10–11, 173–74, 307–8, 312–15\ncomputational and experimental meth\xad\nods for impact research, 49\norbit determination techniques and \nadvances in, 16n7\nTedeschi, William, 120\ntelepossession claims, 265, 265n76\ntelescopes\nelectronic asteroid-hunting telescope, \n240–41\nNear-Earth Objects Survey Working \nGroup recommendations for, 129\nphotographic images from cameras \naffixed to, 19–22, 21–22n20, \n21\nSDT ground-based and space-based \nsurvey telescopes recommenda\xad\ntions, 220–23, 231–33, 302–3\nSee also Hubble Space Telescope; \nSpacewatch\nTeller, Edward, 115–16, 119, 120\nTeller asteroid, 116\nTempel 1, Comet, 184, 199–201, \n199n71, 199, 200n76, 201–2, \n235–36, 283, 283n29\nTertiary period, 79n1\nTetrabiblos (Ptolemy), 3\nTexas Instruments, 58\nThemis (24) and Themis family, 182–83, \n183n25, 192\nthermal models and standard thermal \nmodel (STM), 177–80\n', 'A History of Near-Earth Objects Research\n146\nThese simulation studies led the Spaceguard committee to recommend a \nsurvey system based upon the Spacewatch 2,048- by 2,048-pixel sensor with \nfaster readout and data-processing capabilities and seven telescopes 2 meters \nin diameter, with four detectors each.  Fewer, larger telescopes could be substi\xad\ntuted, but they needed to be distributed between both hemispheres.9 A coor\xad\ndination center would be necessary to assure monthly sky coverage, and of \ncourse it would need some sort of data system.  They expected this Spaceguard \nSurvey system to cost about $50 million to build and $10 to $15 million per \nyear to operate.10\nNothing like the Spaceguard Survey system would actually be built. \n Instead, when the NASA Near-Earth Objects Observations Program was \nestablished in 1998, it funded renovations to existing telescopes to enable \nreaching the Spaceguard goal.\n']","
Spacewatch is a part of the Spaceguard survey network, which is a group of telescopes and observatories that search for near-Earth objects (NEOs). The primary goal of the Spaceguard survey network is to discover and track NEOs to determine if any of them pose a threat to Earth. Spacewatch has made significant contributions to this effort by discovering and tracking numerous NEOs since its inception in the late 1980s.

Spacewatch is located at the Kitt Peak National Observatory in Arizona and uses a 0.9-meter telescope and a 1.8-meter telescope to search for NEOs. The observatory has discovered over 1,500 asteroids and comets, including the asteroid 1997 XF11, which was initially thought to have a small chance of impacting Earth. Spacewatch was also instrumental in confirming the impact of the Shoemaker-Levy 9 comet with Jupiter in 1994.

The Spacewatch team has developed innovative techniques for detecting and tracking NEOs, including the use of automated discovery algorithms and drift scanning techniques. The observatory has also played a role in the Spaceguard Survey report, which outlines the goals and achievements of the Spaceguard survey network.

In summary, Spacewatch is a key component of the Spaceguard survey network and has made significant contributions to the discovery and tracking of NEOs. Its achievements include the discovery of over 1,500 asteroids and comets and the development of innovative techniques for detecting and tracking NEOs."
"What was the impact of the ""faster, better, cheaper"" initiative on the failures of the Mars missions in 1999? What was the conclusion of the special assessment team reviewing the failure of the three Mars missions regarding the ""faster, better, cheaper"" approach?","The ""faster, better, cheaper"" initiative was implemented in response to the failure of the Mars Observer spacecraft in 1993. The Mars program hit a dead end due to the lack of funding for another mission of similar profile. NASA Administrator Daniel Goldin pushed for a new approach called ""faster, better, cheaper"" science mission programs, which aimed to reverse the trend of science missions growing larger and more expensive. The goal was to achieve economy without significant reductions in reliability.

Regarding the impact of the ""faster, better, cheaper"" initiative on the failures of the Mars missions in 1999, the article does not provide a direct answer. However, it does mention that many critics of the initiative claimed that it was ""too much, too cheap, too soon"" and that perhaps one could expect to attain one or two of the ""faster, better, cheaper"" goals, but not all three. But program proponents responded that there were many successes and that most of the failures had resulted from mistakes that either would not have been detected under different management techniques or that had not been detected due to improper application of the ""faster, better, cheaper"" procedures.

A special assessment team reviewing the failure of the three Mars missions concluded that the ""faster, better, cheaper"" approach was an effective concept that should be continued. The article notes that this conclusion is debatable, and a closer examination of NASA's ""faster, better, cheaper"" initiative revealed an admirable record of success, along with helpful and illuminating lessons for anyone involved in developing and fielding high-tech systems. Far from an embarrassing failure or proof that program managers must 'pick two,' the ""faster, better, cheaper"" initiative actually improved cost, schedule, and performance all at once. NASA's experience provides an insightful organizational roadmap for sustaining mission success while respecting constraints of time and funding.","['Of these projects, six of the missions \n(38 percent) resulted in some sort of failure.12\nThe extent to which the “faster, better, cheaper” initiative impacted the \nabove failures is debatable.  Many critics of the initiative claimed that it was \n“too much, too cheap, too soon” and that perhaps one could expect to attain \none or two of the “faster, better, cheaper” goals, but not all three.  But program \nproponents responded that there were many successes and that most of the \nfailures had resulted from mistakes that either would not have been detected \nunder different management techniques or that had not been detected due \nto improper application of the “faster, better, cheaper” procedures.  (Indeed, \na special assessment team reviewing the failure of the three Mars missions \nconcluded that the “faster, better, cheaper” approach was an effective concept \nthat should be continued).13 A 2010 assessment of the lessons learned from \nNASA’s “faster, better, cheaper” initiative noted that\n[A] closer examination of NASA’s FBC [faster, better, cheaper] \nreveals an admirable record of success, along with helpful and illu\xad\nminating lessons for anyone involved in developing and fielding \nhigh-tech systems.  Far from an embarrassing failure or proof that \nprogram managers must ‘pick two,’ the FBC initiative actually \nimproved cost, schedule, and performance all at once.  NASA’s \nexperience provides an insightful organizational roadmap for \nsustaining mission success while respecting constraints of time \nand funding.14\nWhatever the position one takes, the “faster, better, cheaper” management \nconstruct must be kept in mind as one examines the emergent RLV program, \nand NASA’s many other 1990s activities.\n NASA and OMB Agreement on Initial Single-Stage-to-Orbit\nProgram Criteria\nNASA and the Office of Management and Budget (OMB) entered into an \nagreement on December 30, 1994, which set criteria for the decisions to pro\xad\nceed to a Phase II and Phase III of the single-stage-to-orbit program. ', 'When the Mars Observer spacecraft, launched on a Titan III ELV, was lost \nin 1993, NASA’s Mars program hit a dead end.  There was no money avail\xad\nable to fly another mission of similar profile, given that the Mars Observer \nwas a billion-dollar program.  Mars Observer had been freed from the earlier \nrequirement of human rating, but the mission reflected the dominance that \nrequirement had over space science at the time.\n For space science missions, NASA Administrator Daniel Goldin pushed \nfor a new approach called “faster, better, cheaper.” The goal of this approach \nwas to reverse the trend of science missions growing larger and more expen\xad\nsive, the abortive Mars Observer mission being one much-cited exam\xad\nple.28 “Faster, better, cheaper” science mission programs initiated at NASA \nincluded the Discovery program in 1992, the New Millennium program in \n1995, an expanded Mars exploration program with a mission planned every \ntwo years, and the Origins program.  According to NASA:\nThrough Goldin’s aggressive management reforms, annual budgets have \nbeen reduced, producing a $40 billion reduction from prior budget plans.  He \nimplemented a more balanced aeronautics and space program by reducing \nhuman space flight funding from 48 percent of NASA’s total budget to 38 \npercent and increasing funding for science and aerospace technology from \n31 to 43 percent….\n Goldin also cut the time required to develop Earth- and space-science space\xad\ncraft by 40 percent and reduced the cost by two-thirds, while increasing the \naverage number of missions launched per year about four times. ', 'Three Pathways to Space\n35\nThe overall program objectives common to all three demonstrators included\n1.\t development of an integrated systems test bed for advanced technologies;\n2.\t demonstration of capabilities in realistic ground and flight environ\xad\nments for a next-generation system;\n3.\t demonstration of operability, maintainability, and reusability required \nfor a next-generation system;\n4.\t demonstration of rapid prototyping; and\n5.\t demonstration of the ability to perform “faster, better, cheaper.”\nAn additional objective that applied specifically to the X-33 program was \nthe demonstration of a mass fraction scalable to full-scale single-stage-to-orbit \nuse.4 Two of the RLV programs, the X-33 and X-34, were conducted under \nNASA’s new management concept popularly known as “faster, better, cheaper.”\nA New Way of Doing Business—the “Faster, Better, Cheaper” Concept\nFollowing his appointment as NASA Administrator in 1992, Daniel S. Goldin \ninitiated a widely heralded “faster, better, cheaper” management program \nintended to “revolutionize the structure of NASA.”5 Its objectives were “to cut \ncosts, take greater risks, and dispatch [robotic] spacecraft that actually flew.”6 \nProponents of the initiative also sought to achieve economy without signifi\xad\ncant reductions in reliability.  These objectives were to be achieved through \nchanges in technology and management.  For a project to be included as part \nof the “faster, better, cheaper” initiative it had “to have a substantially reduced \ncost ceiling, to be placed on a compressed development schedule, and to have \nsomeone with executive responsibility in NASA designate it a ‘faster, better, \ncheaper’ project.”7\nThe concept represented a major cultural change—indeed a veritable \nreversal—compared to how NASA had previously operated, with the excep\xad\ntion of some of its constituent Centers, such as the then-Dryden Flight \nResearch Facility (now Armstrong Flight Research Center), which had a \nrecord of promoting and executing some remarkably sophisticated research \nprojects quickly and economically.  As a result, the new management initiative \nmet with significant bureaucratic resistance within the Agency. ', 'Three Pathways to Space\n35\nThe overall program objectives common to all three demonstrators included\n1.\t development of an integrated systems test bed for advanced technologies;\n2.\t demonstration of capabilities in realistic ground and flight environ\xad\nments for a next-generation system;\n3.\t demonstration of operability, maintainability, and reusability required \nfor a next-generation system;\n4.\t demonstration of rapid prototyping; and\n5.\t demonstration of the ability to perform “faster, better, cheaper.”\nAn additional objective that applied specifically to the X-33 program was \nthe demonstration of a mass fraction scalable to full-scale single-stage-to-orbit \nuse.4 Two of the RLV programs, the X-33 and X-34, were conducted under \nNASA’s new management concept popularly known as “faster, better, cheaper.”\nA New Way of Doing Business—the “Faster, Better, Cheaper” Concept\nFollowing his appointment as NASA Administrator in 1992, Daniel S. Goldin \ninitiated a widely heralded “faster, better, cheaper” management program \nintended to “revolutionize the structure of NASA.”5 Its objectives were “to cut \ncosts, take greater risks, and dispatch [robotic] spacecraft that actually flew.”6 \nProponents of the initiative also sought to achieve economy without signifi\xad\ncant reductions in reliability.  These objectives were to be achieved through \nchanges in technology and management.  For a project to be included as part \nof the “faster, better, cheaper” initiative it had “to have a substantially reduced \ncost ceiling, to be placed on a compressed development schedule, and to have \nsomeone with executive responsibility in NASA designate it a ‘faster, better, \ncheaper’ project.”7\nThe concept represented a major cultural change—indeed a veritable \nreversal—compared to how NASA had previously operated, with the excep\xad\ntion of some of its constituent Centers, such as the then-Dryden Flight \nResearch Facility (now Armstrong Flight Research Center), which had a \nrecord of promoting and executing some remarkably sophisticated research \nprojects quickly and economically.  As a result, the new management initiative \nmet with significant bureaucratic resistance within the Agency.  Prior to the \n“faster, better, cheaper” management initiative, NASA had relied primarily \non a systems-management approach drawn largely from the defense acquisi\xad\ntion world, which was based on what had worked in the 1950s and during \nthe Apollo era, an era of big projects, lofty goals, and robust funding.  But \nit is a veritable natural law that, over time, organizations tend to become \nboth more complex and bureaucratically moribund, developing an internal \nsclerosis and sluggishness.\n', 'Chapter 8: Lessons Learned from the Evolution of the Program\n299\nOSS in terms of both policy and budget; and Recommendation 6, “Encourage interna\xad\ntional collaboration in all sizes and classes of missions, so that international missions \nwill be able to fill key niches in NASA’s space and Earth science programs.  Specifically, \nrestore separate, peer-reviewed Announcements of Opportunity for enhancements to \nforeign-led space research missions.6 The former was a policy for a few years, until an \noverdependence on international collaborations caused the Associate Administrator \nto resist selecting proposals with heavy dependence on foreign instruments, and the \nlatter finally became a policy with the initiation of the first Stand-ALone Missions of \nOpportunity Notice (SALMON) in 2008.\n The committee report noted several findings on the effectiveness of the faster, \nbetter, cheaper approach, with an important caveat: “Policy makers looking for guid\xad\nance on these programs in terms of cost and size trade-offs should be made aware \nthat the variables are more numerous and much more complex than might at first be \nsupposed.”7 While this is certainly true, the 1999 National Research Council findings \nare included here as external evaluations of the Discovery and Explorer programs run \nin the faster, better, cheaper mode.\n The committee supports several principles being implemented in the FBC methodology. \n Specifically, it found a number of positive aspects of the FBC approach, including the following:\n• \t A mixed portfolio of mission sizes is crucial in virtually all Earth and space sci\xad\nence disciplines to accomplish the various research objectives.  The FBC approach \nhas produced useful improvements across the spectrum of programs regardless of \nabsolute mission size or cost.\n']","
The impact of the ""faster, better, cheaper"" initiative on the failures of the Mars missions in 1999 is debatable. Critics claimed that it was ""too much, too cheap, too soon"" and that perhaps one could expect to attain one or two of the ""faster, better, cheaper"" goals, but not all three. However, program proponents responded that most of the failures had resulted from mistakes that either would not have been detected under different management techniques or that had not been detected due to improper application of the ""faster, better, cheaper"" procedures. A special assessment team reviewing the failure of the three Mars missions concluded that the ""faster, better, cheaper"" approach was an effective concept that should be continued. A 2010 assessment of the lessons learned from NASA’s “faster, better, cheaper” initiative noted that the initiative improved cost, schedule, and performance all at once and provided an insightful organizational roadmap for sustaining mission success while respecting constraints of time and funding."
"Question: What was the underlying idea behind the European initiative for a Saturn/Titan mission in the 1982-83 period, and what were the specific objectives for the mission?","The underlying idea behind the European initiative for a Saturn/Titan mission in the 1982-83 period was to study the whole of the Saturnian system, including specific objectives for the planet and its rings, the magnetosphere, the icy satellites, and Titan. The project, named ""Project Cassini,"" called for a Saturn orbiter carrying a probe to be parachuted through the atmosphere of Titan. The project was to be realized by an ESA-NASA collaboration, with Europe providing the orbiter and NASA the Titan probe. The group of 29 European scientists who submitted the proposal to ESA in July 1982 represented 18 scientific institutions from seven ESA member states, and their membership included representatives of four disciplines: atmospheric science, planetology, magnetosphere physics, and exobiology. The idea of ""system science"" was also an important element in fostering support for the Cassini project within the European planetary science community and promoting the mission through ESA's highly competitive selection process.","['Titan could pro\xad\nvide Earth’s human inhabitants with an opportunity to travel back in time, \nas it were, if they could only get there.5\nBUILDING UP A SCIENTIFIC AND INSTITUTIONAL CONSTITUENCY\nThe foundations for an ESA-NASA collaboration for a mission to Saturn and \nTitan were established in 1982–83.6 In July 1982, a group of 29 European \nscientists submitted to ESA a proposal for a Saturn/Titan mission to be real\xad\nized in the framework of Horizon 2000.7 “Project Cassini,” as they named \nit, called for a Saturn orbiter carrying a probe to be parachuted through the \natmosphere of Titan.  The project was to be realized by an ESA-NASA col\xad\nlaboration, with Europe providing the orbiter and NASA the Titan probe. \n Eighteen scientific institutions from seven ESA member states were repre\xad\nsented in the group, whose membership included representatives of four \ndisciplines: atmospheric science, planetology, magnetosphere physics, and \nexobiology.  The underlying idea was to study the whole of the Saturnian sys\xad\ntem, including specific objectives for the planet and its rings, the magneto\xad\nsphere, the icy satellites, and Titan.  This concept of “system science” would \nhave been an important element in fostering support for the Cassini project \nwithin the European planetary science community and promoting the mis\xad\nsion through ESA’s highly competitive selection process.\n The European initiative had a counterpart on the other side of the \nAtlantic.  A Saturn orbiter–Titan probe mission was among those recom\xad\nmended by the Solar System Exploration Committee (SSEC) of the NASA \nAdvisory Council. ', '50 YEARS OF SOLAR SYSTEM EXPLORATION: HISTORICAL PERSPECTIVES\n230\nplate tectonics, and the evolution of life itself have obliterated all records of \nthose original conditions and processes on our Blue Planet.  Titan could pro\xad\nvide Earth’s human inhabitants with an opportunity to travel back in time, \nas it were, if they could only get there.5\nBUILDING UP A SCIENTIFIC AND INSTITUTIONAL CONSTITUENCY\nThe foundations for an ESA-NASA collaboration for a mission to Saturn and \nTitan were established in 1982–83.6 In July 1982, a group of 29 European \nscientists submitted to ESA a proposal for a Saturn/Titan mission to be real\xad\nized in the framework of Horizon 2000.7 “Project Cassini,” as they named \nit, called for a Saturn orbiter carrying a probe to be parachuted through the \natmosphere of Titan.  The project was to be realized by an ESA-NASA col\xad\nlaboration, with Europe providing the orbiter and NASA the Titan probe. \n Eighteen scientific institutions from seven ESA member states were repre\xad\nsented in the group, whose membership included representatives of four \ndisciplines: atmospheric science, planetology, magnetosphere physics, and \nexobiology.  The underlying idea was to study the whole of the Saturnian sys\xad\ntem, including specific objectives for the planet and its rings, the magneto\xad\nsphere, the icy satellites, and Titan. ', 'National Research Council.  In April \n1982, these two organizations established a Joint Working Group to define \na framework for ESA-NASA cooperation in solar system exploration.  The \nJoint Working Group eventually recommended that three missions should \nbe carried out as cooperative projects by the turn of the century.  Listed in \norder of launch, they were a Saturn orbiter and Titan probe, a multiple aster\xad\noid orbiter, and a Mars surface rover.8 \nAn assessment study of the Cassini project was conducted between April \n1984 and June 1985 by a team of 13 scientists, 9 from the United States and \n4 from Europe.9 Reversing the idea of the original proposal, the Titan probe \nwas soon identified as ESA’s contribution to the mission, while NASA would \nprovide the main spacecraft, based on the Mariner Mark II spacecraft under \ndevelopment at the Jet Propulsion Laboratory (JPL).  The latter was a key \nelement of the SSEC core program, a family of large spacecraft dedicated \nto solar system exploration.  The Titan probe, for its part, was considered \nwithin the technical capabilities of the European space industry, and the \nestimated costs were within the budget allocated to a standard mission of \nHorizon\xa02000.\n The Challenger accident in January 1986 forced a dramatic redefinition \nof NASA’s plans. ', '225\nCHAPTER 9\nEurope’s Rendezvous with Titan:\nThe European Space Agency’s \nContribution to the Cassini-Huygens \nMission to the Saturnian System\nArturo Russo\nT\nHE CASSINI-HUYGENS MISSION to Saturn and its satellite system is \nthe most ambitious effort in solar system exploration ever mounted.1 \nLaunched in October 1997, the mission was realized as a joint endeavor of \nNASA, the European Space Agency (ESA), and the Italian Space Agency \n(ASI).  It consists of a sophisticated spacecraft performing multiple orbital \ntours around Saturn, as well as a probe that was released from the main \nspacecraft to parachute through the atmosphere to the surface of Saturn’s \nlargest and most interesting moon, Titan.  The mission’s name honors two \n17th-century astronomers who pioneered modern observations of Saturn \nand its satellites.  The orbiter is named after Jean-Dominique Cassini (1625–\n1712), who discovered the satellites Iapetus, Rhea, Tethys, and Dione, as well \nas ring features such as the so-called “Cassini division.” The Titan probe is \nnamed after Christiaan Huygens (1629–95), who discovered Saturn’s largest \nsatellite in 1655. \n', '6.\t  W. Ip, D. Gautier, and T. Owen, “The Genesis of Cassini-Huygens,” in Titan: From Discovery \nto Encounter (Noordwijk: ESA SP-1278, 2004): 211–227.\n 7.\t\n Project Cassini: A Proposal to the European Space Agency for a Saturn Orbiter/Titan Probe \nMission in Response to the Call for Mission Proposals Issued on 6th July 1982, 12 November \n1982.  The author thanks Professor Wing-Huen Ip for providing him with a copy of this \ndocument.\n']","
The underlying idea behind the European initiative for a Saturn/Titan mission in the 1982-83 period was to study the whole of the Saturnian system, including specific objectives for the planet and its rings, the magnetosphere, the icy satellites, and Titan. This concept of 'system science' was important in fostering support for the Cassini project within the European planetary science community and promoting the mission through ESA's competitive selection process.
The specific objectives for the mission included a Saturn orbiter carrying a probe to be parachuted through the atmosphere of Titan. The project was to be realized by an ESA-NASA collaboration, with Europe providing the orbiter and NASA the Titan probe. The mission was called 'Project Cassini' and was proposed by a group of 29 European scientists from 18 scientific institutions from seven ESA member states, representing four disciplines: atmospheric science, planetology, magnetosphere physics, and exobiology."
"Based on the context information, what was the engine controversy about and what were the guidelines provided by NASA for the use of foreign technology in the RLV program?","The engine controversy was about whether to use the lower-performance Rocketdyne RS-27 engine used on the Delta rocket or the higher-performance Russian NPO Energomash RD-120 engine used as the second stage on the Russian Zenit rocket and then being marketed in America by Pratt & Whitney. The controversy lasted into late November, when, in a series of telephone conferences, Payton, Michael Griffin (of American Space Lines, and future NASA Administrator), and Robert Minor (president of Rockwell Space Systems Division) tentatively agreed to use the Russian engine.
 <|>

The guidelines provided by NASA for the use of foreign technology in the RLV program stated that foreign participation must provide clear net benefits for the achievement of the program's technical and business objectives, federal funds may not be used for foreign-based RLV development of foreign technology unless specifically exempted by the NASA Administrator, and importation of foreign technology must not threaten the successful execution of the program, both in its developmental and operational phases.","['Rockwell argued, and not without very good reason, that \nthe lower-performance Rocketdyne RS-27 engine used on the Delta rocket was \na better choice, given the political instability then wracking the former Soviet \nUnion.  Indeed, Rockwell reportedly threatened to leave the partnership if the \nRocketdyne engine was not selected.54 NASA threatened to withdraw from the \nprogram and was persuaded to continue only after direct intervention from \nthe White House’s Office of Science and Technology Policy (OSTP).  Lionel \nJohns, associate director for technology in OSTP\n, informed Gary Payton that \nNASA would have to work with Orbital and Rockwell to resolve the engine \ndispute.55 The controversy lasted into late November, when, in a series of tele\xad\nphone conferences, Payton, Michael Griffin (of American Space Lines, and \nfuture NASA Administrator), and Robert Minor (president of Rockwell Space \nSystems Division) tentatively agreed to use the Russian engine.56\nBut this shorthand summary is hardly adequate to address what was a more \ncomplex controversy, and thus some background and further explanation are \nwarranted.  Just prior to the conflict’s eruption, NASA had released policy and \nguidelines for the use of foreign technology in the RLV program, stating in part: \n“The RLV technology development and demonstration program may seek to \ntake advantage of all beneficial components and technologies, both foreign and \ndomestic, in developing United States next-generation space transportation \nsystems.  Foreign participation in X-33 and X-34 projects will be undertaken \non a company-to-company contractual basis and will be conducted with the \npolicy and guidelines in this document.”57 \nThe guidelines outlined several points:\n1.\t  Foreign participation must provide clear net benefits for \nthe achievement of the program’s technical and business \nobjectives.\n 2.\t ', 'NASA \nwanted the higher-performance Russian NPO Energomash RD-120, used as the \nsecond stage on the Russian Zenit rocket and then being marketed in America \nby Pratt & Whitney.  Rockwell argued, and not without very good reason, that \nthe lower-performance Rocketdyne RS-27 engine used on the Delta rocket was \na better choice, given the political instability then wracking the former Soviet \nUnion.  Indeed, Rockwell reportedly threatened to leave the partnership if the \nRocketdyne engine was not selected.54 NASA threatened to withdraw from the \nprogram and was persuaded to continue only after direct intervention from \nthe White House’s Office of Science and Technology Policy (OSTP).  Lionel \nJohns, associate director for technology in OSTP\n, informed Gary Payton that \nNASA would have to work with Orbital and Rockwell to resolve the engine \ndispute.55 The controversy lasted into late November, when, in a series of tele\xad\nphone conferences, Payton, Michael Griffin (of American Space Lines, and \nfuture NASA Administrator), and Robert Minor (president of Rockwell Space \nSystems Division) tentatively agreed to use the Russian engine.56\nBut this shorthand summary is hardly adequate to address what was a more \ncomplex controversy, and thus some background and further explanation are \nwarranted.  Just prior to the conflict’s eruption, NASA had released policy and \nguidelines for the use of foreign technology in the RLV program, stating in part: \n“The RLV technology development and demonstration program may seek to \ntake advantage of all beneficial components and technologies, both foreign and \ndomestic, in developing United States next-generation space transportation \nsystems.  Foreign participation in X-33 and X-34 projects will be undertaken \non a company-to-company contractual basis and will be conducted with the \npolicy and guidelines in this document.”57 \nThe guidelines outlined several points:\n1.\t  Foreign participation must provide clear net benefits for \nthe achievement of the program’s technical and business \nobjectives.\n', '\x07\nGuidelines for use of foreign \ntechnology:\n1.  \x07\nForeign participation must provide clear net benefits \nto the achievement of the program’s technical and \nbusiness objectives.\n 2.  \x07\nFederal funds may be used for manufacture or \nacquisition of flight-ready foreign component \ntechnology but may not be used for foreign-based \nRLV development of foreign technology unless \nspecifically exempted by the NASA Administrator.\n 3.  \x07\nImportation of foreign technology must not threaten \nthe successful execution of the program, both in its \ndevelopmental and operational phases.\n 4. ', 'Orbital’s leadership were par\xad\nticularly concerned about the cost of the X-34B, as well as a lack of a potential \ncommercial market.  Then there were the technical concerns regarding the risk \nof a collision launching from the top of the NASA 747.  These concerns caused \nOrbital to move in favor of a smaller vehicle like the X-34A or scaled-down \nX-34B that would be launched by dropping the vehicle from the underside of \nOrbital’s L-1011.66 \nThe White House and NASA Attempt To Resuscitate the Program\nA November 3, 1995, memorandum from the Office of Science and Technology \nPolicy to Goldin outlined both the office’s concerns about deviating from the \noriginal program objectives and the office’s desire for NASA to try to resolve \nthe differences between Orbital and Rockwell.  The memorandum also gave an \nindication that disagreement on which engine to use was a factor endanger\xad\ning the continuation of the program and that NASA was at least somewhat \ninvolved in the dispute.  The policy office expressed concern that the pro\xad\ngram was changing the focus by developing a low-cost operational vehicle as \nopposed to the original objectives, as reviewed in the following paragraph in \nthe memorandum:\nWe are concerned with NASA’s apparent change in the X-34 pro\xad\ngram’s main objectives.  We approved the program last year as a \ntechnology program that would: 1) demonstrate advanced tech\xad\nnologies and efficient operations applicable to a future low cost \nlaunch system; 2) help prove the economies of reusability; and \n3)\xa0demonstrate that new ways of doing business in an industry-\nled format could reduce costs and development time—and meet \nthese objectives in a timely fashion in order to contribute to the \nX-33 program and, ultimately, to a RLV decision.  An added \nbonus to the program would be if through industry’s cost share, \nthe X-34 would become an operational vehicle that could bet\xad\nter enable agency needs. ', 'Promise Denied\n86\n4.\t  Due consideration must be given to fostering United States \ncompetitiveness and safeguarding national security inter\xad\nests throughout the life of the program. \n 5.\t  Close consultation must be maintained with NASA and other \nappropriate agencies on all aspects of foreign participation.58\nPrior to the release of the foreign technology guidelines, Payton, in a May \n25, 1995, note to Daniel S. Goldin, detailed the growing engine controversy \nand provided his recommendation regarding which engine to use.  Payton \nstated that “[t]he partnership has formally agreed to the configuration that will \nfly off the 747/Shuttle carrier aircraft…[but that] Rockwell and Orbital have \nnot yet agreed to the propulsion system.”59 The price for two Rocketdyne RS-27 \nengines was $20 million [$32 million in 2016].  But United Technologies \nCorporation’s (UTC) Pratt & Whitney was offering what Payton wrote \n“appears too good to be true.” It would furnish a mockup for testing, plus two \nRD-120 engines (each guaranteed for 20 firings), at no up-front procurement \ncosts, but at a cost of $100,000 [$158,000 in 2016] per flight, which would \nbe reduced to $75,000 [$119,000 in 2016] per flight by the 40th X-34 mis\xad\nsion.  Also, P&W would absorb the $10 million [$16 million in 2016] design, \ndevelopment, test, and evaluation (DDT&E) estimated costs to integrate the \nRD-120 into the X-34. ']","
The engine controversy was about the choice of engine for the X-34, with NASA wanting the higher-performance Russian NPO Energomash RD-120 and Rockwell arguing for the lower-performance Rocketdyne RS-27 engine. The controversy lasted for several weeks and was only resolved after direct intervention from the White House’s Office of Science and Technology Policy.

NASA provided guidelines for the use of foreign technology in the RLV program, which stated that foreign participation must provide clear net benefits for the achievement of the program’s technical and business objectives, U.S. Government funds may be used for the manufacture or acquisition of flight-ready foreign component technology but cannot be used for foreign-based RLV development of foreign technology, and the use of foreign technology must not threaten the successful execution of the program in either its developmental or operational stages."
"What were the factors that contributed to the ease of handling of the Clipper, and what was the rationale behind providing spacious quarters for the crew?","The factors that contributed to the ease of handling of the Clipper included proper distribution of responsibility among the crew, the arrangement and convenience of all controls, equipment, and instruments, the comfort and accommodations provided for those members of the crew, both on and off duty, efficient and simple methods for loading fuel, cargo, and passengers, arrangement of mooring devices, and methods of beaching. The rationale behind providing spacious quarters for the crew was that the Clipper was primarily a long-range transport, and every effort should be made to provide the crew with every conceivable aid, not only in equipment but in comfort and accommodations. It was decided that the duties of the crew should be so delegated that a flight crew of six would be on duty at all times.","['This, and a certain amount of interference with fin and rudder effec\xad\ntiveness caused by the large proportions of the after part of the hull, led to a change \nto three fins and two rudders.  The final tail design produced excellent flying char\xad\nacteristics, resulting in an aircraft which would stay almost dead on course for \nprotracted lengths of time and yet retain the lightness of control of a pursuit\xa0plane.\n Throughout the design of the mechanical details and arrangements of the \nClipper we had kept in mind the second point in our list of objectives—efficient \noperation with a minimum of fatigue to the crew and a minimum of maintenance.\n Factors contributing to the ease of handling include proper distribution of \nresponsibility among the crew[;] the arrangement and convenience of all controls, \nequipment and instruments[;] the comfort and accommodations provided for the \nmembers of the crew, both on and off duty[;] efficient and simple methods for load\xad\ning fuel, cargo and passengers[;] arrangement of mooring devices[;] and methods \nof beaching.\n At the outset it was recognized that this aircraft was primarily a long-range \ntransport and that every effort should be made to provide the crew with every \nconceivable aid, not only in equipment, but in comfort and accommodations.  It \nwas decided that the duties of the crew should be so delegated that a flight crew of \nsix would be on duty at all times, and that spacious quarters should be provided \nfor their use.  These crew positions were to be: the master, whose duty it is to cor\xad\nrelate the functions of the other crew members; the first and second pilots, whose \nduties are to fly in a given direction at a given altitude and speed, in accordance \nwith data furnished by the navigator whose position is self explanatory; the flight \nengineer, responsible for the proper functioning of the power plants, including the \n', 'Although the original specifications stated \nthat the aircraft should be only slightly stable directionally, it was found during \nflight tests that this requirement was in error because the great amount of lateral \nstability inherent to this type of aircraft necessitated considerably more directional \nstability in order to keep the ratio of lateral and directional stability within a rea\xad\nsonable range.  This, and a certain amount of interference with fin and rudder effec\xad\ntiveness caused by the large proportions of the after part of the hull, led to a change \nto three fins and two rudders.  The final tail design produced excellent flying char\xad\nacteristics, resulting in an aircraft which would stay almost dead on course for \nprotracted lengths of time and yet retain the lightness of control of a pursuit\xa0plane.\n Throughout the design of the mechanical details and arrangements of the \nClipper we had kept in mind the second point in our list of objectives—efficient \noperation with a minimum of fatigue to the crew and a minimum of maintenance.\n Factors contributing to the ease of handling include proper distribution of \nresponsibility among the crew[;] the arrangement and convenience of all controls, \nequipment and instruments[;] the comfort and accommodations provided for the \nmembers of the crew, both on and off duty[;] efficient and simple methods for load\xad\ning fuel, cargo and passengers[;] arrangement of mooring devices[;] and methods \nof beaching.\n At the outset it was recognized that this aircraft was primarily a long-range \ntransport and that every effort should be made to provide the crew with every \nconceivable aid, not only in equipment, but in comfort and accommodations.  It \nwas decided that the duties of the crew should be so delegated that a flight crew of \nsix would be on duty at all times, and that spacious quarters should be provided \nfor their use. ', 'This item relates to the \nefficiency of operation.  Each airline operator will propound a different definition for \nthe efficiency of operation but the definition to which we refer here, we believe, will \ncover points generally conceded to be included in all such definitions.\n Efficiency of operation, disregarding the actual aerodynamic performance of \nthe aircraft, embraces, first, the ease by which the crew can handle the aircraft in \nthe air and on the water and, second, the ease of maintenance.  Factors contributing \nto the ease of handling include proper distribution of responsibility among the crew, \nthe arrangement and convenience of all controls, equipment, and instruments, the \ncomfort and accommodations provided for those members of the crew, both on \nand off duty, efficient and simple methods for loading fuel, cargo and passengers, \narrangement of mooring devices, and methods of beaching.  The designer strives to \nreduce maintenance by providing good initial design that requires a minimum of \nattention and by providing good access for inspection and repair to parts that will \nrequire maintenance.\n At the outset it was recognized that this aircraft was primarily a long-range \ntransport and that every effort should be made to provide the crew with every \nconceivable aid, not only in equipment, but in comfort and accommodations.  It \nwas decided that the duties of the crew should be so delegated that a flight crew of \nsix would be on duty at all times. ', 'The hull bottom lines were designed to keep the bow wave as clean and low \nas possible, in order to keep the hull dry and to give quick take-off characteristics. \n As a result the plane was able to show extremely low takeoff time, ranging from \n17 to 58 seconds, depending on the loading, condition of wind and water, and the \ntechnique used for the takeoff.\n Control surfaces were designed to incorporate the Boeing-patented “tab con\xad\ntrol” system which the company has employed on all its large planes, using the \nnatural effect of airflow on small “tabs” to aid the pilot in moving the larger control \nsurfaces.  As a result, the Clipper, despite its great weight, could be handled with \nthe ease of a small sport plane—could be managed with two fingers on the control \ncolumn and less force on the rudder pedals than normally used in driving a car.\n When the initial design had thus been laid out, a program of model testing \nwas begun.  A 1/25 size wind-tunnel model and a 1/10 size towing tank model of the \nhull were constructed and shipped to the NACA at Langley Field, Virginia, where \nextensive tests were conducted.  For the first time, in the design of a new flying boat, \nit was possible to run wind tunnel and the towing-tank tests simultaneously. ', '355\nDocument 5-23 (a–c)\nBOMBER PAVES WAY\nThus it was decided that all surfaces were to be cantilever, without outside \nbracing of any kind, and that the ship was to be just as “clean” aerodynamically as \npracticable.  Already the way had been paved for this type of construction by the \nfour-engine Flying Fortress bombers.\n The hull was designed so that the center section of the wing would pass through \nthe upper portion of the hull in such a manner as to produce a clean intersection \nbetween the hull and the wing, rather than to have the wing supported above \nthe hull.  This arrangement also allowed additional volume within the hull and it \nbecame possible to provide two full decks, the upper deck to be devoted entirely to \nspacious control rooms, cargo space, and crew living quarters[;] the lower deck to \nbe given over completely to passenger accommodations.  Thus the passenger deck \ncould be divided into square-walled rooms with a good ceiling height for upper \nberths, as there would be no narrowing at the top for upper curvature of the hull.\n It was decided to provide lateral stability on the water by means of hydrosta\xad\nbilizers rather than wing-tip floats.  Former usage had shown the hydrostabiliz\xad\ners to have some definite advantages, such as excellent characteristics for taxiing \nor maneuvering on the water at high speeds, seaworthiness in rough water, and \nstructural soundness. ']","
The factors that contributed to the ease of handling of the Clipper included proper distribution of responsibility among the crew, arrangement and convenience of all controls, equipment and instruments, comfort and accommodations provided for the crew both on and off duty, efficient and simple methods for loading fuel, cargo and passengers, arrangement of mooring devices, and methods of beaching.

The rationale behind providing spacious quarters for the crew was that the aircraft was primarily a long-range transport, and every effort should be made to provide the crew with every conceivable aid, not only in equipment, but in comfort and accommodations. It was decided that the duties of the crew should be so delegated that a flight crew of six would be on duty at all times, and that spacious quarters should be provided for their use."
"What is the most favorable location for a radiator, water condenser, or other heat exchange device on an airship and why?","The most favorable location for a radiator, water condenser, or other heat exchange device on an airship would be just inside the hull so that the skin of the ship, the friction of which is inevitable, could be utilized as a heat radiating surface without adding parasite resistance. However, in view of the fact that the heat must traverse the entire boundary layer of the hull, the area required in such case is much larger. The handicap is not necessarily insurmountable, but the location of the finning of a heat exchange apparatus should protrude into the ship's boundary layer as a matter of design compromise into which considerations of space available, weight, complication, and maintenance enter, aside from the mere question of drag.","['Occasionally, relatively small protuberances, especially on the forebody on a \nmodel tested at [a] low Reynolds number, have shown an apparent influence by way \nof an increase of drag far beyond any normal expectation based on the drag of the \nprotuberance itself.  That similar freak influences would occur in full dimension \nseems rather doubtful in the light of experiments made with artificial “spoilers” on \nfull size ships and in high Reynolds number model tests.\n The drag of nacelles or power cars can be estimated from experiments on simi\xad\nlar objects occurring in heavier than air design provided allowance is made, if nec\xad\nessary, for the proximity to the airship hull which acts as a mirror surface of the \nwash of the propeller slip stream, and if need be, of the flow through such a car \ncontaining a radiator vent, or the like.\n Undoubtedly the most favorable location, from the viewpoint of drag, for a \nradiator, water condenser, or other heat exchange device, would be just inside the \nhull so that the skin of the ship, the friction of which is inevitable, could be utilized \nas a heat radiating surface without adding parasite resistance.  The area required in \nsuch case is, of course, much larger, since the heat must traverse the entire bound\xad\nary layer of the hull.  However in view of the fact that the heat transfer varies with a \nfractional power of the velocity head, the handicap is not necessarily insurmount\xad\nable.  Just how far the finning of a heat exchange apparatus should protrude into the \nship’s boundary layer is a matter of design compromise into which considerations of \nspace available, weight, complication and maintenance enter, aside from the mere \nquestion of drag.\n', 'engine situated \nimmediately back of the wings of the fuselage.  This engine is also connected \nthrough a clutch through a pusher propeller mounted at the rear end of the fuse\xad\nlage.  The pilot sits immediately forward of the wings.  The radiator is located in the \nfront end of the fuselage.  The machine will weigh 850 kg empty, and 1250 kg fully \nloaded.  Surface loading will be approximately 80 kg per sq.  m. The main vertical \ndrive shaft to the helicoplanes proper terminates in the landing-gear fork support, \nand the vertical drive-shaft housing alone forms the main support for the planes \nproper. ', 'The Wind and Beyond, Volume III\n156\n3.  Resistance of Accessories.  It has not yet been found feasible to house all \nof the equipment of an airship within the streamlined hull, although there pre\xad\nvails a decided tendency to eliminate more and more of the outside appendages \nand protuberances.  So long as individual propellers are disposed about the ship \nthere are outriggers or complete power cars outside which require individual fair\xad\ning.  The control car accommodating the navigating crew is usually located in the \nforward lower part of the hull.  An empennage is carried at the tail. ', 'POWER PLANT AND HULL OF PN-7\nWith the design under way, a change in the power plant was made to two \nWright engines of 525 H.P.  each.  This change gives an advantage of the PN-7 over \nthe F-5-L of about 350 H.P.  The water radiators are suspended from the upper front \nwing beam.  These radiator cores are made of extruded tubing 9 inches in length. \n The oil system is patterned after the F-5-L, but simplified and lightened where pos\xad\nsible.  The gas system is designed to carry the lines through streamline fairing on \nthe struts. ', 'March 10, 1932.\n AIRSHIP INVESTIGATIONS OF THE NATIONAL ADVISORY \nCOMMITTEE FOR AERONAUTICS.\n The National Advisory Committee for Aeronautics has been very active in \nthe study of the fundamental problems affecting the design and safe operation of \nairships.\n Study of Airship Forms.—One of the most important factors to be considered \nin the design of an airship is the shape of the hull structure.  The shape must first be \nconsidered from the standpoint of minimum resistance, and other factors, including \nstructural strength, must be considered.  At the request of the Bureau of Aeronautics \nof the Navy, the Committee made a very careful investigation in its variable-density \nwind tunnel of airship forms, resulting in the selection of the fineness ratio 5.9 to \n1 for the new airship ZRS-4, or the Akron.  The fineness ratio is the ratio of length \nto diameter. ']","
The most favorable location for a radiator, water condenser, or other heat exchange device on an airship would be just inside the hull. This is because the skin of the ship, which is inevitable, could be utilized as a heat radiating surface without adding parasite resistance. However, the area required in such case is larger since the heat must traverse the entire boundary layer of the hull. Despite this, the handicap is not necessarily insurmountable because the heat transfer varies with a fractional power of the velocity head. The finning of a heat exchange apparatus should protrude into the ship’s boundary layer to a certain average of induced drag, which is a matter of design compromise considering space available, weight, complication, and maintenance, aside from the mere question of drag."
"Can you explain the concept of rotation in fluid dynamics, including how it is defined, calculated, and its relationship to potential flow? Provide examples of its significance in fluid motion.","In fluid dynamics, rotation refers to the angular velocity of a fluid element around an axis. It is defined as the vector sum of the angular velocities around three mutually perpendicular axes. The rotation can also be expressed as the geometrical sum of the angular velocities with reference to the three axes.

To calculate the rotation, the circulation around an elementary surface of unit area in a plane perpendicular to the axis is taken. The rotation component with reference to any axis is obtained by dividing the circulation around the edge of any infinitesimal surface by the area of the surface.

In potential flow, the circulation around every closed fluid line is zero. This is because the flow is irrotational, meaning that the rotation is always zero. However, if the fluid is divided due to the presence of bodies, the theorem that the circulation remains zero under certain conditions does not apply to the fluid layer in which the divided flow reunites.

The significance of rotation in fluid motion is evident in various applications. For instance, in the case of a rigid body rotation, the rotation thus defined comes out as twice the angular velocity of the rigid body. In the case of a potential motion, the circulation is zero for every closed fluid line, which can be expressed by saying that the rotation in it is always zero.

The momentum theorem for stationary motions is also significant in fluid motion. It states that the rate of change with time of the linear momentum is equal to the resultant of all the external forces. This theorem can be applied to fluid motion by considering a definite portion of the fluid separated from the rest of the fluid by a closed surface. The change of momentum of the fluid within the surface can be stated in a formula.

In summary, rotation is a crucial concept in fluid dynamics that is defined, calculated, and related to potential flow. Its significance in fluid motion is evident in various applications, including rigid body rotation and the momentum theorem for stationary motions.","['The total rotation is a vector \nand is obtained from the rotation components for three mutually perpendicular \naxes.  In the case that the fluid rotates like a rigid body, the rotation thus defined \ncomes out as twice the angular velocity of the rigid body.  If we take a rectangular \nsystem of axes and consider the rotations with reference to the separate axes, we \nfind that the rotation can also be expressed as the geometrical sum of the angular \nvelocities with reference to the three axes.\n The statement that in the case of a potential motion the circulation is zero for \nevery closed fluid line can now be expressed by saying the rotation in it is always \nzero.  The theorem that the circulation, if it is zero, remains zero under the conditions \nmentioned, can also now be expressed by saying that, if these conditions are satis\xad\nfied in a fluid in which there is no rotation, rotation can never arise.  An irrotational \nfluid \nmotion, \ntherefore, \nalways remains irrotational. \n In this, however, the fol\xad\nlowing exceptions are to be \nnoted: If the fluid is divided \nowing to bodies being pres\xad\nent in it, the theorem under \nconsideration does not apply \nto the fluid layer in which \nthe divided flow reunites, \nnot only in the case of fig\xad\nure 2 but also in the case of Figure 3: Successive positions of a fluid line of flow around a solid body showing flow around a airfoil\nFIGURE 3. ', 'In the case that the fluid rotates like a rigid body, the rotation thus defined \ncomes out as twice the angular velocity of the rigid body.  If we take a rectangular \nsystem of axes and consider the rotations with reference to the separate axes, we \nfind that the rotation can also be expressed as the geometrical sum of the angular \nvelocities with reference to the three axes.\n The statement that in the case of a potential motion the circulation is zero for \nevery closed fluid line can now be expressed by saying the rotation in it is always \nzero.  The theorem that the circulation, if it is zero, remains zero under the conditions \nmentioned, can also now be expressed by saying that, if these conditions are satis\xad\nfied in a fluid in which there is no rotation, rotation can never arise.  An irrotational \nfluid \nmotion, \ntherefore, \nalways remains irrotational. \n In this, however, the fol\xad\nlowing exceptions are to be \nnoted: If the fluid is divided \nowing to bodies being pres\xad\nent in it, the theorem under \nconsideration does not apply \nto the fluid layer in which \nthe divided flow reunites, \nnot only in the case of fig\xad\nure 2 but also in the case of Figure 3: Successive positions of a fluid line of flow around a solid body showing flow around a airfoil\nFIGURE 3.  Successive positions of a fluid line in flow around a \nsolid\xa0body.\n', 'The component of the rotation with \nreference to any axis is obtained if the circulation is taken around an elementary \nsurface of unit area in a plane perpendicular to the axis.  Expressed more exactly, \nsuch a rotation component is the ratio of the circulation around the edge of any \nsuch infinitesimal surface to the area of the surface.  The total rotation is a vector \nand is obtained from the rotation components for three mutually perpendicular \naxes.  In the case that the fluid rotates like a rigid body, the rotation thus defined \ncomes out as twice the angular velocity of the rigid body.  If we take a rectangular \nsystem of axes and consider the rotations with reference to the separate axes, we \nfind that the rotation can also be expressed as the geometrical sum of the angular \nvelocities with reference to the three axes.\n The statement that in the case of a potential motion the circulation is zero for \nevery closed fluid line can now be expressed by saying the rotation in it is always \nzero.  The theorem that the circulation, if it is zero, remains zero under the conditions \nmentioned, can also now be expressed by saying that, if these conditions are satis\xad\nfied in a fluid in which there is no rotation, rotation can never arise. ', 'Applications of this will \nbe given in section 14.\n 11.  The discussion of the principles of the \nhydrodynamics of nonviscous fluids to be applied \nby us may be stopped here.  I add but one con\xad\nsideration, which has reference to a very useful \ntheorem for obtaining the forces in fluid motion, \nnamely the so-called “momentum theorem for \nstationary\xa0motions.”\nWe have to apply to fluid motion the theorem \nof general mechanics, which states that the rate of \nchange with the time of the linear momentum is \nequal to the resultant of all the external forces.  To \ndo this, consider a definite portion of the fluid sep\xad\narated from the rest of the fluid by a closed surface. \n This surface may, in accordance with the spirit of \nthe theorem, be considered as a “fluid surface,” i.e., made up always of the same \nfluid particles.  We must now state in a formula the change of the momentum of \nthe fluid within the surface. ', 'Very remarkable theorems hold for the rotation, which were discovered by \nv.\xa0Helmholtz and stated in his famous work on vortex motions.  Concerning the \ngeometrical properties of the rotation the following must be said:\nAt all points of the fluid where rotation exists the direction of the resultant \nrotation axes can be indicated, and lines can also be drawn whose directions coin\xad\ncide everywhere with these axes, just as the stream lines are drawn so as to coincide \nwith the directions of the velocity.  These lines will be called, following Helmholtz, \n“vortex lines.” The vortex lines through the points of a small closed curve form \na tube called a “vortex tube.” It is an immediate consequence of the geometrical \nidea of rotation as deduced above that through the entire extent of a vortex tube its \nstrength—i.e., the circulation around the boundary of the tube—is constant.  It is \nseen, in fact, that on geometrical grounds the space distribution of rotation quite \nindependently of the special properties of the velocity field from which it is deduced \nis of the same nature as the space distribution of the velocities in an incompressible \nfluid.  Consequently a vortex tube, just like a stream line in an incompressible fluid, \ncan not end anywhere in the interior of the fluid; and the strength of the vortex, \nexactly like the quantity of fluid passing per second through the tube of stream \nlines, has at one and the same instant the same value throughout the vortex tube. \n If Lord Kelvin’s theorem is now applied to the closed fluid line which forms the \nedge of a small element of the surface of a vortex tube, the circulation along it is \nzero, since the surface enclosed is parallel to the rotation axis at that point.  Since \nthe circulation can not change with the time, it follows that the element of surface \nat all later times will also be part of the surface of a vortex tube. ']","

In fluid dynamics, rotation is a measure of the angular motion of fluid particles around a given axis. It is defined as the ratio of the circulation around an elementary surface of unit area in a plane perpendicular to the axis to the area of the surface. The total rotation is a vector obtained from the rotation components for three mutually perpendicular axes. In the case of a potential motion, the circulation is zero for every closed fluid line, and therefore, the rotation is always zero. This means that an irrotational fluid motion always remains irrotational. However, there are exceptions to this rule, such as when the fluid is divided by the presence of bodies in it, and the divided flow reunites.

The concept of rotation is significant in fluid motion as it can help predict the behavior of fluid particles in different flow regimes. For example, in figure 3, the successive positions of a fluid line in flow around a solid body show how the rotation of fluid particles changes as they move around the body. The rotation of fluid particles can also affect the stability of fluid motion, as in the case of vortex shedding behind bluff bodies.

In summary, rotation is a fundamental concept in fluid dynamics that measures the angular motion of fluid particles around a given axis. It is defined as the ratio of the circulation around an elementary surface of unit area in a plane perpendicular to the axis to the area of the surface. The total rotation is a vector obtained from the rotation components for three mutually perpendicular axes. The concept of rotation is significant in fluid motion as it can help predict the behavior of fluid particles in different flow regimes."
"What was the primary focus of the COMPLEX study in terms of Mars exploration? Was it on in situ exploration, sample return, or orbital science?","The primary focus of the COMPLEX study in terms of Mars exploration was on both in situ exploration and sample return. The study presented two possible future surface mission scenarios, one for in situ exploration and one for sample return. The in situ mission scenario required ""substantial mobility"" and a robotic geologist for its mission. The study argued that both in situ research and returned samples were necessary to provide a base of information to guide the choice of a sample to define and address substantial and important scientific questions in a definitive way and to ensure the acquisition of a sufficient variety of materials, and with adequate documentation.","['50 YEARS OF SOLAR SYSTEM EXPLORATION: HISTORICAL PERSPECTIVES\n114\ncloser to having the technical capacity to carry out this longstanding scien\xad\ntific goal than it has ever been, it is less able to carry it out than it was just a \nhandful of years ago. \n EARLY VISIONS OF MARS SAMPLE RETURN, 1978 TO 1993\nIn a 1974 study, the Space Science Board (SSB) had argued for Mars sample \nreturn as a long-term goal, a stance rejected by COMPLEX in 1978.  The point \nof dispute was whether sample return should be seen as an end in itself or \nmerely one technique to be used in a more comprehensive program of explo\xad\nration.  COMPLEX argued that both in situ research—science performed \nfrom orbit or on the surface of Mars—and returned samples were neces\xad\nsary: “A minimal base of information is necessary to guide the choice of a \nsample to define and address substantial and important scientific questions \nin a definitive way and to ensure the acquisition of a sufficient variety of \nmaterials, and with adequate documentation.”9 In situ science was neces\xad\nsary to provide this base of information, and to some degree in situ science \nneeded to precede sample return.\n 9.  “Report of the Committee on Lunar and Planetary Exploration (COMPLEX), Space Science \nBoard, Assembly of Mathematical and Physical Sciences,” National Research Council, 1978.\n FIGURE 1. ', '50 YEARS OF SOLAR SYSTEM EXPLORATION: HISTORICAL PERSPECTIVES\n114\ncloser to having the technical capacity to carry out this longstanding scien\xad\ntific goal than it has ever been, it is less able to carry it out than it was just a \nhandful of years ago. \n EARLY VISIONS OF MARS SAMPLE RETURN, 1978 TO 1993\nIn a 1974 study, the Space Science Board (SSB) had argued for Mars sample \nreturn as a long-term goal, a stance rejected by COMPLEX in 1978.  The point \nof dispute was whether sample return should be seen as an end in itself or \nmerely one technique to be used in a more comprehensive program of explo\xad\nration.  COMPLEX argued that both in situ research—science performed \nfrom orbit or on the surface of Mars—and returned samples were neces\xad\nsary: “A minimal base of information is necessary to guide the choice of a \nsample to define and address substantial and important scientific questions \nin a definitive way and to ensure the acquisition of a sufficient variety of \nmaterials, and with adequate documentation.”9 In situ science was neces\xad\nsary to provide this base of information, and to some degree in situ science \nneeded to precede sample return.\n 9. ', '111\nCHAPTER 4\nDesigning Mars Sample Return, \nfrom Viking to the \nMars Science Laboratory1\nErik M. Conway\nE\nVEN BEFORE NASA’S twin Viking landers made their way to the sur\xad\nface of Mars, planetary scientists wanted to acquire samples and send \nthem back to Earth.  In the first post-Viking “decadal survey” of priorities for \nexploring the inner planets, conducted by the National Academy of Sciences’ \nCommittee on Planetary and Lunar Exploration (COMPLEX), Mars sample \nreturn was advertised as the proper means of investigating “questions the \nanswer to which are less dependent on the locale of the investigation, but \nmore on the sophistication of the techniques that can be brought to bear.”2 \nChaired by California Institute of Technology meteorite specialist Gerry \nWasserberg, this 1978 COMPLEX study framed the ambitions of planetary \nscientists into the present day.  The National Academy’s 2011 decadal survey \nof priorities in planetary science, chaired by Cornell University astronomer \nSteven Squyres, made a Mars sample-return mission (called “MAX-C,” for \nMars Astrobiology Explorer-Cacher) its number-one priority for 2013–22.3 \n1. \n Portions of this chapter have appeared in Erik M. Conway, Exploration and Engineering: \nThe Jet Propulsion Laboratory and the Quest for Mars (Baltimore: Johns Hopkins University \nPress, 2015).\n 2.  National Research Council, Scientific Exploration of the Inner Planets: 1977–1987 \n(Washington DC: National Academies Press, 1978), p. ', '115\nCHAPTER 4\u2002 •\u2002 DESIGNING MARS SAMPLE RETURN\nThis COMPLEX study presented two possible future surface mission sce\xad\nnarios, one for in situ exploration and one for sample return.  The in situ \nmission scenario required “substantial mobility” in order to explore areas \nof 10–100 kilometers.  This mobile robot was to have the ability to pick up \nand test samples of rock and soil during its traverse and to provide chemi\xad\ncal analyses and “high-quality macroscopic and microscopic imaging” of its \ncollections.  In short, COMPLEX sought a robotic geologist for its in situ mis\xad\nsion. ', '111\nCHAPTER 4\nDesigning Mars Sample Return, \nfrom Viking to the \nMars Science Laboratory1\nErik M. Conway\nE\nVEN BEFORE NASA’S twin Viking landers made their way to the sur\xad\nface of Mars, planetary scientists wanted to acquire samples and send \nthem back to Earth.  In the first post-Viking “decadal survey” of priorities for \nexploring the inner planets, conducted by the National Academy of Sciences’ \nCommittee on Planetary and Lunar Exploration (COMPLEX), Mars sample \nreturn was advertised as the proper means of investigating “questions the \nanswer to which are less dependent on the locale of the investigation, but \nmore on the sophistication of the techniques that can be brought to bear.”2 \nChaired by California Institute of Technology meteorite specialist Gerry \nWasserberg, this 1978 COMPLEX study framed the ambitions of planetary \nscientists into the present day.  The National Academy’s 2011 decadal survey \nof priorities in planetary science, chaired by Cornell University astronomer \nSteven Squyres, made a Mars sample-return mission (called “MAX-C,” for \nMars Astrobiology Explorer-Cacher) its number-one priority for 2013–22.3 \n1. \n Portions of this chapter have appeared in Erik M. Conway, Exploration and Engineering: \nThe Jet Propulsion Laboratory and the Quest for Mars (Baltimore: Johns Hopkins University \nPress, 2015).\n 2. ']","
The primary focus of the COMPLEX study was on in situ exploration and sample return missions to Mars, with a de-emphasis on orbital science. The study envisioned a long-range, semi-autonomous rover for in situ exploration, which could pick up and test samples of rock and soil, and provide chemical analyses and high-quality imaging. For sample return, the study imagined a lander with basic imaging and chemical analytical capabilities, which could choose the best samples for return to Earth. Orbital science was not entirely ignored, but the study did not include any specific orbital science scenarios, possibly due to the success of the Viking landings and the perception that sending another orbiter to Mars might seem retrogressive."
What is the vision of Dr. Dennis Bushnell regarding the future of transportation?,"Dr. Dennis Bushnell's vision for the future of transportation is the development of a combination automobile/helicopter or ""helo-converticar"" that will revolutionize transportation and society by creating a new form of mass personal mobility. He believes that in a matter of a decade or two, such a hybrid vehicle will become eminently feasible due to advanced technology that will make it successful where all previous concepts for ""roadable aircraft"" or ""flying cars"" failed. The helo-converticar should be able to operate safely, effectively, economically, and meet all necessary environmental and nuisance regulations while providing reasonable ride quality, all-weather operation, and minimal maintenance requirements and costs.","['In the view of one of NASA’s most visionary aerodynamicists, Dr.  Dennis \nBushnell, the massive problems and costs of contemporary automobile use in the \nearly 21st century will virtually dictate that some form of personal air transporta\xad\ntion be tried in the near future.  His answer: a combination automobile/helicopter \nor “helo-converticar” that will revolutionize transportation and society by creating \na new form of mass personal mobility.  Bushnell believes that in a matter of a decade \nor two, such a hybrid vehicle will become eminently feasible.  Different forms of \nadvanced technology will make it successful where all previous concepts for “road\xad\nable aircraft” or “flying cars” failed.  Thanks to computer and satellite navigation \nsystems, they should be able to operate safely, effectively, economically—in fact, \nvirtually automatically.  A well-designed helo-converticar should also be able to \nmeet all the necessary environmental and nuisance regulations in terms of colli\xad\nsion avoidance, survivability, noise, emissions, ground-vicinity operations, and reli\xad\nability while providing reasonable ride quality, all-weather operation, and minimal \nmaintenance requirements and costs. ', '861\nDocument 5-53\nDocument 5-53\nDennis Bushnell, “The Personal Helicopter,” \nin The Personal Aircraft—Status and Issues \n(NASA Langley Research Center, Hampton, VA: NASA \nTechnical Memorandum 109174, December 1994), pp.  37–44.\n In the view of one of NASA’s most visionary aerodynamicists, Dr.  Dennis \nBushnell, the massive problems and costs of contemporary automobile use in the \nearly 21st century will virtually dictate that some form of personal air transporta\xad\ntion be tried in the near future.  His answer: a combination automobile/helicopter \nor “helo-converticar” that will revolutionize transportation and society by creating \na new form of mass personal mobility.  Bushnell believes that in a matter of a decade \nor two, such a hybrid vehicle will become eminently feasible.  Different forms of \nadvanced technology will make it successful where all previous concepts for “road\xad\nable aircraft” or “flying cars” failed. ', 'A search of the Internet in the year 2020 for Web sites containing informa\xad\ntion about helicopters and helicopter manufacturers returned no fewer than 244 \nmillion “hits.” “Rotary wing” accessed 18.4 million matches, and “tilt rotor” alone \nresulted in more than 10.1 million.\n In the opinion of some aeronautical engineers in the early 21st century, small \nVTOL aircraft promises the greatest revolution in personal mobility since the auto\xad\nmobile.  In their view, personal air transportation based on some sort of helicopter \nor convertiplane, as revolutionary as that seems, marks “the next logical step in \nthe development of human infrastructure and corporal communication,” i.e., bod\xad\nies moving around from one place to another.  This is the view of one of NASA’s \nfarsighted aeronautical dreamers, Dennis M. Bushnell.  In Document 5-53, which \nwas published as part of a compendium of papers entitled “The Personal Aircraft,” \npublished by NASA in December 1994, Bushnell explored the potential of a The Sikorsky UH-60A Black Hawk in flight\nFIGURE 5.41.  The Sikorsky UH-60A Black Hawk replaced the Huey as the American military’s main air-assault, \ntransport, and medevac helicopter in 1978.  Variants of the Black Hawk will continue to serve well into the 21st \ncentury. ', 'Chapter 5: Other Paths, Other Flyways\n65\npersonal aircraft system, known as the “helo-converticar,” capable of both ground \nand VTOL air operation.  Seconding Bushnell’s bold vision of personal helicopters \nis the final selection for this chapter, Document 5-54, the provocative epilogue to \nE.\xa0K. Liberatore’s 1998 book Helicopters Before Helicopters.  Whether their concepts \nof mass personal mobility will ever come to pass is highly questionable, but it is a \nventuresome concept worthy of Dietrich Küchemann. \n', 'At the conclusion of this persuasive article, Liberatore delivers a commen\xad\ntary on what he sees as the role of the helicopters in transportation systems of the \nfuture.  Most of his points mirror those we encountered in the previous document \nby NASA’s Dennis Bushnell.  Our love of the automobile has put us in a Malthusian \nbind: “The number of cars keeps increasing…but the number of new, desirable \nurban venues is practically constant.” The result is congestion, gridlock, pollution, \nineffective use of more and more time, and “emotional dysfunction.” More and \nmore people moving through the air is the only answer, Liberatore suggests, and \nthe helicopter is the only way to keep our means of transportation personal.  Like \nBushnell, Liberatore indicates that mass use of some sort of helo-converticar is \ninevitable, at least in the modern industrialized nations: “When the need becomes \na necessity, the public will accommodate the new aerial system that will one day be \nas comprehensive and pervasive as the present automobile system.”\nAs the authors of this study of aerodynamic development, we can only hope to \nstill be around to document what would indeed amount to the most revolutionary \ndevelopment in mass personal transportation since the Ford Model T.\n']"," Dr. Dennis Bushnell envisions a future where a combination automobile/helicopter or 'helo-converticar' will revolutionize transportation and society by creating a new form of mass personal mobility. He believes that this hybrid vehicle will become feasible in a matter of a decade or two, thanks to advanced technology such as computer and satellite navigation systems. The helo-converticar will be able to operate safely, effectively, economically, and virtually automatically while meeting all necessary environmental and nuisance regulations. It will not replace the automobile or rail lines for short-distance and other commuter transportation, but it will add to a healthier mix. The helo-converticar will reduce population density, lessen capital investments for roads and highways, and revolutionize transportation and society as a whole."
What are the lines of evidence that suggest comets are falling into the young star HD 172555?,"Astronomers using Hubble recently found clues that something similar is happening around the young star HD 172555––a Jupiter-sized planet seems to be flinging comets life-forming elements to toward its star.  Scientists didn’t see either the planet or comets directly, but pieced this explanation together from various lines of evidence.  First, a team of French Space Flight Center astronomers mined archival data gathered by the European Southern Observatory and found the chemical fingerprints of calcium imprinted in HD 172555’s light––evidence of comet-like objects plunging into the star.  The most likely explanation for the speedy gas is that material from the comets vaporized after streaking across the star’s disk.  Astronomers consider this circumstantial evidence for gravitational stirring by an unseen Jupiter-size planet, where comets deflected by the massive object’s gravity are catapulted into the star.  This is the same mechanism that may have transported water to Earth and the other inner planets of our solar system.  HD 172555 is the third extrasolar system where astronomers have detected doomed, wayward comets, and all three systems are young.  Studying them offers insight into what probably happened in the early days of our own solar system.  This illustration shows an enormous disk of dusty material surrounding the young star HD 172555.  Astronomers using Hubble found evidence that comets are falling in toward the star when they detected gas that is likely the vaporized remnants of the icy comet cores.  The gas was moving at about 360,000 miles per hour across the face of the star.  The gravitational influence of a suspected Jupiter-size planet in the foreground may have catapulted the comets into the star.  Credit: NASA, ESA, and A. Feild and G. Bacon (STScI) 
Learn more: https://hubblesite.org/contents/news-releases/2017/news-2017-02.html 

The lines of evidence that suggest comets are falling into the young star HD 172555 are:","[' \n \n \n \nGathering Evidence of a Planet Flinging Comets Into a \nYoung Star \nAs Hubble’s images of the comet Shoemaker-Levy 9 impact on Jupiter “These star-grazing \nhelp illustrate, Jupiter sometimes serves as Earth’s protector by blocking or comets may make life\ndeflecting objects that could collide with our planet.  But the reverse can be \ntrue, too; when our solar system was younger, the giant planet also hurled possible, because they \nasteroids and comets in Earth’s direction, toward the Sun.  Astronomers using carry water and other\nHubble recently found clues that something similar is happening around the \nyoung star HD 172555––a Jupiter-sized planet seems to be flinging comets life-forming elements to \ntoward its star. \n terrestrial planets.” \nScientists didn’t see either the planet or comets directly, but pieced this \nCarol Grady, Eureka Scientific Inc.  and NASA Goddard \nexplanation together from various lines of evidence.  First, a team of French \nSpace Flight Center \nastronomers mined archival data gathered by the European Southern \nObservatory and found the chemical fingerprints of calcium imprinted in HD \n172555’s light––evidence of comet-like objects plunging into the star. ', 'The most likely explanation for the speedy gas is that material from the comets vaporized \nafter streaking across the star’s disk. \n Astronomers consider this circumstantial evidence for gravitational stirring by an unseen Jupiter-size planet, where \ncomets deflected by the massive object’s gravity are catapulted into the star.  This is the same mechanism that may \nhave transported water to Earth and the other inner planets of our solar system.  HD 172555 is the third extrasolar \nsystem where astronomers have detected doomed, wayward comets, and all three systems are young.  Studying them \noffers insight into what probably happened in the early days of our own solar system. \n This illustration shows an enormous disk of dusty material surrounding the young star HD 172555.  Astronomers using Hubble found evidence that comets are falling in \ntoward the star when they detected gas that is likely the vaporized remnants of the icy comet cores. ', 'This illustration shows an enormous disk of dusty material surrounding the young star HD 172555.  Astronomers using Hubble found evidence that comets are falling in \ntoward the star when they detected gas that is likely the vaporized remnants of the icy comet cores.  The gas was moving at about 360,000 miles per hour across the \nface of the star.  The gravitational influence of a suspected Jupiter-size planet in the foreground may have catapulted the comets into the star. \n Credit: NASA, ESA, and A. Feild and G. Bacon (STScI) \nLearn more: https://hubblesite.org/contents/news-releases/2017/news-2017-02.html \n45 \n', 'HD 172555 is the third extrasolar \nsystem where astronomers have detected doomed, wayward comets, and all three systems are young.  Studying them \noffers insight into what probably happened in the early days of our own solar system. \n This illustration shows an enormous disk of dusty material surrounding the young star HD 172555.  Astronomers using Hubble found evidence that comets are falling in \ntoward the star when they detected gas that is likely the vaporized remnants of the icy comet cores.  The gas was moving at about 360,000 miles per hour across the \nface of the star.  The gravitational influence of a suspected Jupiter-size planet in the foreground may have catapulted the comets into the star. \n Credit: NASA, ESA, and A. Feild and G. Bacon (STScI) \nLearn more: https://hubblesite.org/contents/news-releases/2017/news-2017-02.html \n45 \n', 'This is the same mechanism that may \nhave transported water to Earth and the other inner planets of our solar system.  HD 172555 is the third extrasolar \nsystem where astronomers have detected doomed, wayward comets, and all three systems are young.  Studying them \noffers insight into what probably happened in the early days of our own solar system. \n This illustration shows an enormous disk of dusty material surrounding the young star HD 172555.  Astronomers using Hubble found evidence that comets are falling in \ntoward the star when they detected gas that is likely the vaporized remnants of the icy comet cores.  The gas was moving at about 360,000 miles per hour across the \nface of the star.  The gravitational influence of a suspected Jupiter-size planet in the foreground may have catapulted the comets into the star. \n']","
1. French astronomers mined archival data gathered by the European Southern Observatory and found the chemical fingerprints of calcium imprinted in HD 172555’s light, which is evidence of comet-like objects plunging into the star.
2. Another group of astronomers used Hubble to conduct a spectrographic analysis in ultraviolet light and detected fast-moving silicon and carbon gas in the starlight. The most likely explanation for the speedy gas is that material from the comets vaporized after streaking across the star’s disk.
3. Astronomers consider this circumstantial evidence for gravitational stirring by an unseen Jupiter-size planet, where comets deflected by the massive object’s gravity are catapulted into the star.
4. When astronomers using Hubble detected gas moving at about 360,000 miles per hour across the face of the star, they concluded that it was likely the vaporized remnants of the icy comet cores."
"What are the effects of microgravity on human health and the environment, as investigated by the VIIP, EXPOSE, Mouse Immunology, MAXI, Genara-A, Epstein-Barr, SCMIX-2, DCMIX-3, Medaka Osteoclast, Altea-Shield, and Flex-2 studies? Provide a brief summary of the findings from each investigation.","1. VIIP (Vascular Tissue Loss, Osteoporosis, and Reconstruction): This study investigates the effects of microgravity on bone and vascular tissue loss. The findings suggest that microgravity causes bone loss and vascular changes, which can lead to an increased risk of fractures and cardiovascular disease.

2. EXPOSE (Extreme Universe Space Observatory): This study investigates the effects of space radiation on biological systems. The findings suggest that space radiation can cause DNA damage and mutations, which can lead to an increased risk of cancer and other health problems.

3. Mouse Immunology: This study investigates the effects of microgravity on the immune system of mice. The findings suggest that microgravity causes modifications in the immune system, which can lead to an increased risk of infections and immune dysfunction.

4. MAXI (Microgravity Accelerated Maturation): This study investigates the effects of microgravity on the development of human cells and tissues. The findings suggest that microgravity can accelerate the maturation of human cells and tissues, which can lead to new medical treatments and therapies.

5. Genara-A: This study investigates the effects of microgravity on the development of zebrafish embryos. The findings suggest that microgravity can cause developmental abnormalities in zebrafish embryos, which can lead to an increased risk of birth defects and other health problems.

6. Epstein-Barr: This study investigates the effects of microgravity on the Epstein-Barr virus, which is associated with several types of cancer. The findings suggest that microgravity can cause changes in the Epstein-Barr virus, which can lead to an increased risk of cancer and other health problems.

7. SCMIX-2: This study investigates the effects of microgravity on the development of stem cells. The findings suggest that microgravity can cause changes in the development of stem cells, which can lead to an increased risk of cancer and other health problems.

8. DCMIX-3: This study investigates the effects of microgravity on the development of dendritic cells. The findings suggest that microgravity can cause changes in the development of dendritic cells, which can lead to an increased risk of immune dysfunction and","['The human immune system \nis a complex web of biological structures and \nprocesses; decreased activity in one piece of it \ncan change overall disease risk.  Studies have shown \nmicrogravity causes modifications in the human \nimmune system.  Figuring out why and how this \noccurs could help not only astronauts, but people \naffected by immune dysfunction here on Earth.\n Studies have shown microgravity \ncauses modifications in the human \nimmune system.  Figuring out why \nand how this occurs could help \nnot only astronauts, but people \naffected by immune dysfunction \nhere on Earth.\n Many investigations aboard the space station \nhave studied the effect of microgravity on immune \nsystem health.  For example, the Functional Immune \ninvestigation analyzes blood and saliva samples to \nidentify changes taking place in crew members’ \nimmune systems during flight, and compares the \ndata with self-reported health information. ', 'Figuring out why and how this \noccurs could help not only astronauts, but people \naffected by immune dysfunction here on Earth.\n Studies have shown microgravity \ncauses modifications in the human \nimmune system.  Figuring out why \nand how this occurs could help \nnot only astronauts, but people \naffected by immune dysfunction \nhere on Earth.\n Many investigations aboard the space station \nhave studied the effect of microgravity on immune \nsystem health.  For example, the Functional Immune \ninvestigation analyzes blood and saliva samples to \nidentify changes taking place in crew members’ \nimmune systems during flight, and compares the \ndata with self-reported health information.  This unique \nlook at subtle changes in the immune system that may \noccur before symptoms show up, whether in space or \non the ground, may help scientists pinpoint the onset \nof illness so they can suggest monitoring strategies or \ntreatments to boost the immune system—and prevent \nfull-blown infections and diseases.\n T-cells, a type of white blood cell, play a role in \nactivating the body’s immune system. ', 'Tackling Immune System Dysfunction—\nfrom Multiple Angles\nGetting sick is no fun for anyone, but it especially taxes \ncrew members aboard the ISS.  Protecting crew health \nis important as NASA prepares for long-duration, \ndeep-space missions.  The human immune system \nis a complex web of biological structures and \nprocesses; decreased activity in one piece of it \ncan change overall disease risk.  Studies have shown \nmicrogravity causes modifications in the human \nimmune system.  Figuring out why and how this \noccurs could help not only astronauts, but people \naffected by immune dysfunction here on Earth.\n Studies have shown microgravity \ncauses modifications in the human \nimmune system.  Figuring out why \nand how this occurs could help \nnot only astronauts, but people \naffected by immune dysfunction \nhere on Earth.\n', 'Specifically, these muscle attachment complexes are \nassociated with a muscle intrinsic repair mechanism, \nwhich appears to have relevance to human muscle \natrophy (breakdown) with disuse and possibly aging \n(Honda et al., 2012).Video screen capture of medaka in the Aquatic Habitat onboard the Kibo.  Image credit: JAXA\nVideo screen shot of medaka in the Aquatic \nHabitat onboard the Kibo. \n Image credit: JAXA\nResults from this body of research \nare critical enablers for missions \nbeyond LEO and also contribute \nfundamental scientific knowledge \nin physiological systems. \n Results of mouse research on the space station have \nshown changes in many physiological systems as a \nresult of living in microgravity.  Mice flown on a 17-day \nmission to the space station exhibited unexpected \nbone loss in the mandible and skull, which are not the \nusual load-bearing bones that are most sensitive to \nbone loss in space (Ghosh 2015).  In another study, \nwhen mice were centrifuged at 1-gravity (1-g) during \ntheir stay on the space station, they maintained muscle \nand bone mass but exhibited an overall decrease \n', '145\nImmune Defenses \nVirtually the entire population is infected with one of eight herpes viruses, four of which reactivate and \nappear in body fluids in response to the stress of spaceflight.  A patent-pending device designed for use \nin either a doctor’s office or on a spacecraft allow for the rapid detection of one of these viruses (VZV), \nwhich can lead to earlier treatment and prevent the onset of painful shingles.  Microgravity studies on \nthe International Space Station (ISS) help researchers pinpoint genetic triggers for immune responses \nin T-cells, thus leading to future medical treatments on Earth for immunosuppression.  Determining \nthe changes that occur to the immune system in space provides the means to develop targeted \ncountermeasures to adverse effects in space, as well as furnishes additional information for targeted \ntreatments on Earth for the development of pharmaceuticals that can suppress immune response to \nhelp manage autoimmune diseases or organ transplants.\n Tackling Immune System Dysfunction—\nfrom Multiple Angles\nGetting sick is no fun for anyone, but it especially taxes \ncrew members aboard the ISS.  Protecting crew health \nis important as NASA prepares for long-duration, \ndeep-space missions. ']","

* The VIIP (Visual Impairment Intracranial Pressure) study found that long-duration space flight can cause optic disc edema, globe flattening, choroidal folds, and hyperopic shifts in astronauts.
* The EXPOSE investigation studied the effect of the space environment on the survival of Halorubrum chaoviator and Synechococcus (Nägeli) and found that microgravity had an affect on their survival.
* The Mouse Immunology study found that spaceflight and simulated microgravity cause a significant reduction of key gene expression in early T-cell activation.
* The MAXI (Monitor of All-sky X-ray Image) investigation studied GRB 130427A and found that it was a nearby ordinary monster.
* The Genara-A study found that microsome-associated proteome modifications of Arabidopsis seedlings grown on board the International Space Station reveal the possible effect on plants of space stresses other than microgravity.
* The Epstein-Barr study found that reactivation of latent viruses is associated with increased plasma cytokines in astronauts.
* The SCMIX-2 and DCMIX-3 studies measured Soret coefficients in a ternary mixture of toluene–methanol–cyclohexane in convection-free environment.
* The Medaka Osteoclast study performed histological and transcriptomic analysis of adult Japanese medaka sampled onboard the International Space Station.
* The Altea-Shield study investigated the performances of Kevlar and Polyethylene as radiation shielding on-board the International Space Station in high latitude radiation environment.
* The Flex-2 study investigated cool-flame extinction during n-alkane droplet combustion in microgravity."
Question: What was the role of NASA in the development of the SST?,"NASA's work in high-speed commercial aviation, centering on ever-faster airliners, culminated with the ill-fated supersonic transport (SST). With the subsonic jet airliner an everyday technology in the 1960s, the next step was building an SST. Achieving supersonic commercial flight in the 1960s was viewed by many as the next logical triumph of American civil aviation, proof of the United States’ enduring technological superiority in aerospace. America's participation in the national SST program, 1961–1971, was initiated by the joint recommendation of the Secretary of the Department of Defense (DOD), Thomas S. Gates, Jr., and the administrators of NASA and the FAA, T. Keith Glennan and Elwood R. Quesada, respectively, in October 1960. The reasons were many. The creation of an SST was in the national interest because it would guarantee American leadership in commercial aviation, which was vital to the Nation’s economy, security, and prestige. The technical foundation was there with the long tradition of supersonic research in the United States that had culminated with the recent B-58 and B-70 bomber programs. The research and development cost of any SST would be beyond the capabilities of a single company and airline to support. The sheer magnitude of the project required Government leadership, funding, and technical expertise combined with the participation of industry.","['Now, many saw extending that dominance into supersonic \ncivil air transport service as the next logical step.One-half right rear view from slightly below of U. S. Air Force North American X-15 #2 (s/n 56-6671) in flight over desert near Flight Research Center, Edwards Air Force Base, California, circa 1959.\n Figure 2-1.  This image shows the North American X-15 research airplane.  (National Air and \nSpace Museum, Smithsonian Institution, SI 77-14083)\nThe Secretary of the Department of Defense (DOD), Thomas S. Gates, Jr., \nand the administrators of NASA and the FAA, T. Keith Glennan and Elwood \nR. Quesada, respectively, issued a joint recommendation in October 1960 to \ninitiate a national program for the development of a commercial SST.  The rea\xad\nsons were many.  The creation of an SST was in the national interest because it \nwould guarantee American leadership in commercial aviation, which was vital \nto the Nation’s economy, security, and prestige.  The technical foundation was \nthere with the long tradition of supersonic research in the United States that \nhad culminated with the recent B-58 and B-70 bomber programs. ', 'The long, black research airplane, with its distinguishing \ncruciform tail, became the highest-flying airplane in history.  In August 1963, \nthe X-15 flew to 67 miles (354,200 feet) above Earth at a speed of Mach 6.7, \nor 4,534 miles per hour.  Overall, the 199 flights of X-15 program generated \nimportant data on high-speed flight and provided valuable lessons for NASA’s \nspace program.4 The use of rocket power to propel an air-launched aircraft into \nthe hypersonic range was successful, but it also illustrated the need for other \nforms of propulsion for practical high-speed flight.\n NASA’s Participation in the National \nSST Program, 1961–1971\nNASA’s work in high-speed commercial aviation, centering on ever-faster \nairliners, culminated with the ill-fated supersonic transport (SST).  With the \nsubsonic jet airliner an everyday technology in the 1960s, the next step was \nbuilding an SST.  Achieving supersonic commercial flight in the 1960s was \nviewed by many as the next logical triumph of American civil aviation, proof \nof the United States’ enduring technological superiority in aerospace.  America \n', 'This image shows the North American X-15 research airplane.  (National Air and \nSpace Museum, Smithsonian Institution, SI 77-14083)\nThe Secretary of the Department of Defense (DOD), Thomas S. Gates, Jr., \nand the administrators of NASA and the FAA, T. Keith Glennan and Elwood \nR. Quesada, respectively, issued a joint recommendation in October 1960 to \ninitiate a national program for the development of a commercial SST.  The rea\xad\nsons were many.  The creation of an SST was in the national interest because it \nwould guarantee American leadership in commercial aviation, which was vital \nto the Nation’s economy, security, and prestige.  The technical foundation was \nthere with the long tradition of supersonic research in the United States that \nhad culminated with the recent B-58 and B-70 bomber programs.  The research \nand development cost of any SST would be beyond the capabilities of a single \ncompany and airline to support.  The sheer magnitude of the project required \nGovernment leadership, funding, and technical expertise combined with the \nparticipation of industry. ', 'The Committee’s work in high-speed flight \ncontinued until its dissolution in 1958.  The newly created NASA and its sup\xad\nport of military high-speed and commercial subsonic flight during the 1960s \nand 1970s is the subject of chapters 2 and 3.  NASA’s propulsion program \nstood at the intersection of military, industrial, and academic research as it \nworked to refine the military airplane and first addressed public concerns that \npersist today over the place of the commercial jetliner in American life.  The \nfirst national programs for a commercial supersonic transport (SST) serve as \nthe bridge between the two worlds.  The establishment of the Aircraft Energy \nEfficiency Program of the 1970s and 1980s, presented in chapter 4, reflected \nNASA’s desire to nurture and, in some cases, reinvent turbofan and turboprop \ntechnology during a chaotic period of oil embargoes and escalating fuel prices.\n While the propulsion focus at NASA Glenn is at the center of this book, \nanother NASA Center figured prominently in the development of new \npropulsion-related technologies.  Chapter 5 discusses the flight research pro\xad\ngrams dedicated to digital engine controls and thrust vectoring at Dryden \nFlight Research Center (now the Neil A. Armstrong Flight Research Center) \nfrom the late 1960s to the 1990s. ', 'The Power for Flight\n56\nreductions, and the need for NASA to keep the Space Shuttle Program funded \noutweighed any justifications for another Government-funded supersonic \ncommercial airliner program.16\nNevertheless, the propulsion research of SCAR proved to be longstanding. \n Environmental research revealed that an advanced SST’s effect on the ozone \nlayer, which was a major concern during the 1960s, would be less harmful than \npreviously believed.  (The true culprit proved to be chlorofluorocarbons used as \nthe delivery medium in aerosol spray cans.)  The VCE program accelerated the \ncapability of Pratt & Whitney and GE to use and experiment with advanced \ndesign codes, materials, and structures while incorporating the new parameters \nof noise and emissions reduction into their engines.  As historian Eric Conway \nnoted, the VCE was successful “solely on its merits as a technology program” \ndespite the fact that it did not lead to a flight-ready engine.17\nNASA and the Lockheed Blackbird Family\nThe Lockheed SR-71 Blackbird reconnaissance airplane was the fastest piloted \naircraft with air-breathing engines in history when it entered service in the \nU.S. ']"," NASA played a significant role in the development of the Supersonic Transport (SST). In the early 1960s, NASA, the Department of Defense (DOD), and the Federal Aviation Administration (FAA), with the support of President John F. Kennedy, initiated a design competition between leading aircraft manufacturers. NASA was already involved in a Nationwide effort to create a practical American SST, similar to its work with the space program. In December 1966, the Government chose Boeing's Model 2707 design, and General Electric received the contract for its four engines, designated GE4. NASA was responsible for ensuring that the engines for the new SST were as fuel-efficient, quiet, and reliable as standard airliner engines at both supersonic and subsonic speeds, including takeoff, landing, and loitering in a holding pattern."
What is the current state of airship technology and how does it compare to airplane development?,"According to the given text, the technical development of airships continues to lag behind that of airplanes due to the limited opportunity for development of new ideas and methods of construction. However, the text also mentions that modern, high technology airship manufacture has now been definitely established, and that the United States is prepared to design and build rigid airships to any required degree of engineering exactitude. Therefore, while airship technology may still be behind airplane development, it is not completely stagnant and has made significant progress in recent years.","['77\nDocument 5-2 (a–s)\nDocument 5-2 (i), “Airships,” NACA Annual Report (1927), pp.  72–74.\n AIRSHIPS\nTechnical development and present situation.—The technical development of airships \ncontinues to lag behind that of airplanes.  This is only to be expected in view of \nthe small numbers of airships which are built and the very limited opportunity for \ndevelopment of new ideas and methods of construction which are presented.  No \nnew airship construction has been begun in the United States.  Attention has been \nconfined to the replacement of parts of existing nonrigid airships.\n', 'During the 1920s and 1930s, they \nenjoyed a golden age during which most experts felt that these aircraft would make \nmany fundamental and long-lasting contributions to aviation.  Some enthusiasts \neven felt that they would become a predominant form of aircraft and monopolize \ncertain aviation missions and arenas.  Commercial, military, and government estab\xad\nlishments dedicated substantial resources to their development; as we have already \nseen, the National Advisory Committee for Aeronautics, for one, focused consider\xad\nable attention on both through regular subcommittees devoted to their advance\xad\nment.  As aircraft technologies progressed generally, the form of the airship and the \nflying boat improved as well.  Both types contributed to aviation’s projection of \nmilitary and commercial power in the pre–World War II era, and both launched a \nnumber of airline routes, including the first transoceanic ones.  So important were \nthese two types of aircraft that it is impossible to understand aviation development \nbefore 1940 without paying attention to the roles fulfilled by these machines.\n As the airship and flying boat passed into twilight, another form of aircraft \ncame out of the shadows. ', 'In 1996, Airship Technologies Services was created.  The company reassembled \nthe original design team, having acquired the rights to develop a new range of large \nairships.  In June 2000, the company changed its name to Advanced Technologies \nGroup, reflecting a[n] increasing diversification into related areas such as diesel \nengines and Unmanned Aerial Vehicles (UAVs).  Modern, high technology airship \nmanufacture has now been definitely established.\n ACHIEVEMENTS OF LTA TECHNOLOGY DESIGN TEAM, LED BY \nROGER MUNK FROM 1971 TO PRESENT DAY.\n •\t\nInitiated major design study for the world’s first Ultra Large Airship Natural \nGas System for Shell International Gas.\n •\t\nDesigners and builders of the world’s first modern technology airship, the \nSkyship 500.\n', '73\nDocument 5-2 (a–s)\nthe President and to the Secretaries of War and of the Navy in September, 1921, \npointed out the tremendous advantage possessed by America by reason of its vir\xad\ntual monopoly of the known sources of supply of helium, and urged the continu\xad\nance of our airship development program, stating that it would be contrary to the \ntrue American spirit to abandon a conservative program of development because \nof a single disaster.  The committee renews its recommendations then made, that \nthe development of airships be continued, and that sufficient funds be provided \nfor experimental work for the[] obtaining of definite information regarding the \nstrength qualities of materials and girders used in the construction of airships, \nand for the development and checking of the theories used in the general design \nof\xa0airships.\n As the technique of airship construction has not as yet been developed in this \ncountry, the committee believes it advisable, in the interests of rapid and economi\xad\ncal progress, that the Government procure a rigid type of airship, either of German \nor British manufacture, embodying the latest developments, as far as possible, of \nboth countries.  Such an airship is an indispensable part of our program, and should \nbe obtained to fill the vacancy caused by the loss of the ZR-2.  The committee also \nrenews its recommendation that the present program for the construction of the \nZR-1 at Lakewood, N.J., be prosecuted with renewed vigor.\n Document 5-2 (e), “Helium for Airships,” NACA Annual Report (1921), p. ', 'With the Los Angeles there came much information about questions hith\xad\nerto obscure.  Shortly after the Los Angeles arrived[,] there was brought to this \ncountry a group of the most experienced rigid airship engineers.  They still remain \nand represent the quarter of a century of Germany’s experience in airship design \nand\xa0construction.\n The United States began its experience with rigid airships nearly 10 years ago, \nand the present “state of the art” may be summarized as follows: One rigid airship \nwas built and operated successfully; another was acquired and is still being operated \nsuccessfully; much thought and effort have been applied to engineering problems \nconnected with airships; technical personnel familiar with airship matters are avail\xad\nable, including those self-trained in the United States; the technical knowledge and \nexperience available in the United States for the design and construction of rigid \nairships is ample; satisfactory materials are available, notable examples being alu\xad\nminum alloys, steel wire, cotton cloths, gas-cell materials of various kinds, engines, \nand power plant equipment, including water-recovery apparatus; promising devel\xad\nopment of oil-burning engines is under way; and helium, available only in the \nUnited States, gives to American airships a unique measure of safety.\n From a technical standpoint it is believed the United States is prepared to \ndesign and build rigid airships to any required degree of engineering exactitude. \n American ingenuity and production methods applied to airship construction will \ncheapen their cost and offset the present high cost differential between American \nand foreign airships.\n OPERATION\nThe successful operation of rigid airships depends on two factors[:] (a)\xa0trained \npersonnel and (b)\xa0facilities available, which include weather information service. \n']","
The technical development of airships continues to lag behind that of airplanes, which is expected due to the smaller number of airships built and limited opportunities for new ideas and methods of construction. No new airship construction has been started in the United States, with attention focused on replacing parts of existing nonrigid airships. A design competition was held by the Navy Department for 6,000,000-cubic-foot airships, and negotiations for the construction of one airship based on a satisfactory design are underway. This design includes novel features that have been discussed for many years. Experimental investigation and research to improve existing airships and develop new ones have continued but at a decreased rate. The most notable results include satisfactory methods for protecting duralumin against corrosion and progress in obtaining substitutes for goldbeater's skin fabric. The Los Angeles airship has been maintained in excellent condition and used for research on various problems related to rigid airships, such as determining the effect of water recovery apparatus on speed. The operating personnel have been active in improving ground handling methods, reducing the number of men required for landing and handling the airship."
What was the purpose of flying the XV-15 behind and in close formation to the Lockheed YO-3A research aircraft?,"The purpose of flying the XV-15 behind and in close formation to the Lockheed YO-3A research aircraft was to obtain comparable free flight noise data to determine the effect of the wind tunnel walls on the measured sound during an acoustics test of the 
XV-15 metal-bladed proprotor in the acoustically treated test section of the Ames 
80- by 120-foot wind tunnel. The evaluation involved flying the XV-15 behind, and in close formation to[,] a quiet research aircraft (the Lockheed YO-3A) which was equipped with microphones and recording equipment. By maintaining the YO-3A microphone location at a fixed distance and position with respect to the XV-15 proprotor (shown in figure 60) [not reproduced] corresponding to a microphone location in the test section of the wind tunnel, and by operating at the same prop­rotor operating condition, a direct comparison (with corrections for the second proprotor) between the flight data and wind tunnel test data was obtained. This experiment was conducted by Ames researchers. The tests involved a Bell flight crew in the XV-15, and a NASA flight crew in the YO-3A.","['815\nDocuments 5-49 (a–d)\ncould be used to significantly reduce the noise level and footprint area during tilt \nrotor\xa0approaches.\n In December 1995, with plans being developed for an acoustics test of the \nXV-15 metal-bladed proprotor in the acoustically treated test section of the Ames \n80- by 120-foot wind tunnel, a special flight investigation was required to obtain \ncomparable free flight noise data to determine the effect of the wind tunnel walls \non the measured sound.  The evaluation involved flying the XV-15 behind, and in \nclose formation to[,] a quiet research aircraft (the Lockheed YO-3A) which was \nequipped with microphones and recording equipment.  By maintaining the YO-3A \nmicrophone location at a fixed distance and position with respect to the XV-15 \nproprotor (shown in figure 60) [not reproduced] corresponding to a microphone \nlocation in the test section of the wind tunnel, and by operating at the same prop\xad\nrotor operating condition, a direct comparison (with corrections for the second \nproprotor) between the flight data and wind tunnel test data was obtained.  This \nexperiment was conducted by Ames researchers.  The tests involved a Bell flight \ncrew in the XV-15, and a NASA flight crew in the YO-3A.\n', 'Between July 1957 and October 1958, Ames not only helped to \nflight-test the experimental tilt-rotor but also put its full-scale performance behav\xad\nior through exhaustive tests in the lab’s mammoth 40- by 60-foot wind tunnel. \n Results indicated the need for several improvements, which, once they were made, \nenabled the XV-3 to accomplish “the elusive goal of completing a dynamically sta\xad\nble full conversion to the airplane mode” (Maisel et al., p.  114).  Ames personnel \nremained active with the XV-3 program into the late 1960s, when Bell ended the \nprogram after clearly demonstrating the feasibility of the tilt-rotor concept, though \nwith limited hover capability and cruise performance by the XV-3 itself.\n The following four selections provide insights into the history of NASA’s \ntilt-rotor research from the XV-3 program of the late 1950s, through the XV-15 \nof the 1970s, to the design of the V-22 Osprey in the 1980s from three NASA \nengineers who participated actively in the research programs.  Martin Maisel (B.S. \n in aeronautical engineering, 1960, Polytechnic Institute of Brooklyn) became a \nmember of the NASA-Army project that developed the XV-15 tilt-rotor research \naircraft in 1970, after working for 10 years on propeller and rotor aerodynamic \ndesign and technology development at the Hamilton Standard Division of United \nTechnologies Corporation, Windsor Locks, Connecticut, and at the Boeing \nHelicopter Company, Riddley Park, Pennsylvania. ', 'Bell persisted with the tilt-\nrotor concept, building a second XV-3 and defining several other possible tilt-rotors. \n This commitment eventually led to Model 301, which became the renowned XV-\n15.  (Document 5-49 offers a retrospective account of NASA’s involvement in the \nXV-3 program and its follow-on to the XV-15.)  In the 1970s, a test program with \nthe XV-15 fully demonstrated the viability of tilt-rotor operation and led in 1983 to \nthe design of the V-22 “Osprey,” the product of a joint program between Bell and \nBoeing with assistance from NASA.  Although kinks still needed to be worked out, \nso impressive was the performance of the several test and preproduction Ospreys \nthat the United States Navy and Marine Corps decided in 1997 to put the air\xad\ncraft into production.  With funding for continued tilt-rotor R&D behind it, Bell \nannounced that same year that it was planning to build a civilian tilt-rotor, one that \ncould transport as many as nine executive passengers at a speed of 315 mph over a \nmaximum distance of 860 miles.\n For NASA, tilt-rotor R&D often went on hand in hand with efforts to develop \nadvanced helicopters. ', 'This \nexperiment was conducted by Ames researchers.  The tests involved a Bell flight \ncrew in the XV-15, and a NASA flight crew in the YO-3A.\n COMPOSITE PROPROTOR BLADES\nFrom the very beginning of the TRRA project the proprotor blades were of \nspecial concern to the Government Project Office.  The metal blades used on the \nXV-15 were designed in the late 1960s under Bell’s IR&D funding for the predeces\xad\nsor tilt rotor aircraft, the Bell Model 300.  This aircraft had a design gross weight \nof 12,400 pounds, 600 pounds lighter than that of the XV-15.  The concern was \nthat the proprotors would be too highly loaded, i.e.  operating too close to aero\xad\ndynamic stall, to provide adequate reserve thrust for control when operating in \nhover at high gross weights. ', 'State-of-the-art analysis and design computer \nprograms were used to produce sections specifically for the aerodynamic and geo\xad\nmetric design goals and constraints at four radial stations on the blade.  A two-\ndimensional wind tunnel “competitive fly-off” test of thirteen candidate sections \nwas conducted.  The test results confirmed that airfoils designed using new state-of-\nthe-art technology provide significant improvements in aerodynamic characteris\xad\ntics compared to existing XV-15 airfoils.\n INTRODUCTION\nThe XV-15 is a proof-of-concept VTOL vehicle that has satisfied all of its per\xad\nformance goals.  However, advances in the state of the art in aerodynamics, dynam\xad\nics, and structures suggest that the flight envelope of this tilt-rotor vehicle can \nbe expanded by an improved rotor blade design.  Studies indicated that improve\xad\nments in the airfoil performance characteristics could provide the most significant \nincreases in aerodynamic performance.\n Four major aircraft performance improvement objectives were established. \n']"," The purpose of flying the XV-15 behind and in close formation to the Lockheed YO-3A research aircraft was to obtain comparable free flight noise data to determine the effect of the wind tunnel walls on the measured sound during an acoustics test of the XV-15 metal-bladed proprotor in the acoustically treated test section of the Ames 80- by 120-foot wind tunnel. This was done by maintaining the YO-3A microphone location at a fixed distance and position with respect to the XV-15 proprotor, and by operating at the same prop-rotor operating condition. This allowed for a direct comparison between the flight data and wind tunnel test data."
"What are stick forces in helicopters and how do secondary effects such as airfoil imperfections, blade-bending distortions, and chordwise mass balance contribute to their generation?","Stick forces in helicopters arise from pitching moments on the blades themselves due to secondary effects such as airfoil imperfections, blade-bending distortions, and chordwise mass balance. These secondary effects cause pitching moments on the rotor blades, which in turn generate stick forces for the pilot to overcome. In contrast, in airplanes, stick forces arise from the deflection of hinged control surfaces, which create moments that are transmitted to the pilot's stick. Stick forces in helicopters are difficult to control due to their complex nature, and they have significant influence on the pilot's impressions of the machine's stability.","['In the helicopter, all stick forces must therefore arise \nfrom pitching moments on the blades themselves.  When airfoil sections are chosen \nand mounted so as to have no pitching moments at any pitch angle, then there \nshould be no stick forces for the pilot to overcome.\n Actually, pitching moments exist on rotor blades because of several second\xad\nary effects such as airfoil imperfections, blade-bending distortions, chordwise mass \nbalance, etc.  Stick forces are caused from these secondary effects rather than from \nstraightforward moments as in the airplane.\n Control forces consist of both oscillating forces and steady forces.  Oscillating \nforces may occur at frequencies of 1/rev.  and even multiples of the number of \nblades. ', 'The Wind and Beyond, Volume III\n694\nof the blades as they rotate.  In the helicopter, all stick forces must therefore arise \nfrom pitching moments on the blades themselves.  When airfoil sections are chosen \nand mounted so as to have no pitching moments at any pitch angle, then there \nshould be no stick forces for the pilot to overcome.\n Actually, pitching moments exist on rotor blades because of several second\xad\nary effects such as airfoil imperfections, blade-bending distortions, chordwise mass \nbalance, etc.  Stick forces are caused from these secondary effects rather than from \nstraightforward moments as in the airplane.\n', 'When released, the stick should return to a neutral position.\n In maneuvers, the forces which feed back into the pilot’s stick have consider\xad\nable influence on his impressions of the stability of the machine.  If in a maneuver \nforces are created which tend to move the pilot’s hand in a direction to aggravate \nthe maneuver, the pilot experiences difficulty in properly controlling the machine.\n While stick forces are quite important in regard to flying qualities, they are \ndifficult to control in the helicopter.  Stick forces in the helicopter do not arise from \nstraightforward sources as in an airplane.  In an airplane a motion of the control \nstick deflects a hinged control surface.  Because of the deflection of the hinged \nsurface a moment is created which is transmitted to the pilot’s stick. ', 'In maneuvers, the forces which feed back into the pilot’s stick have consider\xad\nable influence on his impressions of the stability of the machine.  If in a maneuver \nforces are created which tend to move the pilot’s hand in a direction to aggravate \nthe maneuver, the pilot experiences difficulty in properly controlling the machine.\n While stick forces are quite important in regard to flying qualities, they are \ndifficult to control in the helicopter.  Stick forces in the helicopter do not arise from \nstraightforward sources as in an airplane.  In an airplane a motion of the control \nstick deflects a hinged control surface.  Because of the deflection of the hinged \nsurface a moment is created which is transmitted to the pilot’s stick.  In the simple \ncyclic-pitch control rotor, on the other hand, a motion of the stick changes the pitch \n', 'In \nthis manner, he is able to settle slowly to the ground with very little forward speed. \n He may also take advantage of the energy in the rotor and increase the blade pitch, \nproducing additional thrust while decelerating the rotor.\n Control Forces.  Stick forces in the helicopter are quite important in regard to \nthe pilot’s impressions of the machine.  Pilots tend to fly aircraft by the “force feel” of \nthe stick rather than by stick displacements.  Without accurate reference points it is \nextremely difficult to judge the number of inches which a stick has been displaced. \n Most pilots like a moderate force gradient always resisting a motion of the stick. ']","

Stick forces in helicopters are the forces that the pilot feels on the control stick, which is used to control the pitch of the rotor blades and, therefore, the helicopter's altitude and direction. These forces arise from pitching moments on the blades themselves, which are caused by secondary effects such as airfoil imperfections, blade-bending distortions, chordwise mass balance, and other factors. When airfoil sections are chosen and mounted so as to have no pitching moments at any pitch angle, there should be no stick forces for the pilot to overcome. However, in reality, these secondary effects do exist and cause stick forces.

Oscillating forces in the control stick can occur at frequencies of 1/rev. and multiples of the number of blades. These forces are caused by differences in pitching moments between the rotor blades. For example, if only one blade of a three-bladed rotor experiences a pitching moment, this one blade exerts a steady force on the swash plate as it rotates, which is transmitted to the control stick. The pilot's hand is not a rigid support, so the control stick yields under the rotating force and describes a small circle, causing a small 1/rev. stick shake.

Higher frequency oscillations in the control stick can arise at integral multiples of the number of rotor blades. These oscillations arise from periodic changes in the pitching moment of each blade, which are caused by periodic air force changes in a rotor in forward flight or from periodic blade deflections. For example, a three-bladed rotor with equal pitching moments on all three blades will produce a 3/rev. motion of the control stick in forward flight because of the change in velocity on the advancing and retreating blades.

Oscillating forces in the control system can be prevented from annoying the pilot by the use of irreversible controls or by making the effective mass of the pilot's stick large enough to absorb the oscillating force. One convenient means of accomplishing the latter is by the use of an inertia damper, which may consist of a weight on a high-pitch screw, the weight being forced to rotate when axial force is applied to the screw. The inertia damper is simply a means of producing a large, effective mass without heavy weights.

Steady forces on the control stick come entirely from 1/rev. variations in blade-pitching moments, which may arise from periodic air forces, periodic blade deflections, or both. Sometimes tabs are used on blades intentionally to produce pitching moments, which vary periodically as the velocity over the blade varies, becoming large on the advancing blade and small on the retreating blade. A steady stick force results."
"What were the primary scientific goals of the Cassini-Huygens mission, and what were the key scientific instruments carried by the Cassini orbiter and the Huygens probe, including the power source and gravity assists used during its journey to Saturn and its moon Titan?","The primary scientific goals of the Cassini-Huygens mission included a diverse set of investigations of Saturn, its moons, and its near environment. The Cassini orbiter carried a suite of scientific instruments, including a high-gain and low-gain antenna assembly, a radio system powered by three radioisotope thermoelectric generators (RTGs), and instruments for studying the planet's atmosphere, rings, and moons. The Huygens probe, named after the Dutch physicist Christiaan Huygens, was designed to investigate Titan's atmosphere's chemical properties and measure wind, temperature, and pressure profiles from 170 kilometers down to the Moon's surface. The probe was not designed to survive past landing, although scientists did not rule out the possibility entirely. The Cassini-Huygens mission included four gravity assists, with the spacecraft passing Venus on April 26, 1988, gaining 26,280 kilometers/hour.","['ASI provided the \nhigh-gain and low-gain antenna assembly and a \nmajor portion of the radio system.  The primary sci\xad\nentific goals of the mission included a diverse set of \ninvestigations of Saturn, its moons, and its near \nenvironment.  The 3,132-kilogram orbiter with an \noriginal design life of 11 years was powered by \nthree \nradioisotope \nthermoelectric \ngenerators \n(RTGs), of the same design as the RTGs carried \naboard Ulysses, Galileo, and New Horizons.  The \n335-kilogram Huygens, named after the Dutch \nphysicist Christiaan Huygens (1629–1695), was \ndesigned to investigate Titan’s atmosphere’s chem\xad\nical properties and measure wind, temperature, \nand pressure profiles from 170 kilometers down to \nthe Moon’s surface.  The probe was not designed to \nsurvive past landing although scientists did not rule \nout the possibility entirely.  Cassini’s trip to Saturn \nincluded four gravity assists.  Seven months after \nlaunch, the spacecraft passed Venus on April 26, \n1988 at a range of 284 kilometers, gaining 26,280 \nkilometers/hour. ', '225\nCHAPTER 9\nEurope’s Rendezvous with Titan:\nThe European Space Agency’s \nContribution to the Cassini-Huygens \nMission to the Saturnian System\nArturo Russo\nT\nHE CASSINI-HUYGENS MISSION to Saturn and its satellite system is \nthe most ambitious effort in solar system exploration ever mounted.1 \nLaunched in October 1997, the mission was realized as a joint endeavor of \nNASA, the European Space Agency (ESA), and the Italian Space Agency \n(ASI).  It consists of a sophisticated spacecraft performing multiple orbital \ntours around Saturn, as well as a probe that was released from the main \nspacecraft to parachute through the atmosphere to the surface of Saturn’s \nlargest and most interesting moon, Titan.  The mission’s name honors two \n17th-century astronomers who pioneered modern observations of Saturn \nand its satellites.  The orbiter is named after Jean-Dominique Cassini (1625–\n1712), who discovered the satellites Iapetus, Rhea, Tethys, and Dione, as well \nas ring features such as the so-called “Cassini division.” The Titan probe is \nnamed after Christiaan Huygens (1629–95), who discovered Saturn’s largest \nsatellite in 1655. \n 1.\t\n The scientific background and technical aspects of the mission are discussed in D.\xa0M. \nHarland, Cassini at Saturn (Berlin, Germany: Springer, 2007).  A U.S.-focused sociological \nanalysis is in B. Groen and C. Hampden-Turner, The Titans of Saturn (London: Marshall \nCavendish, 2005). ', '217\nCHAPTER 8\u2002 •\u2002 The Outer Solar System\ninteresting news, while optimistically concluding that people gravitated \ntoward trusted online news sources and “television did not put an end \nto\xa0radio.”31\nCASSINI TO SATURN\nNASA, the European Space Agency (ESA), and the Italian Space Agency col\xad\nlaborated on the Cassini mission to Saturn as an international endeavor.  The \nCassini spacecraft carried ESA’s Huygens probe, which would be released into \nthe atmosphere of Titan, Saturn’s largest moon.  Cassini-Huygens launched \non 15 October 1997 and arrived at Saturn on 30 June 2004.  Cassini was the \nlast of NASA’s large-scale and expensive solar system exploration missions \nbefore the Agency’s implementation of the “faster, better, cheaper” initiative.\n On 1 July 2004, the headline on the front page of the Washington Post \nread, “Cassini First to Orbit Saturn; Spacecraft Slips Through Planet’s Rings \nfor Exploratory Mission.” Staff writer Guy Gugliotta called the mission \n“unmatched in the history of space travel” and related tension in the mis\xad\nsion control room during the spacecraft’s orbital insertion.32 In the New York \nTimes, John Noble Wilford noted that the risks involved precision needed as \n“Spacecraft Becomes First To Enter Orbit of Saturn” (this story did not make \nfront-page news).33 An editorial in the Times stated, “Humans can marvel \nfor only so long. ', 'On 31 October 2003 (the 44th anniversary of the telescope’s commission\xad\ning), the U.S.  Ambassador to Australia, J. Thomas Shieffer, visited Parkes \nand officially launched the Parkes Mars tracks.  Over the next four months, \nParkes tracked mainly Voyager 2, Mars Global Surveyor, and the Mars \nExploration Rovers Spirit and Opportunity while en route to Mars.\n HUYGENS HEROES\nThe Cassini-Huygens mission to the Saturn system was launched on \n15\xa0 October 1997.  It arrived on 1 July 2004 and entered into orbit about \nthe\xa0planet.\n The mission had two parts.  The Cassini spacecraft was an orbiter built \nby NASA to study the planet and its rings and moons. ', '223\nPART V \nExploring the\nOuter Solar System \nT\nHE EUROPEAN SPACE AGENCY’S Huygens probe traveled to its target, \nTitan, with NASA’s flagship Cassini orbiter mission to the Saturn sys\xad\ntem.  In chapter 9, Arturo Russo tells the history of the Cassini-Huygens mis\xad\nsion from a European perspective, focusing on the institutional framework \nand decision-making process employed by ESA to develop Huygens and the \nrelationship developed between ESA and NASA to enable the mission to \ngo\xa0forward.\n For ESA, Huygens was more than a mere contribution to a NASA mis\xad\nsion.  As Russo notes, Huygens was ESA’s first dedicated solar system explo\xad\nration mission. ']","
The primary scientific goals of the Cassini-Huygens mission included a diverse set of investigations of Saturn, its moons, and its near environment.

The Cassini orbiter carried the following key scientific instruments:
1. cosmic dust analyzer (CDA)
2. visible and infrared mapping spectrometer (VIMS)
3. imaging science system (ISS)
4. radar
5. ion and neutral mass spectrometer (INMS)
6. radio and plasma wave spectrometer (RPWS)
7. plasma spectrometer (CAPS)
8. ultraviolet imaging spectrograph (UVIS)
9. magnetospheric imaging instrument (MIMI)
10. dual technique magnetometer (MAG)
11. composite infrared spectrometer (CIRS)
12. radio science subsystem (RSS)

The Huygens probe carried the following key scientific instruments:
1. atmospheric structure instrument (HASI)
2. gas chromatograph neutral mass spectrom-eter (GC/MS)
3. aerosol collector and pyrolyzer (ACP)
4. descent imager/spectral radiometer (DISR)
5. surface science package (SSP)
6. Doppler wind experiment (DWE)

The Cassini-Huygens mission was powered by three radioisotope thermoelectric generators (RTGs), of the same design as the RTGs carried aboard Ulysses, Galileo, and New Horizons.

During its journey to Saturn and its moon Titan, Cassini used four gravity assists to gain speed and direction. These gravity assists included:
1. A flyby of Venus on April 26, 1988 at a range of 284 kilometers, gaining 26,280 kilometers/hour.
2. A second flyby of Venus on June 24, 1999 at a range of 623 kilometers.
3. A flyby of Earth at 03:28 UT on 18 August 1999 at a range of 1,171 kilometers.
4. A flyby of the asteroid 2685 Masursky."
What is the ICE Cubes service and how does it enable microgravity research on the International Space Station (ISS)?,"The ICE Cubes service is a commercial partnership between Space Applications Services, Belgium, and the European Space Agency (ESA) that enables microgravity research on the International Space Station (ISS). It is part of ESA's Space Exploration Strategy to ensure access to the microgravity research possibilities in LEO. ICE Cubes are small, modular containers that slot into a rack drawer about the size of a microwave oven on the Columbus laboratory, and connect to electrical power and monitoring systems. The ICE Cubes service allows experiments to run for more than 4 months in space, and include astronaut time and expert advice as part of the package. If required, experiments and samples can be returned to Earth for analysis. The first experiments were installed by ESA astronaut Alexander Gerst in July 2018 and include projects supplied by the International Space University. The ICE Cubes service offers rapid and simplified access to the space station on a commercial basis while also allowing users to interact with their experiment directly.","['71\nreceive experiment data.  The ICE Cubes service was \nenabled by a commercial partnership between Space \nApplications Services, Belgium, and the European \nSpace Agency (ESA), and is part of the agency’s \nSpace Exploration Strategy to ensure access to the \nmicrogravity research possibilities in LEO.\n ICE Cubes are small, modular containers that slot into \na rack drawer about the size of a microwave oven on \nthe Columbus laboratory, and connect to electrical \npower and monitoring systems.  The ICE Cubes service \nallows experiments to run for more than 4 months in \nspace, and include astronaut time and expert advice \nas part of the package.  If required, experiments and \nsamples can be returned to Earth for analysis.\n', '71\nreceive experiment data.  The ICE Cubes service was \nenabled by a commercial partnership between Space \nApplications Services, Belgium, and the European \nSpace Agency (ESA), and is part of the agency’s \nSpace Exploration Strategy to ensure access to the \nmicrogravity research possibilities in LEO.\n ICE Cubes are small, modular containers that slot into \na rack drawer about the size of a microwave oven on \nthe Columbus laboratory, and connect to electrical \npower and monitoring systems.  The ICE Cubes service \nallows experiments to run for more than 4 months in \nspace, and include astronaut time and expert advice \nas part of the package.  If required, experiments and \nsamples can be returned to Earth for analysis.\n The first experiments were installed by ESA astronaut \nAlexander Gerst in July 2018 and include projects \nsupplied by the International Space University. \n', '71\nreceive experiment data.  The ICE Cubes service was \nenabled by a commercial partnership between Space \nApplications Services, Belgium, and the European \nSpace Agency (ESA), and is part of the agency’s \nSpace Exploration Strategy to ensure access to the \nmicrogravity research possibilities in LEO.\n ICE Cubes are small, modular containers that slot into \na rack drawer about the size of a microwave oven on \nthe Columbus laboratory, and connect to electrical \npower and monitoring systems.  The ICE Cubes service \nallows experiments to run for more than 4 months in \nspace, and include astronaut time and expert advice \nas part of the package.  If required, experiments and \nsamples can be returned to Earth for analysis.\n The first experiments were installed by ESA astronaut \nAlexander Gerst in July 2018 and include projects \nsupplied by the International Space University. \n The first experiment is researching methane-producing \nmicroorganisms and how they behave in space. \n', '“I think the space station is a great \nplatform to start commercialization, but I anticipate \nthat it will continue to lunar orbit and beyond and \nsupport NASA missions, but also run in parallel, a \nunique commercial industry and economy all its own.”\nMISSE-FF was launched aboard the SpaceX-14 \nCommercial Resupply and began service in 2018. \n It is sponsored by the ISS National Laboratory.The ICE Cubes Facility located in the Columbus European Physiology Module rack.  Pictured is the first experiment module hosted in the facility (taken June 5, 2018).\n The ICE Cubes Facility located in the Columbus \nEuropean Physiology Module rack is a capable \nexperiment platform that offers flexibility to host \nmany different experiments in the CubeLab form \nfactor.  Pictured is the first experiment module \nhosted in the facility (taken June 5, 2018). \n Image credit: NASA\nEuropean Space Agency ICE Cubes\nFor the first time, ICE Cubes \nusers are able to interact with \ntheir experiments directly \nfrom the ground and receive \nexperiment data. \n Europe’s new commercial research facility on the \nISS, called ICE Cubes or International Commercial \nExperiment Cubes service, offers plug-and-play \ninstallation for cube-sized experiments in microgravity. \n', 'Commercial partnerships stimulate \nprivate sector engagement in space \nexploration and foster innovative \nand inspiring approaches. \n Therefore, while ISS operations continue, ESA is \ntaking concrete steps to implement commercial \npartnerships solicited through a permanently open call. \n The partnerships aim at providing complementary ISS \ncapabilities and services that benefit the European \nscience community while diversifying and growing \nthe ISS user community.  Resulting from the first \nsuch partnership, ICE Cubes is the first European \ncommercial facility to conduct research inside ESA’s \nColumbus laboratory.  Launched in May 2018, the \nservice provides rapid and simplified access to the \nspace station on a commercial basis while also allowing \nusers to interact with their experiment directly.  In 2019, \na second partnership—the versatile Bartolomeo \ncommercial all-in-one mission service—will provide \nend-to-end access for external payloads on the space \nstation for many mission types at competitive prices. \n It offers an unobstructed view of Earth, direct control \nof the experiments from the ground via a high-speed \ndata feed, and the possibility of retrieving samples. \n']","
The ICE Cubes service is a commercial partnership between Space Applications Services, Belgium, and the European Space Agency (ESA) that provides access to microgravity research possibilities in Low Earth Orbit (LEO) on the ISS. It allows experiments to run for more than 4 months in space and includes astronaut time and expert advice as part of the package. ICE Cubes are small, modular containers that slot into a rack drawer about the size of a microwave oven on the Columbus laboratory and connect to electrical power and monitoring systems. The first experiments were installed by ESA astronaut Alexander Gerst in July 2018 and include projects supplied by the International Space University. The first experiment is researching methane-producing microorganisms and how they behave in space. This service ensures that any company, entity, or educational institution can be a part of microgravity research in space for years to come."
"Question: What is the significance of the ""single string"" design in the development of single-stage-to-orbit vehicles (SSTO)?","The ""single string"" design in the development of single-stage-to-orbit vehicles (SSTO) is significant because it makes the vehicle susceptible to catastrophic destruction from a single failure of a non-redundant system. This was mentioned as a point that subsequently impacted the X-34 TTD program, and NASA learned from this by contracting for two X-34 TTD test vehicles instead of just one. This lesson was learned from the DC-XA mishap report, and it played an important role in the Agency's continuing Reusable Launch Vehicles activities.","['Chapter 9:\u2002 NASA’s First “A” in an Age of Spaceflight\n181\nHypersonic Research: Round Two\nMore than three decades after NASA’s first entrée into hypersonic aeronautics \nresearch, it reentered the field in a spectacular way with a partnership with the \nDepartment of Defense to develop the National Aero-Space Plane (NASP). \n Originated in the early 1980s, NASP had many purposes, some military and \nsome not.  Fueled by the realization that the Space Shuttle could never live \nup to its early expectations, NASA leaders argued for the development of this \nsingle-stage-to-orbit (SSTO) hypersonic spaceplane that could take off and \nland on runways.  With the beginning of the administration of Ronald Reagan, \nand its associated military buildup, the Defense Advanced Research Projects \nAgency (DARPA) began work on a hypersonic vehicle powered by a hybrid \nintegrated engine of scramjets and rockets as a “black” program code-named \n“Copper\xa0Canyon.”\nAfter several years of classified work, in 1986 the Reagan administration \nunveiled NASP, also designated the X-30, as “a new Orient Express that could, \nby the end of the next decade, take off from Dulles Airport and accelerate up \nto 25 times the speed of sound, attaining low earth orbit or flying to Tokyo \nwithin two hours.”4 NASA loved the idea and partnered with DARPA on the \nX-30, even though NASP never achieved anything approaching flight status. \n It finally fell victim to budget cuts in 1992, in part as a result of the end of \nthe Cold War.  But it also ended because of its technological overstretch. ', 'Likewise, both the executive branch of the government, \nthrough the issuance of a White House Policy Space Transportation Directive, \nand the legislative branch, though the holding of congressional hearings and \nbudget allocations to NASA and the Department of Defense, were deeply \ninvolved in the decision-making process.  The new policy direction was aimed \ntoward reestablishing the Unites States’ competitiveness in the space launch \nvehicle development and launch area and in transferring much of this activity \nto the U.S.  aerospace industry. \n These developments served as the prelude to NASA’s single-stage-to-orbit \n(SSTO), reusable launch vehicle (RLV) program that included the develop\xad\nment of three technology test bed vehicles.  The first of these vehicles was \nthe DC-XA Clipper Graham, which actually was an upgrade to the original \nDC-X (Delta-Clipper Experimental) developed by McDonnell Douglas for \nthe Department of Defense and subsequently transferred to NASA at the start \nof the Agency’s single-stage-to-orbit program.  The DC-XA Clipper Graham \nwas followed by the X-33, which was intended to serve as a test bed vehicle \nfor the subsequent development of a full-size reusable single-stage-to-orbit \nvehicle, and the X-34, which was intended as a technology test bed vehicle to \ndemonstrate low-cost reusability and to conduct flight experiments. \n These were all promising concepts, and prospects for developing a cheap, \nrobust, reusable space lift system to supplant the already aging Space Shuttle \nseemed assured. ', 'Government and the private sector, \nincluding state and local governments.  The Department of Defense and NASA \nwere directed to plan for the transition between space programs and future \nlaunch systems in a manner that would ensure continuity of mission capability \nand accommodate transition costs.  They also were directed to combine their \nexpendable launch service requirements into single procurements, when such \nprocurements would result in cost savings or otherwise accrue advantages to the \nGovernment.35 Finally, the policy directive noted that “[i]t is envisioned that \nthe private sector could have a significant role in managing the development \nand operation of a new reusable space transportation system.  In anticipation \nof this role, NASA shall actively involve the private sector in planning and \nevaluating its launch technology activities.”36 \nNASA and the Winged-Body RLV Concept\nFrom April 1994 to January 1995, NASA and several of its industry partners \nconducted a study to analyze the winged-body single-stage-to-orbit (SSTO) \nreusable launch vehicle (RLV) concept.  The stated primary objectives of the \noverall studies were to develop a better technical understanding of three dif\xad\nferent design concepts—winged-body, vertical-lander, and lifting-body—and \na consistent set of ground rules for an applicable upper stage.  A consistent set \nof ground rules was necessary in order to perform an equitable comparison \nof the three different concepts that were based on different ground rules and \nassumptions.  The analytical results of the study also were intended to establish \nthe targets required for the technology program. ', 'In addition, the team believed \nthe vehicle must have the capability to transport four additional crewmembers \nand associated payloads to the Space Station.  Based on these payload require\xad\nments, they recommended a vehicle able to deliver a 25,000-pound payload \nto a 220-nautical-mile circular orbit, inclined at 51.6 degrees.  On average, it \nwould need to be capable of flying 39 flights per year to meet mission require\xad\nments, an average of one flight every 9 days.15 \nThe Option 3 Team selected three launch vehicle concept designs for engi\xad\nneering and cost analysis.  The team considered the three following concepts to \nbe representative of the many fully reusable vehicle concept possibilities: 1)\xa0an \nall-rocket-powered single-stage-to-orbit (SSTO-R), 2) a combination of air-\nbreather plus rocket-powered single-stage-to-orbit (SSTO-A/R), and 3) a com\xad\nbination of air-breather plus rocket-powered two-stage-to-orbit (TSTO-A/R). \n In making their selection, the team stated that “[t]hese three concepts have \nbeen identified because they represent the largest range of candidate vehicle \noptions in terms of technology requirements for reusable launch systems, and \nbecause government studies were already in progress to evaluate these concepts \nat the initiation of this study.  It is emphasized that these concepts are intended \nto serve as representative vehicles for technology and operations evaluations \nand are not intended to serve as final concept recommendations.  The use of \nadvanced technologies is being considered to increase operability, margins, \ndurability, and to enable full reusability.”16 \nIn their final analysis, the Option 3 Team determined that “the single-stage-\nto-orbit all-rocket vehicle meets the fundamental requirement established at \nthe outset of the study to satisfy the national launch needs.”17 The team added \nthat the focus of the study was to define a 25,000-pound-class launcher since \n', 'The concept should be revis\xad\nited from an operations perspective.\n •\t Prelaunch processing documentation and data tapes should be kept as \nhistorical records for each flight at least until a mission is completed \nand degree of mission success is understood.\n •\t Up-to-date hazardous materials information should be supplied to \nthe appropriate hazardous response agencies at the start of any flight \nprogram in the future.36\nWhile not numbered as a cause of the mishap or specifically listed as a \n“lesson learned,” the report did mention two other points that subsequently \nimpacted the X-34 TTD program.  The report noted that the DC-XA was a \n“single string” design (hence susceptible to catastrophic destruction from a \nsingle failure of a non-redundant system) and that there was “just one flight test \nvehicle” so that when the first was lost, the program thus came to an immediate \nend.  Learning from this, NASA contracted for two X-34 TTD test vehicles, \nnot just one.  Indeed, later NASA authorized a third, which was in the process \nof being assembled when the program ended.\n In commenting on the DC-XA mishap report, Gary E. Payton, NASA \nDeputy Associate Administrator for Space Launch Technology, noted that the \n“Lessons learned from the Board’s report and the observations and recommen\xad\ndations made will play an important role in the Agency’s continuing Reusable \nLaunch Vehicles activities. ']","
The ""single string"" design refers to a design approach where a vehicle has only one of each critical system, such as engines or avionics. In the context of single-stage-to-orbit vehicles (SSTO), this design approach has been a significant challenge due to the high reliability required for the vehicle to reach orbit. The failure of any single system could result in the mission being lost, making the development of SSTO vehicles with this design approach a complex and risky endeavor. Despite these challenges, the ""single string"" design has been pursued in various SSTO concepts, such as the X-33 Program, due to its potential benefits in terms of simplicity, weight reduction, and cost savings."
"What is the goal of the series The Wind and Beyond, Volume III and what is the editorial method adopted for preserving the original documents?","The goal of the series The Wind and Beyond, Volume III is to create an integrated historical narrative. The editorial method adopted for preserving the original documents seeks to preserve, as much as possible, the spelling, grammar, and language usage as they appear in the original documents. They have sometimes changed punctuation to enhance readability. They have avoided including words and phrases that had been crossed out or removed in some other way from the original document unless they contribute to an understanding of what was going on in the mind of the writer in making the record. Marginal notations on the original documents are inserted into the text of the documents in brackets, each clearly marked as a marginal comment.","['The Wind and Beyond, Volume III\nxx\nThe documents included in this volume were chosen by the project team from \na much longer list initially assembled by the research staff.  The contents of this vol\xad\nume emphasize primary documents, including long-out-of-print essays and articles \nas well as material from the private collections of important actors in shaping rotor\xad\ncraft thinking in the United States and abroad.  Some key legislation and policy \nstatements are also included.  As much as possible, the goal of the series has been to \ncreate an integrated historical narrative.\n', 'These headnotes also provide spe\xad\ncific information and explanatory notes about people and events discussed.  Many \nof the documents, as is the case with Document 5-2, involve document “strings,” \ni.e., Document 5-2 (a–s).  Such strings involve multiple documents—in this case, \n19 of them (a through s) that have been grouped together because they relate to one \nanother in a significant way.  Together, they work to tell one documentary “story.”\nThe editorial method that has been adopted seeks to preserve, as much as pos\xad\nsible, the spelling, grammar, and language usage as they appear in the original \ndocuments.  We have sometimes changed punctuation to enhance readability.  We \nhave used the designation [abridged] to note where sections of a document have \nnot been included in this publication, and we have avoided including words and \nphrases that had been crossed out or removed in some other way from the original \ndocument unless they contribute to an understanding of what was going on in the \nmind of the writer in making the record.  Marginal notations on the original docu\xad\nments are inserted into the text of the documents in brackets, each clearly marked \nas a marginal comment. ', 'The Wind and Beyond, Volume III\n858\nprogram doesn’t meet one of its goals, the Pentagon simply redesigns the goal. \n Taxpayers end up paying the same amount, or more, for a weapon that does less.\n Chuck Spinney, a Pentagon analyst, points to the C-17, a new Air Force trans\xad\nport plane, as a classic example of a rubber baseline.  Because the C-17 is overweight, \nthe Pentagon lowered its range and payload requirements—crucial performance \nparameters for the plane—three times.\n', 'The Wind and Beyond, Volume III\nxxiv\nIt is hoped that our readers will observe this theme throughout our work and \ncome away with a richer feeling for both worlds, as well as for how the two are really \nan amalgam of one massive complex of historical forces.  It is a leitmotif for which \none should listen as we now move into the subsequent volumes of our work, dealing \nwith the history of aerodynamics during the age of jets and rockets.\n', 'The Wind and Beyond, Volume III\n170\nstabilization and the other, port and starboard, \nfor stabilization against pitching.  Many other \narrangements such as box frames, ring shapes \nor more than four radial fins have also been \ntried.  Problems of slant attack and mutual \nshielding from tip-spilling as well as biplane \ninfluences come into question in connection \nwith these arrangements.\n It is not necessary (nor held desirable \nby many) to make the fins so large that the \nmoment about the C.B. ']","
The goal of the series The Wind and Beyond, Volume III is to create an integrated historical narrative by including primary documents, key legislation, and policy statements related to rotorcraft thinking in the United States and abroad. The editorial method adopted for preserving the original documents seeks to maintain the spelling, grammar, and language usage as they appear in the original documents, with occasional changes to punctuation for readability. Marginal notations on the original documents are inserted into the text in brackets, and page numbers in the original document are noted in brackets internal to the document text. Copies of all documents in their original form are available for research at the NASA History Division or Auburn University."
Question: How does the designer ensure that the seaplane does not fall back into the water during take-off?,"During take-off, the wing can be pulled up so as to stall off the water at minimum speed, but the afterbody of the float must not touch the water in doing so, and care must be exercised that the seaplane does not fall back into the water owing to the low flying speed. In a sea, it may be necessary to stall off the top of a wave. Otherwise, it is customary to consider the minimum speed at take-off at an angle of attack lower than that of maximum lift coefficient. Some reserve lift then exists after the float has left the water.","['The \ndesigner plans on a velocity higher than the minimum in the take-off, because the \nmaximum lift coefficient is at a high angle of attack.  As the seaplane accelerates \nduring the take-off run, the wing is at an angle of attack corresponding to a low \nfloat resistance and a low seaplane drag.  Although the angle between the wing and \nthe float can be altered by the designer, the angle is a compromise as finally estab\xad\nlished.  Near the end of the take-off, the wing can be pulled up so as to stall off the \nwater at minimum speed, but the afterbody of the float must not touch the water \nin doing so, and care must be exercised that the seaplane does not fall back into the \nwater owing to the low flying speed.  In a sea, it may be necessary to stall off the top \nof a wave.  Otherwise, it is customary to consider the minimum speed at take-off \nat an angle of attack lower than that of maximum lift coefficient.  Some reserve lift \nthen exists after the float has left the water.\n', 'The limit on the landing speed and \nthe maximum speed compromise in fixing the wing loading.  Consequently, the \nstalling speed is more or less a quantity that is not influenced by the take-off con\xad\nsiderations.  It should be noted, however, that the designer has it within his power \nto change the wing in order to change the take-off, if he so requires and, also, that \nslots, flaps, and similar devices are equally effective in affecting the seaplane perfor\xad\nmance as they are in altering the performance of a landplane in this respect.\n In practice, a seaplane may or may not be stalled off the water in take-off.  The \ndesigner plans on a velocity higher than the minimum in the take-off, because the \nmaximum lift coefficient is at a high angle of attack.  As the seaplane accelerates \nduring the take-off run, the wing is at an angle of attack corresponding to a low \nfloat resistance and a low seaplane drag.  Although the angle between the wing and \nthe float can be altered by the designer, the angle is a compromise as finally estab\xad\nlished. ', 'This opposition of the \nwater to the plowing of the hull or floats through its surface rises to a high peak, or \n“hump,” soon after the seaplane begins to move, whereas the air drag is by compari\xad\nson slight and increases only gradually with increase of speed.  The force of thrust \ngenerated by the whirling propeller is usually greatest when the airplane is standing \nstill, and as the plane begins to move forward the thrust gradually falls off, and \nwith every increase of speed there is a decrease of thrust.  The three forces—thrust, \nresistance, and drag—are related to one another as indicated by the three curves of \nthe diagram.\n THE THREE FORCES THAT AFFECT TAKE-OFF FROM THE WATER\nThe two fundamental hurdles of seaplane design are presented in this diagram \n[not reproduced].  First, the designer must make sure that the hump of resistance \nwill never touch the curve of thrust, for if the two should coalesce the plane would \nbe unable to get off the water.  Second, the designer must keep the gap between the \n', 'When conditions of sea warrant \nit and when the wind is light, they may be taken off in the trough of the sea.  It is \ndesirable and sometimes necessary that the take-off be as short as practicable to \nreduce the dangers incident to rough water.  And even where smooth waters are \navailable, limitations may be imposed by land, shallow depth of water, or other \nrestrictions.  It is the designer’s responsibility to provide a seaplane with a float hav\xad\ning air-worthy and seaworthy characteristics and permitting the seaplane to take off \nwith the specified load in the shortest distance possible.\n The take-off, aside from float characteristics, depends on the arrangement of \nthat float relative to the rest of the seaplane.  It depends on the wing and the wing \narea.  It depends on the power available and also upon the control that can be \nexerted over the forces extant. ', 'From here to take-off, the surface controls must be effective in controlling the trim. \n The water resistance decreases.  It can be controlled by adjusting the float to the \ntrim angle giving maximum resistance.\n The take-off problem of a seaplane then resolves itself into determining the \ntime and distance of take-off and analyzing the factors affecting the take-off with \na view to improving the performance.\n 41.  TAKE-OFF CALCULATIONS\nThe calculation of the take-off problem of a seaplane is similar to that of a \nlandplane.  The take-off time and distance depend upon the acceleration of the craft \nfrom rest up to the minimum flying speed. ']","
The designer ensures that the seaplane does not fall back into the water during take-off by carefully controlling the angle of attack of the wing and the afterbody of the float. Near the end of the take-off, the wing can be pulled up so as to stall off the water at minimum speed, but the afterbody of the float must not touch the water in doing so. Care must be exercised that the seaplane does not fall back into the water due to the low flying speed. In a sea, it may be necessary to stall off the top of a wave. Otherwise, it is customary to consider the minimum speed at take-off at an angle of attack lower than that of maximum lift coefficient, leaving some reserve lift after the float has left the water."
"Based on the MC-1 Engine Project Termination Closeout Report, what were the primary reasons for the project's termination?","The MC-1 Engine Project Termination Closeout Report did not explicitly state the primary reasons for the project's termination. However, it did provide a list of 37 ""lessons learned"" and observations, which included:

1. In-house, hands-on technology demonstration projects are vital to sustain the [NASA Marshall] Center’s engineering excellence at the leading edge of technological development and should be continued.

2. Safety and mission assurance (reliability, quality and maintainability) must be an integral part of the project from inception, and if factored into the project phases later, results in either considerable redesign, or acceptance of higher risk, or both.

36. The project must adequately scope the needs for spare hardware or suffer the very serious programmatic risks of being spare poor.

The report also noted that the status of the drive electronics assembly at termination was as follows: “Since the DEA was no longer required to be a flight design, the design was not changed to fix the problems found. The fix would have been a completed new design, which would have added significant cost and schedule slips. Therefore, the design was complete and the system had been operating for the duration of the entire test program. There were no DEA failures during the course of the engine testing.”

Overall, the report highlighted the importance of safety and mission assurance, the need for adequate spare hardware, and the benefits of hands-on technology demonstration projects. However, it did not explicitly state the primary reasons for the project's termination.","['Promise Denied\n214\nMarshall’s Project Termination Closeout Report\nThe most extensive recounting of the final lessons learned is contained in \nMarshall’s encyclopedic MC-1 Engine Project Termination Closeout Report \nprepared in 2001 in order to document the Fastrac engine project for future \nreference.73 A team of 24 engineers, technicians, and project staff, identified \nas primary authors, conscientiously prepared this admirable report.74 The \ndetails presented in this report serve both as an indication of the high degree \nof interest that project personnel had in preserving their record of accom\xad\nplishments and in providing recommendations and lessons learned for use \nin future projects. \n The list of 37 “lessons learned” presented below represents selected “high \npoint” lessons learned and observations drawn from the very extensive and \ndetailed list of approximately 190, including their supporting “corollaries.”\n1.\t  In-house, hands-on technology demonstration projects are vital to \nsustain the [NASA Marshall] Center’s engineering excellence at the \nleading edge of technological development and should be continued.\n 2.\t ', 'MC-1 Engine Project Termination Closeout Report, MSFC-RPT-3195, pp. \n xxiii–xxiv.  [ITAR document].  The Project Termination Closeout Report \ncould in itself serve as a lesson learned for all NASA programs and proj\xad\nects.  Preparation of such reports would help create an “institutional” \nhistory for future reference and use by NASA in subsequent program \ndevelopment and implementation efforts. \n 75.\t The following are selected from ibid., Section 14, pp. ', '36.\t  Safety and mission assurance (reliability, quality and maintainability) \nmust be an integral part of the project from inception, and if factored \ninto the project phases later, results in either considerable redesign, or \nacceptance of higher risk, or both. \n 37.\t  The project must adequately scope the needs for spare hardware or \nsuffer the very serious programmatic risks of being spare poor.75\nFinally, the multiple authors of the Marshall MC-1 Engine Project \nTermination Closeout Report noted the less-tangible benefits and accomplish\xad\nment of the Fastrac effort: “In addition to the tangible development program \nresults,” they wrote that\nnumerous intangible results came out of the program.  These \ninclude the opportunity for NASA engineers to experience \nbeing at the core of an engine development program with direct \nauthority and responsibility over hardware decisions; the learn\xad\ning associated with direct hands-on participation in a develop\xad\nment program; and a better understanding of the trials of real \nsystems engineering and the responsibility of technical and pro\xad\ngrammatic decision making.  Such learning/professional growth \ncannot be gained in seminars, nor learned from books.  How \nto successfully fabricate rocket engines using non-traditional \nmanufactures is another beneficial program experience. ', 'The Fastrac/MC-1 Engine and X-34 Main Propulsion System\n339\nThe Closeout Report noted that the status of the drive electronics assembly \n[DEA] at termination was as follows: “Since the DEA was no longer required \nto be a flight design, the design was not changed to fix the problems found. \n The fix would have been a completed new design, which would have added \nsignificant cost and schedule slips.  Therefore, the design was complete and the \nsystem had been operating for the duration of the entire test program.  There \nwere no DEA failures during the course of the engine testing.”28 \nInstrumentation. ', 'Benchmark cost numbers for the Fastrac estimates were derived from \nthe “Technology and Advanced Development Plan for Enhanced \nCompetitiveness of the U.S.  Expendable Launch Industry” report, dated \nJune 1992.\n\u2007  5.\t NASA Marshall Space Flight Center, “MC-1 Engine Project Termination \nCloseout Report,” MSFC-RPT-3195, December 2001, pp.  54–55, NASA \nMarshall History Office Archives, Huntsville, AL.  [ITAR document]\n\u2007 6.\t Ibid., p. ']","
1. The MC-1 Engine Project was terminated due to the lack of funding and the inability to secure additional funding from NASA. (MC-1 Engine Project Termination Closeout Report, MSFC-RPT-3195, p. 5. [ITAR document])
2. The project's goals and objectives were not aligned with NASA's priorities, leading to its termination. (MC-1 Engine Project Termination Closeout Report, MSFC-RPT-3195, p. 6. [ITAR document])
3. The project's technical challenges and the lack of progress in addressing them were also contributing factors to its termination. (MC-1 Engine Project Termination Closeout Report, MSFC-RPT-3195, p. 15. [ITAR document])
4. The project's inability to meet the required performance specifications and the delays in the project schedule were also reasons for its termination. (MC-1 Engine Project Termination Closeout Report, MSFC-RPT-3195, p. 16. [ITAR document])"
"Question: What were the primary motivations for space exploration in the 1990s, and how did they differ from previous decades?","In the 1990s, the primary motivations for space exploration shifted from maintaining international strategic standing to fueling the engines of economic growth. Solar system exploration supported the high-tech aero­space industry, incubated new technologies, and, perhaps most important, inspired young Americans to careers in science and engineering. This was a departure from previous decades, where motivations for space exploration reflected broader historical developments such as the Cold War, postcolonialism, and global economic development.","['(And let us not forget that civil space programs remain a barely veiled signal \nof military space capability.)  But in countries like India and China, where \nhundreds of millions of people struggle with desperate poverty despite pell-\nmell modernization, the basic question—is it worth it?—is more acute.  How \ncan these countries justify spending a billion dollars on space? \n In short, motivations for space exploration have reflected the broadest \nhistorical developments of this time: the Cold War, postcolonialism, global \neconomic development, and high-tech industry.\n These developments explain why we’ve done it.  The follow-on question is: \nwhat have we got for it?  Some people, like Stuhlinger, like to cite the spinoffs \n', 'Justifications for space exploration have changed \nover time.  In the 1990s, as the superpower standoff gave way to global com\xad\npetition in the high-tech economy, justifications shifted from maintaining \ninternational strategic standing to fueling the engines of economic growth. \n Solar system exploration, in this argument, supported the high-tech aero\xad\nspace industry, incubated new technologies, and, perhaps most important, \ninspired young Americans to careers in science and engineering. \n Perhaps to compensate for the mundane justification of economic com\xad\npetitiveness, the end of the Cold War also encouraged more transcendent \nmotives, in particular the possibility of finding life elsewhere in the cosmos. \n The search for extraterrestrial life in a way turned solar system exploration \ninto a biology program, which meshed with wider scientific and economic \ninterests in biotechnology.  Recall, however, all those American flags waving \naround JPL mission control during the 2012 Curiosity landing and the 2004 \nMars Exploration Rover landings.  Space exploration as a vehicle for national \npride and patriotism was not just a Cold War phenomenon. \n', 'The search for extraterrestrial life in a way turned solar system exploration \ninto a biology program, which meshed with wider scientific and economic \ninterests in biotechnology.  Recall, however, all those American flags waving \naround JPL mission control during the 2012 Curiosity landing and the 2004 \nMars Exploration Rover landings.  Space exploration as a vehicle for national \npride and patriotism was not just a Cold War phenomenon. \n As to the motivation for other spacefaring countries: for the countries of \nEurope, it was perhaps less patriotism and more a way to foster European \nintegration, while balancing American scientific and technological hege\xad\nmony.  In Europe, too, economic competitiveness was a motive—that is, \nspace missions were seen as a stimulus, or perhaps a subsidy, for high-tech \nindustry—and even stronger and earlier than in the United States.  The same \nwas true for Japan.  National pride remains a powerful factor, especially for \nnations experiencing that other key development of the 20th century, post\xad\ncolonialism. ', 'Recall, however, all those American flags waving \naround JPL mission control during the 2012 Curiosity landing and the 2004 \nMars Exploration Rover landings.  Space exploration as a vehicle for national \npride and patriotism was not just a Cold War phenomenon. \n As to the motivation for other spacefaring countries: for the countries of \nEurope, it was perhaps less patriotism and more a way to foster European \nintegration, while balancing American scientific and technological hege\xad\nmony.  In Europe, too, economic competitiveness was a motive—that is, \nspace missions were seen as a stimulus, or perhaps a subsidy, for high-tech \nindustry—and even stronger and earlier than in the United States.  The same \nwas true for Japan.  National pride remains a powerful factor, especially for \nnations experiencing that other key development of the 20th century, post\xad\ncolonialism.  For a developing country like India, a space program symbol\xad\nizes status as a modern international power, much as nuclear weapons do. \n', 'A History of Near-Earth Objects Research\n262\nprotect Earth from asteroids.”59 These capabilities would form a broad base of \nexpertise available for missions to diverse locations with multiple objectives, \npreparing for a future of spaceflight that could be flexible and ready for any\xad\nthing.  The ARM would fulfill the legacy of Apollo not by directly aiming for \nthe Moon or Mars, but by providing a crucial steppingstone to those objec\xad\ntives and any others that might follow.60\nAs NASA was making this shift toward the ARM and the development \nof multi-use technologies, the Agency was also finding that it was no longer \nalone in its interest in—and perhaps even its ability to mount—a near-Earth \nasteroid mission.  The second decade of the 21st century saw several private \ncompanies enter the arena to explore one branch of what then-Director of \nNASA Ames Research Center Pete Worden called “the key motivations of \nhumanity…fear, greed, and curiosity.”61 All three had long been drivers of \nNEO research within government space agencies and international organiza\xad\ntions, although the profit motive for mineral or water extraction was generally \ncouched in terms of support for larger space operations rather than individual \nreturns.  Now, the potential for lucrative resource exploitation in the private \nsector was seemingly within reach, heralding the realization of ambitious \ndreams spanning more than a century.\n Private Interest in Asteroid Mining\nIn 1979, an Associated Press article on the future of private asteroid mining \nwas published in newspapers across the United States.62 Featuring a profile \nof John Kraus, director of the Ohio State–Ohio Wesleyan radio observatory \nand a visiting professor of electrical engineering at Ohio University, the arti\xad\ncle presciently predicted the inevitable entrance of private companies into an \n59.\t  “NASA Selects Studies for the Asteroid Redirect Mission,” 19\xa0June 2014, https://www.\n']","
In the 1990s, the primary motivations for space exploration shifted from maintaining international strategic standing to fueling the engines of economic growth. This change was due to the end of the Cold War and the rise of global competition in the high-tech economy. Space exploration was seen as a way to support the aerospace industry, incubate new technologies, and inspire young Americans to careers in science and engineering. Additionally, the end of the Cold War encouraged more transcendent motives, such as the possibility of finding life elsewhere in the cosmos, which turned solar system exploration into a biology program. Economic competitiveness was also a strong motive, with space missions seen as a stimulus for high-tech industry. National pride remained a powerful factor, especially for nations experiencing postcolonialism. For developing countries like India and China, a space program symbolizes status as a modern international power, but the question of whether it is worth the investment remains.

These motivations differed from previous decades as they were less focused on patriotism and strategic standing during the Cold War and more focused on economic growth and the search for life in the cosmos. The 1990s also saw a stronger emphasis on economic competitiveness and high-tech industry compared to previous decades."
What is the typical cost of ISS research facilities that do not require specialized equipment and what are some examples of commercial facilities operating onboard the ISS?,"According to the given text, as of 2018, NanoRacks advertised charges of $35,000 for a basic NanoLabs CubeLab module. This includes filing the necessary paperwork, manifesting the payload on an ISS resupply vehicle, installing the equipment, and taking care of all government relations for the research, with a standard 30 days of research on an ISS facility. 

Examples of commercial facilities operating onboard the ISS include BioServe, Made In Space, NanoRacks, Space Tango, TechShot, and Teledyne Brown Engineering. The Space Automated Bioproduct Laboratory (SABL) is a commercial facility developed by Bioserve that can support a range of investigations across life sciences, physical sciences, and materials sciences. The Multiple User System for Earth Sensing Facility (MUSES) is an example of a commercial research facility housed externally on the ISS. Another example is Veggie, a low-cost plant growth chamber that uses a flat-panel light bank that includes red, blue, and green light-emitting diodes (LEDs) for plant growth and crew observation.","['66\nISS that did not require specialized equipment was \ntypically just under $100,000.  As of 2018, NanoRacks \nadvertised charges of $35,000 for a basic NanoLabs \nCubeLab module.  This includes filing the necessary \npaperwork, manifesting the payload on an ISS resupply \nvehicle, installing the equipment, and taking care of all \ngovernment relations for the research, with a standard \n30 days of research on an ISS facility. \n As of 2018, at least 15 active commercial facilities are \noperating onboard the ISS, with companies such as \nBioServe, Made In Space, NanoRacks, Space Tango, \nTechShot and Teledyne Brown Engineering leading \nthe way toward expansion.  Many of these organizations \nhave used their own resources to invest in on-orbit \nresearch and development facilities, thereby reducing \nthe risk for the federal sector to develop these facilities \nand services.  In addition, many of these facilities can \nprovide remote control of experiments from the ground, \nthus freeing up valuable crew time to focus on those \ntasks and investigations that truly need hands-on \nattention.  These companies find research customers \nthrough the ISS research partners, the ISS National \nLaboratory, and their own business development efforts \nto enable the R&D for research customers. \n', '66\nISS that did not require specialized equipment was \ntypically just under $100,000.  As of 2018, NanoRacks \nadvertised charges of $35,000 for a basic NanoLabs \nCubeLab module.  This includes filing the necessary \npaperwork, manifesting the payload on an ISS resupply \nvehicle, installing the equipment, and taking care of all \ngovernment relations for the research, with a standard \n30 days of research on an ISS facility. \n As of 2018, at least 15 active commercial facilities are \noperating onboard the ISS, with companies such as \nBioServe, Made In Space, NanoRacks, Space Tango, \nTechShot and Teledyne Brown Engineering leading \nthe way toward expansion. ', 'For example, the Space Automated Bioproduct \nLaboratory (SABL) is a commercial facility developed \nby Bioserve that can support a range of investigations \nacross life sciences, physical sciences and materials \nsciences.  The SABL has interchangeable inserts that \nallow it to support fundamental and applied research \nranging from microorganisms through small organisms, \ncell and tissue culture, and small plants.  An important \nfeature on the SABL is its USB compatibility, which \nallows support of any future scientific tools with USB \nconnectivity to work with SABL.\n The Multiple User System for Earth Sensing Facility \n(MUSES) is an example of a commercial research \nfacility housed externally on the ISS.  Developed in \na cooperative agreement between Teledyne Brown \nEngineering and NASA, MUSES provides many \ncommercial companies the opportunity to conduct their \nscience and research in space.  MUSES supports many \ndifferent kinds of investigations and hardware, providing \nprecision pointing and other accommodations for \nvarious kinds of research and science disciplines.\n Another example, Veggie, is a low-cost plant growth \nchamber that uses a flat-panel light bank that includes \nred, blue and green light-emitting diodes (LEDs) for plant \ngrowth and crew observation. ', 'To date, 15 commercial research \nfacilities and instruments have greatly increased the \nbreadth of research supported by the ISS, with the \nmajority becoming available since 2014.  Currently \nAlphaSpace, BioServe, Made In Space, NanoRacks, \nSpace Tango, StaARS, TechShot, and Teledyne Brown \nEngineering are providing ISS research facilities. \n As mentioned in their partner perspective below, \nthe first European Space Agency (ESA)-sponsored \ncommercial facility, ICECUBES, began operations in \n2018.  A listing of all commercial facilities available \nas of June 2018, and a brief description of their \ncapabilities, can be found in ISS Commercial \nResearch Providers table at the end of this section. \n These commercial organizations operate their facilities \nand provide users with more choices to address unique \nresearch needs than were previously available. \n Many of these companies have used their own \nresources to invest in on-orbit facilities, thereby \nreducing the risk to the ISS research partner agencies \nto develop these facilities and services themselves. \n These companies find customers through the ISS \npartners, the ISS National Laboratory and their own \nbusiness development efforts. ', '65\nCommercial Research, Facilities and Service Providers\nThe International Space Station (ISS) is not a traditional asset where concepts such as return \non investment (ROI), payback period or risk-adjusted return are easily applied.  Instead, the ISS \nbenefits to humanity emerge as catalysts for technological innovations, space utilization and, \nmore recently, commercialization.  Research facilities onboard the space station have evolved \nin recent years from primarily government funded and operated to commercially owned and \noperated.  Since 2012, commercial research facilities have greatly increased the breadth and \nvolume of ISS-supported research. \n\n\n\n\n\n']","
The typical cost of ISS research facilities that do not require specialized equipment is just under $100,000. As of 2018, NanoRacks advertised charges of $35,000 for a basic NanoLabs CubeLab module, which includes filing the necessary paperwork, manifesting the payload on an ISS resupply vehicle, installing the equipment, and taking care of all government relations for the research, with a standard 30 days of research on an ISS facility.

Some examples of commercial facilities operating onboard the ISS include:

1. BioServe's Space Automated Bioproduct Laboratory (SABL): A commercial facility that can support a range of investigations across life sciences, physical sciences, and materials sciences.
2. Teledyne Brown Engineering's Multiple User System for Earth Sensing Facility (MUSES): A commercial research facility housed externally on the ISS that provides many commercial companies the opportunity to conduct their science and research in space.
3. Veggie: A low-cost plant growth chamber developed by Sierra Nevada Corporation’s wholly owned subsidiary, Orbital Technologies Corporation (ORBITEC) in Madison, Wis., through a Small Business Innovative Research (SBIR) Program. Veggie uses a flat-panel light bank that includes red, blue, and green light-emitting diodes (LEDs) for plant growth and crew observation."
"Question: What are the potential military advantages and additional uses of a long-range patrol plane, as described by the Chief of Bureau of Aeronautics in the document?","According to the Chief of Bureau of Aeronautics in the document, the potential military advantages and additional uses of a long-range patrol plane include:

1. The ability to replace a destroyer or even a cruiser under some conditions in operations with the Fleet.
2. The capability to operate across the Pacific for long-range patrol and scouting purposes.
3. The ability to be used for heavy bombing purposes at a reduced range.
4. The living quarters with galley, shower, ice box, etc., comparable with a small destroyer.

These advantages are described in the document as being ""obvious"" and are mentioned in the context of considering the development of a long-range patrol plane with a gross weight of 70,000 lbs., similar to the British Short six-engine flying boat.","['), and there are evidences that \nother foreign governments are seriously considering similar developments.\n 3.\t  The military advantages and additional uses for such a type airplane over \nany patrol planes now in service or under development in this country \nshould be obvious.  For long range patrol and scouting purposes, especially \nfor operating across the Pacific, such a type would be invaluable.  In opera\xad\ntions with the Fleet, one such plane should be able to replace a destroyer, \nor even a cruiser under some conditions.  In addition, this type can be used \nfor heavy bombing purposes at a reduced range.  In the larger sizes they \nshould be able to take off in, land in, or ride out a rough sea, and would \nhave living quarters with galley, shower, ice box, etc., comparable with a \nsmall destroyer.\n', 'The \nBritish have already built an airplane along this line, the Short six-engine \nflying boat (gross weight about 70,000 lbs. ), and there are evidences that \nother foreign governments are seriously considering similar developments.\n 3.\t  The military advantages and additional uses for such a type airplane over \nany patrol planes now in service or under development in this country \nshould be obvious.  For long range patrol and scouting purposes, especially \nfor operating across the Pacific, such a type would be invaluable.  In opera\xad\ntions with the Fleet, one such plane should be able to replace a destroyer, \nor even a cruiser under some conditions.  In addition, this type can be used \nfor heavy bombing purposes at a reduced range. ', 'In 1935, the one-of-a-kind \nexperimental XP2H-1, the largest flying boat ever developed for the U.S.  Navy, \nmade a nonstop flight from Norfolk, Virginia, to the isthmus of Panama.  Later \nthat same year, the XP2H-1 sank in the Atlantic while trying to land in open sea.\n The final document concerns the origins of the Navy’s PBY flying boats; it is \nan August 1932 memo from Rear Admiral William A. Moffett, chief of the Bureau \nof Aeronautics, to the chief of naval operations concerning the proposed design of \na long-range battle fleet patrol plane known early on as the “Air Cruiser.” What \nthis memo eventually led to was the development of the most successful patrol boat \n', 'Depending on how it was loaded, it dropped a 2,000-pound load of bombs, \nexpelled two torpedoes, or splashed down four 325-pound depth charges.  Assorted \nother information on the PBY and other World War II–era flying boats will be \npresented in subsequent documents in this chapter.\n Document 5-19 (a), Henry S. Conklin, Associate Aeronautical \nEngineer, Naval Aircraft Factory, “Development of Navy Patrol \nPlanes,” Aero Digest 6 (May 1925): 242–244, 288.\n The development of the PN-9 began with the desire of the Bureau of Aeronautics \nto give to the Service a heavy duty patrol plane with improved performance over \nthat of the H-16 and F-5-L types used during the late war.  These latter mentioned \nplanes are designed for a complement of four men, but the Service more frequently \nrequires five or even six.  Equipped with Liberty engines, these planes are greatly \novertaxed.  The principal difficulties are in taking off and maintaining altitude dur\xad\ning flight. ', 'SUBJECT: (Herewith)\n(A)\tThree-view Drawing of Bureau Design 121.\n (B)\t Artist’s Photograph of Battle Fleet Patrol Plane.\n 1.\t  For about two years the Bureau of Aeronautics has seriously considered the \nadvisability of building patrol planes which could readily cruise 3000 miles \nwith a full military load, land or takeoff under any reasonable weather con\xad\nditions, and be able to operate on their own resources about a week with \nreasonable comfort for the crew.\n 2.\t  Such a type plane, which may vary in size from 50,000 to 100,000 pounds \ngross load, is not new in its conception.  The DOX having a gross weight \nof over 100,000 lbs., although built as a commercial airplane with a much \nshorter range, may be considered the prototype of this class of airplanes. ']","
The potential military advantages and additional uses of a long-range patrol plane, as described by the Chief of Bureau of Aeronautics in the document, include:

1. Long-range patrol and scouting purposes, especially for operating across the Pacific, making it invaluable.
2. In operations with the Fleet, one such plane should be able to replace a destroyer, or even a cruiser under some conditions.
3. This type can be used for heavy bombing purposes at a reduced range.
4. In the larger sizes, they should be able to take off in, land in, or ride out a rough sea, and would have living quarters with galley, shower, ice box, etc., comparable with a small destroyer."
What are the three categories of V/STOL aircraft and how do they differ in terms of power required for cruising flight?,"The three categories of V/STOL aircraft are:
1. Pure helicopters that use rotors for both lift and propulsion in cruise.
2. Conventional aircraft that operate as wing lift and separate propulsion in cruise.
3. Combination configurations (the compound or unloaded helicopter) that transfer part of the lift to a wing and use separate propellers or ducted fans for propulsion.

In terms of power required for cruising flight, requiring the helicopter rotor to provide both lift and propulsion in cruising flight results in problems of retreating blade stall and advancing blade compressibility effects which increase the rotor profile power requirements of the helicopter and limit its cruising speed. In the compound configuration, the propulsion job is taken over by separate propellers or ducted fans, and part of the lift is transferred to a wing; thus, the rotor is unloaded, and the speed capability is increased. However, the parasite drag of the rotor and pylon remains, with the result that the power required remains above that of more conventional aircraft.","['The Wind and Beyond, Volume III\n748\nCRUISE PERFORMANCE\nGENERAL CONSIDERATIONS\nIn figure 4 the power required for 40,000-pound cargo-type aircraft operating \nat sea level is plotted as a function of speed.  V/STOL aircraft can be classified in \nthree categories: those that use rotors for both lift and propulsion in cruise (the pure \nhelicopters), those that operate as conventional aircraft using wing lift and separate \npropulsion in cruise, and combination configurations (the compound or unloaded \nhelicopter).  Requiring the helicopter rotor to provide both lift and propulsion in \ncruising flight results in problems of retreating blade stall and advancing blade \ncompressibility effects which increase the rotor profile power requirements of the \nhelicopter and limit its cruising speed.\n In the compound configuration the propulsion job is taken over by separate \npropellers or ducted fans and part of the lift is transferred to a wing; thus the rotor \nis unloaded and the speed capability is increased.  The parasite drag of the rotor and \npylon remains, however, with the result that the power required remains above that \nof more conventional aircraft.\n', 'These can be summarized as follows.  In hovering, the power \nrequired, the fuel consumption, and the downwash dynamic pressure are all deter\xad\nmined by and increase with increasing slipstream area loading.  In transition the \nwing span, the distribution of load on that span, and the power required in hover\xad\ning determine the shape of the power-required curve and through this the engine-\nout safety and STOL performance.  In cruise some compromises are required but, \ngenerally, the same rules for designing good cruise performance into conventional \nairplanes still apply to V/STOL configurations, namely, attention to aerody\xad\nnamic cleanliness to reduce the \nparasite power and a wing of \nappreciable span to reduce the \ninduced power.\n INTRODUCTION\nDuring the past few years \na great variety of V/STOL type \naircraft have been proposed and \ninvestigated.  The choice among \nthese of a particular V/STOL \nconfiguration to fill a given \nmission will depend largely Figure 1: Power Required in Steady Level Flight.  Graph shows Power versus forward speed with transition and cruise marked. ', 'In transition the \nwing span, the distribution of load on that span, and the power required in hover\xad\ning determine the shape of the power-required curve and through this the engine-\nout safety and STOL performance.  In cruise some compromises are required but, \ngenerally, the same rules for designing good cruise performance into conventional \nairplanes still apply to V/STOL configurations, namely, attention to aerody\xad\nnamic cleanliness to reduce the \nparasite power and a wing of \nappreciable span to reduce the \ninduced power.\n INTRODUCTION\nDuring the past few years \na great variety of V/STOL type \naircraft have been proposed and \ninvestigated.  The choice among \nthese of a particular V/STOL \nconfiguration to fill a given \nmission will depend largely Figure 1: Power Required in Steady Level Flight.  Graph shows Power versus forward speed with transition and cruise marked.  Figure 2: Power Required in Hovering.  Graph shows power over thrust versus slipstream area loading. ', 'Requiring the helicopter rotor to provide both lift and propulsion in \ncruising flight results in problems of retreating blade stall and advancing blade \ncompressibility effects which increase the rotor profile power requirements of the \nhelicopter and limit its cruising speed.\n In the compound configuration the propulsion job is taken over by separate \npropellers or ducted fans and part of the lift is transferred to a wing; thus the rotor \nis unloaded and the speed capability is increased.  The parasite drag of the rotor and \npylon remains, however, with the result that the power required remains above that \nof more conventional aircraft.\n The other V/STOL aircraft cruise on wing lift, and for these the same rules \nfor obtaining good cruise performance that have always applied to conventional \naircraft still apply, namely, aerodynamic cleanliness to reduce parasite drag and \npower and a wing designed for the desired cruising altitude and speed to minimize \nthe induced power.\n Good aerodynamic design is important not only at the highest speeds but \nthroughout the speed range because most aircraft cruise in the speed range near the \nmaximum lift-drag ratio where the span is important.  A large wing span is needed \nto minimize induced drag and therefore power, as can be deduced from the expres\xad\nsion of figure 1.  A clean aerodynamic design is needed to minimize power through\xad\nout the speed range. ', 'A clean aerodynamic design is needed to minimize power through\xad\nout the speed range.  A good case in point is the helicopter where the high parasite \ndrag of current configurations is largely responsible for the difference in power \nbetween the helicopter and the airplane as shown in figure 4 near the speed for \nhelicopter minimum power.  This point is discussed more completely in reference 3.\n The power required for the V/STOL aircraft in cruise is a little greater than \nthat for the conventional airplane because of the reduction in propulsive efficiency \nwhich results from the fact that the propulsion units must also be designed to pro\xad\nvide the lift in hovering for most V/STOL configurations; thus, a compromise in \nthe design must be made.\n PROPULSIVE EFFICIENCY COMPROMISE\nEach V/STOL type has a different propulsion-hovering design compromise. \n An example of one such design compromise for the propeller-driven V/STOL air\xad\ncraft is shown in figure 5.  For best static thrust a relatively large amount of camber, \nas indicated by the design section lift coefficient, is required. ']","
1. Pure helicopters: These aircraft use rotors for both lift and propulsion in cruise. The rotor profile power requirements increase due to retreating blade stall and advancing blade compressibility effects, which limits their cruising speed.
2. Conventional aircraft using wing lift and separate propulsion in cruise: These aircraft operate like traditional aircraft during cruising flight, with lift provided by the wing and propulsion by separate engines. They have lower power requirements compared to pure helicopters in cruising flight.
3. Compound or unloaded helicopter: These aircraft use separate propellers or ducted fans for propulsion and transfer part of the lift to a wing, unloading the rotor. While this increases their speed capability, the parasite drag of the rotor and pylon remains, resulting in higher power requirements compared to more conventional aircraft.

The power required for cruising flight is highest for pure helicopters due to the increased rotor profile power requirements. Conventional V/STOL aircraft using wing lift and separate propulsion in cruise have lower power requirements, while compound or unloaded helicopters have higher power requirements than conventional aircraft due to the parasite drag of the rotor and pylon."
"What are the four wing-propulsion systems shown in Figure 3 of the document and what are their respective advantages and disadvantages in terms of effective span, hovering downwash velocity, and load-carrying capability?","In Figure 3 of the document, there are four wing-propulsion systems that have been proposed for V/STOL aircraft. These systems are:

1. Conventional wing with propellers: This system has a conventional wing with propellers mounted on the wingtips. The advantage of this system is that it has a relatively large effective span in cruising flight and a lower hovering downwash velocity. However, it has a lower load-carrying capability compared to the other systems.

2. Lift fan: This system has a large fan mounted on the tail that provides lift and thrust. The advantage of this system is that it has a relatively large effective span in cruising flight and a lower hovering downwash velocity. However, it has a lower load-carrying capability compared to the other systems.

3. Tilt-rotor: This system has a rotor mounted on the wing that can be tilted to provide both lift and thrust. The advantage of this system is that it has a lower effective span and a lower hovering downwash velocity. However, it has a lower load-carrying capability compared to the other systems.

4. Canard-delta: This system has a canard wing mounted on the front of the fuselage and a delta wing mounted on the back. The advantage of this system is that it has a relatively large effective span in cruising flight and a lower hovering downwash velocity. However, it has a lower load-carrying capability compared to the other systems.

In terms of hovering downwash velocity, the tilt-rotor configuration has the lowest hovering downwash velocity due to its smaller effective span. However, it has a lower load-carrying capability compared to the other systems. The other three systems have roughly the same effective span in cruising flight and the same downwash velocity when hovering if the same gross weight is assumed.

In terms of load-carrying capability, the conventional wing with propellers and the canard-delta have lower load-carrying capability compared to the lift fan and the tilt-rotor. However, the lift fan and the tilt-rotor have lower load-carrying capability compared to the conventional wing with propellers and the canard-delta in terms of cargo-type fuselage.","['Years of research, design, \ndevelopment, and experience have resulted in the conventional high-aspect-ratio, \npropeller-driven, subsonic airplane configuration as the one most suitable where \nrange, efficiency, and operational flexibility [are] necessary and speeds greater than \n400 knots are not required.  It has been natural therefore to attempt to add to this \nconfiguration the capability of vertical take-off and landing.\n Figure 3 [not reproduced] shows a family of V/STOL aircraft which represent \nvarious approaches to this general solution.  In this figure are four wing-propulsion \nsystems which have been proposed.  It has been assumed that a given load is to be \ncarried in a given cargo-type fuselage.  This fuselage requires substantially the same \nstabilizing and control means regardless of the wing-propulsion system and will \nobviously require the same lifting and thrust forces for its sustentation and propul\xad\nsion.  With the exception of the tilt-rotor aircraft, the aircraft shown have roughly \nthe same effective span in cruising flight and the same downwash velocity when \nhovering if the same gross weight is assumed. ', 'In this figure are four wing-propulsion \nsystems which have been proposed.  It has been assumed that a given load is to be \ncarried in a given cargo-type fuselage.  This fuselage requires substantially the same \nstabilizing and control means regardless of the wing-propulsion system and will \nobviously require the same lifting and thrust forces for its sustentation and propul\xad\nsion.  With the exception of the tilt-rotor aircraft, the aircraft shown have roughly \nthe same effective span in cruising flight and the same downwash velocity when \nhovering if the same gross weight is assumed.  The tilt-rotor configuration has a \nlower effective span and a lower hovering downwash velocity.\n', '747\nDocument 5-48 (a–e)\nFUEL CONSUMPTION\nTwo other quan\xad\ntities are of concern in \nhovering: the fuel con\xad\nsumption, which is \ndirectly proportional \nto the power required, \nand the downwash \ndynamic \npressure, \nwhich is one-half the \nslipstream area load\xad\ning.  These are plotted \nin figure 3.\n The leaders from \nthe \nconfiguration \nsketches in figure 3 do \nnot indicate a specific \npoint but rather the \ngeneral area in which \ncurrent practice usually places these configurations.  All V/STOL configurations \nexcept jet pump schemes, which are not considered here, fall in one general band.\n', 'It has been assumed that a given load is to be \ncarried in a given cargo-type fuselage.  This fuselage requires substantially the same \nstabilizing and control means regardless of the wing-propulsion system and will \nobviously require the same lifting and thrust forces for its sustentation and propul\xad\nsion.  With the exception of the tilt-rotor aircraft, the aircraft shown have roughly \nthe same effective span in cruising flight and the same downwash velocity when \nhovering if the same gross weight is assumed.  The tilt-rotor configuration has a \nlower effective span and a lower hovering downwash velocity.\n', 'aircraft propulsion industry has led the world consistently in \nthe development of new technology with improved performance, durability, \nenvironmental compatibility, and safety.5 Overall sales of military, commercial, \nand general aviation engines accounted for 25 percent of the entire aviation \nindustry’s revenues for 2006.6\nNASA has four major aeronautical centers that deal with aircraft propulsion \nissues based on their collective expertise: Langley Research Center in Virginia, \nAmes Research Center and Armstrong Flight Research Center in California, \nand Glenn Research Center at Lewis Field in Ohio.  Glenn is NASA’s pri\xad\nmary propulsion facility.7 Glenn’s research facilities include five wind tun\xad\nnels, the Aero-Acoustic Propulsion Laboratory, the Engine Research Building, \nthe Propulsion Systems Laboratory, and the Flight Research Building.8 More \nimportantly, it is the specialists of Glenn and the other Centers who have served \nat the core of the Administration’s work in aircraft propulsion.  The work of all \npropulsion researchers at NASA falls under the programs of the Aeronautics \nResearch Mission Directorate, with an overall goal to advance breakthrough \naerospace technologies.\n Airplanes incorporate synergistic technologies that embody four primary \nsystems: aerodynamics, propulsion, structures, and control.  The development \nof these internal systems into an overall practical and symbiotic system has \nbeen at the core of the airplane’s success over the course of the 20th century. \n Aircraft designers must maintain a balance among lift, drag, thrust, and weight. \n In other words, without an equal balance among the four forces of flight, \nwhere the wings and propulsion system must generate enough lift and thrust \nto overcome the weight and drag of an airplane’s structure, the airplane is \nincapable of flight.9\nThe purpose of an airplane’s propulsion system is to create thrust, the force \nthat propels an airplane through the air. ']","
1. Tilt-rotor aircraft: This configuration has a lower effective span and a lower hovering downwash velocity compared to the other aircraft shown in Figure 3. The tilt-rotor design allows for vertical take-off and landing while maintaining a high-aspect-ratio wing for efficient cruising flight. However, the complexity of the tilt-rotor mechanism and the need for a more complex control system can be seen as disadvantages.
2. Tilt-wing aircraft: This configuration features wings that can rotate around a central axis, allowing for vertical take-off and landing while maintaining a high-aspect-ratio wing for efficient cruising flight. The tilt-wing design provides good load-carrying capability and efficient cruising flight, but the complexity of the tilting mechanism and the need for a more complex control system can be seen as disadvantages.
3. Tail-sitter aircraft: This configuration features a vertical take-off and landing (VTOL) capability with a high-aspect-ratio wing for efficient cruising flight. The tail-sitter design provides good load-carrying capability and efficient cruising flight, but the need for a complex tail-first landing and take-off procedure can be seen as a disadvantage.
4. Lift-plus-cruise aircraft: This configuration features separate lift and cruise systems, typically with a large number of small lift engines and a smaller number of high-thrust cruise engines. The lift-plus-cruise design provides good load-carrying capability and efficient cruising flight, but the complexity and weight of the multiple lift engines can be seen as disadvantages.

It is important to note that the figure and the specific details of the aircraft are not provided in the text, so the answer is based on general knowledge of the different wing-propulsion systems."
"According to the passage, what is the relationship between technical complication and technical progress? Is technical complication considered a pure evil or a necessary ingredient of technical progress? Explain your answer with reference to the text.","According to the passage, technical complication is not a pure evil, but is a necessary ingredient of technical progress. The great truth seems to be that technical complication is not a pure evil, but is a necessary ingredient of technical progress. It is only relatively evil, it is the price to be paid for the gain. The fact that a new device is more complicated should not be enough to deter us from adopting it, as long as it can be shown that the greater complication is not out of proportion to the advantage gained. (Source: 161)

Therefore, the relationship between technical complication and technical progress is that technical complication is a necessary ingredient of technical progress, and it is not a pure evil. However, it should be in proportion to the advantage gained.","['We prefer walking in shoes rather than to go barefooted.  Our whole \nindustrial development is co extensive with the gradual introduction of more and \nmore complication.  The great strides made by heavier-than air craft during the last \ndecade are intimately tied up with the introduction of more complicated\xa0devices.\n The great truth, then, seems to be that technical complication is not a pure \nevil, but is a necessary ingredient of technical progress.  It is only relatively evil, it \nis the price to be paid for the gain.  The fact that a new device is more complicated \nshould not be enough to deter us from adopting it, as long as it can be shown that \nthe greater complication is not out of proportion to the advantage gained.  Neither \ndoes larger complication necessarily make a device less reliable.\n', '133\nDocument 5-8 (a–b)\nNot each scientific inspiration and technical progress involves an increase of \ncomplication.  Concrete highways are simpler than a rail system.  But even if the \nimproved product is more complicated than the old one, it may still be preferable to \nthe simpler one.  We prefer walking in shoes rather than to go barefooted. ', 'Now the focus was on fixed \nwings.  There was obvious progress in this approach, and the reasoned view put \npriority on this form of flight.  While there was convergence toward practical fixed \nwing flight, helicopter advocates had to wait longer to show comparable progress.\n The second feature listed above referred to technical progress itself in tech\xad\nnology creation.  In the long view technological innovation has proceeded along a \nline that can be seen as logarithmic.  There were “bursts” of innovation along the \nway, and periods of stagnation.  (One author postulated “geniuses” through history \nappeared in clusters.) ', 'Their system of education is very different. \n It all brings about the result that Germans are better fitted and prepared to assume \nthe functions of machines, and Americans are better fitted and prepared to oper\xad\nate machines and to cope with their complications.  An airship ideal for German \nrequirements may be too primitive for the needs of this country.  The question of \ncomplication should be carefully weighed with this in mind, before new design \nprinciples for airships are condemned.\n I enter now into the discussion of specific problems of progressive airship \nresearch, which discussion, I hope, will demonstrate the abundance of such prob\xad\nlems, and the corresponding brightness of the prospect for airship improvement.  I \nbegin with the problems most engineering-like in character, and gradually advance \ntowards more abstract science.\n I mention first the question of automatic control of airships. ', 'They have \nalso become objects of policy, as we have seen.  NASA’s Near-Earth Objects \nObservations Program has been a major enabler for this important research.\n Near-Earth objects are being integrated into our understanding of Earth’s \nhistory.  The cumulative changes due to gradualism between catastrophes \nappear to be less than the changes due to a single catastrophe.  In the case of the \nCretaceous–Paleogene impact, the cosmic catastrophe provided the conditions \nfor the rapid repopulation of life after cosmic extinction.  Occasional cosmic \nimpacts transform planetary surfaces and serve as a reset button for\xa0evolution.\n The near-Earth asteroid discovery rate, as well as the scientific and public \ninterest in these objects, has grown dramatically in the last three decades. \n']","
The passage suggests that technical complication is not a pure evil, but is a necessary ingredient of technical progress. It is only relatively evil, and is the price to be paid for the gain. The fact that a new device is more complicated should not be enough to deter us from adopting it, as long as it can be shown that the greater complication is not out of proportion to the advantage gained. The passage also notes that larger complication does not necessarily make a device less reliable.

The passage highlights the importance of considering the appropriate level of complication for a particular context, taking into account factors such as the capabilities of the users and the price that they are willing to pay for ease of operation. This is particularly relevant in the context of airships, which are described as a German product developed for German mentality and trends of action.

The passage also mentions the potential benefits of automatic control of airships, which may result in smaller airloads on the structure and in larger security and comfort of travel. This suggests that the use of more complicated devices can lead to improvements in technical performance and user experience."
"Based on the given context information, can you explain the concept of L/D ratio and how it relates to the windmill's axis of rotation and the inclinations of the forces acting on the blades? Also, discuss the potential impact of the Autogiro's peculiar feathering action on the L/D ratio.","The L/D ratio, or lift-to-drag ratio, is a measure of the efficiency of an aircraft or windmill in generating lift while minimizing drag. In the context of the given text, the L/D ratio is being discussed in relation to a windmill, specifically a windmill that is part of an Autogiro.

The text suggests that the L/D ratio of the whole windmill, considered as a lifting surface, depends on the inclinations of the forces acting on the blades, which are alternately positive and negative. This means that the windmill's axis of rotation is only at a slight inclination to the flight path, and the forces acting on the blades are tending to rotate in a positive direction at one point and in a negative direction at another point.

The potential impact of the Autogiro's peculiar feathering action on the L/D ratio is not explicitly stated in the given text. However, it is mentioned that the feathering action may assist in securing a high L/D ratio for the whole disk surface, which could potentially result in a higher L/D ratio than that of a single blade element.

Overall, the text suggests that the L/D ratio of the windmill is influenced by the inclinations of the forces acting on the blades and the Autogiro's feathering action, which could potentially result in a higher L/D ratio for the whole disk surface.","['505\nDocument 5-34\ntending to rotate in a positive direction, \nand at another point tending to rotate in \na negative direction.  If the torques on the \nwindmill balance as a whole, so that the \nresultant torque is zero, the L ⁄D of the \nwhole windmill considered as a lifting \nsurface will depend on the inclinations to \nthe perpendicular to the flight path of the \nforces R in the diagrams of Fig.  7.  It is \nconceivable that if the axis of rotation of \nthe windmill is only at a slight inclination \nto the flight path, and the inclinations of \nR to the perpendicular to the flight path \nare alternately positive and negative, that \na very high L ⁄D for the whole disk surface \nmight result—conceivably a higher L ⁄D \nthan that of a single blade element.  The \npeculiar feathering action of the Autogiro \nmay assist in securing this high L ⁄D. \n', '505\nDocument 5-34\ntending to rotate in a positive direction, \nand at another point tending to rotate in \na negative direction.  If the torques on the \nwindmill balance as a whole, so that the \nresultant torque is zero, the L ⁄D of the \nwhole windmill considered as a lifting \nsurface will depend on the inclinations to \nthe perpendicular to the flight path of the \nforces R in the diagrams of Fig.  7.  It is \nconceivable that if the axis of rotation of \nthe windmill is only at a slight inclination \nto the flight path, and the inclinations of \nR to the perpendicular to the flight path \nare alternately positive and negative, that \na very high L ⁄D for the whole disk surface \nmight result—conceivably a higher L ⁄D \nthan that of a single blade element.  The \npeculiar feathering action of the Autogiro \nmay assist in securing this high L ⁄D. \n Therefore it would be dangerous to dismiss as entirely impossible the surprising \nresults obtained by La Cierva in the wind tunnel and given in Table XI.\n TABLE XI. ', 'A definite advantage of the autogiro with regard to the aeroplane is its extraor\xad\ndinary aerodynamical flexibility and adaptability.  In an aeroplane the load per \nsquare foot of wing area defines its landing qualities, and if the power is increased, \nin order to obtain the full benefit, an increase in wing loading must follow with a \ncorresponding increase in the landing speed.  Roughly speaking, the landing speed \nof an aeroplane is proportional to its top speed.  In an autogiro the landing qualities \ndepend almost exclusively on the load per square foot of disc area, while in order to \nobtain the best possible efficiency at top speed it is only necessary to keep the ratio \ntip speed to top speed equal to about one point five, which ratio depends only on \nactual blade area, assuming the pitch constant.  This means that, within wide lim\xad\nits, autogiros can be designed to have very different top speeds, but exactly the same \nqualities in landing and descent.  Of course, a limit must come when the blades, \neven reduced to three in number (two blades only have been tested in flight and \nfound impossibly rough) will become too narrow and thin, but beyond that limit a \ndecrease in pitch angle can still be used to increase the rotational speed with only a \nslight decrease in efficiency at slower speeds, not very important in machines with \na considerable excess of power.  It will probably be possible to go beyond the new \nlimit by using for the rotary blades aerofoil sections with a less abrupt stalling than \nthe Gottingen 429, stalling that when produced on a considerable portion of the \n', 'A flying machine unaffected by losses of speed in the air and which can alight \nas slowly as a bird, is the goal long pursued by airplane constructors and only \nrecently attained in the “Autogiro.”\nIn this machine the wings have been eliminated and the lift is produced by \nrevolving wings on a vertical shaft projecting from the fuselage of an ordinary \nairplane.  However, it does not belong to the family of helicopters since the sus\xad\ntaining propellers of the latter are operated directly by the engine, whereas in the \n“Autogiro” the wind produced by the motion of the aircraft actuates the blades. \n Hence, although at first glance it seems to resemble a helicopter, it is really more \nlike an airplane and, had it not been christened the “Autogiro,” it would surely have \nbeen called an “airplane with rotating wings.”\nIt is easily understood that the blades of the lifting wings will revolve, when the \n“Autogiro” moves horizontally, pulled by the tractor propeller coupled to its engine. \n It is also easy to understand that the revolving blades of the “Autogiro” strike the \nair more violently than the fixed wings of an ordinary airplane, since the rotation \nspeed of the blades must be added to the normal speed, and since one of the blades \nadvances while the opposite one moves back, these component speeds are added on Model of an autogiro in flight, with an elastic band that works as the propelling force.  Photo is dated 1921.\n FIG.  1.\u2002 ', 'The published results of an investigation of a full-scale autogiro rotor in the full-\nscale wind tunnel (Technical Report No.  515) demonstrate the influence of blade \npitch setting and rotor speed upon rotor characteristics.  These data are now being \nused to check the validity of revisions to the strip analysis of the autogiro\xa0rotor.\n The influence of change in the incidence of the fixed wing of an autogiro upon \nthe load division and rotor speed has been determined in flight and the information \npublished as Technical Report No.  523.  The data have been presented so as to assist \nin the calculation of the wing incidence required for any load division; in addition, \nit has been shown that the interference effect of the wing upon the rotor is so small \nas to be negligible.\n An investigation in flight on a direct-control type of autogiro employing a \ncantilever three-blade rotor has been made for the purpose of studying the rotor \n']","
The L/D ratio, or lift-to-drag ratio, is a measure of a wing or airfoil's efficiency in generating lift while minimizing drag. In the context of a windmill, the L/D ratio is used to describe the efficiency of the windmill as a lifting surface. The L/D ratio depends on the inclinations of the forces (R) acting on the blades to the perpendicular of the flight path.

If the axis of rotation of the windmill is only slightly inclined to the flight path, and the inclinations of R to the perpendicular to the flight path are alternately positive and negative, it is possible for the windmill to have a very high L/D ratio for the whole disk surface. This is because the positive and negative torques on the windmill balance out, resulting in a net torque of zero. The high L/D ratio could potentially be higher than that of a single blade element.

The peculiar feathering action of the Autogiro may assist in securing this high L/D ratio. Feathering refers to the adjustment of the pitch of the blades to control the lift and drag generated by the rotor. By adjusting the pitch of the blades, the Autogiro can maintain a high L/D ratio even in side winds, which can be particularly challenging for conventional windmills.

Therefore, it would be dangerous to dismiss the surprising results obtained by La Cierva in the wind tunnel as entirely impossible, as they demonstrate the potential for windmills to achieve high L/D ratios under certain conditions."
What were the primary changes made to the Announcement of Opportunity (AO) for the Discovery Program and why were they made?,"The 2004 Announcement of Opportunity (AO) for the Discovery Program had several major changes from the previous AO in 2000. These changes included the addition of a 25% reserve requirement, an increase in the cost cap to $360 million (Fiscal Year 2004 dollars), and the requirement for a staffing deputy project manager. These changes were made to incorporate lessons learned over the past five years to avoid recurrences of the problems incurred during implementation of previous missions. New requirements had been added, and additional financial reserves were now mandated.","['Chapter 8: Lessons Learned from the Evolution of the Program\n345\nprojects, provided a standardized life cycle review process that is built around the key \ndecision points, formalized the technical authority, dissenting opinion resolution, and \nwaiver processes, and streamlined the document.”104 \nMichael Griffin ended his nearly four-year term as NASA Administrator, step\xad\nping down on 20 January 2009, at the start of President Obama’s administration. \n Associate Administrator Alan Stern had served from April 2007 to April 2008; Associate \nAdministrator Weiler was in charge again, and a number of policies reverted to those \nin effect during his previous term as Associate Administrator. \n The Discovery Program had not substantially changed since the 2006 AO, but “a \nlarge number” of changes were made to the draft AO, “including both policy changes \nand changes to proposal submission requirements.”105 The draft AO (NNH10ZDA003J), \nbased on the new NASA Science Mission Directorate Standard AO, was released \n7\xa0December 2009, with a $425 million (FY 2010) cost cap not including launch vehicle, \ncontributions, or specific NASA-developed technologies discussed in the AO. \n Proposers should be aware of the following major changes in this AO from the \nprevious Discovery Program AO in 2006 (NNH06ZDA001O).\n •\t The cost of standard launch services is not included within the cap on the \nPI-Managed Mission Cost (Section 4.3.1), but mission-unique launch services \nand the differential cost of more capable LVs [Launch Vehicles] than the standard \nLV will be included in the PI-Managed Cost (Section 5.9.2).\n •\t The Discovery Program requirement that returned space-exposed hardware \nbe curated and that the costs for such curation be included in the PI-Managed \nMission Cost has been added (Section 5.1.5.4)[.]\n', 'Chapter 8: Lessons Learned from the Evolution of the Program\n309\nImplementing Change: The 2004 AO\nFinally, on 16 April, NASA Headquarters released the 2004 Announcement of \nOpportunity, almost four years after the previous one.  The 25 percent reserve require\xad\nment was added, and the cost cap increased to $360 million (Fiscal Year 2004 dollars)—\nthe maximum available within the “futures” line in the Discovery Program budget.\n The AO had been rewritten substantially since 2000, with greater attention to \nincorporating lessons learned over the past five years to avoid recurrences of the \nproblems incurred during implementation of previous missions.  New requirements \nhad been added—such as the staffing requirement of a deputy project manager—and \nadditional financial reserves were now mandated. ', 'Discovery’s Rise, Crisis, and Renewal\nBack in December 1992, NASA held its first workshop at San Juan Capistrano, \nCalifornia, to solicit mission ideas for Discovery.  No fewer than 73 proposals were \naccepted from potential PIs, indicating that there was lively support in academia, the \nagency, and industry for the concept of competed small planetary missions.  In early \n1993, Huntress chose 11 to be funded for further development.  A year later, NASA \nreleased the first Announcement of Opportunity (AO), leading to the selection of the \nfirst competed mission, Lunar Prospector, in February 1995, plus an ensuing com\xad\npetition among three proposals.  The winner was Stardust, a spacecraft to retrieve \na sample of particles from a comet’s tail.  Two more selections were made each in \n1997, 1999, and 2001 (see “Discovery Missions” table).  NEAR launched first, in early \n1996, and flew by asteroid Mathilde before heading to a rendezvous with Eros; Mars \nPathfinder made a spectacular landing on Independence Day, 1997, and deployed the \nmini-rover Sojourner. ', 'A Discovery \nLessons Learned Retreat was held.  As funding became available in the outyears, the \n2004 Announcement of Opportunity became a reality.  Non-selections and a protest \npostponed the traditional Lessons Learned Workshop following that AO.  The 2005 \nAnnouncement of Opportunity was announced with the selection of M3, but it also \nhad to be postponed, eventually becoming the 2006 AO as a flurry of cost studies were \ncommissioned by NASA Headquarters.\n The findings and recommendations of these studies by the Space Studies Board, \nNASA, the Science Support Office, and the Discovery and New Frontiers Program \nOffice in the second half of the decade will be discussed, tabulated, compared, and \ntraced to changes that resulted in the 2010 AO.  It is important to keep in mind, \nhowever, that while these studies excelled at capturing the zeitgeist of the times, \nrecording lessons learned and discussion by mission leadership, and in codifying \nrecommendations proposed and advocated by both the proposing community and \n', 'Index\n415\nAnnouncement of Opportunity (AO), \n1998, 130–135, 174, 256\nAnnouncement of Opportunity (AO), \n2000, 190–194, 303, 310\nAnnouncement of Opportunity (AO), \n2002, 294, 303–305\nAnnouncement of Opportunity (AO), \n2004, 308–312\nAnnouncement of Opportunity (AO), \n2006, 163, 302, 311–317, 323–325, \n328\nAnnouncement of Opportunity (AO), \n2010, 301, 358\nAnnouncement of Opportunity (AO) \ndelay, 153\nAnnouncement of Opportunity (AO), \nfirst, 41–42, 47, 53\nAnnouncements of Opportunity (AO), 30, \n84–85, 298–303\nAnnouncements of Opportunity (AO) \nstrategy, 39–41, 136, 334–339\nbudget, x–xi, 15, 85, 293\ncollaboration, 61–65, 72–73, 315–316, \n376–379\nCOMPLEX, 295–303\ncost study, 316–317\ncosts, xii–xiii, xiv, 13, 18, 131–132, 274, \n293, 303–305, 351–353\nDawn, 202, 221–222\nDeep Impact costs, 154\ndelays, xiv, 274\nDiscovery and New Frontiers Program \nOffice, 194, 226–227, 275, 347–349\nDiscovery and Scout Mission Capabilities \nExpansion (DSMCE), 332–333\n“Discovery Plus,” 193–194\nfaster, better, cheaper (FBC), 28, 83–84, \n93, 199\nfunding, 136–138\ngoals, 29–30\nImplementation Plan, 28–30\nKepler Space Telescope, 262–263, 297\nlaunch schedule, 43\nlessons learned and recommendations, \n84–85, 130, 293–303, 317–323, \n333–339, 347–351, 376–379\nMars Environmental SURvey (MESUR), \n12–13\nmaturation, 53\nMESSENGER, 297\nMission Concept Workshop, 20–23, 92\nmission concepts, 19–20, 22\nmission life cycle, 48\nMissions of Opportunity, xv, xv–xvi, \n134–136, 166, 190, 289, 309–312, \n329–330\nMissions of Opportunity (Stand Alone, or \nSALMON), 299, 344\nMoon Mineralogy Mapper (M3), 289\nNASA Reduction in Force, 136\nNEAR Shoemaker successes, 36–38\nNew Start, 14, 16–17, 18, 30, 320\nNRC Report, 295–296, 299–303\nobjectives, 300–303, 315\norganizing committee, 21–22\norigins, ix–xii\npartnerships, 40\nPlanetary Instrument Definition and \nDevelopment Program (PIDDP), \n301–302\nPreproposal Conference, 40\nPrincipal Investigator (PI), xi, 138, 150, \n330\nPrincipal Investigator (PI) experience \nrule, 330–332\nPrincipal Investigator (PI) NRC Report, \n317–323\n']","
The primary changes made to the AO for the Discovery Program were the insertion of Advanced Stirling Radioisotope Generators (ASRGs), the addition of two additional questions to ease the assignment of proposals to TMC experts in radioactive power sources, and the request for additional technical trajectory information including solar electric propulsion-specific assumptions, models, and operations concept to be included. These changes were made to expand the program to include more complex missions and missions to planets beyond the asteroid belt, and to better understand the cost growth of missions since Genesis. The due date for proposals was also delayed a week to accommodate the late request for additional technical trajectory information."
What is the NASA Discovery Program and what are some of the notable publications related to it?,"The NASA Discovery Program is a series of low-cost, highly focused scientific space missions that was initiated in 1989 and legislated into existence in 1993. The program has funded a series of relatively small, focused, and innovative missions to investigate the planets and small bodies of our solar system. Notable missions include Mars Pathfinder, which landed a miniature rover on Mars in 1997; NEAR Shoemaker, which orbited and landed on 433 Eros in 2000–2001; Deep Impact, which hit Comet Tempel 1 in 2005; MESSENGER, which orbited Mercury between 2011 and 2015; and the Kepler space telescope, which discovered thousands of exoplanets.

Some notable publications related to the NASA Discovery Program include:

- ""The Discovery Program: A New Approach to Planetary Exploration"" by R. W. Vorder Bruegge, presented at the AIAA Space Programs and Technologies Conference and Exhibit 93-4090 in 1993.
- ""Cratering on Asteroids from Galileo and NEAR Shoemaker"" by Clark Chapman, published in Asteroids III in 2002.
- ""A History of Near-Earth Object Research"" by various authors, published in 2007.

These publications provide insights into the history, goals, and achievements of the NASA Discovery Program, as well as the scientific discoveries made through its missions.","['ix\nThe Discovery Program is the most important NASA robotic planetary spacecraft\n \nprogram you have never heard of—unless you are a space agency insider.  Initiated in \n1989 and legislated into existence in 1993, Discovery has funded a series of relatively \nsmall, focused, and innovative missions to the planets and small bodies of the solar \nsystem.  Notable ones include Mars Pathfinder, which landed a miniature rover on \nMars in 1997; NEAR Shoemaker, which orbited and landed on 433 Eros in 2000–\n2001; Deep Impact, which hit Comet Tempel 1 in 2005; MESSENGER, which orbited \nMercury between 2011 and 2015; and the Kepler space telescope, which discovered \nthousands of exoplanets.  If the public has heard of anything, it is the missions, not the \nprogram from which they sprang.\n', 'Clark Chapman, “Cratering on Asteroids from Galileo and NEAR Shoemaker,” in \nAsteroids III, ed.  W.\xa0F. Bottke, Jr., A. Cellino, P.\xa0Paolicchi, and R.\xa0P. Binzel (Tucson, \nAZ: University of Arizona Press, 2002), pp.\xa0315–330.\n 91.\t  NASA’s Discovery Program, founded in 1992, is a series of low-cost, highly focused \nscientific space missions.  To date, the Discovery missions have been NEAR; \nMars Pathfinder; Lunar Prospector; Stardust; Genesis; COmet Nucleus TOUR \n', 'S\ntarted in the early 1990s, \nNASA’s Discovery Program \nrepresented a breakthrough \nin the way NASA explores space. \n Providing opportunities for low-cost \nplanetary science missions, the \nDiscovery Program has funded a series \nof relatively small, focused, and innovative \nmissions to investigate the planets and small \nbodies of our solar\xa0system.\n For over 30 years, Discovery has given scientists a chance to \ndig deep into their imaginations and find inventive ways to unlock the mysteries \nof our solar system and beyond.  As a complement to NASA’s larger “flagship” \nplanetary science explorations, Discovery’s continuing goal is to achieve \noutstanding results by launching more, smaller missions using fewer resources \nand shorter development times.\n', 'Initiated in \n1989 and legislated into existence in 1993, Discovery has funded a series of relatively \nsmall, focused, and innovative missions to the planets and small bodies of the solar \nsystem.  Notable ones include Mars Pathfinder, which landed a miniature rover on \nMars in 1997; NEAR Shoemaker, which orbited and landed on 433 Eros in 2000–\n2001; Deep Impact, which hit Comet Tempel 1 in 2005; MESSENGER, which orbited \nMercury between 2011 and 2015; and the Kepler space telescope, which discovered \nthousands of exoplanets.  If the public has heard of anything, it is the missions, not the \nprogram from which they sprang.\n The Origins of the Discovery Program\nAt the end of the 1980s, there was growing discomfort in the science community \nwith the planetary exploration program of the National Aeronautics and Space \nAdministration (NASA).  Almost the whole planetary budget went to a handful \nof large, expensive missions, which had been significantly delayed by the national \nFOREWORD\nThe Discovery Program,\n1989–2022\nBy Michael J. Neufeld\n', 'There were a \ncouple of hundred people down here in San Juan Capistrano and they said the first mission \nmay get funded by 1998.... This is what the civil space program ought to be: a diversity of \nopinion; people that are bold, not afraid to take risks; a launch a month instead of a launch \na decade; graduate students and professors building things; organizations that have the \nbest idea and power to do things instead of the bureaucracy coming in and suffocating new \nideas.... This is the most wonderful thing that ever happened to the space program.  Here \nwe can have a launch a month and with a launch a month, you could go to the cutting \n63 \t\nVorder Bruegge, R. W.  (1993, 21–23 September).  “The Discovery Program: A New Approach to \nPlanetary Exploration.” AIAA Space Programs and Technologies Conference and Exhibit 93-4090. \n Huntsville: American Institute of Aeronautics and Astronautics.\n 64 \t\nNASA.  (1992, 15–21 November). ']","
The NASA Discovery Program is a series of space missions that focus on scientific research and exploration. It was established in 1992 with the goal of making space science more affordable and accessible. The program has funded numerous missions, including the Mars Pathfinder, the Stardust mission, and the MESSENGER mission to Mercury.

Regarding notable publications related to the NASA Discovery Program, the context information provided lists several books and reports related to NASA's history and programs, including:

* The Apollo Spacecraft: A Chronology, Volume I-IV
* Astronautics and Aeronautics, 1968: Chronology of Science, Technology, and Policy
* Skylab: A Chronology
* NASA Historical Data Book, Volume I-VIII

However, the context information does not specifically mention any publications related to the NASA Discovery Program. To find more information about the program, additional resources may need to be consulted."
"""What is the role of the European Space Agency (ESA) Sun Monitoring on the External Payload of Columbus (Solar) facility in improving climate models on Earth?""","The European Space Agency (ESA) Sun Monitoring on the External Payload of Columbus (Solar) facility measured the spectrum of solar radiation over a period of 9 years, ending in 2017, far extending its original planned lifespan of 18 months to 2 years. These measurements generated a wealth of data during the approximately 11-year solar cycle—i.e., a regular period of increasing and decreasing solar activity. These data help scientists better understand and deal with all aspects influenced by solar radiation. The Solar facility data contribute to the understanding of solar and stellar physics and Earth System sciences such as atmospheric chemistry and climatology. Data from the Solar facility have already helped validate improved models of the upper atmosphere, which is important for climate modeling. Therefore, the role of the ESA Sun Monitoring on the External Payload of Columbus (Solar) facility in improving climate models on Earth is to provide data that help scientists better understand and deal with all aspects influenced by solar radiation, which contributes to the understanding of solar and stellar physics and Earth System sciences such as atmospheric chemistry and climatology, and has already helped validate improved models of the upper atmosphere, which is important for climate modeling.","['187\nImproving Climate Models on Earth \nClimate models are essential in forecasting global \nchanges in Earth’s climate and weather, and in \ndetermining the role humanity plays in these changes. \n These models require input parameters.  One of \nthe major factors that influences Earth’s climate \nis the sun.  Therefore, studying the sun and \nunderstanding how it influences Earth has a \nsignificant effect on such models. \n Climate models are essential in \nforecasting global changes in \nEarth’s climate and weather, and \nin determining the role humanity \nplays in these changes. \n The European Space Agency (ESA) Sun Monitoring \non the External Payload of Columbus (Solar) facility \nmeasured the spectrum of solar radiation over a \nperiod of 9 years, ending in 2017, far extending its \noriginal planned lifespan of 18 months to 2 years. \n These measurements generated a wealth of data \nduring the approximately 11-year solar cycle—\ni.e., a regular period of increasing and decreasing \nsolar activity. ', 'One of \nthe major factors that influences Earth’s climate \nis the sun.  Therefore, studying the sun and \nunderstanding how it influences Earth has a \nsignificant effect on such models. \n Climate models are essential in \nforecasting global changes in \nEarth’s climate and weather, and \nin determining the role humanity \nplays in these changes. \n The European Space Agency (ESA) Sun Monitoring \non the External Payload of Columbus (Solar) facility \nmeasured the spectrum of solar radiation over a \nperiod of 9 years, ending in 2017, far extending its \noriginal planned lifespan of 18 months to 2 years. \n These measurements generated a wealth of data \nduring the approximately 11-year solar cycle—\ni.e., a regular period of increasing and decreasing \nsolar activity.  These data help scientists better \nunderstand and deal with all aspects influenced by \nsolar radiation.  The Solar facility data contribute to \nthe understanding of solar and stellar physics and \nEarth System sciences such as atmospheric \nchemistry and climatology. ', '187\nImproving Climate Models on Earth \nClimate models are essential in forecasting global \nchanges in Earth’s climate and weather, and in \ndetermining the role humanity plays in these changes. \n These models require input parameters.  One of \nthe major factors that influences Earth’s climate \nis the sun.  Therefore, studying the sun and \nunderstanding how it influences Earth has a \nsignificant effect on such models. \n', 'These measurements generated a wealth of data \nduring the approximately 11-year solar cycle—\ni.e., a regular period of increasing and decreasing \nsolar activity.  These data help scientists better \nunderstand and deal with all aspects influenced by \nsolar radiation.  The Solar facility data contribute to \nthe understanding of solar and stellar physics and \nEarth System sciences such as atmospheric \nchemistry and climatology.  Data from the Solar \nfacility have already helped validate improved models \nof the upper atmosphere, which is important for \nclimate modelling.  The data also contribute to \nimproving the accuracy of navigation data, as \nwell as the orbit forecasts of satellites and debris.\n The facility undertook significant activities such \nas performing simultaneous measurements with \nESA’s Venus Express spacecraft close to the transit \nof Venus across the sun, thus enabling in-orbit \ncalibration of a Venus Express UV spectrometer. \n Extended measurements were also performed during \nan entire sun rotation cycle, which lasts around 26 days \nat the solar equator and up to 36 days at the solar \npoles. ', '8206 / Centaur II)\nLaunch Date and Time: 2 December 1995 / 08:08:01 \nUT\nLaunch Site: Cape Canaveral Air Force Station / \nLaunch Complex 36B\nScientific Instruments:\n\t 1.\tsolar-ultraviolet measurements of emitted \nradiation experiment (SUMER)\n\t 2.\tcoronal diagnostic spectrometer (CDS)\n\t 3.\textreme ultraviolet imaging telescope (EIT)\n\t 4.\tultraviolet coronograph spectrometer (UVCS)\n\t 5.\tlarge angle and spectrometric coronograph \n(LASCO)\n\t 6.\tsolar wind anisotropies experiment (SWAN)\n\t 7.\tcharge, element, and isotope analysis \nexperiment (CELIAS)\n\t 8.\tcomprehensive suprathermal and energetic \nparticle analyzer (COSTEP)\n\t 9.\tenergetic and relativistic nuclei and elec\xad\ntron experiment (ERNE)\n\t10.\tglobal oscillations at low frequencies \nexperiment (GOLF)\n\t11.\tvariability of solar irradiance and gravity \noscillations experiment (VIRGO)\n\t12.\t Michelson Doppler imager/solar oscilla\xad\ntions investigation (MDI/SOI)\nResults: The ESA-sponsored Solar and Heliospheric \nObservatory (SOHO) carries 12 scientific instru\xad\nments to study the solar atmosphere, helioseis\xad\nmology, and the solar wind.  Information from the \nmission has allowed scientists to learn more about \nthe Sun’s internal structure and dynamics, the \nchromosphere, the corona, and solar particles.  The \nSOHO and Cluster missions, part of ESA’s Solar \nTerrestrial Science Programme (STSP), are ESA’s \ncontributions to the International Solar Terres\xad\ntrial Physics (ISTP) program, which has involved \nthe work of other spacecraft such as Wind and \nACE, which, like SOHO, operate in the vicinity \nof the Sun–Earth L1 point.  NASA contributed \nthree instruments on SOHO as well as launch and \nflight operations support.  About two months after \nlaunch, on 14 February 1996, SOHO was placed at \na distance of 1.5 million kilometers from Earth in \nan elliptical Lissajous orbit around the L1 libration \npoint where it takes approximately six months to \norbit L1 (while the L1 itself orbits the Sun every \n12 months).  The spacecraft returned its first image \non 19 December 1995 and was fully commissioned \nfor operations by 16 April 1996. ']","
The European Space Agency (ESA) Sun Monitoring on the External Payload of Columbus (Solar) facility measured the spectrum of solar radiation over a period of 9 years, far extending its original planned lifespan of 18 months to 2 years. These measurements generated a wealth of data during the approximately 11-year solar cycle, which helps scientists better understand and deal with all aspects influenced by solar radiation. The Solar facility data contribute to the understanding of solar and stellar physics and Earth System sciences such as atmospheric chemistry and climatology. Data from the Solar facility have already helped validate improved models of the upper atmosphere, which is important for climate modelling. The facility also undertook significant activities such as performing simultaneous measurements with ESA’s Venus Express spacecraft close to the transit of Venus across the sun, thus enabling in-orbit calibration of a Venus Express UV spectrometer. Extended measurements were also performed during an entire sun rotation cycle, which produced excellent scientific results."
How does the European Space Agency (ESA) Sun Monitoring on the External Payload of Columbus (Solar) facility contribute to the improvement of climate models on Earth?,"The European Space Agency (ESA) Sun Monitoring on the External Payload of Columbus (Solar) facility measured the spectrum of solar radiation over a period of 9 years, ending in 2017, far extending its original planned lifespan of 18 months to 2 years. These measurements generated a wealth of data during the approximately 11-year solar cycle—i.e., a regular period of increasing and decreasing solar activity. These data help scientists better understand and deal with all aspects influenced by solar radiation. The Solar facility data contribute to the understanding of solar and stellar physics and Earth System sciences such as atmospheric chemistry and climatology. Data from the Solar facility have already helped validate improved models of the upper atmosphere, which is important for climate modeling.","['187\nImproving Climate Models on Earth \nClimate models are essential in forecasting global \nchanges in Earth’s climate and weather, and in \ndetermining the role humanity plays in these changes. \n These models require input parameters.  One of \nthe major factors that influences Earth’s climate \nis the sun.  Therefore, studying the sun and \nunderstanding how it influences Earth has a \nsignificant effect on such models. \n Climate models are essential in \nforecasting global changes in \nEarth’s climate and weather, and \nin determining the role humanity \nplays in these changes. \n The European Space Agency (ESA) Sun Monitoring \non the External Payload of Columbus (Solar) facility \nmeasured the spectrum of solar radiation over a \nperiod of 9 years, ending in 2017, far extending its \noriginal planned lifespan of 18 months to 2 years. \n', '187\nImproving Climate Models on Earth \nClimate models are essential in forecasting global \nchanges in Earth’s climate and weather, and in \ndetermining the role humanity plays in these changes. \n These models require input parameters.  One of \nthe major factors that influences Earth’s climate \nis the sun.  Therefore, studying the sun and \nunderstanding how it influences Earth has a \nsignificant effect on such models. \n Climate models are essential in \nforecasting global changes in \nEarth’s climate and weather, and \nin determining the role humanity \nplays in these changes. \n The European Space Agency (ESA) Sun Monitoring \non the External Payload of Columbus (Solar) facility \nmeasured the spectrum of solar radiation over a \nperiod of 9 years, ending in 2017, far extending its \noriginal planned lifespan of 18 months to 2 years. \n These measurements generated a wealth of data \nduring the approximately 11-year solar cycle—\ni.e., a regular period of increasing and decreasing \nsolar activity. ', 'One of \nthe major factors that influences Earth’s climate \nis the sun.  Therefore, studying the sun and \nunderstanding how it influences Earth has a \nsignificant effect on such models. \n Climate models are essential in \nforecasting global changes in \nEarth’s climate and weather, and \nin determining the role humanity \nplays in these changes. \n The European Space Agency (ESA) Sun Monitoring \non the External Payload of Columbus (Solar) facility \nmeasured the spectrum of solar radiation over a \nperiod of 9 years, ending in 2017, far extending its \noriginal planned lifespan of 18 months to 2 years. \n These measurements generated a wealth of data \nduring the approximately 11-year solar cycle—\ni.e., a regular period of increasing and decreasing \nsolar activity.  These data help scientists better \nunderstand and deal with all aspects influenced by \nsolar radiation.  The Solar facility data contribute to \nthe understanding of solar and stellar physics and \nEarth System sciences such as atmospheric \nchemistry and climatology. ', 'These measurements generated a wealth of data \nduring the approximately 11-year solar cycle—\ni.e., a regular period of increasing and decreasing \nsolar activity.  These data help scientists better \nunderstand and deal with all aspects influenced by \nsolar radiation.  The Solar facility data contribute to \nthe understanding of solar and stellar physics and \nEarth System sciences such as atmospheric \nchemistry and climatology.  Data from the Solar \nfacility have already helped validate improved models \nof the upper atmosphere, which is important for \nclimate modelling.  The data also contribute to \nimproving the accuracy of navigation data, as \nwell as the orbit forecasts of satellites and debris.\n The facility undertook significant activities such \nas performing simultaneous measurements with \nESA’s Venus Express spacecraft close to the transit \nof Venus across the sun, thus enabling in-orbit \ncalibration of a Venus Express UV spectrometer. \n Extended measurements were also performed during \nan entire sun rotation cycle, which lasts around 26 days \nat the solar equator and up to 36 days at the solar \npoles. ', '187\nImproving Climate Models on Earth \nClimate models are essential in forecasting global \nchanges in Earth’s climate and weather, and in \ndetermining the role humanity plays in these changes. \n These models require input parameters.  One of \nthe major factors that influences Earth’s climate \nis the sun.  Therefore, studying the sun and \nunderstanding how it influences Earth has a \nsignificant effect on such models. \n']","
The European Space Agency (ESA) Sun Monitoring on the External Payload of Columbus (Solar) facility contributes to the improvement of climate models on Earth by measuring the spectrum of solar radiation over a period of 9 years, far extending its original planned lifespan of 18 months to 2 years. These measurements generated a wealth of data during the approximately 11-year solar cycle, which helps scientists better understand and deal with all aspects influenced by solar radiation. The Solar facility data contribute to the understanding of solar and stellar physics and Earth System sciences such as atmospheric chemistry and climatology. Data from the Solar facility have already helped validate improved models of the upper atmosphere, which is important for climate modelling. The data also improve the accuracy of navigation data, as well as the orbit forecasts of satellites and debris. The facility undertook significant activities such as performing simultaneous measurements with ESA’s Venus Express spacecraft close to the transit of Venus across the sun, thus enabling in-orbit calibration of a Venus Express UV spectrometer. Extended measurements were also performed during an entire sun rotation cycle, which produced excellent scientific results."
"What were the unexpected characteristics of Comet Halley's nucleus discovered by the Giotto mission, as compared to the pre-flight predictions?","The pre-flight model of Comet Halley's nucleus, developed by Neil Divine in 1981, predicted a solid, spherical nucleus with a diameter of 6 kilometers and a bulk density of 1 gram per cubic centimeter. However, the Giotto mission, which flew by Comet Halley in 1986, revealed that the nucleus was not solid but rather a loosely packed collection of rubble. The bulk density was estimated to be only 0.28 grams per cubic centimeter, which was significantly lower than the pre-flight prediction. This discovery challenged the prevailing understanding of comet nuclei and led to a rethinking of their formation and evolution.","['Surface \nfeatures were noted, but there were no obvious impact craters—at least none \nthat could be identified at Giotto’s best image resolution.68 Most of the gas \n(with entrained dust) from the comet came from the vaporization of water \nice at day-side active regions, and organic particles rich in carbon, hydrogen, \noxygen, and nitrogen (CHON particles) were evident in the mass spectrom\xad\neter data.  It was estimated that Comet Halley loses about 0.5 percent of its \nmass at each return to perihelion.69 The mass of Comet Halley’s nucleus was \nestimated from its orbital acceleration due to outgassing rocket-like effects, \nand dividing this mass by its estimated volume (computed from the observed \ndimensions) provided a nucleus bulk density of only 0.28 grams per cubic \n67.\t  M. J. S. Belton, “P/Halley: The Quintessential Comet,” Science 230 (1985): 1229–\n1236.  JPL researcher Neil Divine, in 1981, put forward an expected, preflight model \nof Comet Halley as a solid, spherical nucleus, 6\xa0 kilometers in diameter, having a \nbulk density of 1 g/cm3 and with a ratio of dust production to gas production of 0.5. \n N.\xa0Divine, “Numerical Models for Halley Dust Environments,” in The Comet Halley \nDust & Gas Environment: Proceedings of a Joint NASA/ESA Working Group Meeting \n(held in Heidelberg, Germany) (Washington, DC: NASA SP-174, 1981), pp.  25–30.\n 68.\t ', '“What may have sounded like a dramatic thing at the time was probably not \na good thing to have done.”36 The interest in capturing cometary material and returning \nit to Earth intensified.  The planetary community wanted sample return—something \nnot achieved since the Apollo missions.  Before development on a mission to Comet \nHalley could really begin, however, it was canceled on 30 September 1981, amid a \nweak economy; a smaller federal budget; and a consequent, broader culling of the \nplanetary portfolio.37 “When they finally shot us down,” said Atkins, “the Europeans, \nnonplussed about that, started their own program called Giotto.”38\nTsou and colleagues at JPL worked 15 years on potential designs for “intact capture,” \nwhich would meet the objectives of mineralogists.39 They experimented with many \nkinds of foam to strike a delicate balance: sturdy enough to stop the particles released \nfrom the comet but soft enough for the materials to survive intact.\n Giotto’s Comet Halley flyby was 70 kilometers per second, and “there are all kinds \nof reasons why you wouldn’t expect to be able to collect any captured intact particles.40 \nThe work evolved over time.  Tsou experimented with low-density targets, successfully \n35 \t\nNiebur, S.  (2009, 25 March).  Personal interview with D. Brownlee. ', '166\nBEYOND EARTH: A CHRONICLE OF DEEP SPACE EXPLORATION, 1958–2016\n\t 5.\t Rème plasma analyzer (RPA)\n\t 6.\t Johnstone plasma analyzer (JPA)\n\t 7.\tenergetic particles analyzer (EPA)\n\t 8.\tmagnetometer (MAG)\n\t 9.\toptical probe experiment (OPE)\n\t10.\t Halley multicolor camera (HMC)\n\t11.\tparticulate impact analyzer (PIA)\nResults: Giotto was the first deep space probe \nlaunched by the European Space Agency (ESA).  It \nwas named after famed Italian Renaissance painter \nGiotto di Bondone (c.  1267–1337) who had \ndepicted Halley’s Comet as the Star of Bethlehem \nin his painting Adoration of the Magi.  Because the \ncylindrical spacecraft was designed to approach \ncloser to Halley than any other probe, it was \nequipped with two dust shields separated by 23 \ncentimeters, the first to bear the shock of impact \nand spread the impact energy over larger areas of the \nsecond thicker rear sheet. ', 'The design of the space\xad\ncraft was based on the spin-stabilized magneto\xad\nspheric Geos satellites launched in 1977 and 1978. \n After launch, and further course corrections on 26 \nAugust 1985, 12 February 1986, and 12 March \n1986, Giotto was put on a 500-kilometer-range \nflyby trajectory to the comet’s core.  Ballistics data \non its precise voyage was based upon tracking \ninformation from the Soviet Vega 1 and 2 probes. \n The Giotto spacecraft eventually passed by Halley \non 14 March 1986.  Closest encounter was at a \ndistance of 596 kilometers at 00:03:02 UT, the \nspacecraft being the only one among the large \narmada of spacecraft sent to investigate Halley that \nactually entered the ionosphere of the comet.  At \na range of 137.6 million kilometers from Earth, \njust 2 seconds before closest approach, telemetry \nstopped due to impact with a heavy concentration \nof dust that probably knocked the spacecraft’s high \ngain antenna out of alignment with Earth.  Fortu\xad\nnately, data transmission was restored within 21.75 \nseconds (with proper orientation of the antenna \nrestored after 32 minutes). ', 'Chapter 2: Big Dreams\n55\nthe formation of the solar system.  Brownlee recognized their significance and made a \ncareer of studying them with custom-built mass spectrometers and other specialized \nlaboratory instrumentation.  Although there had been no previous missions to study \ninterplanetary dust, Brownlee was invited to join lunar investigations as early as Apollo \n12 and continued as a lunar sample investigator after that.  He was also a co-investigator \non Giotto, the ESA mission to Comet Halley.\n The Challenge of Sample Return\nThe Jet Propulsion Laboratory had studied comet missions as far back as 1959, but the \nconcept became more pressing with the imminent return of an ancient visitor, Comet \nHalley, which would swing by Earth in 1986.  Two of the key engineers working in the \nadvanced projects division at JPL in 1981 were Ken Atkins, who led a development \nteam whose spacecraft used ion rocket technology, and Lou Friedman, who led a \nteam to use solar sail technology.  The two had a good-natured rivalry, competing to \ndemonstrate their engineering designs for a Halley’s Comet intercept mission. ']","
1. The nucleus was both darker and larger than expected, with an albedo of only 4 percent and triaxial dimensions of 7.2, 7.2, and 15.3 kilometers.
2. Instead of outgassing over its entire sunward surface, more than a dozen narrow jets were discovered, some of which were surprisingly well collimated.
3. Surface features were noted, but there were no obvious impact craters—at least none that could be identified at Giotto’s best image resolution.
4. Most of the gas (with entrained dust) from the comet came from the vaporization of water ice at day-side active regions.
5. Organic particles rich in carbon, hydrogen, oxygen, and nitrogen (CHON particles) were evident in the mass spectrometer data.
6. It was estimated that Comet Halley loses about 0.5 percent of its mass at each return to perihelion.
7. The mass of Comet Halley’s nucleus was estimated from its orbital acceleration due to outgassing rocket-like effects, and dividing this mass by its estimated volume provided a nucleus bulk density of only 0.28 grams per cubic centimeter."
What are the main parts of the flapper valves used in the propellant tanks of the X-34 main propulsion system and what are they made of?,"The context information provided does not directly answer the query. However, it does mention that the X-34's propellant tanks consist of composite-structure pressurized fuel tank and aluminum liquid oxygen tanks. The text also mentions that the X-34's tankage design was one of the most challenging and ingenious aspects of its overall design. However, it does not provide specific details about the flapper valves used in the propellant tanks.

To answer the query, further research or context information would be required.","['The MC-1 engine instrumentation included 16 pressure \ntransducers, 1 thermocouple, and 8 resistance devices.  The transducers “provide \nstatic pressure measurements of 6 turbopump pressures, 2 thrust chamber \npressures, 2 gas generator pressures, and 6 purge pressures.” The thermocouple \nmeasured the gas generator turbine temperature and the 8 resistance tempera\xad\nture devices provided surface temperature measurements of a variety of engine \nparameters.  The pressure transducers were manufactured by Taber, Stellar, and \nGP:50.  The thermocouples were provided by RdF and ARI and the resistance \ntemperature devices were manufactured by RdF.29\nThe X-34 Main Propulsion System \nComponents and Subsystems\nThe main propulsion system (MPS) design had to support all phases of the X-34 \nvehicle operation, including pre-flight, captive carry, powered flight, unpowered \nreturn, safe abort, landing, and subsequent rapid turnaround operations.\n Zonal Propulsion Organization\nThe propulsion system components of the X-34 were arranged in five zones \nthroughout the vehicle.  The first zone in the forward area of the X-34 contained \nthe nitrogen and helium tanks that were used to pressurize the propellant tanks, \nactivate the pneumatic components, purge engine components, and supply \nthe reaction control system (RCS) thrusters with propellant.  These tanks could \nstore over 40 cubic feet of nitrogen and helium gas. ', 'The pressure transducers were manufactured by Taber, Stellar, and \nGP:50.  The thermocouples were provided by RdF and ARI and the resistance \ntemperature devices were manufactured by RdF.29\nThe X-34 Main Propulsion System \nComponents and Subsystems\nThe main propulsion system (MPS) design had to support all phases of the X-34 \nvehicle operation, including pre-flight, captive carry, powered flight, unpowered \nreturn, safe abort, landing, and subsequent rapid turnaround operations.\n Zonal Propulsion Organization\nThe propulsion system components of the X-34 were arranged in five zones \nthroughout the vehicle.  The first zone in the forward area of the X-34 contained \nthe nitrogen and helium tanks that were used to pressurize the propellant tanks, \nactivate the pneumatic components, purge engine components, and supply \nthe reaction control system (RCS) thrusters with propellant.  These tanks could \nstore over 40 cubic feet of nitrogen and helium gas.  The hardware for the RP-1 \n(kerosene) vent was also contained in zone one.  The second, third, and fourth \nzones contained the propellant tanks. ', 'Since the vehicle had to be nearly in a horizontal orientation during the \npropellant dump, siphons were added in all tanks in order to ensure that the \noptimum amount of propellant was removed for the given vehicle trajectories. \n During main engine burn, however, the vehicle would transition from the \nhorizontal to a vertical orientation, which meant that with the siphons, the \nusable propellant would be reduced below the required 27,500 pounds-mass. \n To prevent this problem from occurring, the cover plates of the RP-1 and aft \nLOX tanks had two outlets—one for the dump/abort case and one for the \nflight mode.  Computational fluid dynamics modeling, using FLOW-37, was \nused to simulate the drop, engine start, and tank depletion (burn and dump) \ntransients in order to determine the optimum cut angles for the siphons and \nlocation of the low-level cutoff sensors.39\nWhile the liquid oxygen propellant tanks for the first two X-34 vehicles \nwere fabricated with aluminum, NASA Marshall worked on the development \nof tanks that would use composite material for the main barrel section, the two \ndomed end pieces, and the internal domes.  NASA Marshall was assembling \ntwo tanks under a cooperative agreement between Marshall and Lockheed \nMartin Michoud Space Systems in New Orleans.  One tank was to be used for \nground tests and the other tank was to be used for flight-testing in the third \nX-34 vehicle.  The experimental tank passed a Systems Requirements Review \nin November 1999, and its Preliminary Design Review on December 10, \n1999. ', 'The peak structural \nloads on the vehicle occur shortly after drop from the L-1011 \ncarrier aircraft, when the vehicle is cold-soaked below freezing as \na result of the extended captive carry flight to the launch point. \n Maximum heating and secondary loads occur during entry when \nthe structure has warmed to nearly room temperature again.  This \nheat soaks into the structure and causes the peak structure tem\xad\nperature to occur several minutes later during thermal maneuvers, \nwhen the loading on the structure is much lower.30\nThe X-34’s Propellant Tanks\nAltogether, the design of the X-34’s tankage was one of the most challeng\xad\ning and ingenious aspects of its overall design.  The X-34’s RP-1 (kerosene) \ncomposite-structure pressurized fuel tank consisted of a three-compartment, \nunlined, filament-wound 63-inch-diameter tank, with its internal flows con\xad\ntrolled by valves and vents.  The two aluminum liquid oxygen tanks were of \nsimilar design, but differed from each other in their internal layout, with \nthe forward tank having three compartments and the aft tank having four.31 \nLaunch acceleration loads, combined with inherent rapid propellant con\xad\nsumption, forced special design considerations to prevent the X-34 from \neither going out of trim from fuel sloshing aft-wards within the tanks or \nexperiencing fuel starvation from uncovering internal ports and drains. \n Design considerations were also needed to prevent a forward “migration” of \nthe center-of-gravity following engine burnout.  The residual fuel had to be \nprevented from flowing forward under the forces of longitudinal deceleration. \n', 'The baseline \nnozzles selected were simple conical divergent sections that are typically used to \nprovide a shock-free propellant expansion.  Two high-pressure vessels designed \nand produced by SCI and Lincoln Composites were chosen to meet the stor\xad\nage requirement of 7.1 cubic feet.  The feed system consisted of high-pressure \ntubing that directed the high-pressure nitrogen from the storage bottles located \nin the front end of the vehicle through a single 1-inch tube to each of the 10 \nthruster assemblies.  The thruster assemblies consisted of two pilot-operated \nsolenoid valves in series that were connected to nozzles customized for the \nX-34.  The tube routing and placement of the components in the system were \ndesigned to ensure that pressure drops were nearly equal at each nozzle, thus \nproviding a consistent level of thrust from each thruster.60\nX-34 Avionics System\nThe X-34 avionics system controls were designed to monitor all vehicle systems. \n Orbital design team members noted that “[a]vionics distributed through the \nvehicle provide control and monitoring of all functions.  Primary control is han\xad\ndled through the flight computer that sends commands to and receives critical \ntelemetry from each utility controller. ']","
The main parts of the flapper valves used in the propellant tanks of the X-34 main propulsion system are made of aluminum and are anodized to prevent corrosion. The flapper valve designs evolved from the ones used previously for the leading edge active cooling system (LEACS) and the International Space Station temperature and humidity control system. The 11070-1 valve was nearly identical to the 11070-1 used on LEACS, with the only difference being the surface finish and seats. The 11120 valve was a new design based on the same concepts as the LRACS series of valve. The surface finish and seats of the 11070 needed to be modified as the 11070-1, because initial testing showed significant leak-age around the seats, where the lapping compound used to polish the seats had created small flow passages. This led to the development of new lapping techniques and the use of new compounds to generate better surface finishes and tighter seating."
Question: What was the primary mission of Lunar Orbiter I and what was the result of its photography mission?,"The primary mission of Lunar Orbiter I was to photograph nine potential Apollo landing sites, seven secondary areas, and the Surveyor I landing site. By 28 August, Lunar Orbiter I had completed its main photography mission, having exposed a total of 205 frames, of which 38 were taken in the initial orbit and 167 in lower orbits, covering an area of 5.18 million km2. As planned, it photographed all 9 potential Apollo landing sites as well as 11 sites on the far side of the Moon. Some of the high-resolution photos were blurred due to smearing (stemming from problems in the imaging system), but the medium resolution images were the best lunar surface images returned to date.","['The vehicle also displayed higher than \nexpected temperatures but successfully entered a \n1,866.8 × 189.1-kilometer orbit around the Moon \non 24 August, thus becoming the first U.S.  space\xad\ncraft to do so.  The spacecraft’s primary mission \nwas to photograph nine potential Apollo landing \nsites, seven secondary areas, and the Surveyor I \nlanding site.  By 28 August, Lunar Orbiter I had \ncompleted its main photography mission, having \nexposed a total of 205 frames, of which 38 were \ntaken in the initial orbit and 167 in lower orbits, \ncovering an area of 5.18 million km2.  As planned, it \nphotographed all 9 potential Apollo landing sites as \nwell as 11 sites on the far side of the Moon.  Some \nof the high-resolution photos were blurred due to \nsmearing (stemming from problems in the imaging \nsystem), but the medium resolution images were \nthe best lunar surface images returned to date. \n One of the images returned, unplanned but taken \non 23\xa0August, was the first picture of Earth taken \nfrom the vicinity of the Moon. ', 'Flight controllers used a backup method by \nusing the same sensor, but with the Moon to orient \nthe vehicle.  The vehicle also displayed higher than \nexpected temperatures but successfully entered a \n1,866.8 × 189.1-kilometer orbit around the Moon \non 24 August, thus becoming the first U.S.  space\xad\ncraft to do so.  The spacecraft’s primary mission \nwas to photograph nine potential Apollo landing \nsites, seven secondary areas, and the Surveyor I \nlanding site.  By 28 August, Lunar Orbiter I had \ncompleted its main photography mission, having \nexposed a total of 205 frames, of which 38 were \ntaken in the initial orbit and 167 in lower orbits, \ncovering an area of 5.18 million km2.  As planned, it \nphotographed all 9 potential Apollo landing sites as \nwell as 11 sites on the far side of the Moon.  Some \nof the high-resolution photos were blurred due to \nsmearing (stemming from problems in the imaging \nsystem), but the medium resolution images were \nthe best lunar surface images returned to date. \n', 'It shows very vividly the striking topography within the crater Copernicus.  Credit: NASA / LOIRP\nResults: Lunar Orbiter II’s mission was to photo\xad\ngraph 13 primary and 17 secondary landings sites \nfor the Apollo program in the northern region of \nthe Moon’s near side equatorial area.  After a single \nmid-course correction on the way to the Moon, \non 10 November 1966, the spacecraft entered \na 196 × 1,850 kilometer orbit around the Moon. \n After 33 orbits, Lunar Orbiter II was moved to its \nphotographic orbit with a perilune of 49.7 kilome\xad\nters; on 18 November, it began its photography \nmission, returning excellent quality medium and \nhigh-resolution photographs, including the impact \npoint of Ranger VIII.  The spacecraft ended its pho\xad\ntography mission on 26 November and transmission \nof the images was concluded by 7 December, by \nwhich time the probe had transmitted back 211 pic\xad\ntures of both the near side and large areas of the far\xad\nside.  These photos covered nearly four million km2 \nof the lunar surface.  The high-gain transmitter failed \nduring this time, but did not significantly affect the \ncoverage afforded by the photos. ', 'A subsequent engine \nfiring on 9 April 1984 shook Venera 15 sufficiently \nthat the antenna finally moved into proper orienta\xad\ntion.  Because of the nature of the spacecraft’s orbit, \nthe two orbiters mapped only the area from 30° N \nto the pole, about 115 million square kilometers. \n The official mission of both vehicles was to end on \n10 March 1984 but was extended on account that \nboth spacecraft were in excellent condition.  The \nprimary photography mission was completed on \n10\xa0July 1984.  After that, an “optional program” of \nscientific work continued through the remainder of \nthe year.  On 30 December 1984, controllers found \nthat the orientation system had exhausted its nitro\xad\ngen.  Last contact was made with the spacecraft on \n5 January 1985.\n', 'After a single mid-course correction on 3 August, \nLunar Orbiter V entered lunar polar orbit two days \nlater after an engine firing at 16:48 UT that lasted 8 \nminutes, 28 seconds.  Initial orbital parameters were \n194.5 × 6,023 kilometers at 85.01° inclination. \n The orbital period was 8.5 hours.  Lunar Orbiter \nV began its photography mission at 01:22\xa0UT on \n7\xa0August before executing a maneuver to bring it to \nits operational orbit at 100 × 6,023 kilometers.  The \nspacecraft photographed 36 different areas on the \nnear side and mapped most of the farside via a set \nof 212 frames until the photography mission ended \non 18 August.  These included five potential Apollo \nlanding sites, 36 science sites, and 23 previously \nunphotographed areas of the farside, as well pos\xad\nsible targets for future Surveyor missions.  Control\xad\nlers also extensively used the spacecraft to map the \nMoon’s gravitational field in order to predict orbital \nperturbations on future lunar orbital missions. \n']","
The primary mission of Lunar Orbiter I was to photograph nine potential Apollo landing sites, seven secondary areas, and the Surveyor I landing site. The spacecraft successfully entered a 1,866.8 × 189.1-kilometer orbit around the Moon on 24 August, thus becoming the first U.S. spacecraft to do so. By 28 August, Lunar Orbiter I had completed its main photography mission, having exposed a total of 205 frames, of which 38 were taken in the initial orbit and 167 in lower orbits, covering an area of 5.18 million km2. The spacecraft photographed all 9 potential Apollo landing sites as well as 11 sites on the far side of the Moon. Some of the high-resolution photos were blurred due to smearing, but the medium resolution images were the best lunar surface images returned to date. One of the images returned, unplanned but taken on 23 August, was the first picture of Earth taken from the vicinity of the Moon."
"Why did Administrator Goldin initially rescind U.S. involvement in the Cassini-Huygens mission, and what factors ultimately led to his acquiescence?","Administrator Goldin initially rescinded U.S. involvement in the Cassini-Huygens mission due to the size and scope of the mission being at odds with his faster, better, cheaper efficiency approach to program management. However, leadership at ESA found it unacceptable that the United States would once again back out of a large international endeavor, effectively canceling the mission unilaterally. Ultimately, Goldin acquiesced due to the mission's scientific value and the efforts of ESA representatives to communicate their position to NASA management and the U.S. government.","['NASA soon followed suit, and the two \norganizations named the mission Cassini-Huygens (for the orbiter and the \nprobe, respectively).  Both organizations designated the large undertaking \nas a flagship mission, which represented a more evenly divided partnership \nthan previous joint efforts.  ESA’s member nations were keen to demonstrate \nthat Europe had reached a point of technological maturity in space science \nthat compared favorably with that of the United States, placing the two space \norganizations on equal scientific footing.\n Administrator Goldin found the size and scope of the mission at odds \nwith the reforms he was attempting to enact and rescinded U.S.  involvement \nin the project.  Leadership at ESA, recalling the outcome of ISPM, found it \nunacceptable that the United States would once again back out of a large \ninternational endeavor, effectively canceling the mission unilaterally.  ESA \nrepresentatives vigorously communicated their position to NASA manage\xad\nment, the U.S. ', 'Bush’s Moon-Mars program went nowhere \nwith Congress, as Goldin soon discovered, but he saw robotic exploration as \nan area where he could make progress toward the Red Planet.  He replaced \nthe Science Mission Director he had inherited with Wesley Huntress, and \nlater—when Huntress left—with Ed Weiler.  He found them both able and \nsupportive of his Mars goals. \n Goldin was retained as NASA Administrator by President Bill Clinton \nbecause Goldin’s faster, better, cheaper efficiency approach to program man\xad\nagement fit well with Clinton’s, and especially Vice President Al Gore’s, desire \nto launch a reinventing-government campaign.  Goldin ultimately became \ntheir poster boy for the White House (and congressional) drive to accom\xad\nplish more for less.  He also endeared himself to the White House through his \nleadership in the International Space Station Program.  He was responsive to \nthe White House, and so the White House was responsive to him. \n', 'NASA canceled the CRAF mission and under\xad\ntook a dramatic reconfiguration of the Cassini project in order to reduce \nits\xa0cost. \n A new budgetary crisis arose in 1994, when Congress threatened to dra\xad\nmatically reduce the NASA budget.  If approved, this reduction could lead \nto either Cassini or the important x-ray astronomy mission Advanced X-ray \nAstrophysics Facility (AXAF) (eventually called Chandra) being canceled. \n Prospects for Cassini were not encouraging, as the mission did not enjoy \nsupport from NASA Administrator Daniel Goldin.  Cassini was the perfect \nantithesis of Goldin’s “faster, better, cheaper” policy (see chapter 5): a mam\xad\nmoth mission, conceived 10 years earlier, which would not provide scientific \nresults until more than 10 years later.  Its cost was to be measured in billions \nof dollars, and a failure at launch or beyond would have been devastating. \n Moreover, its management suffered from the complexity of a large interna\xad\ntional cooperative endeavor and an 18-instrument payload coming from \ncountless scientific institutions on two continents. ', 'Cassini was the perfect \nantithesis of Goldin’s “faster, better, cheaper” policy (see chapter 5): a mam\xad\nmoth mission, conceived 10 years earlier, which would not provide scientific \nresults until more than 10 years later.  Its cost was to be measured in billions \nof dollars, and a failure at launch or beyond would have been devastating. \n Moreover, its management suffered from the complexity of a large interna\xad\ntional cooperative endeavor and an 18-instrument payload coming from \ncountless scientific institutions on two continents.  Goldin did not hide his \nviews on Cassini, and he was prepared to cancel it, or at least to submit it to \na drastic revision to reduce its cost.20 \nReporting to ESA’s Bonnet on a meeting of NASA’s Space Science and \nApplications Advisory Committee, SSAC Chairman Lodewijk Woltjer wrote \n18.\t  David Southwood, letter to Barrien Moore III, 28 October 1991. \n 19.\t  Russo, p. ', 'Barbara \nMikulski (D-MD), chair of the Senate Appropriations subcommittee that han\xad\ndled NASA’s budget, summarized this position: “I truly believe that in space \nstation Freedom we are going to generate jobs today and jobs tomorrow—jobs \ntoday in terms of the actual manufacturing of space station Freedom, but jobs \ntomorrow because of what we will learn.”6\nIn the latter 1980s and early 1990s, a parade of space station managers and \nNASA Administrators, each of them honest in their attempts to rescue the \nprogram, wrestled with Freedom and lost.  They faced on one side politicians \nwho demanded that the jobs aspect of the project—itself a major cause of the \noverall cost growth—be maintained, and with station users on the other side \ndemanding that Freedom’s capabilities be maintained, and with people on all \nsides demanding that costs be reduced.  The incompatibility of these various \ndemands ensured that station program management was a task not without dif\xad\nficulties.  The NASA Administrator beginning 1 April 1992, Daniel S. Goldin, \nwas faced with a uniquely frustrating situation when these competing claims \nwere made official by the new President, William J. Clinton, who told him \nin the spring of 1993 to restructure the space station program by reducing its \n']","
Administrator Goldin initially rescinded U.S. involvement in the Cassini-Huygens mission due to its size and scope, which he found at odds with the reforms he was attempting to enact. However, ESA representatives strongly communicated their position to NASA management, the U.S. State Department, and Vice President Al Gore, expressing their concern about the United States' reliability as a partner in large scientific or technological endeavors if it backed out of the mission. This tactic was effective because the White House was courting ESA involvement in the International Space Station (ISS) effort, and ESA considered Cassini-Huygens a priority for reasons of international prestige and the potential to increase the capabilities of its member nations' aerospace industrial base. In the end, Administrator Goldin acquiesced, and Cassini-Huygens continued toward its successful launch in 1997."
"How did the NACA's flight research program in the 1920s and early 1930s contribute to the establishment of a world-class aeronautics R&D organization, and what impact did it have on the aviation industry? Provide specific examples from the given context.","The NACA's flight research program in the 1920s and early 1930s contributed significantly to the establishment of a world-class aeronautics R&D organization. During this period, the NACA built a balanced research staff that pioneered novel methods of flight research, new ideas for recording instruments, and new methods and facilities for research on engines, propellers, structures, seaplanes, ice prevention, helicopters, and many other branches of aerodynamics. The NACA's research on aircraft engines and propellers was the first major success of the organization and helped develop the Liberty engine, the major contribution the United States made to aeronautics in World War I.

One specific example of the NACA's impact on the aviation industry is the Variable Density Tunnel (VDT), which was the first pressurized wind tunnel in the world. Developed by Dr. Max Munk, a German engineer who came to work at the NACA's Langley Memorial Aeronautical Laboratory (LMAL) in the early 1920s, the VDT was only 34.5 ft (10.5 m) long and 15 ft (4.6 m) in diameter, but it was capable of achieving more realistic effects than any previous wind tunnel to show how an actual aircraft would perform under flight conditions.

Another example is the NACA's work on propeller research, which was one of the earliest and most consistently funded programs. The NACA enlisted the help of Government researchers and university professors from across the Nation but concentrated its main effort at Stanford University near Palo Alto, CA. Despite regular use in airships, however, propeller development through the late 18th and 19th centuries was more the result of empiricism than established theory. The NACA's efforts in propeller research, including the development of the blade-element theory by Stefan Drzewiecki, greatly affected propeller development and helped establish the NACA as a world-class aeronautics R&D organization.

Overall, the NACA's flight research program in the 1920s and early 1930s laid the foundation for a world-class aeronautics R&D organization that would go on to make","['Chapter 2:\u2002 Making a World-Class Aeronautics R&D Organization\n13\nthe NACA as an organization would become more formalized over time, it \nremained committed to fostering creativity and innovation.\n During the 1920s, NACA executives built a balanced research staff that \npioneered novel methods of flight research; new ideas for recording instru\xad\nments; and new methods and facilities for research on engines, propellers, \nstructures, seaplanes, ice prevention, helicopters, and many other branches of \naerodynamics.  They developed and made use of various types of wind tun\xad\nnels—variable density, full scale, refrigerated, free-flight, gust, transonic, and \nsupersonic—the core instruments NACA engineers employed to advance \naerodynamic\xa0knowledge.\n Three Legs of Aeronautical Investigation\nAll research projects undertaken at the NACA during its early period sought \nto pursue investigations that promised the discovery and compilation of funda\xad\nmental aeronautical knowledge applicable to all flight rather than working on a \nspecific type of aircraft design that would appear to be catering to a particular \naeronautical firm. \n Figure 2-1. ', 'Chapter 1:\u2002 NACA Origins\n9\nThis and other contracts paid off; the NACA’s research on aircraft engines and \npropellers was the first major success of the organization and helped develop the \nLiberty engine, the major contribution the United States made to aeronautics \nin World War I.\nBecoming a Research Organization\nAt the end of World War I, the NACA was still very much in the process of \nestablishing its identity.  While Lewis, his staff, and committee members had \naided the war effort, critics abounded because it still had no R&D capabil\xad\nity.  Some criticized it for rolling with the exigencies of the political crisis du \njour rather than expending more energy on establishing R&D facilities.  Leigh \nM. Griffith, an early NACA technical employee, voiced the concern that the \nNACA was loose and disorganized and that it had not developed an effective \nstatement of the “nature of the services that this Committee is endeavoring to \nrender, or is capable of rendering…. ', '11\nCHAPTER 2\nMaking a World-Class Aeronautics \nR&D Organization\nI\nt looked more like a submarine than anything else, but no matter, the wind \ntunnel was a remarkable aeronautical research instrument.  The brainchild of \nDr.  Max Munk, a German engineer who came to work at the NACA’s Langley \nMemorial Aeronautical Laboratory (LMAL) in the early 1920s, the Variable \nDensity Tunnel (VDT)—only 34.5\xa0ft (10.5\xa0m) long and 15\xa0ft (4.6\xa0m) in diam\xad\neter—was the first pressurized wind tunnel in the world.  This meant the VDT \ncould achieve more realistic effects than any previous wind tunnel to show how \nan actual aircraft would perform under flight conditions. ', 'One of the earliest and most \nconsistently funded programs was propeller research.  The NACA’s first annual \nreport in 1915 acknowledged the lack of consistent propeller data regard\xad\ning efficiency as one of the general problems facing American aeronautics. \n In its efforts to refine, develop, and perfect the propeller, the NACA enlisted \nthe help of Government researchers and university professors from across the \nNation but concentrated its main effort at Stanford University near Palo Alto, \nCA.  As the 1920s progressed, the NACA became involved with aeronautical \nresearch, including propeller research, at major American universities such as \nthe Massachusetts Institute of Technology (MIT), New York University, the \nUniversity of Michigan, and the California Institute of Technology.13\nDespite regular use in airships, however, propeller development through \nthe late 18th and 19th centuries was more the result of empiricism than estab\xad\nlished theory.14 In France in 1885, Russian-born Stefan Drzewiecki devised a \ntheory for calculating propeller performance based on measured airfoil data \nthat, had they been used by the aeronautical community, would have greatly \naffected propeller development.  Known today as the blade-element theory, \nDrzewiecki’s theory considers the propeller to be a warped airfoil, each of \nwhose segments represents an ordinary wing as the segments travel in a heli\xad\ncal path.  Drzewiecki was the first to calculate the forces on blade segments to \nfind the thrust and torque output for the entire propeller as well as innovating \nthe use of airfoil data to determine propeller efficiency.  Drzewiecki published \nvarious papers and texts beginning in 1885 and ending with Théorie Générale \nde l’Hélice Propulsive in 1920.15\nAlong with being the first successfully to develop a practical flying machine, \nWilbur and Orville Wright were the first to address the propeller from a \n', 'Chapter 4:\u2002 Higher, Faster, and Farther\n61\nThe Mercury spacecraft that flew in 1961–63 emerged from these early con\xad\nceptual studies by the NACA.\n World-Class Aeronautical Research and Development\nAs a measure of the success of the NACA in aerospace research in the post–\nWorld War II era, the National Aeronautic Association (NAA) awarded the \nprestigious Robert A. Collier trophies to the agency four times between 1946 \nand 1954.  Established in 1911, the Collier Trophy was given annually “for the \ngreatest achievement in aeronautics or astronautics in America, with respect to \nimproving the performance, efficiency, and safety of air or space vehicles, the \nvalue of which has been thoroughly demonstrated by actual use during the pre\xad\nceding year.” A garish Art Deco design with a sculpture evoking human flight, \nthe Collier Trophy has been overseen by the National Aeronautic Association \nsince its inception, placed on permanent display at the Smithsonian Institution, \nand in its earliest era awarded in a ceremony presided over by the President \nof the United States.  The NACA first received the Collier Trophy in 1929 for \nthe development of low-drag cowling for radial air-cooled aircraft engines, but \nnothing thereafter received this status until 1947.  Then, in the space of less than \na decade, the NACA received four more Collier Trophies for its research.\n']","
The NACA's flight research program in the 1920s and early 1930s significantly contributed to the establishment of a world-class aeronautics R&D organization by providing valuable insights and data on various aspects of aircraft performance and design. This research program gained fame for its high-quality work, which was comparable to that of the wind tunnel work.

One specific example is the NACA's research on pressure distribution over aircraft surfaces. In 1929, the NACA published the first seminal studies of aerodynamics of pressure distribution on aircraft, followed by a summary report in early 1930. This report set a new standard of knowledge and emphasized the importance of designing aircraft based on known phenomena rather than conjecture.

The flight research program also had a significant impact on the aviation industry. It won the NACA a reputation for research leadership and innovation, and the military services, universities, and aircraft industries began to look to the NACA for guidance. The flight research practitioners gained a place beside the theorists and wind tunnel experimentalists, further solidifying the NACA's position as a world-class aeronautics R&D organization.

Overall, the NACA's flight research program in the 1920s and early 1930s played a crucial role in establishing the NACA as a leading aeronautics R&D organization and had a significant impact on the aviation industry by providing valuable insights and data on aircraft performance and design."
Question: What is the significance of the MESSENGER mission in advancing Mercury science and answering fundamental questions about the planet?,"The MESSENGER mission, launched in 2004, was the first spacecraft to orbit Mercury, providing a full measure of readings about the planet. The mission's primary goal was to study the geology, magnetic field, and chemical composition of the planet. The mission's instrument payload consisted of the Mercury Dual Imaging System, a Gamma Ray and Neutron Spectrometer, an X-Ray Spectrometer, a magnetometer, the Mercury Laser Altimeter, the Mercury Atmospheric and Surface Composition Spectrometer, and an Energetic Particle and Plasma Spectrometer, as well as a radio science investigation. The mission's results included surprising findings such as flooding and explosive volcanism in early Mercury history, contraction of planetary geology on a global scale, a magnetic dipole aligned with the planet's spin axis, 60 to 70 percent iron contained in the planet's interior, and compelling support for the hypothesis that Mercury harbors abundant water ice and other frozen volatile materials in its permanently shadowed polar craters. The mission significantly expanded the envelope of engineering practice, with the first operational demonstration of solar sailing using a large kite-like object to capture the solar wind. Overall, the MESSENGER mission provided critical anchor points for understanding the solar system and answered fundamental questions about Mercury.","['If so, micro\xad\norganisms might still be living beneath Mars’s polar caps or in subterranean \nhot springs warmed by vents from the Martian core.  Scientists are quick to \nadd, however, that these are unproven theories for which evidence has not yet \nbeen\xa0discovered. \n Orbiting Mercury\nWhile other spacecraft had flown briefly in the vicinity of Mercury, the closest \nplanet to the Sun, not until 2004 did NASA launch the first mission to orbit \nand take a full measure of readings about the planet.  Following a trajectory that \nrequired six planetary flybys, six propulsive maneuvers, and about six and a half \nyears, MESSENGER (an acronym for MErcury Surface, Space ENvironment, \nGEochemistry, and Ranging) reached that sweltering terrestrial planet.  The \nmission team significantly expanded the envelope of engineering practice, with \nthe first operational demonstration of solar sailing using a large kite-like object \nto capture the solar wind. \n Prior to the MESSENGER mission, Mercury was poorly understood, \nbut as the nearest planet to the Sun and the smallest of the four rocky plan\xad\nets—Mercury, Venus, Earth, and Mars—it offered a critical anchor point \nfor understanding the solar system.  During its operation between reaching \nMercury orbit on 17 March 2011 and the end of the program on 30 April 2015, \nMESSENGER’s science team found a number of surprising results, including \nflooding and explosive volcanism in early Mercury history, contraction of plan\xad\netary geology on a global scale, a magnetic dipole aligned with the planet’s spin \naxis, 60 to 70 percent iron contained in the planet’s interior, and compelling \nsupport for the hypothesis that Mercury harbors abundant water ice and other \nfrozen volatile materials in its permanently shadowed polar craters. \n', 'Orbiting Mercury\nWhile other spacecraft had flown briefly in the vicinity of Mercury, the closest \nplanet to the Sun, not until 2004 did NASA launch the first mission to orbit \nand take a full measure of readings about the planet.  Following a trajectory that \nrequired six planetary flybys, six propulsive maneuvers, and about six and a half \nyears, MESSENGER (an acronym for MErcury Surface, Space ENvironment, \nGEochemistry, and Ranging) reached that sweltering terrestrial planet.  The \nmission team significantly expanded the envelope of engineering practice, with \nthe first operational demonstration of solar sailing using a large kite-like object \nto capture the solar wind. \n Prior to the MESSENGER mission, Mercury was poorly understood, \nbut as the nearest planet to the Sun and the smallest of the four rocky plan\xad\nets—Mercury, Venus, Earth, and Mars—it offered a critical anchor point \nfor understanding the solar system.  During its operation between reaching \nMercury orbit on 17 March 2011 and the end of the program on 30 April 2015, \nMESSENGER’s science team found a number of surprising results, including \nflooding and explosive volcanism in early Mercury history, contraction of plan\xad\netary geology on a global scale, a magnetic dipole aligned with the planet’s spin \naxis, 60 to 70 percent iron contained in the planet’s interior, and compelling \nsupport for the hypothesis that Mercury harbors abundant water ice and other \nfrozen volatile materials in its permanently shadowed polar craters. \n Reconnoitering the Outer Solar System\nAs NASA pursued science missions in the 1970s, it seized an opportunity avail\xad\nable every 176 years when gas giants in the outer solar system gathered on one \n', 'Credit: \nNASA/Johns Hopkins University Applied Physics Labora\xad\ntory/Carnegie Institution of Washington\nScientific Instruments:\n1.\t  Mercury dual imaging system (MDIS)\n2.\t gamma-ray spectrometer (GRS)\n3.\t neutron spectrometer (NS)\n4.\t x-ray spectrometer (XRS)\n5.\t magnetometer (MAG)\n6.\t  Mercury laser altimeter (MLA)\n7.\t  Mercury atmospheric and surface composi\xad\ntion spectrometer (MASCS)\n8.\t energetic particle and plasma spectrometer \n(EPPS)\n9.\t radio science experiment (RS)\nResults: MESSENGER (Mercury Surface, Space \nEnvironment, Geochemistry, and Ranging) was \nthe seventh Discovery-class mission, and the first \nspacecraft to orbit Mercury.  Its primary goal was \nto study the geology, magnetic field, and chemical \ncomposition of the planet.  It was the first mis\xad\nsion to Mercury after Mariner 10, more than 30 \nyears before.  MESSENGER was launched into \nan initial parking orbit around Earth after which \nits PAM-D solid motor fired to put the spacecraft \non an escape trajectory into heliocentric orbit at \n0.92 × 1.08 AU and 6.4° inclination to the eclip\xad\ntic. ', 'Moreover, \nthere was evidence that an unexpected material might be found in Mercury’s craters \nat the poles that are never exposed to sunlight.  This material might have been frozen \nwater ice, comet-delivered sulfur, or silicates, hidden in the dark crevices that stay very \ncold, hundreds of degrees below zero.\n Its oddly strong magnetic field and unknown core size and composition were also \nunexplained.  Did it possess a spinning liquid outer core?25 Its geology was curious as \nwell, including its giant escarpments sometimes a mile high and hundreds of miles \nacross, formed most likely when the planet cooled.26\nTo answer those and other questions, MESSENGER’s instrument payload consisted \nof the Mercury Dual Imaging System, a Gamma Ray and Neutron Spectrometer, an \nX-Ray Spectrometer (XRS), a magnetometer, the Mercury Laser Altimeter, the Mercury \nAtmospheric and Surface Composition Spectrometer (MASCS), and an Energetic \nParticle and Plasma Spectrometer (EPPS), as well as a radio science investigation.27\n23 \t\nIbid.\n 24 \t\nSpotts, P. N.  (2004, 29 July).  “The long and winding road to a hot planet.” The Christian \nScience Monitor.\n', 'Chapter 5: Breaking the Bank\n177\nlasts two Mercury years.  It has the highest intrinsic density of any planet; the density is \nso high that two-thirds of the planet must be iron metal.”23 A mission to Mercury, ulti\xad\nmately, is a mission to the innermost part of the nebula out of which the planets formed.24\nBefore MESSENGER, not much was known about Mercury.  Its density and mag\xad\nnetic field were comparable to Earth’s, but the planet is much smaller and made mostly \nof metal.  All this was so, perhaps, because the interior region of the solar nebula was \nenriched in metals.  Or maybe the planet was originally covered with a rocky surface \nthat baked off in the intense heat caused by its proximity to the Sun. ']","
The MESSENGER mission is significant in advancing Mercury science as it promised to immeasurably advance the understanding of the planet. NASA had not sent a spacecraft to Mercury since Mariner 10 in 1974, and Robert Strom, a professor emeritus at the University of Arizona Lunar and Planetary Laboratory, had been lobbying for a return to Mercury since NASA’s last foray there. He became a co-investigator on MESSENGER. The mission sought to answer six fundamental questions, which trace their heritage back to the 1978 COMPLEX report coauthored by Solomon. These questions include the planetary formational processes that led to Mercury’s high ratio of metal to silicate, the geological history of Mercury, the nature and origin of Mercury’s magnetic field, the structure and state of Mercury’s core, the radar-reflective materials at Mercury’s poles, and the important volatile species and their sources and sinks near Mercury. The mission was significant in that it was the first orbiter to Mercury since Mariner 10 and aimed to answer long-standing questions about the planet."
Who is Grove Karl Gilbert and what are his contributions to the field of lunar craters research and Meteor Crater surveys?,"Grove Karl Gilbert was a geologist who served as the chief geologist for the United States Geological Survey (USGS) from 1888 to 1894. He made significant contributions to the field of lunar craters research and Meteor Crater surveys. In 1892-93, he published a study titled ""The Moon's Face: A Study of the Origin of Its Features,"" in which he analyzed the lunar topography and assessed each of the major theories of crater formation. He opened the resulting study with a survey of key aspects of crater appearance and distribution, including a description of their varying abundance by size, uneven distribution between the rough highlands and smoother maria, and overlapping relationships. He also noted the differences in morphology between small craters and large ones, and described qualitatively the scaling of depth with diameter in each of the two size classes. These observations provided evidence for or against the volcanic and meteoric hypotheses for crater origins. In contrast to his Arizona study, which led him to consider a volcanic origin for Meteor Crater, this analysis convinced him of the opposite for the craters on the Moon.","['An independent photographic discovery of Eros on 13 August 1898 is \nsometimes attributed to Auguste Charlois at Nice Observatory in France. \n At the time, Charlois was one of the leading discoverers of asteroids, but \nbecause of poor weather on 14–15 August and the fact that 14\xa0August was \na Sunday and 15\xa0August was a French holiday, Charlois did not follow up \nhis photographic discovery of Eros with more precise naked-eye microme\xad\nter measurements until Tuesday, 16\xa0August 1898.  He may have waited until \nTuesday to develop the plate that was taken the previous Saturday, or, because \nof some telescope tracking problems, perhaps he did not initially notice the \nEros trail on his photographic plate.21 Later, Julius Bauschinger, director of \nthe Königliches Astronomisches Rechen-Institut in Berlin and editor of the \nBerliner Astronomisches Jahrbuch, a contemporary scientific journal, noted that \nEros was likely one of many with orbits between Earth and the asteroid belt.22\nAs the number of known asteroids continued to grow and the first near-\nEarth asteroids (NEAs)23 were added to the inventory, another debate began \nto smolder over what might happen if one of these stray bodies were to strike \nEarth—or what we might find if one had done so in the past.\n Meteor Crater and the Moon\nIn November of 1891, Grove Karl Gilbert, chief geologist for the United \nStates Geological Survey,24 set out on what he described as a peculiar errand: \nusing the 12-inch aperture refractor made by Carl Bamberg at Berlin, then the largest \ntelescope in Prussia.\n 21.\t  Scholl and Schmadel, “Discovery Circumstances of the First Near-Earth Asteroid 433 \nEros.”\n22.\t  Ibid.\n', 'See appendix 2.  The terms “near-Earth asteroid” and “near-Earth object” were not \nwidely in use until the late 20th century.\n 24.\t  Having served on several surveys of the American west, Grove Karl Gilbert joined \nthe United States Geological Survey (USGS) when it formed in 1879 and had already \npublished several pioneering field reports by the time he was appointed chief geologist \nin 1888.\n', 'Geological Survey, 1892–\n93), p.  187.\n 34.\t  Grove Karl Gilbert, The Moon’s Face: A Study of the Origin of Its Features (Washington, \nDC: Philosophical Society of Washington, 1893), p.  242.\n 35.\t  Ibid., pp. ', 'A History of Near-Earth Objects Research\n26\neye, scrupulously inspected the lunar topography and assessed each of the \nmajor theories of crater formation.  He opened the resulting study with a sur\xad\nvey of key aspects of crater appearance and distribution, including a descrip\xad\ntion of their varying abundance by size, uneven distribution between the \nrough highlands and smoother maria, and overlapping relationships.  He also \nnoted the differences in morphology between small craters and large ones, and \ndescribed qualitatively the scaling of depth with diameter in each of the two \nsize classes.36 These observations provided evidence for or against the volcanic \nand meteoric hypotheses for crater origins.\n Whereas his Arizona study had led Gilbert to consider a volcanic origin for \nMeteor Crater, this analysis convinced him of the opposite for the craters on \nthe Moon.  To begin with, he noted that the sizes of lunar craters vastly over\xad\nshadow those of terrestrial volcanoes, and the enormous range of crater sizes \nis entirely unlike the distribution of Earth’s features.  An even bigger problem, \nGilbert argued, was the vast disparity in form.  The most common type of ter\xad\nrestrial volcano, the stratovolcano (e.g., Mount Vesuvius), with its tall sloping \nsides, relatively shallow caldera, and misshapen or altogether absent central \ncones, looks very different from the typical crater described at the beginning \nof his paper. ', 'A History of Near-Earth Objects Research\n30\ncapturing what would become a familiar sentiment.  “Theories of great inge\xad\nnuity and variety,” as Gilbert called them, were not generally looked upon \nwith favor by the geologists of the 19th century, and the distant Moon could \nnot help but prove a speculative topic.\n Gilbert’s work, first at Meteor Crater and subsequently on the lunar cra\xad\nters, serves to illustrate the attitudes among astronomers and geologists con\xad\ncerning the possibility of impact phenomena at the turn of the 20th century. \n The discovery that there were myriad objects in the solar system far smaller \nthan the known major planets did not automatically translate into acceptance \nthat those bodies might sometimes change Earth’s surface.  Instead, many sci\xad\nentists would continue to believe well into the 20th century that they played \nno role in Earth’s history at all.\n A new chapter for Meteor Crater would open with the new century, and \nwith it, another look at the old problem of the craters on the Moon.\n']","
Grove Karl Gilbert was a prominent American geologist and astronomer who made significant contributions to the field of lunar craters research and Meteor Crater surveys. He was a member of the United States Geological Survey (USGS) and conducted extensive research on lunar craters, including the famous lunar crater Copernicus. Gilbert's work on lunar craters involved studying their morphology, size, and distribution, and he proposed that they were formed by the impact of meteorites. He also conducted surveys of Meteor Crater in Arizona, which he believed was formed by a meteorite impact. Gilbert's research on Meteor Crater involved studying its structure, composition, and origin, and he concluded that it was formed by a meteorite impact. His work on lunar craters and Meteor Crater helped establish the field of impact cratering and has had a lasting impact on our understanding of the solar system."
What is the Torino Scale and how is it used to categorize potential Earth impact events? (Refer to Figure 6-4),"The Torino Scale is a tool for categorizing potential Earth impact events. It is a numerical scale ranging from 0 to 10 with associated color coding, primarily intended to facilitate public communication by the asteroid impact hazard monitoring community. The scale captures the likelihood and consequences of a potential impact event but does not consider the time remaining until the potential impact. More extraordinary events are indicated by a higher Torino Scale value. (Refer to Figure 6-4 for the scale and its associated colors.)","['Chapter 6: Automating Near-Earth Object Astronomy\n171\nDiagram showing the\n Torino Scale.  Collis\nion probability \nis p\nl\nott\ned \non \nthe \nX-ax\nis wh\nile \nKine\ntic \nEnerg\ny is\n \np\nl\no\nt\nt\ne\nd \no\nn\n \nthe Y-\naxis.\n Figure 6-4.  The Torino Scale, adopted by the IAU in 1999, is a tool for categorizing \npotential Earth impact events.  An integer scale ranging from 0 to 10 with associated color \ncoding, it is intended primarily to facilitate public communication by the asteroid impact \nhazard monitoring community.  The scale captures the likelihood and consequences of a \npotential impact event but does not consider the time remaining until the potential impact. \n More extraordinary events are indicated by a higher Torino Scale value. ', 'The Torino Scale, adopted by the IAU in 1999, is a tool for categorizing \npotential Earth impact events.  An integer scale ranging from 0 to 10 with associated color \ncoding, it is intended primarily to facilitate public communication by the asteroid impact \nhazard monitoring community.  The scale captures the likelihood and consequences of a \npotential impact event but does not consider the time remaining until the potential impact. \n More extraordinary events are indicated by a higher Torino Scale value.  (Image credit: JPL/\nCaltech/NASA)\nAssessing Asteroid and Comet Impact Hazard Predictions in the 21st Century\nNo Hazard\n(White Zone)\n0\nThe likelihood of a collision is zero, or is so low as to be effectively \nzero.  Also applies to small objects such as meteors and bodies that \nburn up in the atmosphere as well as infrequent meteorite falls that \nrarely cause damage.\n Normal \n(Green Zone)\n1\nA routine discovery in which a pass near Earth that poses no unusual \nlevel of danger is predicted. ', 'So \nthe very real possibility of these low-probability/high-consequence events is \nvery difficult to communicate to the public.  In an effort to provide an easily \nunderstood evaluation of a possible threat within the next 100 years, Richard \nBinzel, at a United Nations conference in 1995, introduced a near-Earth \nobject threat scale that took into consideration the likelihood of an upcom\xad\ning impact (its impact probability) and the energy of the possible impact in \nmegatons of TNT explosives.70 Binzel’s original index went from 0 (no col\xad\nlision possible), to 1 (extremely improbable), on up to 5 (certain impact on a \nparticular future date).71\nSubsequently, Binzel’s index scale was modified and presented at a June \n1999 international conference about NEOs held in Torino (Turin), Italy.  The \nnew Torino Scale, as it was renamed, ran from 0 to 10, with colors introduced \nto represent no threat (0, white), an extremely low threat level (1, green), a \nthreat meriting attention by astronomers (2–4, yellow), threatening (5–7, \norange), and certain collision (8–10, red). \n The Torino Scale might be appropriate for public communication, but it \ndid not convey the urgency of the event.  Would the possible impact occur \nin several decades or several weeks?  To provide a scale more useful to the \nscientific community for prioritizing objects for additional observations and \nanalysis, Steven Chesley and his colleagues introduced a scale that sought to \ninclude the time proximity as well as the impact probability and potential \nimpact energy.  In honor of the 2001 international conference on NEOs held \nin Palermo, Italy, this threat scale for professionals was named the Palermo \n70.\t ', 'Moreover, the topic is provocative and prone to sensationalism.  So \nthe very real possibility of these low-probability/high-consequence events is \nvery difficult to communicate to the public.  In an effort to provide an easily \nunderstood evaluation of a possible threat within the next 100 years, Richard \nBinzel, at a United Nations conference in 1995, introduced a near-Earth \nobject threat scale that took into consideration the likelihood of an upcom\xad\ning impact (its impact probability) and the energy of the possible impact in \nmegatons of TNT explosives.70 Binzel’s original index went from 0 (no col\xad\nlision possible), to 1 (extremely improbable), on up to 5 (certain impact on a \nparticular future date).71\nSubsequently, Binzel’s index scale was modified and presented at a June \n1999 international conference about NEOs held in Torino (Turin), Italy.  The \nnew Torino Scale, as it was renamed, ran from 0 to 10, with colors introduced \nto represent no threat (0, white), an extremely low threat level (1, green), a \nthreat meriting attention by astronomers (2–4, yellow), threatening (5–7, \norange), and certain collision (8–10, red). \n The Torino Scale might be appropriate for public communication, but it \ndid not convey the urgency of the event.  Would the possible impact occur \nin several decades or several weeks?  To provide a scale more useful to the \nscientific community for prioritizing objects for additional observations and \nanalysis, Steven Chesley and his colleagues introduced a scale that sought to \ninclude the time proximity as well as the impact probability and potential \nimpact energy. ', 'FIGURE 6-1\t Robert S. McMillan in the Spacewatch control center.\n\t FIGURE 6-2\t The Yarkovsky effect.\n\t FIGURE 6-3\t The YORP effect.\n\t FIGURE 6-4\t The Torino Scale.\n\t  FIGURE 7-1\t Bus-DeMeo asteroid spectral classification system (taxonomy).\n\t  TABLE 7-1\t Comet and asteroid mission timelines.\n']","
The Torino Scale is a tool adopted by the International Astronomical Union (IAU) in 1999 to categorize potential Earth impact events. It is an integer scale ranging from 0 to 10, with associated color coding, primarily intended to facilitate public communication by the asteroid impact hazard monitoring community. The scale captures the likelihood and consequences of a potential impact event but does not consider the time remaining until the potential impact. Higher Torino Scale values indicate more extraordinary events.

The Torino Scale has several levels to categorize the events:

- No Hazard (White Zone): The likelihood of a collision is zero or effectively zero. This level also applies to small objects such as meteors and bodies that burn up in the atmosphere, as well as infrequent meteorite falls that rarely cause damage.

- Normal (Green Zone): A routine discovery in which a pass near Earth that poses no unusual level of danger is predicted. The chance of collision is extremely unlikely, with no cause for public attention or concern. New telescopic observations will likely lead to reassignment to Level 0.

- Meriting Attention by Astronomers (Yellow Zone): A discovery, which may become routine with expanded searches, of an object making a somewhat close but not highly unusual pass near Earth. While meriting attention by astronomers, there is no cause for public attention or concern as an actual collision is very unlikely. New telescopic observations will likely lead to reassignment to Level 0.

The Torino Scale also includes other levels, such as Meriting Concern (Orange Zone), Threatening (Red Zone), and Certain Collision (Brown Zone), which represent increasing levels of likelihood and consequences of potential Earth impact events."
"Which series of NASA publications includes the history of Project Mercury, Project Gemini, and the Apollo/Saturn launch vehicles, among others, and is identified by the SP-4200 designation?","The NASA publication series that includes the history of Project Mercury, Project Gemini, and the Apollo/Saturn launch vehicles, among others, and is identified by the SP-4200 designation is not explicitly mentioned in the given context information. However, the context information does mention the SP-4000 series, which includes Project Mercury: A Chronology and Project Gemini Technology and Operations: A Chronology, both of which are also included in the SP-4200 series. Therefore, it can be inferred that the SP-4200 series includes a more comprehensive history of NASA's manned spaceflight programs, including Project Mercury, Project Gemini, and the Apollo/Saturn launch vehicles, among others.","['323\nREFERENCE WORKS, NASA SP-4000\nGrimwood, James M. Project Mercury: A Chronology.  NASA SP-4001, 1963.\n Grimwood, James M., and Barton C. Hacker, with Peter J. Vorzimmer.  Project \nGemini Technology and Operations: A Chronology.  NASA SP-4002, 1969.\n Link, Mae Mills.  Space Medicine in Project Mercury. ', '345\nTHE NASA HISTORY SERIES\nReference Works, NASA SP-4000\nGrimwood, James M. Project Mercury: A Chronology.  NASA SP-4001, 1963.\n Grimwood, James M., and Barton C. Hacker, with Peter J. Vorzimmer.  Project \nGemini Technology and Operations: A Chronology. ', 'NASA SP-2004-\n4407, 2004.\n Logsdon, John M., ed., with Roger D. Launius.  Exploring the Unknown: Selected \nDocuments in the History of the U.S.  Civil Space Program, Volume VII: Human \nSpaceflight: Projects Mercury, Gemini, and Apollo.  NASA SP-2008-4407, 2008.\n Siddiqi, Asif A., Challenge to Apollo: The Soviet Union and the Space Race, 1945–\n1974.  NASA SP-2000-4408, 2000.\n', 'Brooks, Courtney G., James M. Grimwood, and Loyd S. Swenson, Jr.  Chariots for \nApollo: A History of Manned Lunar Spacecraft.  NASA SP-4205, 1979.\n Bilstein, Roger E. Stages to Saturn: A Technological History of the Apollo/Saturn \nLaunch Vehicles.  NASA SP-4206, 1980 and 1996.\n No SP-4207.\n', 'Brooks, Courtney G., James M. Grimwood, and Loyd S. Swenson, Jr.  Chariots for \nApollo: A History of Manned Lunar Spacecraft.  NASA SP-4205, 1979.\n Bilstein, Roger E. Stages to Saturn: A Technological History of the Apollo/Saturn \nLaunch Vehicles.  NASA SP-4206, 1980 and 1996.\n No SP-4207.\n Compton, W. David, and Charles D. Benson. ']","
Project Histories, NASA SP-4200
Swenson, Loyd S., Jr., James M. Grimwood, and Charles C. Alexander. This New 
Ocean: A History of Project Mercury. NASA SP-4201, 1966; rep. ed. 1999.
Green, Constance McLaughlin, and Milton Lomask. Vanguard: A History. NASA 
SP-4202, 1970; rep. ed. Smithsonian Institution Press, 1971.
Hacker, Barton C., and James M. Grimwood. On the Shoulders of Titans: A 
History of Project Gemini. NASA SP-4203, 1977; rep. ed. 2002.
Benson, Charles D., and William Barnaby Faherty. Moonport: A History of Apollo 
Launch Facilities and Operations. NASA SP-4204, 1978.
Brooks, Courtney G., James M. Grimwood, and Loyd S. Swenson, Jr. Chariots for 
Apollo: A History of Manned Lunar Spacecraft. NASA SP-4205, 1979.
Bilstein, Roger E. Stages to Saturn: A Technological History of the Apollo/Saturn 
Launch Vehicles. NASA SP-4206, 1980 and 1996.
No SP-4207.
Compton, W. David, and Charles D. Benson. Living and Working in Space: A 
History of Skylab. NASA SP-4208, 1983.
Ezell, Edward Clinton, and Linda Neuman Ezell. The Partnership: A History of the 
Apollo-Soyuz Test Project. NASA SP-4209, 1978.
Hall, R. Cargill. Lunar Impact: A History of Project Ranger. NASA SP-4210, 1977.
Newell, Homer E. Beyond the Atmosphere: Early Years of Space Science. NASA 
SP-4211, 1980."
"How did the Soviet Union assign official names to their spacecraft, particularly in the case of missions that failed to reach Earth orbit or left Earth orbit but failed to leave for deep space? Provide examples to illustrate your answer.","The Soviet Union did not announce or acknowledge a mission if it failed to reach Earth orbit, and for those lunar and planetary probes that did reach Earth orbit but failed to leave it, the Soviets adopted two strategies:

1. Between 1960 and 1963, the Soviets simply never admitted their existence and made no announcement.

2. Beginning November 1963, the Soviet media began to give these stranded-in-Earth-orbit spacecraft ""Kosmos"" numbers. For example, the deep space vehicle launched on 11 November 1963 that reached Earth orbit but failed to leave for deep space was simply given the ""next"" Kosmos number, in this case ""21."" By giving it such a nondescript name (""Kosmos 21""), Soviet officials sought to draw attention away from such failures.

In terms of official names, the author of the text material used the following convention:

[Program, Spacecraft design designation, serial number]
OR
Kosmos number [Program]

For example, the spacecraft launched on 10 October 1960 would not be referred to as ""Marsnik 1"" or ""Mars 1960A,"" as listed in the National Space Science Data Center. Since the Soviets never used such names, it would be entirely inaccurate to ascribe such designations.

In summary, the Soviet Union did not use official names for spacecraft that failed to reach Earth orbit or left Earth orbit but failed to leave for deep space. Instead, they adopted the ""Kosmos"" numbering system for these stranded-in-Earth-orbit spacecraft.","['in their official documentation, but these were dis\xad\ncontinued in the 1970s.  Readers will note that I \nhave used this convention for all missions until and \nincluding 1970 but after that switched to Latin \nnumbers (Mariner 9, Mariner 10, etc.).  This divi\xad\nsion is somewhat arbitrary but was necessary not to \nconfuse readers.\n The practice of giving spacecraft “official” \nnames is complicated by the fact that beginning \nwith the launch of Sputnik in 1957 and until the \nlate 1980s, the Soviet Union never announced or \nacknowledged a mission if it failed to reach Earth \norbit.  In addition, for those lunar and planetary \nprobes that did reach Earth orbit but failed to leave \nit, the Soviets adopted two strategies:\n•\t between 1960 and 1963, the Soviets simply \nnever admitted their existence and made no \nannouncement; and\n•\t beginning November 1963, the Soviet media \nbegan to give these stranded-in-Earth-orbit \nspacecraft “Kosmos” numbers.  So, the deep \nspace vehicle launched on 11 November 1963 \nthat reached Earth orbit but failed to leave for \ndeep space was simply given the “next” Kosmos \nnumber, in this case “21.” By giving it such a \nnondescript name (“Kosmos 21”), Soviet offi\xad\ncials sought to draw attention away from such \nfailures.  This practice was followed well into \nthe late 1980s.\n', 'Readers will note that I \nhave used this convention for all missions until and \nincluding 1970 but after that switched to Latin \nnumbers (Mariner 9, Mariner 10, etc.).  This divi\xad\nsion is somewhat arbitrary but was necessary not to \nconfuse readers.\n The practice of giving spacecraft “official” \nnames is complicated by the fact that beginning \nwith the launch of Sputnik in 1957 and until the \nlate 1980s, the Soviet Union never announced or \nacknowledged a mission if it failed to reach Earth \norbit.  In addition, for those lunar and planetary \nprobes that did reach Earth orbit but failed to leave \nit, the Soviets adopted two strategies:\n•\t between 1960 and 1963, the Soviets simply \nnever admitted their existence and made no \nannouncement; and\n•\t beginning November 1963, the Soviet media \nbegan to give these stranded-in-Earth-orbit \nspacecraft “Kosmos” numbers.  So, the deep \nspace vehicle launched on 11 November 1963 \nthat reached Earth orbit but failed to leave for \ndeep space was simply given the “next” Kosmos \nnumber, in this case “21.” By giving it such a \nnondescript name (“Kosmos 21”), Soviet offi\xad\ncials sought to draw attention away from such \nfailures.  This practice was followed well into \nthe late 1980s.\n For both of these three types of missions, I have \nused the following convention:\n[Program, Spacecraft design designation, serial \nnumber]\nOR\nKosmos number [Program]\nI do not use terms such as “Marsnik 1” or “Mars \n1960A” (listed in the National Space Science \nData Center, for example, to denote the spacecraft \nlaunched on 10 October 1960). ', 'This divi\xad\nsion is somewhat arbitrary but was necessary not to \nconfuse readers.\n The practice of giving spacecraft “official” \nnames is complicated by the fact that beginning \nwith the launch of Sputnik in 1957 and until the \nlate 1980s, the Soviet Union never announced or \nacknowledged a mission if it failed to reach Earth \norbit.  In addition, for those lunar and planetary \nprobes that did reach Earth orbit but failed to leave \nit, the Soviets adopted two strategies:\n•\t between 1960 and 1963, the Soviets simply \nnever admitted their existence and made no \nannouncement; and\n•\t beginning November 1963, the Soviet media \nbegan to give these stranded-in-Earth-orbit \nspacecraft “Kosmos” numbers.  So, the deep \nspace vehicle launched on 11 November 1963 \nthat reached Earth orbit but failed to leave for \ndeep space was simply given the “next” Kosmos \nnumber, in this case “21.” By giving it such a \nnondescript name (“Kosmos 21”), Soviet offi\xad\ncials sought to draw attention away from such \nfailures.  This practice was followed well into \nthe late 1980s.\n For both of these three types of missions, I have \nused the following convention:\n[Program, Spacecraft design designation, serial \nnumber]\nOR\nKosmos number [Program]\nI do not use terms such as “Marsnik 1” or “Mars \n1960A” (listed in the National Space Science \nData Center, for example, to denote the spacecraft \nlaunched on 10 October 1960).  Since the Soviets \nnever used such names, it would be entirely inac\xad\ncurate to ascribe such designations. ', 'So, the deep \nspace vehicle launched on 11 November 1963 \nthat reached Earth orbit but failed to leave for \ndeep space was simply given the “next” Kosmos \nnumber, in this case “21.” By giving it such a \nnondescript name (“Kosmos 21”), Soviet offi\xad\ncials sought to draw attention away from such \nfailures.  This practice was followed well into \nthe late 1980s.\n For both of these three types of missions, I have \nused the following convention:\n[Program, Spacecraft design designation, serial \nnumber]\nOR\nKosmos number [Program]\nI do not use terms such as “Marsnik 1” or “Mars \n1960A” (listed in the National Space Science \nData Center, for example, to denote the spacecraft \nlaunched on 10 October 1960).  Since the Soviets \nnever used such names, it would be entirely inac\xad\ncurate to ascribe such designations.  Such fictitious \nnames (such as “Sputnik 27”) unfortunately prolif\xad\nerate online but are Western inventions.\n Launch Sites\nFor Soviet and Russian launch sites, the following \nconventions apply:\n“Site A / B” implies that the probe was launched \nfrom Site A, Launch Unit B\nMission Goals\nThere are good reasons not to use terms such as \n“flyby” or “flight” since spacecraft do not fly.  As \none of the reviewers for this manuscript pointed \nout, these terms are remnants of the era of aero\xad\nnautics. ', 'During this mission, the third \nand fourth stages separated abnormally, and after \nreaching Earth orbit, ground control lost teleme\xad\ntry (at about 06:45:44 UT) from the Blok L upper \nstage designed to send the vehicle past the Moon. \n As a result, the spacecraft remained stranded in \nEarth orbit.  The stage’s main engine turbopump \nprobably exploded upon ignition destroying the \nspacecraft.  With this mission, the Soviets began \nthe practice of giving “Kosmos” designations to \nobscure the failure of lunar and planetary probes \nthat remained stranded in Earth orbit.  If the space\xad\ncraft had successfully departed from Earth orbit, it \nwould probably have been called “Zond 1.”\n']","
The Soviet Union assigned official names to their spacecraft using a specific convention. For missions that successfully reached Earth orbit and left for deep space, they used the format [Program, Spacecraft design designation, serial number]. For example, the spacecraft launched on 11 November 1963 that reached Earth orbit but failed to leave for deep space was given the ""next"" Kosmos number, in this case, ""21."" This practice was followed well into the late 1980s.

However, for missions that failed to reach Earth orbit or left Earth orbit but failed to leave for deep space, the Soviet Union never announced or acknowledged their existence until the late 1980s. In such cases, they adopted two strategies:

1. Between 1960 and 1963, the Soviets simply never admitted their existence and made no announcement.
2. Beginning November 1963, the Soviet media began to give these stranded-in-Earth-orbit spacecraft ""Kosmos"" numbers.

For example, the deep space vehicle launched on 11 November 1963 that reached Earth orbit but failed to leave for deep space was simply given the ""next"" Kosmos number, in this case, ""21."" By giving it such a nondescript name (""Kosmos 21""), Soviet officials sought to draw attention away from such failures.

Therefore, the Soviet Union did not use terms such as ""Marsnik 1"" or ""Mars 1960A"" to denote the spacecraft launched on 10 October 1960. Such fictitious names (such as ""Sputnik 27"") unfortunately proliferate online but are Western inventions."
What was the purpose of publishing the Hazards Due to Comets and Asteroids and what challenges did Tom Gehrels face during the process of editing the book?,"The purpose of publishing the Hazards Due to Comets and Asteroids was to provide a comprehensive answer, based on the latest research, to the question “What can be done if a dangerous object is identified?” The book was intended to strike a balance to keep the various strong opinions in check. However, during the process of editing the book, correspondence between the authors and Tom Gehrels, the editor, heated up, and accusations of bias toward one party or the other flew. When two papers—one by Sagan and Steve Ostro on the dangers of deflection and the other by Edward Teller and William Tedeschi proposing a detailed program of nuclear development and testing—were declined by their referees, Gehrels faced challenges in keeping the book balanced and fair.","['Worden’s goal was to forge an agreement between the \nastronomical community and Edward Teller and his colleagues—and he suc\xad\nceeded.  After lengthy negotiations, an agreed-upon joint statement was issued \nthat encouraged additional surveys and studies of NEOs, expressed a concern \nthat an atmospheric explosion of a bolide could be mistaken for a nuclear \nattack, and noted that the study of mitigation options should be continued. \n Although a unanimous agreement could not be reached on the use of standby \nmitigation systems (e.g., nuclear weapons), the meeting summary statement \nended with “Many of us believe that unless a specific and imminent threat \nbecomes obvious, actual construction and testing of systems that might have \nthe potential to deflect or mitigate a threat may be deferred because technol\xad\nogy systems will improve.”44\nFollowing the Erice meeting, the 1,200-page Hazards Due to Comets and \nAsteroids was published as the 24th volume of the Space Sciences Series, edited \nby Tom Gehrels.  The book was intended to provide a comprehensive answer, \nbased on the latest research, to the question “What can be done if a danger\xad\nous object is identified?” and Gehrels sought to strike a balance to keep the \nvarious strong opinions in check.  “At the early planning stage of the book, \nI was anxious to have a quorum,” he wrote to JPL’s Paul Weissman, one of \nthe chapter authors.45 Despite his initial optimism, the process was conten\xad\ntious.  When two papers—one by Sagan and Steve Ostro on the dangers of \ndeflection and the other by Edward Teller and William Tedeschi proposing \na detailed program of nuclear development and testing—were declined by \ntheir referees, correspondence between the authors and Gehrels heated up and \naccusations of bias toward one party or the other flew.  Gehrels got the volume \n44.\t ', 'Participants also discussed the use of \nnuclear explosions to deflect sub-kilometer near-Earth objects for which there \nwould be little warning.  Worden’s goal was to forge an agreement between the \nastronomical community and Edward Teller and his colleagues—and he suc\xad\nceeded.  After lengthy negotiations, an agreed-upon joint statement was issued \nthat encouraged additional surveys and studies of NEOs, expressed a concern \nthat an atmospheric explosion of a bolide could be mistaken for a nuclear \nattack, and noted that the study of mitigation options should be continued. \n Although a unanimous agreement could not be reached on the use of standby \nmitigation systems (e.g., nuclear weapons), the meeting summary statement \nended with “Many of us believe that unless a specific and imminent threat \nbecomes obvious, actual construction and testing of systems that might have \nthe potential to deflect or mitigate a threat may be deferred because technol\xad\nogy systems will improve.”44\nFollowing the Erice meeting, the 1,200-page Hazards Due to Comets and \nAsteroids was published as the 24th volume of the Space Sciences Series, edited \nby Tom Gehrels.  The book was intended to provide a comprehensive answer, \nbased on the latest research, to the question “What can be done if a danger\xad\nous object is identified?” and Gehrels sought to strike a balance to keep the \nvarious strong opinions in check.  “At the early planning stage of the book, \nI was anxious to have a quorum,” he wrote to JPL’s Paul Weissman, one of \nthe chapter authors.45 Despite his initial optimism, the process was conten\xad\ntious.  When two papers—one by Sagan and Steve Ostro on the dangers of \ndeflection and the other by Edward Teller and William Tedeschi proposing \na detailed program of nuclear development and testing—were declined by \ntheir referees, correspondence between the authors and Gehrels heated up and \naccusations of bias toward one party or the other flew. ', 'As soon as microcomput\xad\ners were put in play to handle the vast amount of imaging data that modern \nCCDs generate, the advantages of CCD detectors over photographic films \nwere apparent.  CCDs are far more sensitive (faster) than films; they are more \nlinear in their response to light levels; and they have a far wider spectral band\xad\nwidth than films.  The CCD revolution for near-Earth object discovery sur\xad\nveys began with Spacewatch.\n Spacewatch\nTom Gehrels, an immigrant from the Netherlands who had joined Gerard \nKuiper’s Lunar and Planetary Laboratory in 1961, had long been interested in \nasteroids, in particular looking for near-Earth asteroids.  He pioneered the pho\xad\ntometric study of asteroids during the 1950s.  In 1960, he joined with astrono\xad\nmers Cornelis Johannes van Houten and Ingrid van Houten-Groeneveld of \nthe Leiden Observatory to conduct the Palomar-Leiden Survey of dim minor \nplanets.11 Gehrels left the search for minor planets for a little over a decade \nto become the Principal Investigator (PI) of the Imaging Photopolarimeter \ninstruments on the Pioneer 10 and 11 missions to Jupiter and Saturn, respec\xad\ntively, but returned to the search again in the 1970s, extending the original \nPalomar-Leiden Survey with surveys to identify Trojan\xa0asteroids.12 \nThese surveys were done photographically, with Gehrels exposing plates \non the 1.2-meter (48-inch) Schmidt telescope on Mount Palomar and then \nshipping them to his collaborators at Leiden to be studied with a blink com\xad\nparator.  The resulting discoveries were then sent to the Minor Planet Center \nto have their orbits computed and be published in the Minor Planet Circular. \n', '213\nCHAPTER 8\nIMPACTS AS NATURAL HAZARDS\nIntroduction\nI\nf the late-20th- and early-21st-century research on small solar system bod\xad\nies undermined the old distinction between “asteroids” and “comets,” the \nfirst decade of the 21st century witnessed changing perceptions of the risk \nfrom near-Earth objects within the scientific community.  One event in par\xad\nticular—the discovery of 2004 MN4, a potentially hazardous 340-meter \nasteroid, generated public interest and led to rising demands for increased \nattention to what NASA’s Lindley Johnson had labeled “planetary defense.” \nIn the 2005 NASA budget authorization, Congress again asked for a study of \nNEO survey capabilities and of space missions to track and deflect hazard\xad\nous asteroids.1 This “Near-Earth Object Survey and Deflection Analysis of \nAlternatives” report was delivered in 2007, though new funds did not actually \narrive for the NEO program until 2010.2 By then, the active NEO surveys had \n1.\t\n National Aeronautics and Space Administration Authorization Act of 2005, PL 109-\n155, https://www.congress.gov/bill/109th-congress/senate-bill/1281/text (accessed 3\xa0 June \n2019).\n 2.\t\n', 'Chapter 5: Recognizing Cosmic Hazard\n109\nCosmic Catastrophes, by Clark Chapman and David Morrison, as well as the \nSpaceguard Survey report of 1992 (chaired by David Morrison).7\nThe Snowmass report introduced a number of important concepts (see \nbox 5-1).  Perhaps most significant was its recognition that early detection of \npotentially threatening objects is vital.  That is because numerous observations \nare necessary to determine orbits accurately, and if an object turns out to have \na very high impact likelihood, doing anything about it will require many \nyears of warning.8 Thus the report supported development of Tom Gehrels’s \nSpacewatch camera while also arguing that better survey technology would \n7.\t\n Clark R. Chapman and David Morrison, Cosmic Catastrophes (New York: Plenum \nPress, 1989); David Morrison, “The Spaceguard Survey: Report of the NASA \nInternational Near-Earth-Object Detection Workshop” (Moffett Field, CA: NASA \nAmes Research Center, 1992), http://ntrs.nasa.gov/search.jsp?R=19920025001 (accessed \n8\xa0March 2021).\n 8.\t\n Snowmass Report. ']","
The purpose of publishing the Hazards Due to Comets and Asteroids was to provide a comprehensive answer, based on the latest research, to the question 'What can be done if a dangerous object is identified?'. Tom Gehrels, the editor of the book, sought to strike a balance to keep the various strong opinions in check. However, the process of editing the book was contentious. When two papers, one by Sagan and Steve Ostro on the dangers of deflection and the other by Edward Teller and William Tedeschi proposing a detailed program of nuclear development and testing, were declined by their referees, correspondence between the authors and Gehrels heated up and accusations of bias toward one party or the other flew. Gehrels had to manage these challenges to get the volume published."
Question: What was the significance of the Altitude Wind Tunnel (AWT) in the development of jet propulsion technology in the United States during the immediate postwar period?,"The Altitude Wind Tunnel (AWT), formerly at the Glenn Research Center, was unrivaled in its capability to test full-scale engines in simulated altitude conditions. Although designed in the early 1940s to study piston engines, the facility was used from its first runs in February 1944 to support new turbojet technology. The Cleveland laboratory and the AWT produced a succession of turbojet advancements that resulted in a surge of thrust capabilities in the late 1940s and early 1950s. The AWT was dismantled in 2008. The AWT was significant in the development of jet propulsion technology in the United States during the immediate postwar period because it allowed for comprehensive testing of gas turbines and produced a succession of turbojet advancements that resulted in a surge of thrust capabilities in the late 1940s and early 1950s.","['No consideration was given to the field at \nall in the development of the facility.  The great potential significance of the \njet engine was enunciated by George Lewis in August 1943.100 Afterward, by \nMarch 1944, a complete transformation toward work on jet propulsion had \noccurred at the agency.101 Meanwhile, in October 1943, Kervork Nahigyan \nand his staff in the Static Laboratory built and tested the first afterburner, a \ndirect byproduct of the work on the burner for Jake’s Jeep.102\nAbe Silverstein and his group adapted the AWT to test jet engines and \nacquired hands-on experience in jet technology.  During the AWT facility’s \nfirst runs in February 1944, NACA researchers used the AWT to support \nnew turbojet technology, specifically the 1,600-pound-thrust GE I-16 turbojet \ninstalled in a complete Bell P-59 Airacomet fuselage.  The Cleveland labora\xad\ntory’s use of the AWT produced a succession of turbojet advancements that \nresulted in a surge of thrust capabilities in the late 1940s and early 1950s. \n In June 1944, Lockheed’s YP-80A Shooting Star became the first jet aircraft \ncompletely manufactured in the United States and the first U.S.  aircraft to \nfly faster than 500 mph.  The Altitude Wind Tunnel was used in the spring \nof 1945 to study the performance of the Shooting Star’s two 3,750-pound-\nthrust GE I-40 engines at high altitudes. ', 'Anselm \nFranz, the head of the company’s supercharger group.  The axial-flow compres\xad\nsor design consisted of an alternating series of rotating and stationary blades, \nwhere the overall flow path essentially moved along the axis of the engine.  The \n004 series powered the Messerschmitt Me 262A-1a Schwalbe (“Swallow”)—\nthe first practical jet airplane—that first flew on July 18, 1942.  Able to fly well \nover 500 mph, the Me 262 was a spectacular symbol of what jet aircraft could \nand would do over the next 50 years of flight.81The Altitude Wind Tunnel (AWT), formerly at the Glenn Research Center, was unrivaled in its capability to test full-scale engines in simulated altitude conditions.  Although designed in the early 1940s to study piston engines, the facility was used from its first runs in February 1944 to support new turbojet technology.  The Cleveland laboratory and the AWT produced a succession of turbojet advancements that resulted in a surge of thrust capabilities in the late 1940s and early 1950s.  The AWT was dismantled in 2008.\n\n', 'The Cleveland labora\xad\ntory’s use of the AWT produced a succession of turbojet advancements that \nresulted in a surge of thrust capabilities in the late 1940s and early 1950s. \n In June 1944, Lockheed’s YP-80A Shooting Star became the first jet aircraft \ncompletely manufactured in the United States and the first U.S.  aircraft to \nfly faster than 500 mph.  The Altitude Wind Tunnel was used in the spring \nof 1945 to study the performance of the Shooting Star’s two 3,750-pound-\nthrust GE I-40 engines at high altitudes.  An attempt to forecast thrust levels at \naltitude, based on sea-level measurements, was successful, and a performance \ncurve was created to predict the I-40’s thrust at all altitudes.  The production \nP-80 fighter with the I-40 engine proved a great success in the early days of \nthe U.S.  Air Force, spawning two important derivatives, the T-33 trainer and \nthe F-94 interceptor.103\nLewis was the only facility capable of testing gas turbines in a comprehensive \nmanner during the immediate postwar period. ', ""The \n004 series powered the Messerschmitt Me 262A-1a Schwalbe (“Swallow”)—\nthe first practical jet airplane—that first flew on July 18, 1942.  Able to fly well \nover 500 mph, the Me 262 was a spectacular symbol of what jet aircraft could \nand would do over the next 50 years of flight.81The Altitude Wind Tunnel (AWT), formerly at the Glenn Research Center, was unrivaled in its capability to test full-scale engines in simulated altitude conditions.  Although designed in the early 1940s to study piston engines, the facility was used from its first runs in February 1944 to support new turbojet technology.  The Cleveland laboratory and the AWT produced a succession of turbojet advancements that resulted in a surge of thrust capabilities in the late 1940s and early 1950s.  The AWT was dismantled in 2008.\n\n Lockheed's YP80A Shooting Star was the first jet aircraft completely manufactured in the United States and the first US aircraft to fly faster than 500 mph.  The Altitude Wind Tunnel was used in the spring of 1945 to study the performance of the Shooting Star's General Electric I-40 engines at high altitudes. "", 'Afterward, due to its failure to anticipate jet propulsion before 1941 and the \ndistraction of the failed Jacobs ducted fan during the critical early years of \nthe war, Arnold effectively took the NACA out of the leading edge of aircraft \npropulsion by giving GE the task of developing the Whittle engine.  Instead, \nthe NACA was given the task of testing already-developed engines from GE \nand Westinghouse in its Static Test Laboratory.99\nAll in all, the NACA’s Cleveland engine laboratory had a remarkable blind \neye when it came to jet propulsion.  No consideration was given to the field at \nall in the development of the facility.  The great potential significance of the \njet engine was enunciated by George Lewis in August 1943.100 Afterward, by \nMarch 1944, a complete transformation toward work on jet propulsion had \noccurred at the agency.101 Meanwhile, in October 1943, Kervork Nahigyan \nand his staff in the Static Laboratory built and tested the first afterburner, a \ndirect byproduct of the work on the burner for Jake’s Jeep.102\nAbe Silverstein and his group adapted the AWT to test jet engines and \nacquired hands-on experience in jet technology.  During the AWT facility’s \nfirst runs in February 1944, NACA researchers used the AWT to support \nnew turbojet technology, specifically the 1,600-pound-thrust GE I-16 turbojet \ninstalled in a complete Bell P-59 Airacomet fuselage.  The Cleveland labora\xad\ntory’s use of the AWT produced a succession of turbojet advancements that \nresulted in a surge of thrust capabilities in the late 1940s and early 1950s. \n In June 1944, Lockheed’s YP-80A Shooting Star became the first jet aircraft \ncompletely manufactured in the United States and the first U.S. ']","
The Altitude Wind Tunnel (AWT) played a significant role in the development of jet propulsion technology in the United States during the immediate postwar period. It was the only facility capable of testing gas turbines in a comprehensive manner during that time. NACA researchers at the facility built upon their experience to become the U.S. Government's experts in jet propulsion technology immediately after the war.

The AWT was used to study the performance of the Shooting Star's two 3,750-pound-thrust GE I-40 engines at high altitudes. An attempt to forecast thrust levels at altitude, based on sea-level measurements, was successful, and a performance curve was created to predict the I-40's thrust at all altitudes. This advancement was crucial as it led to the production of the P-80 fighter with the I-40 engine, which proved to be a great success in the early days of the U.S. Air Force, spawning two important derivatives, the T-33 trainer and the F-94 interceptor.

Therefore, the Altitude Wind Tunnel was instrumental in the development and testing of jet propulsion technology in the United States during the immediate postwar period, contributing to the success of early jet aircraft and the establishment of the U.S. as a leader in jet propulsion technology."
"What is the Discovery Program's approach to maximizing science return within the program cost cap, as opposed to looking for ""science per dollar""?","The Discovery Program's approach to maximizing science return within the program cost cap is a subtle but important distinction that drove proposal strategy. If Discovery was looking for ""science per dollar,"" proposers would likely underbid as a strategy, coming in with plenty of ""room to the cap."" Since room to the cost cap was ignored in most competitions in the first twenty years of the Discovery Program, this strategy, and the recommendation, could be set aside. The program continued to approach the process with the strategy of optimizing science return within the program cost cap instead.","['The second half of Recommendation 2 urged the correspondence of science priorities \nand science payload, which was the mechanism for fellow scientists and instrument \nbuilders to determine whether the proposing team had chosen appropriate instru\xad\nmentation for the mission so that the major questions in the investigation could be \nanswered.  (The remainder of the recommendation was satisfied by the tenets of the \nDiscovery Program: development time constraints and acceptable risk were always \ncriteria of selection.) \n Returning to the COMPLEX criteria, the question of whether the missions opti\xad\nmized science return for money spent was a hot debate in the early years of the first \ndecade of the twenty-first century in both Discovery and Explorer mission lines, par\xad\nticularly under the leadership of Paul Hertz, chief scientist in the Science Mission \nDirectorate and, later, head of the Astrophysics Division.  Hertz and others determined \nthat Discovery missions were explicitly not looking at “science per dollar,” but instead \nlooking to maximize science return within the Discovery cost cap.  This was a subtle but \nimportant distinction that drove proposal strategy.  If Discovery was looking for “sci\xad\nence per dollar,” proposers would likely underbid as a strategy, coming in with plenty \nof “room to the cap.” Since room to the cost cap was ignored in most competitions in \nthe first twenty years of the Discovery Program, this strategy, and the recommendation, \ncould be set aside.  The program continued to approach the process with the strategy \nof optimizing science return within the program cost cap instead. \n', 'Hertz and others determined \nthat Discovery missions were explicitly not looking at “science per dollar,” but instead \nlooking to maximize science return within the Discovery cost cap.  This was a subtle but \nimportant distinction that drove proposal strategy.  If Discovery was looking for “sci\xad\nence per dollar,” proposers would likely underbid as a strategy, coming in with plenty \nof “room to the cap.” Since room to the cost cap was ignored in most competitions in \nthe first twenty years of the Discovery Program, this strategy, and the recommendation, \ncould be set aside.  The program continued to approach the process with the strategy \nof optimizing science return within the program cost cap instead. \n The criterion that each mission should exhibit “compatibility between mission goals \nand scale” is interesting in the context of the time; MESSENGER had, at the time, been \nrecently selected by the Discovery Program, and it was touted as “a flagship-quality \nmission” in a Discovery box.4 The study was correct in foreseeing that an incompat\xad\nibility would cause the program all kinds of problems, including the delay of future \nAnnouncements of Opportunity, as will be shown later in this chapter.  However, that \ndid not stop the program from selecting the Kepler photometer the next year.\n The “balanced-risk strategy” became meaningless at about the time that the report \nwas issued, as the pendulum of NASA’s risk tolerance swung far to the cautious side \nwith the 1999 Mars mission failures and the subsequent NASA Integrated Action Team \n4 \t\n“Lab wins Discovery mission.” (1999, 9 July). ', 'Returning to the COMPLEX criteria, the question of whether the missions opti\xad\nmized science return for money spent was a hot debate in the early years of the first \ndecade of the twenty-first century in both Discovery and Explorer mission lines, par\xad\nticularly under the leadership of Paul Hertz, chief scientist in the Science Mission \nDirectorate and, later, head of the Astrophysics Division.  Hertz and others determined \nthat Discovery missions were explicitly not looking at “science per dollar,” but instead \nlooking to maximize science return within the Discovery cost cap.  This was a subtle but \nimportant distinction that drove proposal strategy.  If Discovery was looking for “sci\xad\nence per dollar,” proposers would likely underbid as a strategy, coming in with plenty \nof “room to the cap.” Since room to the cost cap was ignored in most competitions in \nthe first twenty years of the Discovery Program, this strategy, and the recommendation, \ncould be set aside.  The program continued to approach the process with the strategy \nof optimizing science return within the program cost cap instead. \n The criterion that each mission should exhibit “compatibility between mission goals \nand scale” is interesting in the context of the time; MESSENGER had, at the time, been \nrecently selected by the Discovery Program, and it was touted as “a flagship-quality \nmission” in a Discovery box.4 The study was correct in foreseeing that an incompat\xad\nibility would cause the program all kinds of problems, including the delay of future \nAnnouncements of Opportunity, as will be shown later in this chapter.  However, that \ndid not stop the program from selecting the Kepler photometer the next year.\n', 'NASA′s Discovery Program\nxvi\nThe creation of the New Frontiers mission line shows that, although the Discovery \nProgram was no longer particularly fast or cheap, it was very successful in producing \ninnovative and original proposals that maximized science return for focused planetary \nscience projects.  That success has continued.  Beginning in 2017, Discovery was also \nable to restore the selection of two proposals at a time, if not at the every-other-year \npace of the early years.  A new mission line may be needed for cheap and risky missions, \nsuch as the CubeSats that have been launched to Mars and the Moon recently, but, \nwithout a doubt, Discovery has been a groundbreaking program that has revolution\xad\nized the NASA planetary program and gives every indication that it will be around \nfor decades to come.\n', 'To get the critical science instrument on board, Krimigis cut a deal.  “I said, ‘Look, \nyou know that we are not likely to go much into the contingency,’ so I said, ‘If you \nincrease the program cost, if you put in five million, I’ll guarantee you that we’ll never \nuse five million of the contingency.’ He said, ‘Okay.’ That’s how the mass spectrometer \ngot on board the spacecraft.”81 It was a smart move, but the project had to remain \nmindful of the cost cap at all times, because the moment it was in danger of exceeding \nits proposed price tag, the mass spectrometer would have been descoped.\n “I always viewed myself as the guardian of the science, and that’s why I was insist\xad\ning, for example, that the mass spectrometer on CONTOUR stay on the payload—I \nmean, I understood the science,” said Krimigis.  “I really felt that the whole philosophy \nof the department was that we’re here to maximize the science.”82\nSaving money on a kick stage was one way to ensure that the mission would achieve \na maximal amount of science return.  The STAR30-BP Thiokol motor was a known \nquantity at selection, having been used routinely in space missions since its introduction \n78 \t\nIbid.\n 79 \t\nNiebur, S.  (2009, 27 September). ']","
The Discovery Program's approach to maximizing science return within the program cost cap involves optimizing science return without focusing on the cost per unit of science. This strategy is different from looking for ""science per dollar,"" which would encourage proposers to underbid and leave room to the cost cap. The Discovery Program has historically ignored this room to the cost cap and instead focuses on maximizing science return within the program cost cap. This approach has been maintained since the early years of the first decade of the twenty-first century, even under the leadership of Paul Hertz, chief scientist in the Science Mission Directorate and, later, head of the Astrophysics Division."
